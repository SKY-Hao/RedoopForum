/*
Navicat MySQL Data Transfer

Source Server         : localhost_3306
Source Server Version : 50721
Source Host           : localhost:3306
Source Database       : redoopbbs

Target Server Type    : MYSQL
Target Server Version : 50721
File Encoding         : 65001

Date: 2019-03-21 11:32:56
*/

SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for tbl_action
-- ----------------------------
DROP TABLE IF EXISTS `tbl_action`;
CREATE TABLE `tbl_action` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `name` varchar(50) DEFAULT NULL,
  `log` varchar(255) DEFAULT NULL,
  `status` int(11) DEFAULT '0' COMMENT '状态，0正常，1禁用',
  `update_time` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `name` (`name`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=10004 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_action
-- ----------------------------
INSERT INTO `tbl_action` VALUES ('1', '2017-11-27 17:24:32', '会员注册', '注册了账号', '0', '2018-04-19 11:21:08');
INSERT INTO `tbl_action` VALUES ('2', '2017-11-27 17:24:32', '会员登录', '登录了账号', '0', '2018-04-19 11:21:12');
INSERT INTO `tbl_action` VALUES ('3', '2017-11-27 17:24:32', '修改密码', '修改了密码', '0', '2018-04-19 11:21:15');
INSERT INTO `tbl_action` VALUES ('4', '2017-11-27 17:24:32', '找回密码', '找回了密码', '0', '2018-04-19 11:21:19');
INSERT INTO `tbl_action` VALUES ('5', '2017-11-27 17:24:32', '登录失败', '登录失败', '0', '2018-04-19 11:21:22');
INSERT INTO `tbl_action` VALUES ('3001', '2017-11-27 17:24:32', '删除微博', '删除了微博', '1', '2018-03-01 17:00:45');
INSERT INTO `tbl_action` VALUES ('3002', '2017-11-27 17:24:32', '删除微博评论', '删除了微博评论', '1', '2018-03-01 17:00:27');
INSERT INTO `tbl_action` VALUES ('3003', '2017-11-27 17:24:32', '删除群组', '删除了主题', '0', '2018-04-19 11:22:00');
INSERT INTO `tbl_action` VALUES ('3004', '2017-11-27 17:24:32', '删除群组帖子', '删除了主题帖子', '0', '2018-04-19 11:22:13');
INSERT INTO `tbl_action` VALUES ('3005', '2017-11-27 17:24:32', '删除群组帖子评论', '删除了帖子评论', '0', '2018-04-19 11:21:26');
INSERT INTO `tbl_action` VALUES ('3006', '2017-11-27 17:24:32', '删除文章', '删除文档\n', '0', '2018-04-19 11:22:22');
INSERT INTO `tbl_action` VALUES ('3007', '2017-11-27 17:24:32', '删除文章评论', '删除了文档评论', '0', '2018-04-19 11:22:29');
INSERT INTO `tbl_action` VALUES ('10001', '2017-11-27 17:24:32', '发布微博', '发布了微博', '1', '2018-03-01 17:01:35');
INSERT INTO `tbl_action` VALUES ('10002', '2017-11-27 17:24:32', '群组发帖', '发布了主题帖子', '0', '2018-04-19 11:22:35');
INSERT INTO `tbl_action` VALUES ('10003', '2017-11-27 17:24:32', '发布文章', '发布文档', '0', '2018-04-19 11:22:41');

-- ----------------------------
-- Table structure for tbl_action_log
-- ----------------------------
DROP TABLE IF EXISTS `tbl_action_log`;
CREATE TABLE `tbl_action_log` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `member_id` int(11) DEFAULT NULL,
  `action_id` int(11) DEFAULT NULL,
  `remark` varchar(1000) DEFAULT NULL,
  `type` tinyint(2) DEFAULT '0',
  `foreign_id` int(11) DEFAULT '0',
  `action_ip` varchar(15) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `fk_action_log_member` (`member_id`) USING BTREE,
  KEY `fk_action_log_action` (`action_id`) USING BTREE,
  CONSTRAINT `tbl_action_log_ibfk_1` FOREIGN KEY (`action_id`) REFERENCES `tbl_action` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_action_log_ibfk_2` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=610 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_action_log
-- ----------------------------
INSERT INTO `tbl_action_log` VALUES ('95', '2017-12-01 17:08:06', null, '5', '登录用户名：admin，登录密码：RedoopAdmin123oopadmin', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('96', '2017-12-01 17:08:15', null, '5', '登录用户名：admin，登录密码：RedoopAdmin123', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('100', '2017-12-01 19:50:14', null, '5', '登录用户名：admin，登录密码：RedoopAdmin123', '0', '0', '111.198.230.217');
INSERT INTO `tbl_action_log` VALUES ('101', '2017-12-01 19:50:19', '1', '2', '', '0', '0', '111.198.230.217');
INSERT INTO `tbl_action_log` VALUES ('104', '2017-12-01 21:43:05', null, '5', '登录用户名：admin，登录密码：RedoopAdmin123', '0', '0', '111.198.230.217');
INSERT INTO `tbl_action_log` VALUES ('105', '2017-12-01 21:43:14', '1', '2', '', '0', '0', '111.198.230.217');
INSERT INTO `tbl_action_log` VALUES ('106', '2017-12-01 21:43:25', '1', '3006', 'ID：4，标题：这是一个测试的文章', '0', '0', '111.198.230.217');
INSERT INTO `tbl_action_log` VALUES ('110', '2017-12-05 10:25:26', null, '5', '登录用户名：admin，登录密码：Redoop123', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('111', '2017-12-05 14:57:16', null, '5', '登录用户名：amdin，登录密码：redoopadmin', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('112', '2017-12-05 14:58:15', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('113', '2017-12-05 15:09:02', null, '5', '登录用户名：admin，登录密码：RedoopAdmin123', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('114', '2017-12-05 15:09:07', null, '5', '登录用户名：admin，登录密码：REDOOPADMIN', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('115', '2017-12-05 15:09:13', null, '5', '登录用户名：admin，登录密码：REDOOPADMIN', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('116', '2017-12-05 15:09:21', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('118', '2017-12-05 15:38:36', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('119', '2017-12-05 16:17:46', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('120', '2017-12-07 15:51:26', null, '5', '登录用户名：admin，登录密码：RedoopAdmin123', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('121', '2017-12-07 15:51:32', null, '5', '登录用户名：admin，登录密码：admin', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('122', '2017-12-07 16:49:30', null, '5', '登录用户名：admin，登录密码：admin', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('123', '2017-12-08 09:37:16', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('124', '2017-12-08 09:43:26', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('125', '2017-12-08 11:34:25', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('126', '2017-12-08 15:08:44', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('127', '2017-12-08 15:08:58', '1', '3006', 'ID：5，标题：深度学习大数据行业版本', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('128', '2017-12-08 15:11:21', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('133', '2017-12-08 15:16:04', null, '5', '登录用户名：admin，登录密码：redoopadmined', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('134', '2017-12-08 15:20:55', '7', '1', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('135', '2017-12-08 15:21:12', '7', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('138', '2017-12-08 15:26:41', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('139', '2017-12-08 15:27:10', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('140', '2017-12-08 15:47:31', null, '5', '登录用户名：haowenju，登录密码：redoopadmin', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('141', '2017-12-08 15:47:35', '7', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('143', '2017-12-08 15:52:47', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('144', '2017-12-08 15:58:06', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('145', '2017-12-08 15:58:33', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('146', '2017-12-08 16:02:20', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('147', '2017-12-08 16:12:20', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('148', '2017-12-08 16:18:09', '1', '2', '', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('149', '2017-12-12 13:37:07', null, '5', '登录用户名：haowenju，登录密码：redoopadmin', '0', '0', '223.223.188.66');
INSERT INTO `tbl_action_log` VALUES ('150', '2018-03-02 09:05:56', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('151', '2018-03-02 10:09:58', null, '5', '登录用户名：huangtianhao，登录密码：huangtianhao', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('152', '2018-03-02 10:10:56', '22', '4', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('153', '2018-03-02 10:11:08', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('154', '2018-03-02 14:25:27', '24', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('155', '2018-03-02 15:59:02', '19', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('156', '2018-03-02 16:00:30', '19', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('157', '2018-03-02 17:16:32', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('158', '2018-03-02 17:23:21', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('159', '2018-03-02 17:26:14', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('160', '2018-03-04 05:29:02', '28', '1', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('161', '2018-03-04 05:30:30', '28', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('162', '2018-03-05 10:38:59', '19', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('163', '2018-03-06 09:12:07', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('164', '2018-03-06 14:49:33', '29', '1', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('165', '2018-03-06 14:49:45', '29', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('166', '2018-03-07 09:28:50', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('167', '2018-03-07 11:47:15', '13', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('168', '2018-03-07 14:32:38', '23', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('169', '2018-03-07 15:45:48', '30', '1', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('170', '2018-03-07 15:45:57', '30', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('171', '2018-03-07 19:19:10', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('172', '2018-03-08 08:53:19', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('173', '2018-03-08 09:15:52', '14', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('174', '2018-03-08 16:33:47', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('175', '2018-03-09 08:55:02', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('176', '2018-03-09 09:08:05', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('177', '2018-03-09 14:31:16', '24', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('178', '2018-03-09 15:39:11', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('179', '2018-03-10 08:45:29', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('180', '2018-03-10 11:21:25', null, '5', '登录用户名：mazeteng@redoop.com，登录密码：maeteng157', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('181', '2018-03-10 11:21:31', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('182', '2018-03-10 16:30:01', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('183', '2018-03-10 18:42:41', '8', '3003', 'ID：6，名字：SPACEP', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('184', '2018-03-10 18:43:36', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('185', '2018-03-10 18:43:56', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('186', '2018-03-12 08:52:52', null, '5', '登录用户名：zhangxing@redoop，登录密码：zhangxing163', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('187', '2018-03-12 08:53:01', null, '5', '登录用户名：zhangxing@redoop，登录密码：rdoop163', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('188', '2018-03-12 08:53:47', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('189', '2018-03-12 09:03:52', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('190', '2018-03-12 09:31:08', '13', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('191', '2018-03-12 17:12:18', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('192', '2018-03-12 17:12:33', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('193', '2018-03-13 10:33:41', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('194', '2018-03-13 10:34:26', '24', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('195', '2018-03-13 10:49:25', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('196', '2018-03-13 16:11:25', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('197', '2018-03-14 08:48:00', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('198', '2018-03-14 13:45:16', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('199', '2018-03-14 16:20:02', '31', '1', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('200', '2018-03-14 16:20:10', '31', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('201', '2018-03-15 10:41:45', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('202', '2018-03-16 09:18:26', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('203', '2018-03-16 10:29:27', '24', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('204', '2018-03-16 13:50:00', '32', '1', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('205', '2018-03-16 13:50:10', '32', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('206', '2018-03-19 08:50:04', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('207', '2018-03-20 11:34:09', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('208', '2018-03-20 18:52:28', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('209', '2018-03-20 21:23:50', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('210', '2018-03-21 08:58:13', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('211', '2018-03-21 15:09:06', null, '5', '登录用户名：zhaoshuai@redoop.com，登录密码：zs4253687', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('212', '2018-03-21 15:09:16', '18', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('213', '2018-03-21 15:37:23', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('214', '2018-03-21 18:53:55', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('215', '2018-03-21 19:25:51', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('216', '2018-03-22 09:11:13', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('217', '2018-03-22 10:57:35', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('218', '2018-03-22 14:01:15', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('219', '2018-03-22 14:22:46', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('220', '2018-03-23 08:36:13', '18', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('221', '2018-03-23 08:58:41', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('222', '2018-03-23 15:40:47', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('223', '2018-03-23 17:01:07', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('224', '2018-03-25 17:47:44', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('225', '2018-03-25 21:29:09', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('226', '2018-03-25 21:32:30', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('227', '2018-03-26 08:56:49', '26', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('228', '2018-03-26 09:02:55', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('229', '2018-03-26 18:41:04', '11', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('230', '2018-03-27 09:52:28', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('231', '2018-03-27 10:01:41', '19', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('232', '2018-03-28 09:02:43', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('233', '2018-03-28 09:40:04', '19', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('234', '2018-03-29 09:26:09', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('235', '2018-03-29 09:51:31', '26', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('236', '2018-03-29 11:30:32', '24', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('237', '2018-03-29 13:58:04', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('238', '2018-03-29 14:04:07', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('239', '2018-03-29 14:06:34', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('240', '2018-03-29 14:09:21', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('241', '2018-03-29 14:09:32', null, '5', '登录用户名：huangtianaho，登录密码：huangtianhao', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('242', '2018-03-29 14:09:37', null, '5', '登录用户名：huangtianaho，登录密码：huangtianhao', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('243', '2018-03-29 14:09:41', null, '5', '登录用户名：huangtianaho，登录密码：hth19940511', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('244', '2018-03-29 14:09:47', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('245', '2018-03-29 14:10:40', null, '5', '登录用户名：huangtianhao，登录密码：redoopadmin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('246', '2018-03-29 14:10:46', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('247', '2018-03-29 14:11:00', '1', '3', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('248', '2018-03-29 14:11:16', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('249', '2018-03-29 14:11:26', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('250', '2018-03-29 14:33:06', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('251', '2018-03-29 14:56:37', '24', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('252', '2018-03-30 08:47:48', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('253', '2018-03-30 15:56:02', '16', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('254', '2018-03-30 16:06:36', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('255', '2018-03-30 17:09:32', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('256', '2018-03-30 17:09:34', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('257', '2018-03-30 17:10:09', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('258', '2018-04-03 09:30:48', '16', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('259', '2018-04-03 09:54:24', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('260', '2018-04-03 16:58:37', '16', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('261', '2018-04-04 09:09:18', '15', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('262', '2018-04-04 14:48:17', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('263', '2018-04-04 16:22:37', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('264', '2018-04-04 16:25:02', null, '5', '登录用户名：huangtianhao@redoop.com，登录密码：huangtianhao', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('265', '2018-04-04 16:25:06', null, '5', '登录用户名：huangtianhao@redoop.com，登录密码：hth19940511', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('266', '2018-04-04 16:25:11', null, '5', '登录用户名：huangtianhao，登录密码：hth19940511', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('267', '2018-04-04 16:25:15', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('268', '2018-04-04 16:27:29', '22', '10003', '', '1', '48', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('269', '2018-04-04 16:27:48', '22', '3004', 'ID：48，标题：测试', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('270', '2018-04-04 16:32:54', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('271', '2018-04-06 14:08:49', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('272', '2018-04-06 14:16:08', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('273', '2018-04-08 09:19:32', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('274', '2018-04-08 10:38:22', '19', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('275', '2018-04-08 10:56:24', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('276', '2018-04-08 15:17:00', '16', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('277', '2018-04-09 08:34:56', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('278', '2018-04-09 10:31:12', null, '5', '登录用户名：haowenju@redoop.com，登录密码：6996ilove', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('279', '2018-04-09 10:31:17', null, '5', '登录用户名：haowenju，登录密码：6996ilove', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('280', '2018-04-09 10:31:23', null, '5', '登录用户名：haowenju，登录密码：admin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('281', '2018-04-09 11:07:49', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('282', '2018-04-09 11:07:52', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('283', '2018-04-09 11:08:39', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('284', '2018-04-09 11:34:48', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('285', '2018-04-09 13:42:48', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('286', '2018-04-11 09:17:42', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('287', '2018-04-11 09:19:15', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('288', '2018-04-11 09:21:35', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('289', '2018-04-11 10:34:55', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('290', '2018-04-11 10:35:11', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('291', '2018-04-11 11:37:08', null, '5', '登录用户名：a，登录密码：redoopadmin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('292', '2018-04-11 11:37:10', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('293', '2018-04-11 12:32:24', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('294', '2018-04-11 12:45:41', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('295', '2018-04-11 13:54:13', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('296', '2018-04-12 08:57:21', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('297', '2018-04-12 10:23:21', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('299', '2018-04-12 11:40:45', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('300', '2018-04-12 17:04:24', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('301', '2018-04-13 09:25:50', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('302', '2018-04-13 11:17:42', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('303', '2018-04-13 13:49:44', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('304', '2018-04-13 20:59:51', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('305', '2018-04-13 20:59:59', '1', '3006', 'ID：1，标题：测试hive', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('307', '2018-04-13 21:08:57', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('308', '2018-04-13 21:14:39', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('309', '2018-04-15 12:19:28', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('310', '2018-04-16 08:24:55', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('311', '2018-04-16 11:44:50', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('312', '2018-04-16 13:02:03', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('313', '2018-04-16 14:45:24', '25', '10002', '', '4', '48', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('314', '2018-04-16 14:51:04', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('315', '2018-04-16 16:25:16', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('316', '2018-04-16 16:48:08', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('317', '2018-04-16 17:19:39', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('318', '2018-04-18 14:50:04', null, '5', '登录用户名：admin，登录密码：admin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('319', '2018-04-18 14:50:24', null, '5', '登录用户名：admin，登录密码：admin123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('320', '2018-04-18 14:53:45', null, '5', '登录用户名：admin，登录密码：RedoopAdmin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('321', '2018-04-18 14:53:55', null, '5', '登录用户名：admin，登录密码：RedoopAdmin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('322', '2018-04-18 14:54:06', null, '5', '登录用户名：admin，登录密码：redopadmin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('323', '2018-04-18 14:54:15', null, '5', '登录用户名：admin，登录密码：RedoopAdmin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('324', '2018-04-18 14:54:59', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('325', '2018-04-18 14:59:22', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('326', '2018-04-19 11:17:33', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('329', '2018-04-20 17:13:37', null, '5', '登录用户名：huangtianhao，登录密码：redoopadmin', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('330', '2018-04-20 17:13:42', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('331', '2018-04-20 17:16:02', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('332', '2018-04-20 17:16:12', '1', '3006', 'ID：4，标题：SupersetMySQL视图展现', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('333', '2018-04-20 17:18:28', '22', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('334', '2018-04-20 17:30:35', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('335', '2018-04-20 17:40:58', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('336', '2018-04-20 17:41:03', '1', '3006', 'ID：3，标题：Nifi功能列表', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('337', '2018-04-20 19:05:56', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('338', '2018-04-23 09:12:41', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('339', '2018-04-24 11:31:52', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('340', '2018-04-24 11:33:46', '25', '10002', '', '4', '49', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('341', '2018-04-24 13:15:28', '13', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('342', '2018-04-24 13:16:00', '13', '10002', '', '4', '50', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('343', '2018-04-25 08:49:01', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('344', '2018-04-25 08:49:43', null, '5', '登录用户名：haowenju@redoop.com，登录密码：6996ilove', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('345', '2018-04-25 08:49:48', null, '5', '登录用户名：haowenju，登录密码：6996ilove', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('346', '2018-04-25 08:49:53', null, '5', '登录用户名：haowenju，登录密码：redoop123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('347', '2018-04-25 08:50:45', '7', '4', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('348', '2018-04-25 08:50:57', '7', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('349', '2018-04-25 13:44:30', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('350', '2018-04-25 13:56:03', '25', '10002', '', '4', '51', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('351', '2018-04-27 11:21:27', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('352', '2018-04-27 11:30:09', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('353', '2018-04-27 14:16:45', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('355', '2018-04-27 14:17:47', '1', '3006', 'ID：1，标题：a', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('356', '2018-04-27 14:31:36', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('358', '2018-04-27 14:31:57', '1', '3006', 'ID：2，标题：q', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('359', '2018-04-27 15:50:29', '25', '10003', '', '1', '3', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('360', '2018-04-28 09:26:11', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('361', '2018-04-28 14:51:14', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('362', '2018-04-28 15:34:03', '25', '10002', '', '4', '52', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('363', '2018-04-28 16:15:35', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('364', '2018-04-28 16:19:42', '14', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('365', '2018-04-28 16:24:11', '14', '10003', '', '1', '4', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('366', '2018-04-28 17:14:42', '13', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('367', '2018-04-28 17:15:41', '13', '10003', '', '1', '5', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('368', '2018-04-28 17:40:29', '13', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('369', '2018-04-28 18:47:39', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('370', '2018-04-29 22:14:23', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('371', '2018-04-29 22:14:57', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('372', '2018-04-30 10:40:50', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('373', '2018-05-02 08:59:53', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('374', '2018-05-02 11:09:30', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('375', '2018-05-03 08:49:42', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('376', '2018-05-08 10:08:04', '13', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('377', '2018-05-09 14:15:56', '13', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('378', '2018-05-09 14:18:49', '13', '10002', '', '4', '53', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('379', '2018-05-17 16:19:20', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('380', '2018-05-21 11:19:56', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('381', '2018-05-21 14:44:36', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('382', '2018-05-21 14:44:37', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('383', '2018-05-21 14:44:37', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('384', '2018-05-21 14:44:37', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('385', '2018-05-21 14:44:37', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('386', '2018-05-21 14:44:37', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('387', '2018-05-21 14:44:38', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('388', '2018-05-21 14:44:38', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('389', '2018-05-21 14:44:38', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('390', '2018-05-21 14:44:38', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('391', '2018-05-21 14:44:38', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('392', '2018-05-21 14:44:38', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('393', '2018-05-21 14:44:39', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('394', '2018-05-21 14:44:39', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('395', '2018-05-21 14:44:39', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('396', '2018-05-21 14:44:39', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('397', '2018-05-21 14:44:39', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('398', '2018-05-21 14:44:39', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('399', '2018-05-21 14:44:39', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('400', '2018-05-21 14:44:39', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('401', '2018-05-21 14:44:40', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('402', '2018-05-21 14:44:40', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('403', '2018-05-21 14:44:40', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('404', '2018-05-21 14:44:40', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('405', '2018-05-21 14:44:40', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('406', '2018-05-21 14:44:41', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('407', '2018-05-21 14:44:41', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('408', '2018-05-21 14:44:41', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('409', '2018-05-21 14:44:41', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('410', '2018-05-21 14:44:41', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('411', '2018-05-21 14:44:42', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('412', '2018-05-21 14:44:42', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('413', '2018-05-21 14:44:42', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('414', '2018-05-21 14:44:42', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('415', '2018-05-21 14:44:42', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('416', '2018-05-21 14:44:42', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('417', '2018-05-21 14:44:42', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('418', '2018-05-21 14:44:43', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('419', '2018-05-21 14:44:43', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('420', '2018-05-21 14:44:43', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('421', '2018-05-21 14:44:43', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('422', '2018-05-21 14:44:43', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('423', '2018-05-21 14:44:43', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('424', '2018-05-21 14:44:43', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('425', '2018-05-21 14:44:43', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('426', '2018-05-21 14:44:44', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('427', '2018-05-21 14:44:44', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('428', '2018-05-21 14:44:44', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('429', '2018-05-21 14:44:44', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('430', '2018-05-21 14:44:44', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('431', '2018-05-21 14:44:44', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('432', '2018-05-21 14:44:44', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('433', '2018-05-21 14:44:45', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('434', '2018-05-21 14:44:45', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('435', '2018-05-21 14:44:45', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('436', '2018-05-21 14:44:45', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('437', '2018-05-21 14:44:45', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('438', '2018-05-21 14:44:46', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('439', '2018-05-21 14:44:46', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('440', '2018-05-21 14:44:46', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('441', '2018-05-21 14:44:46', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('442', '2018-05-21 14:44:46', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('443', '2018-05-21 14:44:46', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('444', '2018-05-21 14:44:59', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('445', '2018-05-21 14:45:00', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('446', '2018-05-21 14:45:00', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('447', '2018-05-21 14:45:00', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('448', '2018-05-21 14:45:00', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('449', '2018-05-21 14:45:00', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('450', '2018-05-21 14:45:00', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('451', '2018-05-21 14:45:01', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('452', '2018-05-21 14:45:01', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('453', '2018-05-21 14:45:01', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('454', '2018-05-21 14:45:01', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('455', '2018-05-21 14:45:01', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('456', '2018-05-21 14:45:01', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('457', '2018-05-21 14:45:01', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('458', '2018-05-21 14:45:02', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('459', '2018-05-21 14:45:02', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('460', '2018-05-21 14:45:02', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('461', '2018-05-21 14:45:02', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('462', '2018-05-21 14:45:03', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('463', '2018-05-21 14:45:03', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('464', '2018-05-21 14:45:03', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('465', '2018-05-21 14:45:03', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('466', '2018-05-21 14:45:03', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('467', '2018-05-21 14:45:03', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('468', '2018-05-21 14:45:04', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('469', '2018-05-21 14:45:04', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('470', '2018-05-21 14:45:04', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('471', '2018-05-21 14:45:04', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('472', '2018-05-21 14:45:04', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('473', '2018-05-21 14:45:04', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('474', '2018-05-21 14:45:05', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('475', '2018-05-21 14:45:05', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('476', '2018-05-21 14:45:05', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('477', '2018-05-21 14:45:05', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('478', '2018-05-21 14:45:05', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('479', '2018-05-21 14:45:06', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('480', '2018-05-21 14:45:06', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('481', '2018-05-21 14:45:06', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('482', '2018-05-21 14:45:06', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('483', '2018-05-21 14:45:06', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('484', '2018-05-21 14:45:06', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('485', '2018-05-21 14:45:07', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('486', '2018-05-21 14:45:07', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('487', '2018-05-21 14:45:07', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('488', '2018-05-21 14:45:13', null, '5', '登录用户名：system，登录密码：123', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('489', '2018-05-21 15:33:12', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('490', '2018-05-28 10:34:50', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('491', '2018-05-28 15:12:01', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('492', '2018-05-28 16:07:10', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('493', '2018-05-31 11:30:37', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('494', '2018-06-01 09:37:25', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('495', '2018-06-01 10:22:28', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('496', '2018-06-05 14:41:39', '24', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('497', '2018-06-05 15:09:55', '24', '10002', '', '4', '54', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('498', '2018-06-08 13:54:20', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('499', '2018-06-09 18:22:47', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('500', '2018-06-09 18:23:50', '8', '10002', '', '4', '55', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('501', '2018-06-10 16:24:42', '8', '10002', '', '4', '56', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('502', '2018-06-12 09:11:48', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('503', '2018-06-12 10:43:44', '24', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('504', '2018-06-13 18:06:31', '8', '10002', '', '4', '57', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('505', '2018-06-22 10:17:33', '25', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('506', '2018-06-25 10:12:45', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('507', '2018-07-04 14:12:00', '19', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('508', '2018-07-11 15:45:07', '18', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('509', '2018-07-18 16:58:29', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('510', '2018-07-19 18:49:37', '8', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('511', '2018-07-24 15:54:35', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('512', '2018-07-26 14:41:02', '1', '2', '', '0', '0', '127.0.0.1');
INSERT INTO `tbl_action_log` VALUES ('513', '2018-08-22 17:23:22', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('514', '2018-09-04 10:23:49', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('515', '2018-09-04 10:23:57', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('516', '2018-09-04 10:24:06', null, '5', '登录用户名：huangtianhao@redoop.com，登录密码：hth19940511', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('517', '2018-09-04 10:24:32', null, '5', '登录用户名：hth_swp@163.com，登录密码：hth19940511', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('518', '2018-09-04 10:24:37', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('519', '2018-09-04 10:24:52', null, '5', '登录用户名：HTH_SWP@163.com，登录密码：hth19940511', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('520', '2018-09-04 10:24:59', '22', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('521', '2018-09-04 16:39:48', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('522', '2018-09-13 19:25:02', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('523', '2018-09-13 19:36:07', '8', '10002', '', '4', '58', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('524', '2018-09-20 13:47:28', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('525', '2018-09-20 13:49:16', '8', '10002', '', '4', '59', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('526', '2018-09-26 15:19:35', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('527', '2018-09-26 18:31:23', '33', '1', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('528', '2018-09-26 18:31:29', '33', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('529', '2018-09-28 10:04:33', '25', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('530', '2018-09-28 10:30:05', '25', '10002', '', '4', '60', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('531', '2018-10-11 14:42:58', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('532', '2018-10-17 11:49:50', '18', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('533', '2018-10-23 10:06:37', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('534', '2018-10-26 12:57:07', '25', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('535', '2018-11-02 11:10:50', null, '5', '登录用户名：526107212@qq.com，登录密码：Iou52427', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('536', '2018-11-02 11:11:09', '34', '1', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('537', '2018-11-02 11:11:19', '34', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('538', '2018-11-30 18:40:33', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('539', '2018-11-30 18:41:16', '8', '10002', '', '4', '61', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('540', '2018-12-05 11:06:44', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('542', '2018-12-05 11:07:47', '1', '3006', 'ID：6，标题：红象云腾生态新动态', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('543', '2018-12-11 18:17:32', null, '5', '登录用户名：admin，登录密码：admin', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('544', '2018-12-11 18:17:35', null, '5', '登录用户名：admin，登录密码：redoop123', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('545', '2018-12-11 18:17:38', null, '5', '登录用户名：admin，登录密码：redoop', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('546', '2018-12-11 18:17:43', null, '5', '登录用户名：admin，登录密码：Redoop', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('547', '2018-12-11 18:17:47', null, '5', '登录用户名：admin，登录密码：Redoop123', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('548', '2018-12-11 18:17:54', null, '5', '登录用户名：admin，登录密码：RedoopAdmin', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('549', '2018-12-11 18:22:56', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('550', '2019-01-03 13:37:45', '25', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('551', '2019-01-03 13:37:49', '25', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('552', '2019-01-03 13:58:34', '25', '10002', '', '4', '62', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('553', '2019-01-05 19:32:26', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('554', '2019-01-05 19:34:25', '8', '10002', '', '4', '63', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('555', '2019-01-05 21:18:16', '8', '10002', '', '4', '64', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('556', '2019-01-06 20:05:47', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('557', '2019-01-09 15:06:34', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('558', '2019-01-09 15:12:03', '22', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('560', '2019-01-09 15:18:38', '22', '3004', 'ID：65，标题：SeasBase使用', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('561', '2019-01-09 22:20:33', '8', '10002', '', '4', '66', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('562', '2019-01-09 22:53:26', '8', '10002', '', '4', '67', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('563', '2019-01-10 04:30:51', '8', '10002', '', '4', '68', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('564', '2019-01-10 12:09:00', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('565', '2019-01-14 17:01:47', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('566', '2019-01-15 11:03:12', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('567', '2019-01-15 17:14:43', '22', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('568', '2019-01-16 00:30:12', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('569', '2019-01-16 15:17:07', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('570', '2019-01-19 15:44:01', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('571', '2019-01-19 15:51:30', '8', '10002', '', '4', '69', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('572', '2019-01-24 13:54:58', '8', '10002', '', '4', '70', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('573', '2019-01-24 16:54:57', '8', '10002', '', '4', '71', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('574', '2019-01-24 17:43:46', '8', '10002', '', '4', '72', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('575', '2019-01-24 17:53:40', '8', '10002', '', '4', '73', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('576', '2019-01-24 22:35:58', '8', '10002', '', '4', '74', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('577', '2019-01-24 23:10:41', '8', '10002', '', '4', '75', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('578', '2019-01-27 13:26:00', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('579', '2019-02-11 19:36:57', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('580', '2019-02-11 19:38:05', '8', '10002', '', '4', '76', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('581', '2019-02-12 18:42:38', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('582', '2019-02-12 18:44:34', '8', '3003', 'ID：9，名字：Mobile', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('583', '2019-02-12 18:47:23', '8', '10002', '', '4', '77', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('584', '2019-02-18 13:20:38', '1', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('585', '2019-02-19 14:03:38', '25', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('586', '2019-02-19 16:18:02', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('587', '2019-02-19 18:04:17', '8', '10002', '', '4', '78', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('588', '2019-02-20 01:01:46', '8', '10002', '', '4', '79', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('589', '2019-02-20 10:59:05', null, '5', '登录用户名：tongxiaojun@redoop.com，登录密码：RedOop134', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('590', '2019-02-20 10:59:14', null, '5', '登录用户名：tongxiaojun@redoop.com，登录密码：158820', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('591', '2019-02-20 10:59:22', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('592', '2019-02-20 13:01:54', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('593', '2019-02-21 23:45:53', '8', '2', '', '0', '0', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('594', '2019-02-22 00:01:56', '8', '10002', '', '4', '80', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('595', '2019-02-22 00:29:35', '8', '10002', '', '4', '81', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('596', '2019-02-22 00:33:37', '8', '10002', '', '4', '82', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('597', '2019-02-22 00:35:42', '8', '10002', '', '4', '83', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('598', '2019-02-22 00:41:35', '8', '10002', '', '4', '84', '192.168.0.155');
INSERT INTO `tbl_action_log` VALUES ('599', '2019-02-26 16:14:42', null, '5', '登录用户名：admin，登录密码：admin', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('600', '2019-02-26 16:14:47', '22', '2', '', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('601', '2019-02-26 16:15:15', null, '5', '登录用户名：admin，登录密码：admin', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('602', '2019-02-26 16:15:22', null, '5', '登录用户名：admin，登录密码：redoopAdmin', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('603', '2019-02-26 16:16:19', '1', '4', '', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('604', '2019-02-26 16:16:29', '1', '2', '', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('605', '2019-02-26 16:17:27', '22', '2', '', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('606', '2019-02-26 16:17:41', '1', '2', '', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('607', '2019-02-26 16:18:01', '22', '2', '', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('608', '2019-02-26 16:56:45', '1', '2', '', '0', '0', '0:0:0:0:0:0:0:1');
INSERT INTO `tbl_action_log` VALUES ('609', '2019-02-28 09:22:05', '22', '2', '', '0', '0', '0:0:0:0:0:0:0:1');

-- ----------------------------
-- Table structure for tbl_ads
-- ----------------------------
DROP TABLE IF EXISTS `tbl_ads`;
CREATE TABLE `tbl_ads` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `type` int(11) NOT NULL COMMENT '1是图片链接，2是文字链接，3是代码',
  `name` varchar(100) DEFAULT NULL COMMENT '广告名称',
  `start_time` datetime DEFAULT NULL,
  `end_time` datetime DEFAULT NULL,
  `content` varchar(1000) NOT NULL COMMENT '内容，如果是图片链接，该内容为图片地址，如果是文字链接，改内容是文字描述信息，如果是代码，改内容是广告代码',
  `link` varchar(255) DEFAULT NULL COMMENT '链接，图片链接和文字链接类型时才有效',
  `status` int(1) DEFAULT '0' COMMENT '状态，0禁用，1启用',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_ads
-- ----------------------------

-- ----------------------------
-- Table structure for tbl_archive
-- ----------------------------
DROP TABLE IF EXISTS `tbl_archive`;
CREATE TABLE `tbl_archive` (
  `archive_id` int(11) NOT NULL AUTO_INCREMENT,
  `post_type` int(11) DEFAULT '0' COMMENT '发布类型，1是普通文章，2是群组文章',
  `title` varchar(255) DEFAULT NULL COMMENT '文档标题',
  `member_id` int(11) DEFAULT NULL COMMENT '会员ID',
  `create_time` datetime DEFAULT NULL COMMENT '创建时间',
  `description` varchar(255) DEFAULT NULL COMMENT '描述说明',
  `keywords` varchar(100) DEFAULT NULL COMMENT '关键词',
  `view_rank` int(11) DEFAULT '0' COMMENT '浏览权限，0不限制，1会员',
  `view_count` int(11) DEFAULT '0' COMMENT '浏览次数',
  `writer` varchar(30) DEFAULT '' COMMENT '作者',
  `source` varchar(30) DEFAULT '' COMMENT '来源',
  `pub_time` datetime DEFAULT NULL COMMENT '发布日期',
  `update_time` datetime DEFAULT NULL COMMENT '最后更新时间',
  `thumbnail` varchar(255) DEFAULT NULL COMMENT '缩略图',
  `last_reply` datetime DEFAULT NULL COMMENT '最后回复时间',
  `can_reply` int(1) DEFAULT '0' COMMENT '是否可以回复，0可以回复，1不可以回复',
  `good_num` int(11) DEFAULT '0' COMMENT '点赞数量',
  `bad_num` int(11) DEFAULT '0' COMMENT '踩数量',
  `check_admin` int(11) DEFAULT '0' COMMENT '审核管理员id',
  `content` longtext,
  `favor` int(11) DEFAULT '0' COMMENT '喜欢、点赞',
  `htmlcontent` longtext,
  PRIMARY KEY (`archive_id`)
) ENGINE=InnoDB AUTO_INCREMENT=92 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_archive
-- ----------------------------
INSERT INTO `tbl_archive` VALUES ('3', '0', 'CRH5.2部署文档', '14', '2018-01-22 11:14:40', '这篇文章是CRH5.2产品的部署文档，文章主要讲述CRH5.2部署环境配置和组件的基本安装。', null, '0', '1059', null, null, '2018-01-22 11:14:40', '2018-02-02 11:40:21', null, null, '0', '0', '0', '0', '# 安装ambari\n执行以下任务来安装ambari。\n-  为安装ambari做好准备。\n- 安装ambari-server\n- 设置ambari-server\n- 启动ambari-server\n## 为ambari的安装做准备\n本节描述您应该准备安装集群的信息和环境使用ambari。Ambari提供了一个端到端的管\n理和监视解决方案管理您 的集群。使用ambari Web UI和REST         api，您可以部署、操作和管理配置更改，并从中心监视集群中的所有节点的服务点。\n### 配置主机名映射\n使用文本编辑器，在集群中的每个主机上打开主机文件，并修改主机名，配置集群主机映射。\n\n```\nvi /etc/hostname\nvi /etc/hosts\n```\n> 注意：\n> 不要从您的主机文件中删除下面的两行。删除或编辑以下行可能会导致需要网络的各种程序功能失败\n> \n> ```\n> 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n> ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n> ```\n\n### 设置集群主机免秘钥登录\n要让ambari服务器自动在所有集群主机上安装ambari代理，您必须在ambari服务器主机和其他所有服务器之间设置无密码的SSH连接。ambari服务器主机使用SSH公钥身份验证进行远程操作访问和安装ambari agent。\n> 注意：\n> 您可以选择在每个集群主机上手动安装ambariAgent。在在这种情况下，您不需要生成和分发SSH密钥\n\n**步骤：**\n\n1. 在ambari服务器主机上生成公共和私有SSH密钥。\n\n```\nssh-keygen\n```\n\n2. 分发主机私钥至ambari服务器的每一个主机。\n\n```\nssh-copy-id nx-1\nssh-copy-id nx-2\nssh-copy-id nx-3\n```\n> 注意：\n> nx-1，nx-2 ，nx-3为主机名（我这里以三节点为例）\n\n### 安装httpd服务\nhttpd是Apache超文本传输协议(HTTP)服务器的主程序。被设计为一个独立运行的后台进程，它会建立一个处理请求的子进程或线程的池。\n\n1. 运行下面命令安装httpd服务：\n\n```\nyum install -y httpd\n```\n2. 启动httpd服务\n\n```\nservice httpd start\n```\n### 关闭ambari服务器每台主机防火墙\n火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。\n\n运行下面命令关闭防火墙\n\n```\nsystemctl stop firewalld\n```\n### 关闭每台主机SElinux\n每台主机关闭安全子系统，可以控制程序访问，重启生效\n\n```\nsed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n```\n### 配置主机的jdk java环境\nJava平台由Java虚拟机（Java Virtual Machine）和Java 应用编程接口（Application Programming Interface、简称API）构成。Java 应用编程接口为Java应用提供了一个独立于操作系统的标准接口，可分为基本部分和扩展部分。在硬件或操作系统平台上安装一个Java平台之后，Java应用程序就可运行。现在Java平台已经嵌入了几乎所有的操作系统。这样Java程序可以只编译一次，就可以在各种系统中运行。\n1. 下载JDK安装包，版本为jdk1.8.0_144，将其放入/usr/lib/jvm/ 目录(目录位置可以修改)下\n2. 解压每台主机下的jdk包。\n\n```\ntar -zxvf jdk-8u144-linux-x64.tar.gz\n```\n\n3. 配置每台主机上的java环境变量\n\n```\nvi /etc/profile.d/jdk.sh\nexport JAVA_HOME=/usr/lib/jvm/jdk1.8.0_144\nexport JRE_HOME=//usr/lib/jvm/jdk1.8.0_144/jre\nexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH\nexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH\n\n```\n\n4. 生效每台主机的jdk环境变量\n\n```\nsource /etc/profile\n```\n\n5. 查看每台主机的jdk环境变量\n```\njava –version\njava version \"1.8.0_144\"\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n```\n## 安装ambari-server\n### 配置CRH源\nepo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用\n1. 进入到/etc /yum.repos.d目录下，加载我们crh所需要的repo文件（去官网下载页寻找下载地址：http://www.redhadoop.com/front/redoopCRH）\n\n```\ncd /etc/yum.repos.d/\nwget +repo文件路径（e.g wget http://archive.redoop.com/crh/rpm/5.1.2.6/CRH/x86_64/centos7/ambari.repo）\n\n```\n\n2. 安装ambari-server\n\n```\nyum clean all\nyum install -y ambari-server\n```\n\n## setup ambari-server\n在启动ambari服务器之前，您必须设置ambari服务器。设置配置Ambari与ambari数据库对话，安装JDK，并允许您定制用户帐户ambari服务器守护进程将运行\n\n执行以下命令设置ambari-server\n\n```\nambari-server setup\n```\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ambari-setup.png)\n## 1.4 启动ambari-server\n1. 在ambari服务器主机上运行以下命令\n\n```\nambari-server start\n```\n\n2. 检查ambari服务器进程:\n\n```\nambari-server status\n```\n\n3. 停止ambari-server服务\n\n```\nambari-server stop\n```\n> 注意：\n> 如果您打算为Hive或Oozie使用现有的数据库实例，那么您必须在安装Hadoop集群之前，准备使用非默认数据库\n\n# 搭建CRH集群组件\n在你开始了ambari服务之后，你可以在浏览器中打开Ambari的网址，然后启动。\n## 注册CRH ambari服务主机\n**步骤：**\n1. 	在页面输入http:// < your.ambari.server>:8080，进入ambari的web界面。\n2. 使用默认的用户名和密码登录到ambari服务器，用户名：admin，密码：admin，进入系统你可以修改密码。\n3. 在ambari欢迎页面，选择启动安装向导。\n4. 在Get启动步骤中，为您的集群自定义一个名称。\n5.在选择版本界面，选择你所需要的系统，并添加仓库的链接，（链接可以打开ambari.repo查看）\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/CRH-zhuce-zhuji.png)\n\n---\n\n- 仓库地址查看 e.g\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/cangku-dizhi-e.g.png)\n\n6.添加主机名和主机私钥完成主机注册\ne.g \n主机私钥查看\n\n```\ncat ~/.ssh/id_rsa\n```\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/zhuce-zhuji.png)\n\n## 安装配置CRH组件\n- 安装hadoop（HDFS,MAPREDUCE和ZooKeeper）\n- 安装sqoop，storm，flume，kafka\n- 安装hbase , kafka,log search,spark,spark2,zeppelin \n- 安装HIVE, HAWQ, ,infra,atlas,组件\n- 安装Ranger，rangerKMS\n### 安装hadoop（HDFS,MAPREDUCE和ZooKeeper）\n您可以在定制服务步骤中配置hadoop组件选项（包括Hadoop+mapReduce+hdfs+ZooKeeper）\n**步骤**：\n1. 打开添加服务选择hadoop服务（包括Hadoop+mapReduce+hdfs+ZooKeeper）。\n1. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n1. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n1. 查看安装过程中是否正常，完成安装任务。\n\n### 安装sqoop，storm，flume，kafka\n您可以在定制服务步骤中配置sqoop，storm，flume。kafka组件选项\n\n**步骤：**\n1. 打开添加服务选择sqoop，storm，flume。kafka服务。\n1. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n1. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n1. 查看安装过程中是否正常，完成安装任务。\n\n### 安装hbase , kafka,log search,spark,spark2,zeppelin\n您可以在定制服务步骤中配置hbase , kafka,logsearch,spark,spark2,zeppelin组件选项\n\n**步骤：**\n\n1. 打开添加服务选择hbase , kafka,log search,spark,spark2,zeppelin服务。\n1. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n1. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n1. 查看安装过程中是否正常，完成安装任务。\n\n### 安装HIVE, HAWQ, ,infra,atlas,组件\n您可以在定制服务步骤中配置hive，HAWQ，Infra，atlas组件选项\n**步骤：**\n1. 打开添加服务选择hive，HAWQ，Infra，atlas服务。\n1. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n1. 在ambari配置界面过程中，这几个组件需要配置密码，请设置好您们组件所使用的的密码。\n1. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n1. 查看安装过程中是否正常，完成安装任务。\n\n### 安装Ranger，rangerKMS\n在安装Ranger之前需要配置ambari服务主机的数据库配置并保证确保Ambari Infra已成功安装\n1. 在ambari服务主机上安装mariadb数据库\n\n```\nyum install -y mariadb-server\n```\n\n2. 启动mariadb数据库\n\n```\nsystemctl start mariadb\n```\n\n3. 初始化mariadb数据库并设置数据库密码\n\n```\nmysql_secure_installation\n```\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/set-passwd-mariadb.png)\n4. 进入mariadb数据库需要设置数据库允许远程连接\n\n```\nMariaDB [(none)]> grant all on *.* to root@\'%\' identified by \'root\' with grant option;\nMariaDB [(none)]> flush privileges;\n```\n\n5. 按照安装向导执行如下命令\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-yaoqiu.png)\n\n\n```\nambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n```\n\n6. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）\n\n7. 在定制服务时有几个地方需要填写\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-tianxiexinxi.png)\n\n---\n\n- 填写完成后，测试连接是否成功\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-ceshi-lianjie.png)\n\n---\n\n- 最后一个修改地方\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-on-update.png)\n8. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n9. 查看安装过程中是否正常，完成安装任务。\n\n##### **RangerKMS安装**\n在安装RangerKMS之前需要先对jdk做一步操作,否则会RangerKMS安装成功,但是服务会死掉.\n这个是因为用AES加密时，如果密钥大于128, 会抛出java.security.InvalidKeyException: Illegal key size异常。\n\n之后查看日志文件tail -100f /var/log/ranger/kms/catalina.out\n\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-exception.png)\n\n这时候需要我们去http://www.oracle.com/technetwork/java/javase/downloads/index.html oracle官网上下载对应jdk版本的Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files 文件\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/RangerKMS-JDK-RSA-download.png)\n解压以后将local_policy.jar，US_export_policy.jar的文件拷贝到JAVA_HOME/jre/lib/security 替换原来的文件,之后开始安装RangerKMS\n\n1. 打开添加服务选择RangerKMS服务。\n2. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n3. 在ambari配置界面过程中，需要修改几个部分,修改如下图：\n\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-tianxiexinxi1.png)\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-tianxiexinxi2.png)\n4. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n5. 查看安装过程中是否正常，完成安装任务。\n\n\n', '0', '<h1 id=\"h1--ambari\"><a name=\"安装ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装ambari</h1><p>执行以下任务来安装ambari。</p>\n<ul>\n<li>为安装ambari做好准备。</li><li>安装ambari-server</li><li>设置ambari-server</li><li>启动ambari-server<h2 id=\"h2--ambari-\"><a name=\"为ambari的安装做准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>为ambari的安装做准备</h2>本节描述您应该准备安装集群的信息和环境使用ambari。Ambari提供了一个端到端的管<br>理和监视解决方案管理您 的集群。使用ambari Web UI和REST         api，您可以部署、操作和管理配置更改，并从中心监视集群中的所有节点的服务点。<h3 id=\"h3-u914Du7F6Eu4E3Bu673Au540Du6620u5C04\"><a name=\"配置主机名映射\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置主机名映射</h3>使用文本编辑器，在集群中的每个主机上打开主机文件，并修改主机名，配置集群主机映射。</li></ul>\n<pre><code>vi /etc/hostname\nvi /etc/hosts\n</code></pre><blockquote>\n<p>注意：<br>不要从您的主机文件中删除下面的两行。删除或编辑以下行可能会导致需要网络的各种程序功能失败</p>\n<pre><code>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n</code></pre></blockquote>\n<h3 id=\"h3-u8BBEu7F6Eu96C6u7FA4u4E3Bu673Au514Du79D8u94A5u767Bu5F55\"><a name=\"设置集群主机免秘钥登录\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>设置集群主机免秘钥登录</h3><p>要让ambari服务器自动在所有集群主机上安装ambari代理，您必须在ambari服务器主机和其他所有服务器之间设置无密码的SSH连接。ambari服务器主机使用SSH公钥身份验证进行远程操作访问和安装ambari agent。</p>\n<blockquote>\n<p>注意：<br>您可以选择在每个集群主机上手动安装ambariAgent。在在这种情况下，您不需要生成和分发SSH密钥</p>\n</blockquote>\n<p><strong>步骤：</strong></p>\n<ol>\n<li>在ambari服务器主机上生成公共和私有SSH密钥。</li></ol>\n<pre><code>ssh-keygen\n</code></pre><ol>\n<li>分发主机私钥至ambari服务器的每一个主机。</li></ol>\n<pre><code>ssh-copy-id nx-1\nssh-copy-id nx-2\nssh-copy-id nx-3\n</code></pre><blockquote>\n<p>注意：<br>nx-1，nx-2 ，nx-3为主机名（我这里以三节点为例）</p>\n</blockquote>\n<h3 id=\"h3--httpd-\"><a name=\"安装httpd服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装httpd服务</h3><p>httpd是Apache超文本传输协议(HTTP)服务器的主程序。被设计为一个独立运行的后台进程，它会建立一个处理请求的子进程或线程的池。</p>\n<ol>\n<li>运行下面命令安装httpd服务：</li></ol>\n<pre><code>yum install -y httpd\n</code></pre><ol>\n<li>启动httpd服务</li></ol>\n<pre><code>service httpd start\n</code></pre><h3 id=\"h3--ambari-\"><a name=\"关闭ambari服务器每台主机防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭ambari服务器每台主机防火墙</h3><p>火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。</p>\n<p>运行下面命令关闭防火墙</p>\n<pre><code>systemctl stop firewalld\n</code></pre><h3 id=\"h3--selinux\"><a name=\"关闭每台主机SElinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭每台主机SElinux</h3><p>每台主机关闭安全子系统，可以控制程序访问，重启生效</p>\n<pre><code>sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n</code></pre><h3 id=\"h3--jdk-java-\"><a name=\"配置主机的jdk java环境\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置主机的jdk java环境</h3><p>Java平台由Java虚拟机（Java Virtual Machine）和Java 应用编程接口（Application Programming Interface、简称API）构成。Java 应用编程接口为Java应用提供了一个独立于操作系统的标准接口，可分为基本部分和扩展部分。在硬件或操作系统平台上安装一个Java平台之后，Java应用程序就可运行。现在Java平台已经嵌入了几乎所有的操作系统。这样Java程序可以只编译一次，就可以在各种系统中运行。</p>\n<ol>\n<li>下载JDK安装包，版本为jdk1.8.0_144，将其放入/usr/lib/jvm/ 目录(目录位置可以修改)下</li><li>解压每台主机下的jdk包。</li></ol>\n<pre><code>tar -zxvf jdk-8u144-linux-x64.tar.gz\n</code></pre><ol>\n<li>配置每台主机上的java环境变量</li></ol>\n<pre><code>vi /etc/profile.d/jdk.sh\nexport JAVA_HOME=/usr/lib/jvm/jdk1.8.0_144\nexport JRE_HOME=//usr/lib/jvm/jdk1.8.0_144/jre\nexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH\nexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH\n</code></pre><ol>\n<li>生效每台主机的jdk环境变量</li></ol>\n<pre><code>source /etc/profile\n</code></pre><ol>\n<li>查看每台主机的jdk环境变量<pre><code>java –version\njava version &quot;1.8.0_144&quot;\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n</code></pre><h2 id=\"h2--ambari-server\"><a name=\"安装ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装ambari-server</h2><h3 id=\"h3--crh-\"><a name=\"配置CRH源\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置CRH源</h3>epo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用</li><li>进入到/etc /yum.repos.d目录下，加载我们crh所需要的repo文件（去官网下载页寻找下载地址：<a href=\"http://www.redhadoop.com/front/redoopCRH）\">http://www.redhadoop.com/front/redoopCRH）</a></li></ol>\n<pre><code>cd /etc/yum.repos.d/\nwget +repo文件路径（e.g wget http://archive.redoop.com/crh/rpm/5.1.2.6/CRH/x86_64/centos7/ambari.repo）\n</code></pre><ol>\n<li>安装ambari-server</li></ol>\n<pre><code>yum clean all\nyum install -y ambari-server\n</code></pre><h2 id=\"h2-setup-ambari-server\"><a name=\"setup ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>setup ambari-server</h2><p>在启动ambari服务器之前，您必须设置ambari服务器。设置配置Ambari与ambari数据库对话，安装JDK，并允许您定制用户帐户ambari服务器守护进程将运行</p>\n<p>执行以下命令设置ambari-server</p>\n<pre><code>ambari-server setup\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ambari-setup.png\" alt=\"image\"></p>\n<h2 id=\"h2-1-4-ambari-server\"><a name=\"1.4 启动ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4 启动ambari-server</h2><ol>\n<li>在ambari服务器主机上运行以下命令</li></ol>\n<pre><code>ambari-server start\n</code></pre><ol>\n<li>检查ambari服务器进程:</li></ol>\n<pre><code>ambari-server status\n</code></pre><ol>\n<li>停止ambari-server服务</li></ol>\n<pre><code>ambari-server stop\n</code></pre><blockquote>\n<p>注意：<br>如果您打算为Hive或Oozie使用现有的数据库实例，那么您必须在安装Hadoop集群之前，准备使用非默认数据库</p>\n</blockquote>\n<h1 id=\"h1--crh-\"><a name=\"搭建CRH集群组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>搭建CRH集群组件</h1><p>在你开始了ambari服务之后，你可以在浏览器中打开Ambari的网址，然后启动。</p>\n<h2 id=\"h2--crh-ambari-\"><a name=\"注册CRH ambari服务主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>注册CRH ambari服务主机</h2><p><strong>步骤：</strong></p>\n<ol>\n<li>在页面输入http:// &lt; your.ambari.server&gt;:8080，进入ambari的web界面。</li><li>使用默认的用户名和密码登录到ambari服务器，用户名：admin，密码：admin，进入系统你可以修改密码。</li><li>在ambari欢迎页面，选择启动安装向导。</li><li>在Get启动步骤中，为您的集群自定义一个名称。<br>5.在选择版本界面，选择你所需要的系统，并添加仓库的链接，（链接可以打开ambari.repo查看）<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/CRH-zhuce-zhuji.png\" alt=\"image\"></li></ol>\n<hr>\n<ul>\n<li>仓库地址查看 e.g<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/cangku-dizhi-e.g.png\" alt=\"image\"></li></ul>\n<p>6.添加主机名和主机私钥完成主机注册<br>e.g<br>主机私钥查看</p>\n<pre><code>cat ~/.ssh/id_rsa\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/zhuce-zhuji.png\" alt=\"image\"></p>\n<h2 id=\"h2--crh-\"><a name=\"安装配置CRH组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装配置CRH组件</h2><ul>\n<li>安装hadoop（HDFS,MAPREDUCE和ZooKeeper）</li><li>安装sqoop，storm，flume，kafka</li><li>安装hbase , kafka,log search,spark,spark2,zeppelin </li><li>安装HIVE, HAWQ, ,infra,atlas,组件</li><li>安装Ranger，rangerKMS<h3 id=\"h3--hadoop-hdfs-mapreduce-zookeeper-\"><a name=\"安装hadoop（HDFS,MAPREDUCE和ZooKeeper）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装hadoop（HDFS,MAPREDUCE和ZooKeeper）</h3>您可以在定制服务步骤中配置hadoop组件选项（包括Hadoop+mapReduce+hdfs+ZooKeeper）<br><strong>步骤</strong>：</li></ul>\n<ol>\n<li>打开添加服务选择hadoop服务（包括Hadoop+mapReduce+hdfs+ZooKeeper）。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h3 id=\"h3--sqoop-storm-flume-kafka\"><a name=\"安装sqoop，storm，flume，kafka\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装sqoop，storm，flume，kafka</h3><p>您可以在定制服务步骤中配置sqoop，storm，flume。kafka组件选项</p>\n<p><strong>步骤：</strong></p>\n<ol>\n<li>打开添加服务选择sqoop，storm，flume。kafka服务。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h3 id=\"h3--hbase-kafka-log-search-spark-spark2-zeppelin\"><a name=\"安装hbase , kafka,log search,spark,spark2,zeppelin\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装hbase , kafka,log search,spark,spark2,zeppelin</h3><p>您可以在定制服务步骤中配置hbase , kafka,logsearch,spark,spark2,zeppelin组件选项</p>\n<p><strong>步骤：</strong></p>\n<ol>\n<li>打开添加服务选择hbase , kafka,log search,spark,spark2,zeppelin服务。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h3 id=\"h3--hive-hawq-infra-atlas-\"><a name=\"安装HIVE, HAWQ, ,infra,atlas,组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装HIVE, HAWQ, ,infra,atlas,组件</h3><p>您可以在定制服务步骤中配置hive，HAWQ，Infra，atlas组件选项<br><strong>步骤：</strong></p>\n<ol>\n<li>打开添加服务选择hive，HAWQ，Infra，atlas服务。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>在ambari配置界面过程中，这几个组件需要配置密码，请设置好您们组件所使用的的密码。</li><li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h3 id=\"h3--ranger-rangerkms\"><a name=\"安装Ranger，rangerKMS\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装Ranger，rangerKMS</h3><p>在安装Ranger之前需要配置ambari服务主机的数据库配置并保证确保Ambari Infra已成功安装</p>\n<ol>\n<li>在ambari服务主机上安装mariadb数据库</li></ol>\n<pre><code>yum install -y mariadb-server\n</code></pre><ol>\n<li>启动mariadb数据库</li></ol>\n<pre><code>systemctl start mariadb\n</code></pre><ol>\n<li>初始化mariadb数据库并设置数据库密码</li></ol>\n<pre><code>mysql_secure_installation\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/set-passwd-mariadb.png\" alt=\"image\"></p>\n<ol>\n<li>进入mariadb数据库需要设置数据库允许远程连接</li></ol>\n<pre><code>MariaDB [(none)]&gt; grant all on *.* to root@&#39;%&#39; identified by &#39;root&#39; with grant option;\nMariaDB [(none)]&gt; flush privileges;\n</code></pre><ol>\n<li>按照安装向导执行如下命令<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-yaoqiu.png\" alt=\"image\"></li></ol>\n<pre><code>ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n</code></pre><ol>\n<li><p>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）</p>\n</li><li><p>在定制服务时有几个地方需要填写<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-tianxiexinxi.png\" alt=\"image\"></p>\n</li></ol>\n<hr>\n<ul>\n<li>填写完成后，测试连接是否成功<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-ceshi-lianjie.png\" alt=\"image\"></li></ul>\n<hr>\n<ul>\n<li>最后一个修改地方<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-on-update.png\" alt=\"image\"></li></ul>\n<ol>\n<li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h5 id=\"h5--strong-rangerkms-strong-\"><a name=\"<strong>RangerKMS安装</strong>\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><strong>RangerKMS安装</strong></h5><p>在安装RangerKMS之前需要先对jdk做一步操作,否则会RangerKMS安装成功,但是服务会死掉.<br>这个是因为用AES加密时，如果密钥大于128, 会抛出java.security.InvalidKeyException: Illegal key size异常。</p>\n<p>之后查看日志文件tail -100f /var/log/ranger/kms/catalina.out</p>\n<p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-exception.png\" alt=\"image\"></p>\n<p>这时候需要我们去<a href=\"http://www.oracle.com/technetwork/java/javase/downloads/index.html\">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a> oracle官网上下载对应jdk版本的Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files 文件<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/RangerKMS-JDK-RSA-download.png\" alt=\"image\"><br>解压以后将local_policy.jar，US_export_policy.jar的文件拷贝到JAVA_HOME/jre/lib/security 替换原来的文件,之后开始安装RangerKMS</p>\n<ol>\n<li>打开添加服务选择RangerKMS服务。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>在ambari配置界面过程中，需要修改几个部分,修改如下图：</li></ol>\n<p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-tianxiexinxi1.png\" alt=\"image\"><br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-tianxiexinxi2.png\" alt=\"image\"></p>\n<ol>\n<li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n');
INSERT INTO `tbl_archive` VALUES ('4', '0', ' 卫星影像领域的深度学习数据和模型项目', '1', '2018-01-22 18:31:25', '深度学习和大数据学习需要依赖海量数据，遥感卫星也是深度学习的一个关键场景。后续我会支持更新我们在这个领域的进展，分享今天收集和整理的数据和项目,期待中国航天行业也能有更好的开放性。', null, '0', '875', '', '', '2018-01-22 18:31:25', '2018-05-31 11:30:46', null, null, '0', '0', '0', '0', '**目录 (Table of Contents)**\n\n[TOCM]\n\n[TOC]\n\n深度学习和大数据学习需要依赖海量数据，遥感卫星也是深度学习的一个关键场景。后续我会支持更新我们在这个领域的进展，分享今天收集和整理的数据和项目,期待中国航天行业也能有更好的开放性。\n![SpaceNet](http://explore.digitalglobe.com/rs/782-PEE-248/images/imagesForDG.JPEG)\n\n#[地理空间和环境数据集](https://amazonaws-china.com/cn/public-datasets/)\n\n###在 AWS 上的地球页面了解更多有关如何使用 AWS 上的地理空间数据的信息。\n   \n AWS 上的 [Landsat](http://amazonaws-china.com/public-data-sets/landsat/)：地球陆地卫星图像集合，持续采集由 Landsat 8 卫星拍摄的卫星图像。\n    AWS 上的 [Sentinel-2](https://amazonaws-china.com/public-datasets/sentinel-2/)：地球陆地卫星图像集合，持续采集由 Sentinel-2 卫星拍摄的卫星图像。\n    AWS 上的 [GOES](https://amazonaws-china.com/cn/public-datasets/goes/)：GOES 可以持续提供北美的气候影像并监控该地区的气象和太空环境数据。\n    AWS 上的 [SpaceNet](http://amazonaws-china.com/public-data-sets/spacenet/)：包含商业卫星图像和带标签的训练数据的语料库，用于促进计算机视觉算法的创新发展。\n    AWS 上的 [OpenStreetMap](https://amazonaws-china.com/cn/public-datasets/osm/)：OSM 是一款免费的可编辑世界地图服务，由志愿者创建和维护。可定期在 Amazon S3 中对 OSM 数据进行存档。\n    AWS 上的 [MODIS](https://amazonaws-china.com/public-datasets/modis/)：从美国地质调查局和美国航空航天局管理的中等分辨率成像光谱仪 (MODIS) 中选择产品。\n    [Terrain Tiles](https://amazonaws-china.com/cn/public-datasets/terrain/)：一个全球数据集，提供裸地地形高度，平铺显示以便于使用，在 S3 上提供。\n    [NAIP](https://amazonaws-china.com/cn/public-datasets/naip/)：在美国大陆农作物生长季节捕获的 1 米航空图像\n    AWS 上的 [NEXRAD](https://amazonaws-china.com/cn/public-datasets/nexrad/)：来自下一代气象雷达 (NEXRAD) 网络的实时和存档数据。\n    [NASA NEX](http://amazonaws-china.com/nasa/nex/)：由美国航空航天局维护的地球科学数据集，包括气候变化预测和地球表面的卫星图像。\n    [哥伦比亚特区激光雷达](https://amazonaws-china.com/public-datasets/dc-lidar/)：华盛顿特区的激光雷达点云数据。\n    [EPA 风险筛选环境指标](https://amazonaws-china.com/public-datasets/epa-rsei/)：从 EPA 风险筛选环境指标 (RSEI) 模型得出的详细空气模型结果。\n    [HIRLAM 气象模型](https://amazonaws-china.com/public-datasets/fmi-hirlam/)：HIRLAM (高分辨率有限区域模型) 是一个由芬兰气象研究所管理的实际天气和中尺度气象预测模型。\n\n\n# SpaceNet  卫星影像领域的深度学习数据和模型项目\n![这里写图片描述](http://explore.digitalglobe.com/rs/782-PEE-248/images/SpaceNet_logo_TM.PNG)\nhttp://explore.digitalglobe.com/SpaceNet-Thank-You.html\n\n![这里写图片描述](https://developmentseed.org/assets/graphics/layout/ds-logo-pos.svg)\nhttps://developmentseed.org/projects/\n\n![](https://landsat-pds.s3.amazonaws.com/c1/L8/001/003/LC08_L1GT_001003_20170516_20170516_01_RT/index.html)](https://landsat-pds.s3.amazonaws.com/c1/L8/001/003/LC08_L1GT_001003_20170516_20170516_01_RT/LC08_L1GT_001003_20170516_20170516_01_RT_thumb_small.jpg)\nhttps://landsat-pds.s3.amazonaws.com/index.html\n', '1', '<p><strong>目录 (Table of Contents)</strong></p>\n<p>[TOCM]</p>\n<div class=\"markdown-toc editormd-markdown-toc\">[TOC]</div><p>深度学习和大数据学习需要依赖海量数据，遥感卫星也是深度学习的一个关键场景。后续我会支持更新我们在这个领域的进展，分享今天收集和整理的数据和项目,期待中国航天行业也能有更好的开放性。<br><img src=\"http://explore.digitalglobe.com/rs/782-PEE-248/images/imagesForDG.JPEG\" alt=\"SpaceNet\"></p>\n<h1 id=\"h1-u5730u7406u7A7Au95F4u548Cu73AFu5883u6570u636Eu96C6\"><a name=\"地理空间和环境数据集\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><a href=\"https://amazonaws-china.com/cn/public-datasets/\">地理空间和环境数据集</a></h1><h3 id=\"h3--aws-aws-\"><a name=\"在 AWS 上的地球页面了解更多有关如何使用 AWS 上的地理空间数据的信息。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在 AWS 上的地球页面了解更多有关如何使用 AWS 上的地理空间数据的信息。</h3><p> AWS 上的 <a href=\"http://amazonaws-china.com/public-data-sets/landsat/\">Landsat</a>：地球陆地卫星图像集合，持续采集由 Landsat 8 卫星拍摄的卫星图像。<br>    AWS 上的 <a href=\"https://amazonaws-china.com/public-datasets/sentinel-2/\">Sentinel-2</a>：地球陆地卫星图像集合，持续采集由 Sentinel-2 卫星拍摄的卫星图像。<br>    AWS 上的 <a href=\"https://amazonaws-china.com/cn/public-datasets/goes/\">GOES</a>：GOES 可以持续提供北美的气候影像并监控该地区的气象和太空环境数据。<br>    AWS 上的 <a href=\"http://amazonaws-china.com/public-data-sets/spacenet/\">SpaceNet</a>：包含商业卫星图像和带标签的训练数据的语料库，用于促进计算机视觉算法的创新发展。<br>    AWS 上的 <a href=\"https://amazonaws-china.com/cn/public-datasets/osm/\">OpenStreetMap</a>：OSM 是一款免费的可编辑世界地图服务，由志愿者创建和维护。可定期在 Amazon S3 中对 OSM 数据进行存档。<br>    AWS 上的 <a href=\"https://amazonaws-china.com/public-datasets/modis/\">MODIS</a>：从美国地质调查局和美国航空航天局管理的中等分辨率成像光谱仪 (MODIS) 中选择产品。<br>    <a href=\"https://amazonaws-china.com/cn/public-datasets/terrain/\">Terrain Tiles</a>：一个全球数据集，提供裸地地形高度，平铺显示以便于使用，在 S3 上提供。<br>    <a href=\"https://amazonaws-china.com/cn/public-datasets/naip/\">NAIP</a>：在美国大陆农作物生长季节捕获的 1 米航空图像<br>    AWS 上的 <a href=\"https://amazonaws-china.com/cn/public-datasets/nexrad/\">NEXRAD</a>：来自下一代气象雷达 (NEXRAD) 网络的实时和存档数据。<br>    <a href=\"http://amazonaws-china.com/nasa/nex/\">NASA NEX</a>：由美国航空航天局维护的地球科学数据集，包括气候变化预测和地球表面的卫星图像。<br>    <a href=\"https://amazonaws-china.com/public-datasets/dc-lidar/\">哥伦比亚特区激光雷达</a>：华盛顿特区的激光雷达点云数据。<br>    <a href=\"https://amazonaws-china.com/public-datasets/epa-rsei/\">EPA 风险筛选环境指标</a>：从 EPA 风险筛选环境指标 (RSEI) 模型得出的详细空气模型结果。<br>    <a href=\"https://amazonaws-china.com/public-datasets/fmi-hirlam/\">HIRLAM 气象模型</a>：HIRLAM (高分辨率有限区域模型) 是一个由芬兰气象研究所管理的实际天气和中尺度气象预测模型。</p>\n<h1 id=\"h1-spacenet-\"><a name=\"SpaceNet  卫星影像领域的深度学习数据和模型项目\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>SpaceNet  卫星影像领域的深度学习数据和模型项目</h1><p><img src=\"http://explore.digitalglobe.com/rs/782-PEE-248/images/SpaceNet_logo_TM.PNG\" alt=\"这里写图片描述\"><br><a href=\"http://explore.digitalglobe.com/SpaceNet-Thank-You.html\">http://explore.digitalglobe.com/SpaceNet-Thank-You.html</a></p>\n<p><img src=\"https://developmentseed.org/assets/graphics/layout/ds-logo-pos.svg\" alt=\"这里写图片描述\"><br><a href=\"https://developmentseed.org/projects/\">https://developmentseed.org/projects/</a></p>\n<p><img src=\"https://landsat-pds.s3.amazonaws.com/c1/L8/001/003/LC08_L1GT_001003_20170516_20170516_01_RT/LC08_L1GT_001003_20170516_20170516_01_RT_thumb_small.jpg\" alt=\"](https://landsat-pds.s3.amazonaws.com/c1/L8/001/003/LC08_L1GT_001003_20170516_20170516_01_RT/index.html)\"><br><a href=\"https://landsat-pds.s3.amazonaws.com/index.html\">https://landsat-pds.s3.amazonaws.com/index.html</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('5', '0', 'OpenTSDB简介与安装', '13', '2018-01-23 16:12:29', '本文简单描述了OpenTSDB的工作原理，以及与CRH的HBase服务的结合应用安装', null, '0', '376', null, null, '2018-01-23 16:12:29', null, null, null, '0', '0', '0', '0', '# OpenTSDB简介及安装\n## 简介\n### 工作原理\nOpenTSDB是一个时间序列数据库，由一个 **Time Series Daemon (TSD)** 和一系列命令行实用程序组成。与OpenTSDB交互主要通过运行一个或者多个 TSD 来实现。每个 TSD 是独立的。没有master，没有共享状态，所以你可以运行尽可能多的 TSD 来处理工作负载。每个 TSD 使用开源数据库 [HBase](http://hbase.apache.org/) 或托管Google Bigtable服务来存储和检索时间序列数据。数据模式针对类似时间序列的快速聚合进行了高度优化，以最大限度的减少存储空间。TSD 的用户不需要直接访问底层仓库。你可以通过简单的telnet样式协议，HTTP API 或者简单的内置 GUI 与 TSD 进行通信。所有的通信都发生在同一个端口上(TSD 通过查看接收到的前几个字节来计算出客户端的协议)。\n\n![image](http://opentsdb.net/img/tsdb-architecture.png)\n\n\n## 安装\n这里，我们使用CRH平台中的HBase服务为OpenTSDB存储和检索时间序列数据。  \n操作系统为Centos7，CPU架构为x86。  \n从 [OpenTSDB下载地址](https://github.com/OpenTSDB/opentsdb/releases) 选择合适的版本下载。这里我们以 opentsdb-2.3.0.rpm 为例。\n\n#### 部署HBase\n部署CRH平台的HDFS，ZOOKEEPER以及HBASE服务。详情请参考CRH部署文档。\n\n\n#### 安装OpenTSDB\n将opentsdb安装包下载到本地：\n\n```\nwget https://github.com/OpenTSDB/opentsdb/releases/download/v2.3.0/opentsdb-2.3.0.rpm\n```\n\n执行以下命令进行安装：\n\n```\nyum localinstall opentsdb-2.3.0.rpm\n```\n\nOpenTSDB主要目录介绍：\n\n- /etc/opentsdb —— 配置文件目录\n- /usr/share/opentsdb —— 应用程序目录\n- /usr/share/opentsdb/bin —— \"tsdb\"启动脚本目录\n- /usr/share/opentsdb/lib —— Java JAR library\n- /usr/share/opentsdb/plugins —— 插件和依赖\n- /usr/share/opentsdb/static —— GUI 静态文件\n- /usr/share/opentsdb/tools —— 脚本和其他工具\n- /var/log/opentsdb —— 日志存放目录\n\n安装包安装后包括一个init脚本 */etc/init.d/opentsdb* ，此脚本可以 *start*，*stop* 和 *restart* OpenTSDB。简单地调用 **service opentsdb start** 启动和 **service opentsdb stop** 关闭。\n\n> 注意，在安装之后，tsd 将不是运行状态，所以你能够编辑配置文件。编辑配置文件，然后启动 TSD。\n\n\n#### 建表\n如果你第一次用你的HBase实例运行OpenTSDB，你需要创建必要的HBase表。使用 */usr/share/opentsdb/tools/create_table.sh* 脚本可以轻松建表。执行：\n\n```\ncd /usr/share/opentsdb/tools\nenv COMPRESSION=NONE HBASE_HOME=/usr/crh/current/hbase-master ./create_table.sh \n```\n\n> COMPRESSION参数指定压缩方式，可选值是 NONE，LZO，GZIP，或者 SNAPPY 。这个命令将在指定的HBase中创建四张表：tsdb, tsdb-uid, tsdb-tree 和 tsdb-meta。如果你只是评估OpenTSDB，现在就不用关心压缩方式。在生产环境中，你要使用一个最合适的有效压缩库。\n\n\n#### 配置\n编辑 */etc/opentsdb/opentsdb.conf* 配置文件：\n\n```\ntsd.storage.hbase.zk_basedir = /hbase-unsecure\ntsd.storage.hbase.zk_quorum = xwd1:2181,xwd2:2181,xwd3:2181\n```\n\n> 提示：*tsd.storage.hbase.zk_basedir* 属性值参考 HBase 属性 *zookeeper.znode.parent* 的值；*tsd.storage.hbase.zk_quorum* 属性值为以逗号分隔的要连接的zookeeper节点主机列表，格式如上。\n\n其他配置信息请参考 [配置说明](http://opentsdb.net/docs/build/html/user_guide/configuration.html)\n\n\n#### 启动一个 TSD\n当完成以上配置后，就可以启动 TSD 了：\n\n```\nservie opentsdb start\n```\n\n> 如果 **service opentsdb start** 命令报错，可以直接使用 **/usr/share/opentsdb/etc/init.d/opentsdb start**，其他命令亦同。\n\n在成功启动之后，就可以通过 http://127.0.0.1:4242 (如果这个TSD运行在你的本地机器上)访问 TSD 的web界面。\n\n\n## 总结\n可以看出来，OpenTSDB的安装还是很简单的，当前版本的配置属性也不是很多，应该很容易上手。\n\n但是，想要大规模使用起来，无论开发方面还是运维方面，都需要对OpenTSDB有更多的了解。\n\n这里，我们只简单的介绍了OpenTSDB的工作原理以及安装，更多相关内容将在以后讨论。\n\n\n\n\n\n参考：  \nhttp://opentsdb.net/overview.html  \nhttp://opentsdb.net/docs/build/html/installation.html#id1', '0', '<h1 id=\"h1-opentsdb-\"><a name=\"OpenTSDB简介及安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>OpenTSDB简介及安装</h1><h2 id=\"h2-u7B80u4ECB\"><a name=\"简介\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>简介</h2><h3 id=\"h3-u5DE5u4F5Cu539Fu7406\"><a name=\"工作原理\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>工作原理</h3><p>OpenTSDB是一个时间序列数据库，由一个 <strong>Time Series Daemon (TSD)</strong> 和一系列命令行实用程序组成。与OpenTSDB交互主要通过运行一个或者多个 TSD 来实现。每个 TSD 是独立的。没有master，没有共享状态，所以你可以运行尽可能多的 TSD 来处理工作负载。每个 TSD 使用开源数据库 <a href=\"http://hbase.apache.org/\">HBase</a> 或托管Google Bigtable服务来存储和检索时间序列数据。数据模式针对类似时间序列的快速聚合进行了高度优化，以最大限度的减少存储空间。TSD 的用户不需要直接访问底层仓库。你可以通过简单的telnet样式协议，HTTP API 或者简单的内置 GUI 与 TSD 进行通信。所有的通信都发生在同一个端口上(TSD 通过查看接收到的前几个字节来计算出客户端的协议)。</p>\n<p><img src=\"http://opentsdb.net/img/tsdb-architecture.png\" alt=\"image\"></p>\n<h2 id=\"h2-u5B89u88C5\"><a name=\"安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装</h2><p>这里，我们使用CRH平台中的HBase服务为OpenTSDB存储和检索时间序列数据。<br>操作系统为Centos7，CPU架构为x86。<br>从 <a href=\"https://github.com/OpenTSDB/opentsdb/releases\">OpenTSDB下载地址</a> 选择合适的版本下载。这里我们以 opentsdb-2.3.0.rpm 为例。</p>\n<h4 id=\"h4--hbase\"><a name=\"部署HBase\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>部署HBase</h4><p>部署CRH平台的HDFS，ZOOKEEPER以及HBASE服务。详情请参考CRH部署文档。</p>\n<h4 id=\"h4--opentsdb\"><a name=\"安装OpenTSDB\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装OpenTSDB</h4><p>将opentsdb安装包下载到本地：</p>\n<pre><code>wget https://github.com/OpenTSDB/opentsdb/releases/download/v2.3.0/opentsdb-2.3.0.rpm\n</code></pre><p>执行以下命令进行安装：</p>\n<pre><code>yum localinstall opentsdb-2.3.0.rpm\n</code></pre><p>OpenTSDB主要目录介绍：</p>\n<ul>\n<li>/etc/opentsdb —— 配置文件目录</li><li>/usr/share/opentsdb —— 应用程序目录</li><li>/usr/share/opentsdb/bin —— “tsdb”启动脚本目录</li><li>/usr/share/opentsdb/lib —— Java JAR library</li><li>/usr/share/opentsdb/plugins —— 插件和依赖</li><li>/usr/share/opentsdb/static —— GUI 静态文件</li><li>/usr/share/opentsdb/tools —— 脚本和其他工具</li><li>/var/log/opentsdb —— 日志存放目录</li></ul>\n<p>安装包安装后包括一个init脚本 <em>/etc/init.d/opentsdb</em> ，此脚本可以 <em>start</em>，<em>stop</em> 和 <em>restart</em> OpenTSDB。简单地调用 <strong>service opentsdb start</strong> 启动和 <strong>service opentsdb stop</strong> 关闭。</p>\n<blockquote>\n<p>注意，在安装之后，tsd 将不是运行状态，所以你能够编辑配置文件。编辑配置文件，然后启动 TSD。</p>\n</blockquote>\n<h4 id=\"h4-u5EFAu8868\"><a name=\"建表\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>建表</h4><p>如果你第一次用你的HBase实例运行OpenTSDB，你需要创建必要的HBase表。使用 <em>/usr/share/opentsdb/tools/create_table.sh</em> 脚本可以轻松建表。执行：</p>\n<pre><code>cd /usr/share/opentsdb/tools\nenv COMPRESSION=NONE HBASE_HOME=/usr/crh/current/hbase-master ./create_table.sh\n</code></pre><blockquote>\n<p>COMPRESSION参数指定压缩方式，可选值是 NONE，LZO，GZIP，或者 SNAPPY 。这个命令将在指定的HBase中创建四张表：tsdb, tsdb-uid, tsdb-tree 和 tsdb-meta。如果你只是评估OpenTSDB，现在就不用关心压缩方式。在生产环境中，你要使用一个最合适的有效压缩库。</p>\n</blockquote>\n<h4 id=\"h4-u914Du7F6E\"><a name=\"配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置</h4><p>编辑 <em>/etc/opentsdb/opentsdb.conf</em> 配置文件：</p>\n<pre><code>tsd.storage.hbase.zk_basedir = /hbase-unsecure\ntsd.storage.hbase.zk_quorum = xwd1:2181,xwd2:2181,xwd3:2181\n</code></pre><blockquote>\n<p>提示：<em>tsd.storage.hbase.zk_basedir</em> 属性值参考 HBase 属性 <em>zookeeper.znode.parent</em> 的值；<em>tsd.storage.hbase.zk_quorum</em> 属性值为以逗号分隔的要连接的zookeeper节点主机列表，格式如上。</p>\n</blockquote>\n<p>其他配置信息请参考 <a href=\"http://opentsdb.net/docs/build/html/user_guide/configuration.html\">配置说明</a></p>\n<h4 id=\"h4--tsd\"><a name=\"启动一个 TSD\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>启动一个 TSD</h4><p>当完成以上配置后，就可以启动 TSD 了：</p>\n<pre><code>servie opentsdb start\n</code></pre><blockquote>\n<p>如果 <strong>service opentsdb start</strong> 命令报错，可以直接使用 <strong>/usr/share/opentsdb/etc/init.d/opentsdb start</strong>，其他命令亦同。</p>\n</blockquote>\n<p>在成功启动之后，就可以通过 <a href=\"http://127.0.0.1:4242\">http://127.0.0.1:4242</a> (如果这个TSD运行在你的本地机器上)访问 TSD 的web界面。</p>\n<h2 id=\"h2-u603Bu7ED3\"><a name=\"总结\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>总结</h2><p>可以看出来，OpenTSDB的安装还是很简单的，当前版本的配置属性也不是很多，应该很容易上手。</p>\n<p>但是，想要大规模使用起来，无论开发方面还是运维方面，都需要对OpenTSDB有更多的了解。</p>\n<p>这里，我们只简单的介绍了OpenTSDB的工作原理以及安装，更多相关内容将在以后讨论。</p>\n<p>参考：<br><a href=\"http://opentsdb.net/overview.html\">http://opentsdb.net/overview.html</a><br><a href=\"http://opentsdb.net/docs/build/html/installation.html#id1\">http://opentsdb.net/docs/build/html/installation.html#id1</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('6', '0', 'spark用户使用指南', '14', '2018-01-23 17:17:18', '此文档是spark开发的用户使用指南', null, '0', '579', null, null, '2018-01-23 17:17:18', null, null, null, '0', '0', '0', '0', '# 快速启动spark\n**关于这一部分**\n\nApache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是——Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。\n在Spark 2.0之前，Spark的主要编程接口是具有弹性的分布式数据集(RDD)。在Spark 2.0之后，RDDs被数据集取代，数据集就像RDD一样强类型，但在底层有更丰富的优化。\n## Spark Shell的交互分析\nSpark的shell提供了一种学习API的简单方法，同时还提供了一种强大的工具，可以交互式地分析数据。它可以在Scala中(在JavaVM上运行，因此是使用现有Java库的好方法)或Python。启动它，在Spark目录中运行以下内容\n\n```\n./bin/spark-shell\n```\nSpark的主要抽象是一个称为数据集的项目的分布式集合。数据集可以从Hadoop inputformat(比如HDFS文件)中创建，也可以通过转换其他数据集来创建。让我们从Spark源目录中的README文件的文本中创建一个新的数据集:\n\n```\nscala> val textFile = spark.read.textFile(\"README.md\")\n```\n您可以通过调用一些操作来直接从数据集获得值，或者转换数据集以获得一个新的值:\n\n```\nscala> textFile.count() //这个数据集中的项目数量\nscala> textFile.first()//这个数据集的第一项\n```\n现在让我们将这个数据集转换为一个新的数据集。我们调用filter来返回一个新的数据集，其中有文件中条目的子集。\n\n```\nscala> val linesWithSpark = textFile.filter(line => line.contains(\"Spark\"))\n```\n我们可以将转换和动作链接在一起:\n\n```\nscala> textFile.filter(line => line.contains(\"Spark\")).count()\n```\n## spark其他的数据操作\n数据集动作和转换可以用于更复杂的计算。假设我们想要找到最符合要求的一行:\n\n```\nscala> textFile.map(line => line.split(\" \").size).reduce((a,b) => if (a > b) a else b)\n```\n这首先将一条线映射到一个整型值，创建一个新的数据集。在该数据集上调用reduce，以找到最大的单词计数。映射和减少的参数是Scala函数字面量(闭包)，可以使用任何语言特性或Scala/java库。例如，我们可以很容易地调用其他地方声明的函数。我们将使用math.max()函数使这段代码更容易理解:\n\n```\nscala> import java.lang.Math\nimport java.lang.Math\nscala> textFile.map(line => line.split(\" \").size).reduce((a, b) => Math.max(a, b))\n```\n一个常见的数据流模式是MapReduce，它是由Hadoop普及的。Spark可以很容易地实现MapReduce流:\n\n```\nscala> val wordCounts = textFile.flatMap(line => line.split(\" \")).groupByKey(identity).count()\n```\n在这里，我们调用flatMap，将行数据集转换为单词的数据集，然后将groupByKey和count组合起来，计算文件中的每个单词计数，作为一个(字符串，长)对的数据集。在我们的shell中收集单词计数，我们可以调用收集:\n\n```\nscala> wordCounts.collect()\n```\n## spark缓存\nSpark还支持将数据集拉到集群范围内的内存缓存中。当数据被多次访问时，这是非常有用的，例如在查询一个小的“hot”数据集或者运行像PageRank这样的迭代算法时。作为一个简单的例子，让我们标记一下我们的linesWithSpark数据集来缓存:\n\n```\nscala> linesWithSpark.cache()\nscala> linesWithSpark.count()\nscala> linesWithSpark.count()\n```\n# spark  RDD编程\n> **概述:**\n\n> 在高层次上，每个Spark应用程序都包含一个驱动程序，该程序运行用户的主要功能，并在集群上执行各种并行操作。主要的抽象火花提供了一个有弹性的分布式数据集(RDD)，它是一个可以并行操作的集群节点上划分的元素集合。RDDs是通过在Hadoop文件系统(或任何其他Hadoop支持的文件系统)中的文件开始创建的，或者在驱动程序中使用现有的Scala集合，并对其进行转换。用户还可以要求Spark在内存中持久化一个RDD，这样就可以在并行操作中有效地重用它。最后，RDDs会自动从节点故障中恢复。\n> Spark的第二个抽象是可以在并行操作中使用的共享变量。默认情况下，当Spark在不同的节点上并行地运行一个函数时，它会将函数中使用的每个变量的副本都复制到每个任务中。有时，需要在任务之间共享一个变量，或者在任务和驱动程序之间共享一个变量。Spark支持两种类型的共享变量:广播变量，它可以用于在所有节点上缓存一个值，以及累计变量，这些变量只被“添加”到计数器和求和等变量中。\n\n## spark shell使用\n\n在Spark shell中，在名为sc的变量中已经为您创建了一个特殊的解释器感知的SparkContext，使您自己的SparkContext无法工作。您可以设置上下文连接使用-主参数的主上下文，您可以通过将一个逗号分隔的列表传递给--jars参数，将jar添加到类路径中。您还可以通过向--packages参数提供一个逗号分隔的Maven坐标列表，任何依赖项可能存在的附加存储库(例如Sonatype)都可以传递给--repositores参数。例如，要在运行/spark-shell，请使用:\n\n\n```\n$ ./bin/spark-shell --master local[4]\n```\n或者, 添加 code.jar 包在使用路径, 请使用:\n\n```\n$ ./bin/spark-shell --master local[4] --jars code.jar\n```\n使用Maven坐标包含依赖项:\n\n```\n$ ./bin/spark-shell --master local[4] --packages \"org.example:example:0.1\"\n```\n> 注意：对于一个完整的选项列表，运行spark-shell --help。\n## spark 外部数据集\n\nSpark可以从Hadoop支持的任何存储源中创建分布式数据集，包括本地文件系统、HDFS、Cassandra、HBase、Amazon S3等等。Spark支持文本文件、序列文件和任何其他Hadoop InputFormat。\n可以使用SparkContext的textFile方法创建文本文件RDDs。该方法获取文件的URI(或者是机器上的本地路径，或者是hdfs://、s3n://等等URI)，并将其作为行的集合读取。下面是一个示例调用:\n\n```\nscala> val distFile = sc.textFile(\"data.txt\")\n```\n一旦创建，distFile就可以由数据集操作来执行。例如，我们可以使用映射来添加所有行的大小，并减少操作，如下：\n\n```\ndistFile.map(s => s.length).reduce((a, b) => a + b).\n```\n## spark RDD操作\nRDDs支持两种类型的操作:转换，它从现有的一个中创建一个新的数据集，以及操作，它在数据集上运行一个计算之后，将一个值返回给驱动程序。例如，map是一个转换，它通过一个函数传递每个数据集元素，并返回一个表示结果的新RDD。另一方面，reduce是一个使用某个函数聚合所有RDD元素的动作，并将最终结果返回给驱动程序(尽管也有一个并行的还原ebykey返回一个分布式数据集)。\nSpark中的所有转换都是惰性的，因为它们不会立即计算结果。相反，它们只记住应用于一些基本数据集(例如一个文件)的转换。只有当一个动作需要返回到驱动程序的结果时，才会计算转换。这种设计使Spark能够更高效地运行。例如，我们可以认识到，通过map创建的数据集将被用于减少，只返回到驱动程序的结果，而不是更大的映射数据集。\nSpark的API严重依赖于驱动程序中的传递函数来在集群上运行。有两种推荐的方法:\n\n1. 匿名函数语法，它可以用于简短的代码。\n2. 全局单例对象中的静态方法。例如，您可以定义对象my函数，然后传递my函数。func1,如下所示:\n\n```\nobject MyFunctions {\n  def func1(s: String): String = { ... }\n}\nmyRdd.map(MyFunctions.func1)\n```\n3.请注意，虽然可以在类实例中传递对方法的引用(而不是单例对象)，但这需要发送包含该类的对象和方法。例如,考虑:\n\n```\nclass MyClass {\n  def func1(s: String): String = { ... }\n  def doStuff(rdd: RDD[String]): RDD[String] = { rdd.map(func1) }\n}\n```\n## RDD的基础数据类型\n**并行集合**\n\n并行集合（Parallelized collections）的创建是通过一个已有的集合（Scala Seq）上调用SparkContext的parallelize方法实现的。集合中的元素被复制到一个可并行操作的分布式数据集中，例如：这里演示了如何一个包含1到5数组种创建并行集合：\n\n```\nVal data=Array(1,2,3,4,5)\nVal distData=sc.parallelize(data)\n```\n一旦创建完成，这个分布式数据集（distData）就可以被并行操作，例如：我们可以调用distData.reduce(a,b)=>a+b,将这个数组中的元素相加，我们以后在描述在分布式上的一些操作。\n并行集合一个很重要的参数是切片书（slices），表示一个数据集切分的分数，Spark会在集群上运行一个任务。你可以在集群上为每个CPU设置2-4个切片（slices），正常情况下，Spark会试着基于你的集群状况自动地设置切片的数目，然而，你也可以通过parallelize的第二个参数手动地设置（例如：sc.parallelize(data,10)）。\n\n**外部数据集**\n\nSpark可以从任何一个Hadoop支持的存储源创建分布式数据集，包括你的本地文件系统，HDFS，Cassandra，HBase，Amazon S3等，Spark支持文本文件（text files），SequenceFiles和其他Hadoop InputFormat。\n文本文件RDDs可以使用SparkContext的textFile方法创建，在这个方法里传入文件的URI（机器上的本地路径或hdfs：//,s3n://等），然后他会将文件读取成一个行集合，这里是一个调用例子：\n\n```\nScala> val distFile=sc.textFile(“data.txt”)\n```\n## RDD使用\nRDD actions和tranformations能被用在更多的复杂计算中，比方说，我们想要找到一行中最多的单词数量：\n\n```\nscala> textFile.map(line => line.split(\" \").size).reduce((a, b) => if (a > b) a else b)\n```\n首先履行映射成一个整形数值产生一个新RDD上调用reduce找到行中最大的个数，map和reduce的参数是Scala的函数串（闭包），并且可以使用任何语言特性或者Scala/Java类库，例如，我们可以很方便的调用其他的函数声明，我们使用Math.max()函数让代码更容易理解：\n\n\n```\nscala> import java.lang.Math\nimport java.lang.Math\nscala> textFile.map(line => line.split(\" \").size).reduce((a, b) => Math.max(a, b))\nres5：Int=15\n```\nHadoop流行的一个通用的数据流模式是MapReduce。Spark能够很容易的实现MapReduce\n\n```\nscala> val wordCounts = textFile.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey((a, b) => a + b)\n```\n这里，我们结合flatMap，map和reduceByKey来计算文件里每个单词出现的数量，他的结果是包含一组（String，int）键值对的RDD，我们可以使用[collect]操作在我们的shell中手机单词的数量：\n\n```\nscala> wordCounts.collect()\n```\n# spark SQL使用\n> 概述\n\n> Spark SQL是结构化数据处理的Spark模块。与基本的Spark RDD API不同，Spark SQL提供的接口提供了关于数据的结构和正在执行的计算的更多信息。在内部，Spark SQL使用这些额外的信息执行额外的优化。有几种方法可以与Spark SQL进行交互，其中包括SQL和Dataset API。当计算结果时，使用相同的执行引擎，独立于您使用的api/语言来表示计算。这种统一意味着开发人员可以很容易地在不同的api之间来回切换，这提供了最自然的方式来表达给定的转换。\n\n## Starting Point: SparkSession\nSpark中所有功能的入口点是SparkSession类。要创建一个基本的SparkSession，只需使用SparkSession.builder():\n\n```\nimport org.apache.spark.sql.SparkSession\nval spark = SparkSession\n  .builder()\n  .appName(\"Spark SQL basic example\")\n  .config(\"spark.some.config.option\", \"some-value\")\n  .getOrCreate()\n//对于隐式转换，比如将rdd转换为DataFrames\nimport spark.implicits._\n```\n## 创建DataFrames\n通过一个SparkSession，应用程序可以从一个现有的RDD中创建DataFrames，从一个Hive表，或者从Spark数据源。\n作为一个示例，下面创建一个基于JSON文件内容的DataFrame:\n\n```\nval df = spark.read.json(\"examples/src/main/resources/people.json\")\n// Displays the content of the DataFrame to stdout\ndf.show()\n```\nDataFrames为在Scala、Java、Python和r中的结构化数据操作提供了一种领域特有的语言。\n如前所述，在Spark 2.0中，DataFrames只是Scala和Java API中的行数据集。这些操作也被称为“非类型转换”，与“类型转换”形成鲜明对比的是强类型的scala/java数据集。\n\n这里我们包括一些使用数据集的结构化数据处理的基本示例:\n\n```\nimport spark.implicits._\ndf.printSchema()\ndf.select(\"name\").show()\ndf.select($\"name\", $\"age\" + 1).show()\ndf.filter($\"age\" > 21).show()\ndf.groupBy(\"age\").count().show()\n\n```\n除了简单的列引用和表达式之外，Datasets还有一个丰富的函数库，包括字符串操作、日期算术、常见的数学运算等等。完整的列表在DataFrame函数引用中可用。\n## 以编程方式运行SQL查询\nSparkSession中的sql函数使应用程序能够以编程的方式运行sql查询，并将结果作为DataFrame返回。\n\n```\n//将DataFrame注册为一个SQL临时视图\ndf.createOrReplaceTempView(\"people\")\nval sqlDF = spark.sql(\"SELECT * FROM people\")\nsqlDF.show()\n```\n\n**全局临时视图**\n\nSpark SQL中的临时视图是会话范围的，如果创建它的会话终止，则会消失。如果您想要在所有会话中共享一个临时视图，并在Spark应用程序终止之前保持活力，您可以创建一个全局临时视图。全局临时视图绑定到一个系统保存的数据库globaltemp，我们必须使用限定名来引用它，e.g. SELECT * FROM global_temp.view1.\n\n\n```\n//将DataFrame注册为全局临时视图\ndf.createGlobalTempView(\"people\")\n//全局临时视图绑定到一个系统保存的数据库globaltemp\nspark.sql(\"SELECT * FROM global_temp.people\").show()\n//全局临时视图是交叉会话\nspark.newSession().sql(\"SELECT * FROM global_temp.people\").show()\n\n```\n**创建数据集**\n\n然而，数据集与RDDs类似，而不是使用Java序列化或Kryo，它们使用专门的编码器来序列化对象，以便在网络上进行处理或传输。虽然编码器和标准序列化都负责将对象转换为字节，但编码器是动态生成的代码，并且使用一种格式，允许Spark执行许多操作，如过滤、排序和散列，而不将字节反序列化为对象。\n\n```\n//您可以使用实现产品接口的自定义类\ncase class Person(name: String, age: Long)\n//为案例类创建编码器\nval caseClassDS = Seq(Person(\"Andy\", 32)).toDS()\ncaseClassDS.show()\n//大多数常见类型的编码器是通过引入spark.implicits自动提供的._\nval primitiveDS = Seq(1, 2, 3).toDS()\nprimitiveDS.map(_ + 1).collect() // Returns: Array(2, 3, 4)\n//通过提供一个类，可以将DataFrames转换为数据集。映射将通过名称进行\nval path = \"examples/src/main/resources/people.json\"\nval peopleDS = spark.read.json(path).as[Person]\npeopleDS.show()\n```\n**使用反射推断模式**\n\nSpark SQL的Scala接口支持自动将包含case类的RDD转换为DataFrame。case类定义了表的模式。对case类的参数的名称是使用反射读取的，并成为列的名称。Case类也可以嵌套或包含复杂的类型，例如Seqs或数组。这个RDD可以隐式地转换为一个DataFrame，然后将其注册为一个表。表可以在后续的SQL语句中使用。\n\n```\n	import spark.implicits._\nval peopleDF = spark.sparkContext\n  .textFile(\"examples/src/main/resources/people.txt\")\n  .map(_.split(\",\"))\n  .map(attributes => Person(attributes(0), attributes(1).trim.toInt))\n  .toDF()\n//将DataFrame注册为一个临时视图\npeopleDF.createOrReplaceTempView(\"people\")\n//可以使用Spark提供的SQL方法来运行SQL语句\nval teenagersDF = spark.sql(\"SELECT name, age FROM people WHERE age BETWEEN 13 AND 19\")\n//结果中的列的列可以通过字段索引来访问\nteenagersDF.map(teenager => \"Name: \" + teenager(0)).show()\nteenagersDF.map(teenager => \"Name: \" + teenager.getAs[String](\"name\")).show()\nimplicit val mapEncoder = org.apache.spark.sql.Encoders.kryo[Map[String, Any]]\n//基本类型和case类也可以定义为\n// implicit val stringIntMapEncoder: Encoder[Map[String, Any]] = ExpressionEncoder()\n// row.getValuesMap[T] retrieves multiple columns at once into a Map[String, T]\nteenagersDF.map(teenager => teenager.getValuesMap[Any](List(\"name\", \"age\"))).collect()\n```\n## 以编程的方式指定模式\n当case类不能提前定义时(例如，记录的结构是在一个字符串中编码的，或者文本数据集将被解析，不同的用户将对字段进行不同的预测)，一个DataFrame可以用3个步骤来创建。\n1. 从原始的RDD中创建一个行;\n2. 创建在第1步中创建的RDD中所表示的结构类型的结构类型。\n3. 通过SparkSession提供的createDataFrame方法将模式应用到行的RDD中。\n\n```\nimport org.apache.spark.sql.types._\n// 创建一个RDD\nval peopleRDD = spark.sparkContext.textFile(\"examples/src/main/resources/people.txt\")\n// 模式是用字符串编码的\nval schemaString = \"name age\"\n// 根据模式的字符串生成模式\nval fields = schemaString.split(\" \")\n .map(fieldName => StructField(fieldName, StringType, nullable = true))\nval schema = StructType(fields)\n// 将RDD(人员)的记录转换为行\nval rowRDD = peopleRDD\n  .map(_.split(\",\"))\n  .map(attributes => Row(attributes(0), attributes(1).trim))\n// 将该模式应用于RDD\nval peopleDF = spark.createDataFrame(rowRDD, schema)\n// 使用DataFrame创建一个临时视图\npeopleDF.createOrReplaceTempView(\"people\")\n// 可以通过使用DataFrames创建的临时视图来运行SQL\nval results = spark.sql(\"SELECT name FROM people\")\n// SQL查询的结果是DataFrames并支持所有常规的RDD操作\n// 结果中的列的列可以通过字段索引或字段名来访问。\nresults.map(attributes => \"Name: \" + attributes(0)).show()\n```\n## 聚合函数\n内置的DataFrames函数提供了诸如count()、countDistinct ()、avg()、max()、min()等公共聚合，而这些函数都是为DataFrames设计的，Spark SQL也为Scala和Java中的一些提供了类型安全的版本，用于与强类型数据集一起工作。此外，用户不仅限于预定义的聚合函数，而且可以创建自己的聚合函数。\n\n**无类型定义的聚合函数**\n\n用户必须扩展UserDefinedAggregateFunction抽象类实现一个自定义的无类型的聚合函数。例如，用户定义的平均值可以是这样的:\n\n\n```\nimport org.apache.spark.sql.expressions.MutableAggregationBuffer\nimport org.apache.spark.sql.expressions.UserDefinedAggregateFunction\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.SparkSession\nobject MyAverage extends UserDefinedAggregateFunction {\n  // 这个聚合函数的输入参数的数据类型\n  def inputSchema: StructType = StructType(StructField(\"inputColumn\", LongType) :: Nil)\n  // 聚合缓冲区中的值的数据类型\n  def bufferSchema: StructType = {\n    StructType(StructField(\"sum\", LongType) :: StructField(\"count\", LongType) :: Nil)\n  }\n  // 返回值的数据类型  \ndef dataType: DataType = DoubleType\n  // 这个函数是否总是在相同的输入上返回相同的输出\n  def deterministic: Boolean = true\n  // 初始化给定的聚合缓冲区。缓冲区本身是一个行，除了\n  // 标准方法，例如检索索引中的值(例如get()、getBoolean())\n  // 更新它的价值的机会。注意，缓冲区内的数组和映射仍然是  \n// 不变的.\n  def initialize(buffer: MutableAggregationBuffer): Unit = {\n    buffer(0) = 0L\n    buffer(1) = 0L\n  }\n  // 使用来自输入的新输入数据更新给定的聚合缓冲区缓冲区  \ndef update(buffer: MutableAggregationBuffer, input: Row): Unit = {\n    if (!input.isNullAt(0)) {\n      buffer(0) = buffer.getLong(0) + input.getLong(0)\n      buffer(1) = buffer.getLong(1) + 1\n    }\n  }\n  // 合并两个聚合缓冲区，并将更新后的缓冲区值存储到buffer1\n  def merge(buffer1: MutableAggregationBuffer, buffer2: Row): Unit = {\n    buffer1(0) = buffer1.getLong(0) + buffer2.getLong(0)\n    buffer1(1) = buffer1.getLong(1) + buffer2.getLong(1)\n  }\n  // 计算出最终结果  \ndef evaluate(buffer: Row): Double = buffer.getLong(0).toDouble / buffer.getLong(1)\n}\n// 注册该函数以访问它\nspark.udf.register(\"myAverage\", MyAverage)\nval df = spark.read.json(\"examples/src/main/resources/employees.json\")\ndf.createOrReplaceTempView(\"employees\")\ndf.show()\nval result = spark.sql(\"SELECT myAverage(salary) as average_salary FROM employees\")\nresult.show()\n\n```\n**类型安全的用户定义的聚合函数**\n\n对于强类型数据集的用户定义聚合是围绕聚集器抽象类进行的。例如，类型安全的用户定义的平均值可以是这样的:\n\n\n```\nimport org.apache.spark.sql.expressions.Aggregator\nimport org.apache.spark.sql.Encoder\nimport org.apache.spark.sql.Encoders\nimport org.apache.spark.sql.SparkSession\ncase class Employee(name: String, salary: Long)\ncase class Average(var sum: Long, var count: Long)\nobject MyAverage extends Aggregator[Employee, Average, Double] {\n  // 这个聚合的零值。应该满足任意b+0=b的性质\n  def zero: Average = Average(0L, 0L)\n  // 结合两个值来生成一个新值。对于性能，函数可以修改缓冲区 \n // 然后返回，而不是新建一个对象\n  def reduce(buffer: Average, employee: Employee): Average = {\n    buffer.sum += employee.salary\n    buffer.count += 1\n    buffer\n  }\n  // 合并两个中间值\n  def merge(b1: Average, b2: Average): Average = {\n    b1.sum += b2.sum\n    b1.count += b2.count\n    b1\n  }\n  // 转换输出的输出\n  def finish(reduction: Average): Double = reduction.sum.toDouble / reduction.count\n  // 指定中间值类型的编码器\n  def bufferEncoder: Encoder[Average] = Encoders.product\n  // 指定最终输出值类型的编码器  \ndef outputEncoder: Encoder[Double] = Encoders.scalaDouble\n}\nval ds = spark.read.json(\"examples/src/main/resources/employees.json\").as[Employee]\nds.show()\n// 将函数转换为TypedColumn并给它起一个名字\nval averageSalary = MyAverage.toColumn.name(\"average_salary\")\nval result = ds.select(averageSalary)\nresult.show()\n```\n**数据源**\n\nSpark SQL支持通过DataFrame接口对各种数据源进行操作。DataFrame可以使用关系转换操作，也可以用来创建临时视图。将一个DataFrame注册为一个临时视图允许您在其数据上运行SQL查询。本节描述使用Spark数据源加载和保存数据的一般方法，然后进入用于内置数据源的特定选项。\n\n\n**通用的加载/保存功能**\n\n在最简单的形式中,默认数据源(由spark.sql.sources.default拼花,除非另有配置)将用于所有操作。\n\n\n```\nval usersDF = spark.read.load(\"examples/src/main/resources/users.parquet\")\nusersDF.select(\"name\", \"favorite_color\").write.save(\"namesAndFavColors.parquet\")\n```\n**手动指定选项**\n\n您还可以手动指定将使用的数据源，以及您想要传递给数据源的任何额外选项。数据源由其完全限定的名称(即:org.apache.spark.sql.parquet),但对于内置的来源还可以使用短名称(json、jdbc、csv、文本)。从任何数据源类型加载的DataFrames都可以使用这种语法转换为其他类型。\n\n\n```\nval peopleDF = spark.read.format(\"json\").load(\"examples/src/main/resources/people.json\")\npeopleDF.select(\"name\", \"age\").write.format(\"parquet\").save(\"namesAndAges.parquet\")\n```\n\n**直接在文件上运行SQL**\n\n您可以使用SQL来直接查询该文件，而不是使用read API将文件加载到DataFrame并查询它。\n\n\n```\nval sqlDF = spark.sql(\"SELECT * FROM parquet.`examples/src/main/resources/users.parquet`\")\n```\n\n## Bucketing, Sorting and Partitioning\n\n对于基于文件的数据源，还可以对输出进行存储、排序或分区。嵌接和排序仅适用于持久表:\n\n\n```\npeopleDF.write.bucketBy(42, \"name\").sortBy(\"age\").saveAsTable(\"people_bucketed\")\n```\n\n在使用数据集api时，可以同时使用分区和save。\n\n\n```\nusersDF.write.partitionBy(\"favorite_color\").format(\"parquet\").save(\"namesPartByColor.parquet\")\n```\n\n对于单个表，可以使用分区和嵌接:\n\n\n```\npeopleDF\n  .write\n  .partitionBy(\"favorite_color\")\n  .bucketBy(42, \"name\")\n  .saveAsTable(\"people_partitioned_bucketed\")\n```\n\n分区创建一个目录结构，正如在分区发现节中所描述的那样。因此，它对具有高基数的列的适用性有限。相反，bucketa将数据分布在固定数量的桶中，当许多惟一值是无界的时，可以使用它。\n\n# 结构化流编程\n\n> 结构化流是一个可伸缩的、容错的流处理引擎，构建在Spark SQL引擎上。您可以用相同的方式表示流计算，就像在静态数据上表示批处理一样。Spark SQL引擎将会逐渐地、持续地运行它，并在流数据继续到达时更新最终结果。您可以使用Scala、Java、Python或R中的dataset/dataframe API来表示流媒体聚合、事件时间窗口、流到批连接等等，这些计算都是在同一个优化的Spark SQL引擎上执行的。最后，系统确保了端到端的端对端容错保证，通过检查点和写前面的日志。简而言之，结构化流提供了快速、可伸缩的、容错的、端到端的即时处理，而无需用户去考虑流媒体。\n\n\n## 简单的例子\n\n假设您想要维护从一个数据服务器接收到的一个正在运行的文本数据，而这个数据服务器是通过TCP套接字监听的。让我们看看如何使用结构化的流媒体来表达这个问题。如果你下载Spark，你可以直接运行这个例子。在任何情况下，让我们一步一步地了解这个示例，并了解它是如何工作的。首先，我们必须导入必要的类并创建一个局部SparkSession，这是与Spark相关的所有功能的起点。\n\n\n```\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.SparkSession\nval spark = SparkSession\n  .builder\n  .appName(\"StructuredNetworkWordCount\")\n  .getOrCreate()\nimport spark.implicits._\n```\n\n接下来，让我们创建一个流数据的DataFrame，它表示从服务器接收到的服务器上接收的文本数据，并将DataFrame转换为计算单词计数。\n\n\n```\n//创建来自连接到localhost:9999的输入行流的DataFrame\nval lines = spark.readStream\n  .format(\"socket\")\n  .option(\"host\", \"localhost\")\n  .option(\"port\", 9999)\n  .load()\nval words = lines.as[String].flatMap(_.split(\" \"))\nval wordCounts = words.groupBy(\"value\").count()\n```\n\n现在，我们已经对流数据进行了查询。剩下的就是开始接收数据并计算计数。要做到这一点，我们设置它来打印完整的计数集(outputMode(“complete”)指定，每次更新时都要输出到控制台。然后使用start()启动流计算。\n\n\n```\n// 开始运行将运行计数打印到控制台的查询\nval query = wordCounts.writeStream\n  .outputMode(\"complete\")\n  .format(\"console\")\n  .start()\nquery.awaitTermination()\n```\n\n在执行该代码之后，流计算将在后台启动。查询对象是一个对该活动流查询的句柄，我们已经决定使用瓦伊终止()等待查询的终止，以防止在查询处于活动状态时退出进程。\n要实际执行这个示例代码，您可以在自己的Spark应用程序中编译代码，也可以在下载Spark后运行这个示例。我们展示的是后者。您首先需要运行Netcat(在大多数类unix系统中发现的一个小型实用程序)作为数据服务器\n\n\n```\n$ nc -lk 9999\n```\n\n然后，在一个不同的终端中，您可以通过使用\n\n\n```\n$ ./bin/run-example org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount localhost 9999\n```\n\n然后，在运行netcat服务器的终端中输入的任何行都将被计数并在屏幕上打印。\n\n# spark streaming编程\n\nSpark流是核心Spark API的一个扩展，它支持可伸缩、高吞吐量、容错的实时数据流处理。数据可以从许多来源中摄取，比如卡夫卡、Flume、kin遥感或TCP套接字，并且可以使用复杂的算法来处理，这些算法使用高级功能，如map、reduce、join和window。最后，处理的数据可以被推送到文件系统、数据库和实时指示板。实际上，您可以在数据流上应用Spark的机器学习和图形处理算法。\n\n![image](http://spark.apache.org/docs/latest/img/streaming-arch.png)\n\n在内部，它是这样工作的。Spark流接收实时的输入数据流，并将数据分成几批，然后由Spark引擎处理，以批量生成最终的结果流。\n\n![image](http://spark.apache.org/docs/latest/img/streaming-flow.png)\n\nSpark流提供了一个称为离散流或DStream的高级抽象，它代表了连续的数据流。DStreams可以从诸如卡夫卡、Flume和kinor等来源的输入数据流中创建，也可以通过在其他DStreams上应用高级操作来创建。在内部，DStream被表示为一个RDDs的序列。\n\n**一个简单的例子**\n\n首先，我们导入了Spark流类的名称，以及从StreamingContext到我们的环境中的一些隐式转换，以便向我们需要的其他类添加有用的方法(如DStream)。StreamingContext是所有流媒体功能的主要入口点。我们使用两个执行线程创建一个本地流上下文，一个批处理间隔为1秒。\n\n\n```\nimport org.apache.spark._\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.StreamingContext._ // not necessary since Spark 1.3\n// 创建一个本地流媒体上下文，使用两个工作线程和一个1秒的批处理间隔。.\nval conf = new SparkConf().setMaster(\"local[2]\").setAppName(\"NetworkWordCount\")\nval ssc = new StreamingContext(conf, Seconds(1))\n```\n\n使用这个上下文，我们可以创建一个DStream，它表示来自TCP源的流数据，指定为主机名(例如localhost)和端口(例如9999)。\n\n\n```\nval lines = ssc.socketTextStream(\"localhost\", 9999)\n```\n\n这行DStream表示将从数据服务器接收到的数据流。这个DStream中的每个记录都是一行文本。接下来，我们要将空格字符分割成单词。\n\n\n```\nval words = lines.flatMap(_.split(\" \"))\n```\n\nflatMap是一对多的DStream操作，它通过在源DStream中的每个记录生成多个新记录来创建一个新的DStream。在这种情况下，每一行将被分割成多个单词，而单词流则表示为DStream。接下来，我们要计算这些单词。\n\n\n```\nimport org.apache.spark.streaming.StreamingContext._ \n// 在每批中计算每个单词\nval pairs = words.map(word => (word, 1))\nval wordCounts = pairs.reduceByKey(_ + _)\n// 将这个DStream中生成的每个RDD的前10个元素打印到控制台\nwordCounts.print()\n```\n\n当这些行被执行时，Spark流只会设置它在启动时将执行的计算，并且还没有开始真正的处理。在所有转换设置之后开始处理，我们最后调用\n\n\n```\nssc.start()             // 开始计算\nssc.awaitTermination()  // 等待计算终止\n```\n\n完整的代码可以在Spark流示例网络wordcount中找到。\n如果您已经下载并构建了Spark，那么您可以像下面这样运行这个示例。您首先需要运行Netcat(在大多数类unix系统中发现的一个小型实用程序)作为数据服务器\n\n\n```\n$ nc -lk 9999\n```\n\n然后，在一个不同的终端中，您可以通过使用\n\n\n```\n$ ./bin/run-example streaming.NetworkWordCount localhost 9999\n```\n\n然后，在运行netcat服务器的终端中输入的任何行都将被计数并在屏幕上打印。\n', '0', '<h1 id=\"h1--spark\"><a name=\"快速启动spark\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>快速启动spark</h1><p><strong>关于这一部分</strong></p>\n<p>Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是——Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。<br>在Spark 2.0之前，Spark的主要编程接口是具有弹性的分布式数据集(RDD)。在Spark 2.0之后，RDDs被数据集取代，数据集就像RDD一样强类型，但在底层有更丰富的优化。</p>\n<h2 id=\"h2-spark-shell-\"><a name=\"Spark Shell的交互分析\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Spark Shell的交互分析</h2><p>Spark的shell提供了一种学习API的简单方法，同时还提供了一种强大的工具，可以交互式地分析数据。它可以在Scala中(在JavaVM上运行，因此是使用现有Java库的好方法)或Python。启动它，在Spark目录中运行以下内容</p>\n<pre><code>./bin/spark-shell\n</code></pre><p>Spark的主要抽象是一个称为数据集的项目的分布式集合。数据集可以从Hadoop inputformat(比如HDFS文件)中创建，也可以通过转换其他数据集来创建。让我们从Spark源目录中的README文件的文本中创建一个新的数据集:</p>\n<pre><code>scala&gt; val textFile = spark.read.textFile(&quot;README.md&quot;)\n</code></pre><p>您可以通过调用一些操作来直接从数据集获得值，或者转换数据集以获得一个新的值:</p>\n<pre><code>scala&gt; textFile.count() //这个数据集中的项目数量\nscala&gt; textFile.first()//这个数据集的第一项\n</code></pre><p>现在让我们将这个数据集转换为一个新的数据集。我们调用filter来返回一个新的数据集，其中有文件中条目的子集。</p>\n<pre><code>scala&gt; val linesWithSpark = textFile.filter(line =&gt; line.contains(&quot;Spark&quot;))\n</code></pre><p>我们可以将转换和动作链接在一起:</p>\n<pre><code>scala&gt; textFile.filter(line =&gt; line.contains(&quot;Spark&quot;)).count()\n</code></pre><h2 id=\"h2-spark-\"><a name=\"spark其他的数据操作\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>spark其他的数据操作</h2><p>数据集动作和转换可以用于更复杂的计算。假设我们想要找到最符合要求的一行:</p>\n<pre><code>scala&gt; textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a,b) =&gt; if (a &gt; b) a else b)\n</code></pre><p>这首先将一条线映射到一个整型值，创建一个新的数据集。在该数据集上调用reduce，以找到最大的单词计数。映射和减少的参数是Scala函数字面量(闭包)，可以使用任何语言特性或Scala/java库。例如，我们可以很容易地调用其他地方声明的函数。我们将使用math.max()函数使这段代码更容易理解:</p>\n<pre><code>scala&gt; import java.lang.Math\nimport java.lang.Math\nscala&gt; textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a, b) =&gt; Math.max(a, b))\n</code></pre><p>一个常见的数据流模式是MapReduce，它是由Hadoop普及的。Spark可以很容易地实现MapReduce流:</p>\n<pre><code>scala&gt; val wordCounts = textFile.flatMap(line =&gt; line.split(&quot; &quot;)).groupByKey(identity).count()\n</code></pre><p>在这里，我们调用flatMap，将行数据集转换为单词的数据集，然后将groupByKey和count组合起来，计算文件中的每个单词计数，作为一个(字符串，长)对的数据集。在我们的shell中收集单词计数，我们可以调用收集:</p>\n<pre><code>scala&gt; wordCounts.collect()\n</code></pre><h2 id=\"h2-spark-\"><a name=\"spark缓存\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>spark缓存</h2><p>Spark还支持将数据集拉到集群范围内的内存缓存中。当数据被多次访问时，这是非常有用的，例如在查询一个小的“hot”数据集或者运行像PageRank这样的迭代算法时。作为一个简单的例子，让我们标记一下我们的linesWithSpark数据集来缓存:</p>\n<pre><code>scala&gt; linesWithSpark.cache()\nscala&gt; linesWithSpark.count()\nscala&gt; linesWithSpark.count()\n</code></pre><h1 id=\"h1-spark-rdd-\"><a name=\"spark  RDD编程\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>spark  RDD编程</h1><blockquote>\n<p><strong>概述:</strong></p>\n<p>在高层次上，每个Spark应用程序都包含一个驱动程序，该程序运行用户的主要功能，并在集群上执行各种并行操作。主要的抽象火花提供了一个有弹性的分布式数据集(RDD)，它是一个可以并行操作的集群节点上划分的元素集合。RDDs是通过在Hadoop文件系统(或任何其他Hadoop支持的文件系统)中的文件开始创建的，或者在驱动程序中使用现有的Scala集合，并对其进行转换。用户还可以要求Spark在内存中持久化一个RDD，这样就可以在并行操作中有效地重用它。最后，RDDs会自动从节点故障中恢复。<br>Spark的第二个抽象是可以在并行操作中使用的共享变量。默认情况下，当Spark在不同的节点上并行地运行一个函数时，它会将函数中使用的每个变量的副本都复制到每个任务中。有时，需要在任务之间共享一个变量，或者在任务和驱动程序之间共享一个变量。Spark支持两种类型的共享变量:广播变量，它可以用于在所有节点上缓存一个值，以及累计变量，这些变量只被“添加”到计数器和求和等变量中。</p>\n</blockquote>\n<h2 id=\"h2-spark-shell-\"><a name=\"spark shell使用\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>spark shell使用</h2><p>在Spark shell中，在名为sc的变量中已经为您创建了一个特殊的解释器感知的SparkContext，使您自己的SparkContext无法工作。您可以设置上下文连接使用-主参数的主上下文，您可以通过将一个逗号分隔的列表传递给—jars参数，将jar添加到类路径中。您还可以通过向—packages参数提供一个逗号分隔的Maven坐标列表，任何依赖项可能存在的附加存储库(例如Sonatype)都可以传递给—repositores参数。例如，要在运行/spark-shell，请使用:</p>\n<pre><code>$ ./bin/spark-shell --master local[4]\n</code></pre><p>或者, 添加 code.jar 包在使用路径, 请使用:</p>\n<pre><code>$ ./bin/spark-shell --master local[4] --jars code.jar\n</code></pre><p>使用Maven坐标包含依赖项:</p>\n<pre><code>$ ./bin/spark-shell --master local[4] --packages &quot;org.example:example:0.1&quot;\n</code></pre><blockquote>\n<p>注意：对于一个完整的选项列表，运行spark-shell —help。</p>\n<h2 id=\"h2-spark-\"><a name=\"spark 外部数据集\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>spark 外部数据集</h2></blockquote>\n<p>Spark可以从Hadoop支持的任何存储源中创建分布式数据集，包括本地文件系统、HDFS、Cassandra、HBase、Amazon S3等等。Spark支持文本文件、序列文件和任何其他Hadoop InputFormat。<br>可以使用SparkContext的textFile方法创建文本文件RDDs。该方法获取文件的URI(或者是机器上的本地路径，或者是hdfs://、s3n://等等URI)，并将其作为行的集合读取。下面是一个示例调用:</p>\n<pre><code>scala&gt; val distFile = sc.textFile(&quot;data.txt&quot;)\n</code></pre><p>一旦创建，distFile就可以由数据集操作来执行。例如，我们可以使用映射来添加所有行的大小，并减少操作，如下：</p>\n<pre><code>distFile.map(s =&gt; s.length).reduce((a, b) =&gt; a + b).\n</code></pre><h2 id=\"h2-spark-rdd-\"><a name=\"spark RDD操作\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>spark RDD操作</h2><p>RDDs支持两种类型的操作:转换，它从现有的一个中创建一个新的数据集，以及操作，它在数据集上运行一个计算之后，将一个值返回给驱动程序。例如，map是一个转换，它通过一个函数传递每个数据集元素，并返回一个表示结果的新RDD。另一方面，reduce是一个使用某个函数聚合所有RDD元素的动作，并将最终结果返回给驱动程序(尽管也有一个并行的还原ebykey返回一个分布式数据集)。<br>Spark中的所有转换都是惰性的，因为它们不会立即计算结果。相反，它们只记住应用于一些基本数据集(例如一个文件)的转换。只有当一个动作需要返回到驱动程序的结果时，才会计算转换。这种设计使Spark能够更高效地运行。例如，我们可以认识到，通过map创建的数据集将被用于减少，只返回到驱动程序的结果，而不是更大的映射数据集。<br>Spark的API严重依赖于驱动程序中的传递函数来在集群上运行。有两种推荐的方法:</p>\n<ol>\n<li>匿名函数语法，它可以用于简短的代码。</li><li>全局单例对象中的静态方法。例如，您可以定义对象my函数，然后传递my函数。func1,如下所示:</li></ol>\n<pre><code>object MyFunctions {\n  def func1(s: String): String = { ... }\n}\nmyRdd.map(MyFunctions.func1)\n</code></pre><p>3.请注意，虽然可以在类实例中传递对方法的引用(而不是单例对象)，但这需要发送包含该类的对象和方法。例如,考虑:</p>\n<pre><code>class MyClass {\n  def func1(s: String): String = { ... }\n  def doStuff(rdd: RDD[String]): RDD[String] = { rdd.map(func1) }\n}\n</code></pre><h2 id=\"h2-rdd-\"><a name=\"RDD的基础数据类型\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>RDD的基础数据类型</h2><p><strong>并行集合</strong></p>\n<p>并行集合（Parallelized collections）的创建是通过一个已有的集合（Scala Seq）上调用SparkContext的parallelize方法实现的。集合中的元素被复制到一个可并行操作的分布式数据集中，例如：这里演示了如何一个包含1到5数组种创建并行集合：</p>\n<pre><code>Val data=Array(1,2,3,4,5)\nVal distData=sc.parallelize(data)\n</code></pre><p>一旦创建完成，这个分布式数据集（distData）就可以被并行操作，例如：我们可以调用distData.reduce(a,b)=&gt;a+b,将这个数组中的元素相加，我们以后在描述在分布式上的一些操作。<br>并行集合一个很重要的参数是切片书（slices），表示一个数据集切分的分数，Spark会在集群上运行一个任务。你可以在集群上为每个CPU设置2-4个切片（slices），正常情况下，Spark会试着基于你的集群状况自动地设置切片的数目，然而，你也可以通过parallelize的第二个参数手动地设置（例如：sc.parallelize(data,10)）。</p>\n<p><strong>外部数据集</strong></p>\n<p>Spark可以从任何一个Hadoop支持的存储源创建分布式数据集，包括你的本地文件系统，HDFS，Cassandra，HBase，Amazon S3等，Spark支持文本文件（text files），SequenceFiles和其他Hadoop InputFormat。<br>文本文件RDDs可以使用SparkContext的textFile方法创建，在这个方法里传入文件的URI（机器上的本地路径或hdfs：//,s3n://等），然后他会将文件读取成一个行集合，这里是一个调用例子：</p>\n<pre><code>Scala&gt; val distFile=sc.textFile(“data.txt”)\n</code></pre><h2 id=\"h2-rdd-\"><a name=\"RDD使用\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>RDD使用</h2><p>RDD actions和tranformations能被用在更多的复杂计算中，比方说，我们想要找到一行中最多的单词数量：</p>\n<pre><code>scala&gt; textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a, b) =&gt; if (a &gt; b) a else b)\n</code></pre><p>首先履行映射成一个整形数值产生一个新RDD上调用reduce找到行中最大的个数，map和reduce的参数是Scala的函数串（闭包），并且可以使用任何语言特性或者Scala/Java类库，例如，我们可以很方便的调用其他的函数声明，我们使用Math.max()函数让代码更容易理解：</p>\n<pre><code>scala&gt; import java.lang.Math\nimport java.lang.Math\nscala&gt; textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a, b) =&gt; Math.max(a, b))\nres5：Int=15\n</code></pre><p>Hadoop流行的一个通用的数据流模式是MapReduce。Spark能够很容易的实现MapReduce</p>\n<pre><code>scala&gt; val wordCounts = textFile.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey((a, b) =&gt; a + b)\n</code></pre><p>这里，我们结合flatMap，map和reduceByKey来计算文件里每个单词出现的数量，他的结果是包含一组（String，int）键值对的RDD，我们可以使用[collect]操作在我们的shell中手机单词的数量：</p>\n<pre><code>scala&gt; wordCounts.collect()\n</code></pre><h1 id=\"h1-spark-sql-\"><a name=\"spark SQL使用\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>spark SQL使用</h1><blockquote>\n<p>概述</p>\n<p>Spark SQL是结构化数据处理的Spark模块。与基本的Spark RDD API不同，Spark SQL提供的接口提供了关于数据的结构和正在执行的计算的更多信息。在内部，Spark SQL使用这些额外的信息执行额外的优化。有几种方法可以与Spark SQL进行交互，其中包括SQL和Dataset API。当计算结果时，使用相同的执行引擎，独立于您使用的api/语言来表示计算。这种统一意味着开发人员可以很容易地在不同的api之间来回切换，这提供了最自然的方式来表达给定的转换。</p>\n</blockquote>\n<h2 id=\"h2-starting-point-sparksession\"><a name=\"Starting Point: SparkSession\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Starting Point: SparkSession</h2><p>Spark中所有功能的入口点是SparkSession类。要创建一个基本的SparkSession，只需使用SparkSession.builder():</p>\n<pre><code>import org.apache.spark.sql.SparkSession\nval spark = SparkSession\n  .builder()\n  .appName(&quot;Spark SQL basic example&quot;)\n  .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;)\n  .getOrCreate()\n//对于隐式转换，比如将rdd转换为DataFrames\nimport spark.implicits._\n</code></pre><h2 id=\"h2--dataframes\"><a name=\"创建DataFrames\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建DataFrames</h2><p>通过一个SparkSession，应用程序可以从一个现有的RDD中创建DataFrames，从一个Hive表，或者从Spark数据源。<br>作为一个示例，下面创建一个基于JSON文件内容的DataFrame:</p>\n<pre><code>val df = spark.read.json(&quot;examples/src/main/resources/people.json&quot;)\n// Displays the content of the DataFrame to stdout\ndf.show()\n</code></pre><p>DataFrames为在Scala、Java、Python和r中的结构化数据操作提供了一种领域特有的语言。<br>如前所述，在Spark 2.0中，DataFrames只是Scala和Java API中的行数据集。这些操作也被称为“非类型转换”，与“类型转换”形成鲜明对比的是强类型的scala/java数据集。</p>\n<p>这里我们包括一些使用数据集的结构化数据处理的基本示例:</p>\n<pre><code>import spark.implicits._\ndf.printSchema()\ndf.select(&quot;name&quot;).show()\ndf.select($&quot;name&quot;, $&quot;age&quot; + 1).show()\ndf.filter($&quot;age&quot; &gt; 21).show()\ndf.groupBy(&quot;age&quot;).count().show()\n</code></pre><p>除了简单的列引用和表达式之外，Datasets还有一个丰富的函数库，包括字符串操作、日期算术、常见的数学运算等等。完整的列表在DataFrame函数引用中可用。</p>\n<h2 id=\"h2--sql-\"><a name=\"以编程方式运行SQL查询\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>以编程方式运行SQL查询</h2><p>SparkSession中的sql函数使应用程序能够以编程的方式运行sql查询，并将结果作为DataFrame返回。</p>\n<pre><code>//将DataFrame注册为一个SQL临时视图\ndf.createOrReplaceTempView(&quot;people&quot;)\nval sqlDF = spark.sql(&quot;SELECT * FROM people&quot;)\nsqlDF.show()\n</code></pre><p><strong>全局临时视图</strong></p>\n<p>Spark SQL中的临时视图是会话范围的，如果创建它的会话终止，则会消失。如果您想要在所有会话中共享一个临时视图，并在Spark应用程序终止之前保持活力，您可以创建一个全局临时视图。全局临时视图绑定到一个系统保存的数据库globaltemp，我们必须使用限定名来引用它，e.g. SELECT * FROM global_temp.view1.</p>\n<pre><code>//将DataFrame注册为全局临时视图\ndf.createGlobalTempView(&quot;people&quot;)\n//全局临时视图绑定到一个系统保存的数据库globaltemp\nspark.sql(&quot;SELECT * FROM global_temp.people&quot;).show()\n//全局临时视图是交叉会话\nspark.newSession().sql(&quot;SELECT * FROM global_temp.people&quot;).show()\n</code></pre><p><strong>创建数据集</strong></p>\n<p>然而，数据集与RDDs类似，而不是使用Java序列化或Kryo，它们使用专门的编码器来序列化对象，以便在网络上进行处理或传输。虽然编码器和标准序列化都负责将对象转换为字节，但编码器是动态生成的代码，并且使用一种格式，允许Spark执行许多操作，如过滤、排序和散列，而不将字节反序列化为对象。</p>\n<pre><code>//您可以使用实现产品接口的自定义类\ncase class Person(name: String, age: Long)\n//为案例类创建编码器\nval caseClassDS = Seq(Person(&quot;Andy&quot;, 32)).toDS()\ncaseClassDS.show()\n//大多数常见类型的编码器是通过引入spark.implicits自动提供的._\nval primitiveDS = Seq(1, 2, 3).toDS()\nprimitiveDS.map(_ + 1).collect() // Returns: Array(2, 3, 4)\n//通过提供一个类，可以将DataFrames转换为数据集。映射将通过名称进行\nval path = &quot;examples/src/main/resources/people.json&quot;\nval peopleDS = spark.read.json(path).as[Person]\npeopleDS.show()\n</code></pre><p><strong>使用反射推断模式</strong></p>\n<p>Spark SQL的Scala接口支持自动将包含case类的RDD转换为DataFrame。case类定义了表的模式。对case类的参数的名称是使用反射读取的，并成为列的名称。Case类也可以嵌套或包含复杂的类型，例如Seqs或数组。这个RDD可以隐式地转换为一个DataFrame，然后将其注册为一个表。表可以在后续的SQL语句中使用。</p>\n<pre><code>    import spark.implicits._\nval peopleDF = spark.sparkContext\n  .textFile(&quot;examples/src/main/resources/people.txt&quot;)\n  .map(_.split(&quot;,&quot;))\n  .map(attributes =&gt; Person(attributes(0), attributes(1).trim.toInt))\n  .toDF()\n//将DataFrame注册为一个临时视图\npeopleDF.createOrReplaceTempView(&quot;people&quot;)\n//可以使用Spark提供的SQL方法来运行SQL语句\nval teenagersDF = spark.sql(&quot;SELECT name, age FROM people WHERE age BETWEEN 13 AND 19&quot;)\n//结果中的列的列可以通过字段索引来访问\nteenagersDF.map(teenager =&gt; &quot;Name: &quot; + teenager(0)).show()\nteenagersDF.map(teenager =&gt; &quot;Name: &quot; + teenager.getAs[String](&quot;name&quot;)).show()\nimplicit val mapEncoder = org.apache.spark.sql.Encoders.kryo[Map[String, Any]]\n//基本类型和case类也可以定义为\n// implicit val stringIntMapEncoder: Encoder[Map[String, Any]] = ExpressionEncoder()\n// row.getValuesMap[T] retrieves multiple columns at once into a Map[String, T]\nteenagersDF.map(teenager =&gt; teenager.getValuesMap[Any](List(&quot;name&quot;, &quot;age&quot;))).collect()\n</code></pre><h2 id=\"h2-u4EE5u7F16u7A0Bu7684u65B9u5F0Fu6307u5B9Au6A21u5F0F\"><a name=\"以编程的方式指定模式\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>以编程的方式指定模式</h2><p>当case类不能提前定义时(例如，记录的结构是在一个字符串中编码的，或者文本数据集将被解析，不同的用户将对字段进行不同的预测)，一个DataFrame可以用3个步骤来创建。</p>\n<ol>\n<li>从原始的RDD中创建一个行;</li><li>创建在第1步中创建的RDD中所表示的结构类型的结构类型。</li><li>通过SparkSession提供的createDataFrame方法将模式应用到行的RDD中。</li></ol>\n<pre><code>import org.apache.spark.sql.types._\n// 创建一个RDD\nval peopleRDD = spark.sparkContext.textFile(&quot;examples/src/main/resources/people.txt&quot;)\n// 模式是用字符串编码的\nval schemaString = &quot;name age&quot;\n// 根据模式的字符串生成模式\nval fields = schemaString.split(&quot; &quot;)\n .map(fieldName =&gt; StructField(fieldName, StringType, nullable = true))\nval schema = StructType(fields)\n// 将RDD(人员)的记录转换为行\nval rowRDD = peopleRDD\n  .map(_.split(&quot;,&quot;))\n  .map(attributes =&gt; Row(attributes(0), attributes(1).trim))\n// 将该模式应用于RDD\nval peopleDF = spark.createDataFrame(rowRDD, schema)\n// 使用DataFrame创建一个临时视图\npeopleDF.createOrReplaceTempView(&quot;people&quot;)\n// 可以通过使用DataFrames创建的临时视图来运行SQL\nval results = spark.sql(&quot;SELECT name FROM people&quot;)\n// SQL查询的结果是DataFrames并支持所有常规的RDD操作\n// 结果中的列的列可以通过字段索引或字段名来访问。\nresults.map(attributes =&gt; &quot;Name: &quot; + attributes(0)).show()\n</code></pre><h2 id=\"h2-u805Au5408u51FDu6570\"><a name=\"聚合函数\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>聚合函数</h2><p>内置的DataFrames函数提供了诸如count()、countDistinct ()、avg()、max()、min()等公共聚合，而这些函数都是为DataFrames设计的，Spark SQL也为Scala和Java中的一些提供了类型安全的版本，用于与强类型数据集一起工作。此外，用户不仅限于预定义的聚合函数，而且可以创建自己的聚合函数。</p>\n<p><strong>无类型定义的聚合函数</strong></p>\n<p>用户必须扩展UserDefinedAggregateFunction抽象类实现一个自定义的无类型的聚合函数。例如，用户定义的平均值可以是这样的:</p>\n<pre><code>import org.apache.spark.sql.expressions.MutableAggregationBuffer\nimport org.apache.spark.sql.expressions.UserDefinedAggregateFunction\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.SparkSession\nobject MyAverage extends UserDefinedAggregateFunction {\n  // 这个聚合函数的输入参数的数据类型\n  def inputSchema: StructType = StructType(StructField(&quot;inputColumn&quot;, LongType) :: Nil)\n  // 聚合缓冲区中的值的数据类型\n  def bufferSchema: StructType = {\n    StructType(StructField(&quot;sum&quot;, LongType) :: StructField(&quot;count&quot;, LongType) :: Nil)\n  }\n  // 返回值的数据类型  \ndef dataType: DataType = DoubleType\n  // 这个函数是否总是在相同的输入上返回相同的输出\n  def deterministic: Boolean = true\n  // 初始化给定的聚合缓冲区。缓冲区本身是一个行，除了\n  // 标准方法，例如检索索引中的值(例如get()、getBoolean())\n  // 更新它的价值的机会。注意，缓冲区内的数组和映射仍然是  \n// 不变的.\n  def initialize(buffer: MutableAggregationBuffer): Unit = {\n    buffer(0) = 0L\n    buffer(1) = 0L\n  }\n  // 使用来自输入的新输入数据更新给定的聚合缓冲区缓冲区  \ndef update(buffer: MutableAggregationBuffer, input: Row): Unit = {\n    if (!input.isNullAt(0)) {\n      buffer(0) = buffer.getLong(0) + input.getLong(0)\n      buffer(1) = buffer.getLong(1) + 1\n    }\n  }\n  // 合并两个聚合缓冲区，并将更新后的缓冲区值存储到buffer1\n  def merge(buffer1: MutableAggregationBuffer, buffer2: Row): Unit = {\n    buffer1(0) = buffer1.getLong(0) + buffer2.getLong(0)\n    buffer1(1) = buffer1.getLong(1) + buffer2.getLong(1)\n  }\n  // 计算出最终结果  \ndef evaluate(buffer: Row): Double = buffer.getLong(0).toDouble / buffer.getLong(1)\n}\n// 注册该函数以访问它\nspark.udf.register(&quot;myAverage&quot;, MyAverage)\nval df = spark.read.json(&quot;examples/src/main/resources/employees.json&quot;)\ndf.createOrReplaceTempView(&quot;employees&quot;)\ndf.show()\nval result = spark.sql(&quot;SELECT myAverage(salary) as average_salary FROM employees&quot;)\nresult.show()\n</code></pre><p><strong>类型安全的用户定义的聚合函数</strong></p>\n<p>对于强类型数据集的用户定义聚合是围绕聚集器抽象类进行的。例如，类型安全的用户定义的平均值可以是这样的:</p>\n<pre><code>import org.apache.spark.sql.expressions.Aggregator\nimport org.apache.spark.sql.Encoder\nimport org.apache.spark.sql.Encoders\nimport org.apache.spark.sql.SparkSession\ncase class Employee(name: String, salary: Long)\ncase class Average(var sum: Long, var count: Long)\nobject MyAverage extends Aggregator[Employee, Average, Double] {\n  // 这个聚合的零值。应该满足任意b+0=b的性质\n  def zero: Average = Average(0L, 0L)\n  // 结合两个值来生成一个新值。对于性能，函数可以修改缓冲区 \n // 然后返回，而不是新建一个对象\n  def reduce(buffer: Average, employee: Employee): Average = {\n    buffer.sum += employee.salary\n    buffer.count += 1\n    buffer\n  }\n  // 合并两个中间值\n  def merge(b1: Average, b2: Average): Average = {\n    b1.sum += b2.sum\n    b1.count += b2.count\n    b1\n  }\n  // 转换输出的输出\n  def finish(reduction: Average): Double = reduction.sum.toDouble / reduction.count\n  // 指定中间值类型的编码器\n  def bufferEncoder: Encoder[Average] = Encoders.product\n  // 指定最终输出值类型的编码器  \ndef outputEncoder: Encoder[Double] = Encoders.scalaDouble\n}\nval ds = spark.read.json(&quot;examples/src/main/resources/employees.json&quot;).as[Employee]\nds.show()\n// 将函数转换为TypedColumn并给它起一个名字\nval averageSalary = MyAverage.toColumn.name(&quot;average_salary&quot;)\nval result = ds.select(averageSalary)\nresult.show()\n</code></pre><p><strong>数据源</strong></p>\n<p>Spark SQL支持通过DataFrame接口对各种数据源进行操作。DataFrame可以使用关系转换操作，也可以用来创建临时视图。将一个DataFrame注册为一个临时视图允许您在其数据上运行SQL查询。本节描述使用Spark数据源加载和保存数据的一般方法，然后进入用于内置数据源的特定选项。</p>\n<p><strong>通用的加载/保存功能</strong></p>\n<p>在最简单的形式中,默认数据源(由spark.sql.sources.default拼花,除非另有配置)将用于所有操作。</p>\n<pre><code>val usersDF = spark.read.load(&quot;examples/src/main/resources/users.parquet&quot;)\nusersDF.select(&quot;name&quot;, &quot;favorite_color&quot;).write.save(&quot;namesAndFavColors.parquet&quot;)\n</code></pre><p><strong>手动指定选项</strong></p>\n<p>您还可以手动指定将使用的数据源，以及您想要传递给数据源的任何额外选项。数据源由其完全限定的名称(即:org.apache.spark.sql.parquet),但对于内置的来源还可以使用短名称(json、jdbc、csv、文本)。从任何数据源类型加载的DataFrames都可以使用这种语法转换为其他类型。</p>\n<pre><code>val peopleDF = spark.read.format(&quot;json&quot;).load(&quot;examples/src/main/resources/people.json&quot;)\npeopleDF.select(&quot;name&quot;, &quot;age&quot;).write.format(&quot;parquet&quot;).save(&quot;namesAndAges.parquet&quot;)\n</code></pre><p><strong>直接在文件上运行SQL</strong></p>\n<p>您可以使用SQL来直接查询该文件，而不是使用read API将文件加载到DataFrame并查询它。</p>\n<pre><code>val sqlDF = spark.sql(&quot;SELECT * FROM parquet.`examples/src/main/resources/users.parquet`&quot;)\n</code></pre><h2 id=\"h2-bucketing-sorting-and-partitioning\"><a name=\"Bucketing, Sorting and Partitioning\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Bucketing, Sorting and Partitioning</h2><p>对于基于文件的数据源，还可以对输出进行存储、排序或分区。嵌接和排序仅适用于持久表:</p>\n<pre><code>peopleDF.write.bucketBy(42, &quot;name&quot;).sortBy(&quot;age&quot;).saveAsTable(&quot;people_bucketed&quot;)\n</code></pre><p>在使用数据集api时，可以同时使用分区和save。</p>\n<pre><code>usersDF.write.partitionBy(&quot;favorite_color&quot;).format(&quot;parquet&quot;).save(&quot;namesPartByColor.parquet&quot;)\n</code></pre><p>对于单个表，可以使用分区和嵌接:</p>\n<pre><code>peopleDF\n  .write\n  .partitionBy(&quot;favorite_color&quot;)\n  .bucketBy(42, &quot;name&quot;)\n  .saveAsTable(&quot;people_partitioned_bucketed&quot;)\n</code></pre><p>分区创建一个目录结构，正如在分区发现节中所描述的那样。因此，它对具有高基数的列的适用性有限。相反，bucketa将数据分布在固定数量的桶中，当许多惟一值是无界的时，可以使用它。</p>\n<h1 id=\"h1-u7ED3u6784u5316u6D41u7F16u7A0B\"><a name=\"结构化流编程\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>结构化流编程</h1><blockquote>\n<p>结构化流是一个可伸缩的、容错的流处理引擎，构建在Spark SQL引擎上。您可以用相同的方式表示流计算，就像在静态数据上表示批处理一样。Spark SQL引擎将会逐渐地、持续地运行它，并在流数据继续到达时更新最终结果。您可以使用Scala、Java、Python或R中的dataset/dataframe API来表示流媒体聚合、事件时间窗口、流到批连接等等，这些计算都是在同一个优化的Spark SQL引擎上执行的。最后，系统确保了端到端的端对端容错保证，通过检查点和写前面的日志。简而言之，结构化流提供了快速、可伸缩的、容错的、端到端的即时处理，而无需用户去考虑流媒体。</p>\n</blockquote>\n<h2 id=\"h2-u7B80u5355u7684u4F8Bu5B50\"><a name=\"简单的例子\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>简单的例子</h2><p>假设您想要维护从一个数据服务器接收到的一个正在运行的文本数据，而这个数据服务器是通过TCP套接字监听的。让我们看看如何使用结构化的流媒体来表达这个问题。如果你下载Spark，你可以直接运行这个例子。在任何情况下，让我们一步一步地了解这个示例，并了解它是如何工作的。首先，我们必须导入必要的类并创建一个局部SparkSession，这是与Spark相关的所有功能的起点。</p>\n<pre><code>import org.apache.spark.sql.functions._\nimport org.apache.spark.sql.SparkSession\nval spark = SparkSession\n  .builder\n  .appName(&quot;StructuredNetworkWordCount&quot;)\n  .getOrCreate()\nimport spark.implicits._\n</code></pre><p>接下来，让我们创建一个流数据的DataFrame，它表示从服务器接收到的服务器上接收的文本数据，并将DataFrame转换为计算单词计数。</p>\n<pre><code>//创建来自连接到localhost:9999的输入行流的DataFrame\nval lines = spark.readStream\n  .format(&quot;socket&quot;)\n  .option(&quot;host&quot;, &quot;localhost&quot;)\n  .option(&quot;port&quot;, 9999)\n  .load()\nval words = lines.as[String].flatMap(_.split(&quot; &quot;))\nval wordCounts = words.groupBy(&quot;value&quot;).count()\n</code></pre><p>现在，我们已经对流数据进行了查询。剩下的就是开始接收数据并计算计数。要做到这一点，我们设置它来打印完整的计数集(outputMode(“complete”)指定，每次更新时都要输出到控制台。然后使用start()启动流计算。</p>\n<pre><code>// 开始运行将运行计数打印到控制台的查询\nval query = wordCounts.writeStream\n  .outputMode(&quot;complete&quot;)\n  .format(&quot;console&quot;)\n  .start()\nquery.awaitTermination()\n</code></pre><p>在执行该代码之后，流计算将在后台启动。查询对象是一个对该活动流查询的句柄，我们已经决定使用瓦伊终止()等待查询的终止，以防止在查询处于活动状态时退出进程。<br>要实际执行这个示例代码，您可以在自己的Spark应用程序中编译代码，也可以在下载Spark后运行这个示例。我们展示的是后者。您首先需要运行Netcat(在大多数类unix系统中发现的一个小型实用程序)作为数据服务器</p>\n<pre><code>$ nc -lk 9999\n</code></pre><p>然后，在一个不同的终端中，您可以通过使用</p>\n<pre><code>$ ./bin/run-example org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount localhost 9999\n</code></pre><p>然后，在运行netcat服务器的终端中输入的任何行都将被计数并在屏幕上打印。</p>\n<h1 id=\"h1-spark-streaming-\"><a name=\"spark streaming编程\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>spark streaming编程</h1><p>Spark流是核心Spark API的一个扩展，它支持可伸缩、高吞吐量、容错的实时数据流处理。数据可以从许多来源中摄取，比如卡夫卡、Flume、kin遥感或TCP套接字，并且可以使用复杂的算法来处理，这些算法使用高级功能，如map、reduce、join和window。最后，处理的数据可以被推送到文件系统、数据库和实时指示板。实际上，您可以在数据流上应用Spark的机器学习和图形处理算法。</p>\n<p><img src=\"http://spark.apache.org/docs/latest/img/streaming-arch.png\" alt=\"image\"></p>\n<p>在内部，它是这样工作的。Spark流接收实时的输入数据流，并将数据分成几批，然后由Spark引擎处理，以批量生成最终的结果流。</p>\n<p><img src=\"http://spark.apache.org/docs/latest/img/streaming-flow.png\" alt=\"image\"></p>\n<p>Spark流提供了一个称为离散流或DStream的高级抽象，它代表了连续的数据流。DStreams可以从诸如卡夫卡、Flume和kinor等来源的输入数据流中创建，也可以通过在其他DStreams上应用高级操作来创建。在内部，DStream被表示为一个RDDs的序列。</p>\n<p><strong>一个简单的例子</strong></p>\n<p>首先，我们导入了Spark流类的名称，以及从StreamingContext到我们的环境中的一些隐式转换，以便向我们需要的其他类添加有用的方法(如DStream)。StreamingContext是所有流媒体功能的主要入口点。我们使用两个执行线程创建一个本地流上下文，一个批处理间隔为1秒。</p>\n<pre><code>import org.apache.spark._\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.StreamingContext._ // not necessary since Spark 1.3\n// 创建一个本地流媒体上下文，使用两个工作线程和一个1秒的批处理间隔。.\nval conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;NetworkWordCount&quot;)\nval ssc = new StreamingContext(conf, Seconds(1))\n</code></pre><p>使用这个上下文，我们可以创建一个DStream，它表示来自TCP源的流数据，指定为主机名(例如localhost)和端口(例如9999)。</p>\n<pre><code>val lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)\n</code></pre><p>这行DStream表示将从数据服务器接收到的数据流。这个DStream中的每个记录都是一行文本。接下来，我们要将空格字符分割成单词。</p>\n<pre><code>val words = lines.flatMap(_.split(&quot; &quot;))\n</code></pre><p>flatMap是一对多的DStream操作，它通过在源DStream中的每个记录生成多个新记录来创建一个新的DStream。在这种情况下，每一行将被分割成多个单词，而单词流则表示为DStream。接下来，我们要计算这些单词。</p>\n<pre><code>import org.apache.spark.streaming.StreamingContext._ \n// 在每批中计算每个单词\nval pairs = words.map(word =&gt; (word, 1))\nval wordCounts = pairs.reduceByKey(_ + _)\n// 将这个DStream中生成的每个RDD的前10个元素打印到控制台\nwordCounts.print()\n</code></pre><p>当这些行被执行时，Spark流只会设置它在启动时将执行的计算，并且还没有开始真正的处理。在所有转换设置之后开始处理，我们最后调用</p>\n<pre><code>ssc.start()             // 开始计算\nssc.awaitTermination()  // 等待计算终止\n</code></pre><p>完整的代码可以在Spark流示例网络wordcount中找到。<br>如果您已经下载并构建了Spark，那么您可以像下面这样运行这个示例。您首先需要运行Netcat(在大多数类unix系统中发现的一个小型实用程序)作为数据服务器</p>\n<pre><code>$ nc -lk 9999\n</code></pre><p>然后，在一个不同的终端中，您可以通过使用</p>\n<pre><code>$ ./bin/run-example streaming.NetworkWordCount localhost 9999\n</code></pre><p>然后，在运行netcat服务器的终端中输入的任何行都将被计数并在屏幕上打印。</p>\n');
INSERT INTO `tbl_archive` VALUES ('8', '0', 'XLearning 安装说明文档', '24', '2018-01-25 10:56:39', '本文档介绍了x86_64下XLearning的安装过程。', null, '0', '627', null, null, '2018-01-25 10:56:39', '2018-01-25 11:51:07', null, null, '0', '0', '0', '0', '# 一、版本说明\nhadoop 2.7.3\nTensorFlow 1.1.0\nxlearning 1.1\njava 1.8.0\npyton 2.7.5\n# 二、系统环境安装\n## 1. 安装java\n下载jdk-8u73-linux-x64.tar.gz包，解压，并放置到指定目录（如:/opt/XLearning/software目录）下\n\n\n    tar -xzvf jdk-7u67-linux-x64.tar.gz -C /opt/XLearning/software\n创建软链接\n```shell\ncd /opt/XLearning/software\nln -s jdk1.7.0_67 java\n```\n配置环境变量\n    vim /etc/profile.d/jdk.sh\n    \n        export JAVA_HOME=/opt/XLearning/software/jdk1.7.0_67\n        export JRE_HOME=${JAVA_HOME}/jre\n        export CLASSPATH=$CLASSPATH:${JAVA_HOME}/lib:${JRE_HOME}/lib\n        export PATH=$PATH:${JAVA_HOME}/bin\n环境变量生效\n```shell\nsource /etc/profile\n```\n##  2.安装pip\n下载pip-9.0.1.tar.gz解压，并安装\n```shell\ntar -xzvf pip-9.0.1.tar.gz\ncd pip-9.0.1\npython setup.py install\n```\n# 三、Hadoop部署\n## 1.下载、解压\n```shell\ntar -xzvf hadoop-2.7.3.tar.gz\ncd hadoop-2.7.3/etc/hadoop\n```\n## 2.修改配置文件\n1. hadoop-env.sh文件\n```shell\nvim hadoop-env.sh \nJAVA_HOME = /opt/XLearning/software/java\n```\n1. yarn-env.sh文件\n```shell\nvim yarn-env.sh\nJAVA_HOME = /opt/XLearning/software/java\n```\n1. mapred-env.sh文件\n```shell\nvim mapred-env.sh\nJAVA_HOME = /opt/XLearning/software/java\n```\n1. core-site.xml文件\n```shell\nvim core-site.xml\n```\n修改_HOST，替换为主机名，如test-1\n1. hdfs-site.xml文件\n```shell\nvim hdfs-site.xml\n```\n修改dfs.namenode.name.dir和dfs.datanode.data.dir属性\n```shell\n<property>\n      <name>dfs.namenode.name.dir</name>\n      <value>file:/opt/XLearning/hadoop/data/dfs/name</value>\n      <final>true</final>\n    </property>\n    <property>\n      <name>dfs.datanode.data.dir</name>\n      <value>file:/opt/XLearning/hadoop/data/dfs/data</value>\n      <final>true</final>\n    </property>\n```\n创建目录\n```shell\nmkdir /opt/XLearning/hadoop/data/dfs/name\n```\n1. mapred-site.xml文件\n```shell\nmv mapred-site.xml.template mapred-site.xml\nvim mapred-site.xml\n```\n修改_HOST，替换为主机名，如test-1\n1. yarn-site.xml文件\n```shell\nvim yarn-site.xml\n```\n修改_HOST，替换为主机名，如test-1\n## 3. 配置HADOOP_HOME\n创建软链接\n```shell\ncd /opt/XLearning/software\nln -s hadoop-2.7.3 hadoop\n```\n设置环境变量\n```shell\nvim /etc/profile.d/hadoop.sh\nexport HADOOP_HOME=/opt/XLearning/software/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n```\n## 4.启动Hadoop各项服务\n格式化主节点命名空间\n```shell\ncd hadoop\n./bin/hadoop namenode -format\n```\n启动存储服务和资源管理服务\n```shell\n./sbin/hadoop-daemon.sh start namenode\n./sbin/hadoop-daemon.sh start datanode\n./sbin/yarn-daemon.sh start resourcemanager\n./sbin/yarn-daemon.sh start nodemanager\n./sbin/mr-jobhistory-daemon.sh start historyserver\n```\n查看各项服务的状态\n```shell\njps -ml\n```\n# 四、安装TensorFlow\n 利用pip安装\n ```shell\npip install tensorflow-1.1.0-cp27-cp27mu-linux_x86_64.whl\n```\n Python下验证\n ```shell\n >>>import tensorflow as tf\n  >>>tf.__version__\n```\n# 五、XLearning部署\n## 1. 编译、打包\n```shell\nmvn package\n```\n## 2. 解压\n```shell\ntar -xzvf xlearning-1.1-dist.tar.gz\n```\n## 3. 配置\n```shell\ncd xlearning-1.1\ncd conf\n```\n1  log4j.properties文件\n去掉注释\n```shell\n# Settings the HistoryServer logs\nlog4j.logger.net.qihoo.xlearning.jobhistory=DEBUG,RFA\nlog4j.additivity.net.qihoo.xlearning.jobhistory=false\nlog4j.appender.RFA=org.apache.log4j.RollingFileAppender\nlog4j.appender.RFA.File=/tmp/XLearning/logs/XLearningHistoryServer.log\nlog4j.appender.RFA.Encoding=UTF-8\nlog4j.appender.RFA.Append=true\nlog4j.appender.RFA.MaxFileSize=100MB\nlog4j.appender.RFA.MaxBackupIndex=5\nlog4j.appender.RFA.layout=org.apache.log4j.PatternLayout\n```\n2 xlearning-env.sh文件\n配置JAVA_HOME HADOOP_CONF_DIR\n```shell\nexport JAVA_HOME=/opt/XLearning/software/java\nexport HADOOP_CONF_DIR=/opt/XLearning/software/hadoop/etc/hadoop\n```\n3 xlearning-site.xml\n配置JobHistory信息，修改0.0.0.0为主机名，如test-1\n## 4. 启动XLearning JobHistoryServer服务\n```shell\ncd xlearning-1.1\nsbin/start-history-server.sh\n```\n## 5. XLearning客户端\n配置XLEARNING_HOME\n```shell\nexport XLEARNING_HOME=/opt/XLearning/xlearning-1.1\n```\n创建目录\n```shell\nhadoop fs -mkdir -p /tmp/XLearning/history\nhadoop fs -mkdir -p /tmp/XLearning/eventLog\nhadoop fs -mkdir -p /tmp/XLearning/staging\n```\n上传数据到HDFS\n```shell\nhadoop fs -put data /tmp/\n```\n执行示例\n```shell\ncd examples/tensorflow\nsh run.sh \n```\n运行结果\n![](/upload/images/20180125//f6d56b61-1f80-4fb6-a836-784f7f1ef36b.png)\n![](/upload/images/20180125//1c68174d-978f-4a6e-add3-f1f0a0459aa9.png)', '0', '<h1 id=\"h1--\"><a name=\"一、版本说明\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>一、版本说明</h1><p>hadoop 2.7.3<br>TensorFlow 1.1.0<br>xlearning 1.1<br>java 1.8.0<br>pyton 2.7.5</p>\n<h1 id=\"h1--\"><a name=\"二、系统环境安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>二、系统环境安装</h1><h2 id=\"h2-1-java\"><a name=\"1. 安装java\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. 安装java</h2><p>下载jdk-8u73-linux-x64.tar.gz包，解压，并放置到指定目录（如:/opt/XLearning/software目录）下</p>\n<pre><code>tar -xzvf jdk-7u67-linux-x64.tar.gz -C /opt/XLearning/software\n</code></pre><p>创建软链接</p>\n<pre><code class=\"lang-shell\">cd /opt/XLearning/software\nln -s jdk1.7.0_67 java\n</code></pre>\n<p>配置环境变量<br>    vim /etc/profile.d/jdk.sh</p>\n<pre><code>    export JAVA_HOME=/opt/XLearning/software/jdk1.7.0_67\n    export JRE_HOME=${JAVA_HOME}/jre\n    export CLASSPATH=$CLASSPATH:${JAVA_HOME}/lib:${JRE_HOME}/lib\n    export PATH=$PATH:${JAVA_HOME}/bin\n</code></pre><p>环境变量生效</p>\n<pre><code class=\"lang-shell\">source /etc/profile\n</code></pre>\n<h2 id=\"h2-2-pip\"><a name=\"2.安装pip\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.安装pip</h2><p>下载pip-9.0.1.tar.gz解压，并安装</p>\n<pre><code class=\"lang-shell\">tar -xzvf pip-9.0.1.tar.gz\ncd pip-9.0.1\npython setup.py install\n</code></pre>\n<h1 id=\"h1--hadoop-\"><a name=\"三、Hadoop部署\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>三、Hadoop部署</h1><h2 id=\"h2-1-\"><a name=\"1.下载、解压\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.下载、解压</h2><pre><code class=\"lang-shell\">tar -xzvf hadoop-2.7.3.tar.gz\ncd hadoop-2.7.3/etc/hadoop\n</code></pre>\n<h2 id=\"h2-2-\"><a name=\"2.修改配置文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.修改配置文件</h2><ol>\n<li>hadoop-env.sh文件<pre><code class=\"lang-shell\">vim hadoop-env.sh \nJAVA_HOME = /opt/XLearning/software/java\n</code></pre>\n</li><li>yarn-env.sh文件<pre><code class=\"lang-shell\">vim yarn-env.sh\nJAVA_HOME = /opt/XLearning/software/java\n</code></pre>\n</li><li>mapred-env.sh文件<pre><code class=\"lang-shell\">vim mapred-env.sh\nJAVA_HOME = /opt/XLearning/software/java\n</code></pre>\n</li><li>core-site.xml文件<pre><code class=\"lang-shell\">vim core-site.xml\n</code></pre>\n修改_HOST，替换为主机名，如test-1</li><li>hdfs-site.xml文件<pre><code class=\"lang-shell\">vim hdfs-site.xml\n</code></pre>\n修改dfs.namenode.name.dir和dfs.datanode.data.dir属性<pre><code class=\"lang-shell\">&lt;property&gt;\n   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n   &lt;value&gt;file:/opt/XLearning/hadoop/data/dfs/name&lt;/value&gt;\n   &lt;final&gt;true&lt;/final&gt;\n &lt;/property&gt;\n &lt;property&gt;\n   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n   &lt;value&gt;file:/opt/XLearning/hadoop/data/dfs/data&lt;/value&gt;\n   &lt;final&gt;true&lt;/final&gt;\n &lt;/property&gt;\n</code></pre>\n创建目录<pre><code class=\"lang-shell\">mkdir /opt/XLearning/hadoop/data/dfs/name\n</code></pre>\n</li><li>mapred-site.xml文件<pre><code class=\"lang-shell\">mv mapred-site.xml.template mapred-site.xml\nvim mapred-site.xml\n</code></pre>\n修改_HOST，替换为主机名，如test-1</li><li>yarn-site.xml文件<pre><code class=\"lang-shell\">vim yarn-site.xml\n</code></pre>\n修改_HOST，替换为主机名，如test-1<h2 id=\"h2-3-hadoop_home\"><a name=\"3. 配置HADOOP_HOME\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3. 配置HADOOP_HOME</h2>创建软链接<pre><code class=\"lang-shell\">cd /opt/XLearning/software\nln -s hadoop-2.7.3 hadoop\n</code></pre>\n设置环境变量<pre><code class=\"lang-shell\">vim /etc/profile.d/hadoop.sh\nexport HADOOP_HOME=/opt/XLearning/software/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n</code></pre>\n<h2 id=\"h2-4-hadoop-\"><a name=\"4.启动Hadoop各项服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.启动Hadoop各项服务</h2>格式化主节点命名空间<pre><code class=\"lang-shell\">cd hadoop\n./bin/hadoop namenode -format\n</code></pre>\n启动存储服务和资源管理服务<pre><code class=\"lang-shell\">./sbin/hadoop-daemon.sh start namenode\n./sbin/hadoop-daemon.sh start datanode\n./sbin/yarn-daemon.sh start resourcemanager\n./sbin/yarn-daemon.sh start nodemanager\n./sbin/mr-jobhistory-daemon.sh start historyserver\n</code></pre>\n查看各项服务的状态<pre><code class=\"lang-shell\">jps -ml\n</code></pre>\n<h1 id=\"h1--tensorflow\"><a name=\"四、安装TensorFlow\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>四、安装TensorFlow</h1>利用pip安装<pre><code class=\"lang-shell\">pip install tensorflow-1.1.0-cp27-cp27mu-linux_x86_64.whl\n</code></pre>\nPython下验证<pre><code class=\"lang-shell\">&gt;&gt;&gt;import tensorflow as tf\n&gt;&gt;&gt;tf.__version__\n</code></pre>\n<h1 id=\"h1--xlearning-\"><a name=\"五、XLearning部署\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>五、XLearning部署</h1><h2 id=\"h2-1-\"><a name=\"1. 编译、打包\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. 编译、打包</h2><pre><code class=\"lang-shell\">mvn package\n</code></pre>\n<h2 id=\"h2-2-\"><a name=\"2. 解压\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2. 解压</h2><pre><code class=\"lang-shell\">tar -xzvf xlearning-1.1-dist.tar.gz\n</code></pre>\n<h2 id=\"h2-3-\"><a name=\"3. 配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3. 配置</h2><pre><code class=\"lang-shell\">cd xlearning-1.1\ncd conf\n</code></pre>\n1  log4j.properties文件<br>去掉注释<pre><code class=\"lang-shell\"># Settings the HistoryServer logs\nlog4j.logger.net.qihoo.xlearning.jobhistory=DEBUG,RFA\nlog4j.additivity.net.qihoo.xlearning.jobhistory=false\nlog4j.appender.RFA=org.apache.log4j.RollingFileAppender\nlog4j.appender.RFA.File=/tmp/XLearning/logs/XLearningHistoryServer.log\nlog4j.appender.RFA.Encoding=UTF-8\nlog4j.appender.RFA.Append=true\nlog4j.appender.RFA.MaxFileSize=100MB\nlog4j.appender.RFA.MaxBackupIndex=5\nlog4j.appender.RFA.layout=org.apache.log4j.PatternLayout\n</code></pre>\n2 xlearning-env.sh文件<br>配置JAVA_HOME HADOOP_CONF_DIR<pre><code class=\"lang-shell\">export JAVA_HOME=/opt/XLearning/software/java\nexport HADOOP_CONF_DIR=/opt/XLearning/software/hadoop/etc/hadoop\n</code></pre>\n3 xlearning-site.xml<br>配置JobHistory信息，修改0.0.0.0为主机名，如test-1<h2 id=\"h2-4-xlearning-jobhistoryserver-\"><a name=\"4. 启动XLearning JobHistoryServer服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4. 启动XLearning JobHistoryServer服务</h2><pre><code class=\"lang-shell\">cd xlearning-1.1\nsbin/start-history-server.sh\n</code></pre>\n<h2 id=\"h2-5-xlearning-\"><a name=\"5. XLearning客户端\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5. XLearning客户端</h2>配置XLEARNING_HOME<pre><code class=\"lang-shell\">export XLEARNING_HOME=/opt/XLearning/xlearning-1.1\n</code></pre>\n创建目录<pre><code class=\"lang-shell\">hadoop fs -mkdir -p /tmp/XLearning/history\nhadoop fs -mkdir -p /tmp/XLearning/eventLog\nhadoop fs -mkdir -p /tmp/XLearning/staging\n</code></pre>\n上传数据到HDFS<pre><code class=\"lang-shell\">hadoop fs -put data /tmp/\n</code></pre>\n执行示例<pre><code class=\"lang-shell\">cd examples/tensorflow\nsh run.sh\n</code></pre>\n运行结果<br><img src=\"/upload/images/20180125//f6d56b61-1f80-4fb6-a836-784f7f1ef36b.png\" alt=\"\"><br><img src=\"/upload/images/20180125//1c68174d-978f-4a6e-add3-f1f0a0459aa9.png\" alt=\"\"></li></ol>\n');
INSERT INTO `tbl_archive` VALUES ('9', '0', 'fuse组件与vsftpd服务不兼容', '10', '2018-01-25 11:00:12', '#问题描述集群节点挂载fuse后，通过centos默认的ftp服务vsftpd传输数据会有问题，传输失败#解决方法安装其他ftp服务，pureftpd#安装方法**安装：**wgetftp://ftp.pureftpd.org/pub/pure-ftpd/releases/pure-ftpd-1.0.46.tar.gztarzxfpure-ftpd-1.0.46.tar.gzcdpure-ftpd', null, '0', '475', null, null, '2018-01-25 11:00:12', null, null, null, '0', '0', '0', '0', '#问题描述\n集群节点挂载fuse后，通过centos默认的ftp服务vsftpd传输数据会有问题，传输失败\n#解决方法\n安装其他ftp服务，pureftpd\n#安装方法\n**安装：**\nwget ftp://ftp.pureftpd.org/pub/pure-ftpd/releases/pure-ftpd-1.0.46.tar.gz\ntar zxf pure-ftpd-1.0.46.tar.gz\ncd pure-ftpd-1.0.46\nyum -y install gcc\nyum -y install openssl  openssl-devel\n./configure --prefix=/usr/local/pureftpd --without-inetd --with-altlog --with-puredb --with-throttling --with-peruserlimits --with-tls\nmake && make install\n\n**启动：**\ncd /usr/local/pureftpd/\n./sbin/pure-ftpd ./etc/pure-ftpd.conf\n\n**配置：**\nvim /usr/local/pureftpd/etc/pure-ftpd.conf\n\nChrootEveryone yes //锁定所有用户到家目录中\n\\#TrustedGID 100 //信任组ID100，可以不锁定\nMaxClientsNumber 50 //最大的客户端数量\nMaxClientsPerIP 8 //同一个IP允许8个链接\nDisplayDotFiles no //不显示隐藏文件\nAnonymousOnly no //只允许匿名用户\nNoAnonymous yes//不允许匿名用户\nDontResolve yes //禁止反向解析\nMaxIdleTime 10 //最大空闲10分钟\n\\# LDAPConfigFile /etc/pureftpd-ldap.conf //LDAP配置文件目录\n\\# MySQLConfigFile /etc/pureftpd-MySQL.conf//mysql配置文件目录\n\\# PGSQLConfigFile /etc/pureftpd-pgsql.conf //PGSQL配置文件目录\nPureDB /usr/local/pureftpd/etc/pureftpd.pdb //虚拟用户数据库\n\\# UnixAuthentication yes //主机认证\nLimitRecursion 2000 8 //别表最大显示2000个文件，最深8个目录\nAnonymousCanCreateDirs no //是否允许匿名用户创建目录\n\\#MaxLoad 4 //最多可下载的数量\n\\# PassivePortRange 30000 50000 //主动连接的端口范围\nForcePassiveIP 192.168.0.1 //这个地址总是直到匿名目录\n\\# AnonymousRatio 1 10 //匿名用户上传下载速度比率\n\\# UserRatio 1 10 //用户上传下载速度比率\n\\# Bind 127.0.0.1,21 //绑定IP和端口\n\\# AnonymousBandwidth 8 //匿名用户带宽8KB\n\\# UserBandwidth 8 //用户带宽8KB\nUmask 133:022 //文件和目录的umask\nMinUID 1000 //用户ID至少要大于1000才能登陆\nAllowUserFXP no //是否允许用户使用FXP协议登陆\nAllowAnonymousFXP no //是否允许匿名用户使用FXP协议\nProhibitDotFilesWrite no //是否允许写入点文件\nProhibitDotFilesRead no //是否允许读取点文件\nAnonymousCantUpload yes //不允许匿名用户上传\n\\#NoChmod yes //不允许用户改变权限\n\\#KeepAllFiles yes //允许用户断点续传\n\\#Quota 1000:10//磁盘配额\n\\#MaxDiskUsage 99 //磁盘的最大利用率\n\\#NoRename yes //不允许自动重命名\nIPV4Only yes //只允许使用IPV4协议', '0', '<h1 id=\"h1-u95EEu9898u63CFu8FF0\"><a name=\"问题描述\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问题描述</h1><p>集群节点挂载fuse后，通过centos默认的ftp服务vsftpd传输数据会有问题，传输失败</p>\n<h1 id=\"h1-u89E3u51B3u65B9u6CD5\"><a name=\"解决方法\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>解决方法</h1><p>安装其他ftp服务，pureftpd</p>\n<h1 id=\"h1-u5B89u88C5u65B9u6CD5\"><a name=\"安装方法\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装方法</h1><p><strong>安装：</strong><br>wget ftp://ftp.pureftpd.org/pub/pure-ftpd/releases/pure-ftpd-1.0.46.tar.gz<br>tar zxf pure-ftpd-1.0.46.tar.gz<br>cd pure-ftpd-1.0.46<br>yum -y install gcc<br>yum -y install openssl  openssl-devel<br>./configure —prefix=/usr/local/pureftpd —without-inetd —with-altlog —with-puredb —with-throttling —with-peruserlimits —with-tls<br>make &amp;&amp; make install</p>\n<p><strong>启动：</strong><br>cd /usr/local/pureftpd/<br>./sbin/pure-ftpd ./etc/pure-ftpd.conf</p>\n<p><strong>配置：</strong><br>vim /usr/local/pureftpd/etc/pure-ftpd.conf</p>\n<p>ChrootEveryone yes //锁定所有用户到家目录中<br>#TrustedGID 100 //信任组ID100，可以不锁定<br>MaxClientsNumber 50 //最大的客户端数量<br>MaxClientsPerIP 8 //同一个IP允许8个链接<br>DisplayDotFiles no //不显示隐藏文件<br>AnonymousOnly no //只允许匿名用户<br>NoAnonymous yes//不允许匿名用户<br>DontResolve yes //禁止反向解析<br>MaxIdleTime 10 //最大空闲10分钟<br># LDAPConfigFile /etc/pureftpd-ldap.conf //LDAP配置文件目录<br># MySQLConfigFile /etc/pureftpd-MySQL.conf//mysql配置文件目录<br># PGSQLConfigFile /etc/pureftpd-pgsql.conf //PGSQL配置文件目录<br>PureDB /usr/local/pureftpd/etc/pureftpd.pdb //虚拟用户数据库<br># UnixAuthentication yes //主机认证<br>LimitRecursion 2000 8 //别表最大显示2000个文件，最深8个目录<br>AnonymousCanCreateDirs no //是否允许匿名用户创建目录<br>#MaxLoad 4 //最多可下载的数量<br># PassivePortRange 30000 50000 //主动连接的端口范围<br>ForcePassiveIP 192.168.0.1 //这个地址总是直到匿名目录<br># AnonymousRatio 1 10 //匿名用户上传下载速度比率<br># UserRatio 1 10 //用户上传下载速度比率<br># Bind 127.0.0.1,21 //绑定IP和端口<br># AnonymousBandwidth 8 //匿名用户带宽8KB<br># UserBandwidth 8 //用户带宽8KB<br>Umask 133:022 //文件和目录的umask<br>MinUID 1000 //用户ID至少要大于1000才能登陆<br>AllowUserFXP no //是否允许用户使用FXP协议登陆<br>AllowAnonymousFXP no //是否允许匿名用户使用FXP协议<br>ProhibitDotFilesWrite no //是否允许写入点文件<br>ProhibitDotFilesRead no //是否允许读取点文件<br>AnonymousCantUpload yes //不允许匿名用户上传<br>#NoChmod yes //不允许用户改变权限<br>#KeepAllFiles yes //允许用户断点续传<br>#Quota 1000:10//磁盘配额<br>#MaxDiskUsage 99 //磁盘的最大利用率<br>#NoRename yes //不允许自动重命名<br>IPV4Only yes //只允许使用IPV4协议</p>\n');
INSERT INTO `tbl_archive` VALUES ('10', '0', 'Storm通用命令向导', '19', '2018-01-25 13:55:27', '#Storm通用命令向导#概述所有的Storm命令通过$STORM_HOME/bin/storm脚本使用，不带参数运行storm脚本输出所有命令。命令行客户端命令：&nbsp;&nbsp;&nbsp;**1.jar**&nbsp;&nbsp;&nbsp;**2.sql**&nbsp;&nbsp;&nbsp;**3.kill**&nbsp;&nbsp;&nbsp;**4.activate**&nbs', null, '0', '198', null, null, '2018-01-25 13:55:27', null, null, null, '0', '0', '0', '0', '# Storm通用命令向导\n# 概述\n所有的Storm命令通过$STORM_HOME/bin/storm脚本使用，不带参数运行storm脚本输出所有命令。  \n命令行客户端命令：  \n&nbsp; &nbsp;  &nbsp; **1. jar**  \n&nbsp; &nbsp;  &nbsp; **2. sql**  \n&nbsp; &nbsp;  &nbsp; **3. kill**  \n&nbsp; &nbsp;  &nbsp; **4. activate**  \n&nbsp; &nbsp;  &nbsp; **5. deactivate**  \n&nbsp; &nbsp;  &nbsp; **6. rebalance**  \n&nbsp; &nbsp;  &nbsp; **7. repl**  \n&nbsp; &nbsp;  &nbsp; **8. classpath**  \n&nbsp; &nbsp;  &nbsp; **9. localconfvalue**  \n&nbsp; &nbsp;  &nbsp; **10. remoteconfvalue**  \n&nbsp; &nbsp;  &nbsp; **11. nimbus**  \n&nbsp; &nbsp;  &nbsp; **12. supervisor**  \n&nbsp; &nbsp;  &nbsp; **13. ui**  \n&nbsp; &nbsp;  &nbsp; **14. drpc**  \n&nbsp; &nbsp;  &nbsp; **15. blobstore**  \n&nbsp; &nbsp;  &nbsp; **16. dev-zookeeper**  \n&nbsp; &nbsp;  &nbsp; **17. get-errors**  \n&nbsp; &nbsp;  &nbsp; **18. heartbeats**  \n&nbsp; &nbsp;  &nbsp; **19. kill_workers**  \n&nbsp; &nbsp;  &nbsp; **20. list**  \n&nbsp; &nbsp;  &nbsp; **21. logviewer**  \n&nbsp; &nbsp;  &nbsp; **22. monitor**  \n&nbsp; &nbsp;  &nbsp; **23. node-health-check**  \n&nbsp; &nbsp;  &nbsp; **24. pacemaker**  \n&nbsp; &nbsp;  &nbsp; **25. set_log_level**  \n&nbsp; &nbsp;  &nbsp; **26. shell**  \n&nbsp; &nbsp;  &nbsp; **27. upload-credentials**  \n&nbsp; &nbsp;  &nbsp; **28. version**  \n&nbsp; &nbsp;  &nbsp; **29. help**  \n  \n  \n###  jar  \n语法：\n ``` \n storm jar topology-jar-path class ...\n ```\n 把Storm的jar文件和“~/.storm”的配置放到类路径中，以便当拓扑提交时，StormSubmitter会上传topology-jar-path的jar文件。  \n   \n###  sql  \n语法：\n ``` \nstorm sql sql-file topology-name \n ```\n 将SQL语句编译成一个trident topology并提交到Storm中。  \n   \n###  kill  \n语法：\n ```\nstorm kill topology-name [-w wait-time-secs]\n ```\n 杀死名为topology-name的topology。Storm首先会在拓扑的消息超时时间期间禁用Spout，以允许所有正在处理的消息完成处理。然后，Storm将会关闭Worker并清理它们的状态。可以使用-w标记覆盖Storm在禁用与关闭期间等待的时间长度。  \n   \n###  activate  \n语法：\n ``` \nstorm activate topology-name  \n ```  \n 激活指定topology的Spout。  \n  \n###  deactivate  \n语法：\n ```\nstorm deactivate topology-name \n ```\n 禁用指定topology的Spout。  \n  \n###  rebalance  \n语法：\n ```\nstorm rebalance topology-name [-w wait-time-secs] [-n new-num-workers] [-e component=parallelism]* \n ```\n 有时你可能希望扩散一些正在运行的拓扑的Worker。例如，假设你有一个10个节点的集群，每个节点运行4个Worker，然后假设需要添加另外10个节点到集群中。你可能希望有Spout扩散正在运行中的拓扑的Worker，这样每个节点运行两个Worker。解决的一种方法是杀死拓扑并重新提交拓扑，但Storm提供了一个rebalance的命令，我们可以用一种更简单的方法来做到这一点。  \n rebalance首先会在消息超时时间内禁用拓扑，使用-w可以覆盖超时时间，然后重新均衡分配集群的Worker，拓扑会返回到它原来的状态，即禁用的拓扑仍将禁用，激活的拓扑继续激活。  \n   \n###  repl  \n语法：\n ```\nstorm repl\n ```\n 打开一个包含类路径中的jar文件和配置的Clojure REPL，以便调试时使用。  \n   \n###  classpath\n语法：\n ```\nstorm classpath\n ```\n 打印出Storm客户端运行命令时使用的类路径。  \n   \n###  localconfvalue\n语法：\n ```\nstorm localconfvalue conf-name\n ```\n 打印出本地Storm配置的conf-name的值。本地Storm配置是~/.storm/storm.yaml与defaults.yaml合并的结果。  \n   \n###  remoteconfvalue\n语法：\n ```\nstorm remoteconfvalue conf-name\n ```\n 打印出远程集群Storm配置的conf-name的值。集群Storm配置是$STORM-PATH/conf/storm.yaml与defaults.yaml合并的结果。该命令必须在集群节点上运行。  \n   \n###  nimbus\n语法：\n ``` \nstorm nimbus\n ```\n 启动Nimbus守护进程。该命令应该使用daemontools或者monit工具监控运行。  \n   \n###  supervisor  \n语法：\n ```\nstorm supervisor\n ```\n 启动Supervisor守护进程。该命令应该使用daemontools或者monit工具监控运行。  \n   \n###  ui  \n语法：\n ```\nstorm ui\n ```\n 启动UI守护进程。UI为Storm集群提供了一个Web界面并显示运行拓扑的详细统计信息。该命令应该使用daemontools或者monit工具监控运行。  \n   \n###  drpc  \n语法：\n ```\nstorm drpc\n ```\n 启动一个DRPC守护进程。该命令应该使用daemontools或者monit工具监控运行。  \n   \n###  drpc  \n语法：\n ```\nstorm blobstore cmd\n ```\n ```\nlist [KEY...] \n列出blob存储区中当前的blob。\n\ncat [-f FILE] KEY\n读取blob，然后将其写入文件或标准输出（需要读取访问）。  \n\ncreate [-f FILE] [-a ACL ...] [--replication-factor NUMBER] KEY\n创建一个新的 blob。内容来自文件或输入的输入。ACL 在表单中: [用户名]: [r] [w] [a-] 可以是以逗号分隔的列表。  \n\nupdate [-f FILE] KEY\n更新 [-f 文件] 密钥-更新 blob 的内容。内容来自文件或输入的输入 (需要写访问)。  \n\ndelete KEY\n从blob存储区中删除条目 (需要写访问权限)。  \n\nset-acl [-s ACL] KEY\nacl 在表单中[uo]: [username]: [r] [w] [a-] 可以是逗号分隔列表 (需要管理员访问)。  \n\nreplication --read KEY\n用于读取 blob 的复制因子。  \n\nreplication --update --replication-factor NUMBER KEY where NUMBER > 0\n用于更新 blob 的复制因子。  \n\n例如, 以下内容将使用存储在数据中的数据来创建 mytopo:data.tgz 密钥. tgz用户alice将有完全访问, bob将有读/写访问和其他人将有读取访问。  \n\nStorm blobstore 创建 mytopo:data.tgz data.tgz -a u:alice:rwa, u:bob:rw, o::r.\n ```\n \n###  dev-zookeeper  \n语法：\n ```\nstorm dev-zookeeper\n ```\n 以dev.zookeeper.path配置的值作为本地目录，以storm.zookeeper.port配置的值作为端口，启动一个新的ZooKeeper服务，仅用来开发/测试。  \n   \n###  get-errors  \n语法：\n ```\nstorm get-errors\n ```\n 从运行的topology中获取最新的错误。返回的结果包含组件名称和组件的键值对，结果以 json 格式返回。  \n  \n###  heartbeats  \n语法：\n ```\nstorm heartbeats [cmd]\n ```\n ```\nlist PATH\n 列出 ClusterState 中当前路径下的心跳节点。 \n \nget PATH\n 在路径上获取心跳数据。\n ```\n   \n###  kill_workers  \n语法：\n ```\nstorm kill_workers \n ```\n kill掉Supervisor上运行的worker。这个命令应该运行在Supervisor的节点上。如果群集在安全模式下运行, 则用户需要在节点上具有管理员权限才能成功地kill所有worker。  \n   \n###  list  \n语法：\n ```\nstorm list \n ```\n列出正在运行的topologies及其状态。  \n   \n###  logviewer  \n语法：\n ```\nstorm logviewer \n ```\n 启动Logviewer守护进程。Logviewer提供一个Web接口查看Storm日志文件。该命令应该使用daemontools或者monit工具监控运行。  \n   \n###  monitor  \n语法：\n ```\nstorm monitor topology-name [-i interval-secs] [-m component-id] [-s stream-id] [-w [emitted | transferred]]\n ```\n 以交互方式监视给定topology的吞吐量。可以指定轮询间隔、组件id、流id、监视项 [emitted | transferred] 默认情况下, 轮询间隔为4秒;所有组件id 将被列出;流id为默认;观察状态是\'emitted\'。  \n###  node-health-check  \n语法：\n ```\nstorm node-health-check\n ```\n检查运行在本地的Supervisor的健康状态。  \n   \n###  pacemaker  \n语法：\n ```\nstorm pacemaker\n ```\n启动Pacemaker守护程序。此命令应在 daemontools 或monit工具的监督下运行。  \n   \n###  set_log_level  \n语法：\n ```\nstorm set_log_level -l [logger name]=[log level][:optional timeout] -r [logger name] topology-name\n ```\n动态更改拓扑日志级别  \n日志级别为： 所有、跟踪、调试、信息、警告、错误、致命、关闭和超时是整数秒。  \n ```\n./bin/storm set_log_level -l ROOT=DEBUG:30 topology-name\n将根记录器的级别设置为调试30秒\n \n./bin/storm set_log_level -l com.myapp=WARN topology-name\n设置com.myapp的级别为WARn=N, 警告30秒\n \n./bin/storm set_log_level -l com.myapp=WARN -l com.myOtherLogger=ERROR:123 topology-name\n将com.myapp的级别设置为警告不定期的, 并在123秒认定com.myOtherLogger错误\n \n./bin/storm set_log_level -r com.myOtherLogger topology-name\n清除设置, 重置回原始级别\n ```\n   \n###  shell  \n语法：\n ```\nstorm shell resourcesdir command args\n ```\n执行Shell脚本。\n ```\neg: storm shell resources/ python topology.py arg1 arg2\n ```\n###  upload-credentials  \n语法：\n ```\nstorm upload_credentials topology-name [credkey credvalue]*\n ```\n将一组新的整数上载到运行的topology中。  \n   \n###  version  \n语法：\n ```\nstorm version\n ```\n打印当前Storm的版本号。  \n   \n###  help  \n语法：\n ```\nstorm help\n ```\n打印一条帮助消息或可用命令列表。        \n ', '1', '<h1 id=\"h1-storm-\"><a name=\"Storm通用命令向导\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Storm通用命令向导</h1><h1 id=\"h1-u6982u8FF0\"><a name=\"概述\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>概述</h1><p>所有的Storm命令通过$STORM_HOME/bin/storm脚本使用，不带参数运行storm脚本输出所有命令。<br>命令行客户端命令：<br>&nbsp; &nbsp;  &nbsp; <strong>1. jar</strong><br>&nbsp; &nbsp;  &nbsp; <strong>2. sql</strong><br>&nbsp; &nbsp;  &nbsp; <strong>3. kill</strong><br>&nbsp; &nbsp;  &nbsp; <strong>4. activate</strong><br>&nbsp; &nbsp;  &nbsp; <strong>5. deactivate</strong><br>&nbsp; &nbsp;  &nbsp; <strong>6. rebalance</strong><br>&nbsp; &nbsp;  &nbsp; <strong>7. repl</strong><br>&nbsp; &nbsp;  &nbsp; <strong>8. classpath</strong><br>&nbsp; &nbsp;  &nbsp; <strong>9. localconfvalue</strong><br>&nbsp; &nbsp;  &nbsp; <strong>10. remoteconfvalue</strong><br>&nbsp; &nbsp;  &nbsp; <strong>11. nimbus</strong><br>&nbsp; &nbsp;  &nbsp; <strong>12. supervisor</strong><br>&nbsp; &nbsp;  &nbsp; <strong>13. ui</strong><br>&nbsp; &nbsp;  &nbsp; <strong>14. drpc</strong><br>&nbsp; &nbsp;  &nbsp; <strong>15. blobstore</strong><br>&nbsp; &nbsp;  &nbsp; <strong>16. dev-zookeeper</strong><br>&nbsp; &nbsp;  &nbsp; <strong>17. get-errors</strong><br>&nbsp; &nbsp;  &nbsp; <strong>18. heartbeats</strong><br>&nbsp; &nbsp;  &nbsp; <strong>19. kill_workers</strong><br>&nbsp; &nbsp;  &nbsp; <strong>20. list</strong><br>&nbsp; &nbsp;  &nbsp; <strong>21. logviewer</strong><br>&nbsp; &nbsp;  &nbsp; <strong>22. monitor</strong><br>&nbsp; &nbsp;  &nbsp; <strong>23. node-health-check</strong><br>&nbsp; &nbsp;  &nbsp; <strong>24. pacemaker</strong><br>&nbsp; &nbsp;  &nbsp; <strong>25. set_log_level</strong><br>&nbsp; &nbsp;  &nbsp; <strong>26. shell</strong><br>&nbsp; &nbsp;  &nbsp; <strong>27. upload-credentials</strong><br>&nbsp; &nbsp;  &nbsp; <strong>28. version</strong><br>&nbsp; &nbsp;  &nbsp; <strong>29. help</strong>  </p>\n<h3 id=\"h3-jar\"><a name=\"jar\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>jar</h3><p>语法：</p>\n<pre><code> storm jar topology-jar-path class ...\n</code></pre><p> 把Storm的jar文件和“~/.storm”的配置放到类路径中，以便当拓扑提交时，StormSubmitter会上传topology-jar-path的jar文件。  </p>\n<h3 id=\"h3-sql\"><a name=\"sql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>sql</h3><p>语法：</p>\n<pre><code>storm sql sql-file topology-name\n</code></pre><p> 将SQL语句编译成一个trident topology并提交到Storm中。  </p>\n<h3 id=\"h3-kill\"><a name=\"kill\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>kill</h3><p>语法：</p>\n<pre><code>storm kill topology-name [-w wait-time-secs]\n</code></pre><p> 杀死名为topology-name的topology。Storm首先会在拓扑的消息超时时间期间禁用Spout，以允许所有正在处理的消息完成处理。然后，Storm将会关闭Worker并清理它们的状态。可以使用-w标记覆盖Storm在禁用与关闭期间等待的时间长度。  </p>\n<h3 id=\"h3-activate\"><a name=\"activate\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>activate</h3><p>语法：</p>\n<pre><code>storm activate topology-name\n</code></pre><p> 激活指定topology的Spout。  </p>\n<h3 id=\"h3-deactivate\"><a name=\"deactivate\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>deactivate</h3><p>语法：</p>\n<pre><code>storm deactivate topology-name\n</code></pre><p> 禁用指定topology的Spout。  </p>\n<h3 id=\"h3-rebalance\"><a name=\"rebalance\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>rebalance</h3><p>语法：</p>\n<pre><code>storm rebalance topology-name [-w wait-time-secs] [-n new-num-workers] [-e component=parallelism]*\n</code></pre><p> 有时你可能希望扩散一些正在运行的拓扑的Worker。例如，假设你有一个10个节点的集群，每个节点运行4个Worker，然后假设需要添加另外10个节点到集群中。你可能希望有Spout扩散正在运行中的拓扑的Worker，这样每个节点运行两个Worker。解决的一种方法是杀死拓扑并重新提交拓扑，但Storm提供了一个rebalance的命令，我们可以用一种更简单的方法来做到这一点。<br> rebalance首先会在消息超时时间内禁用拓扑，使用-w可以覆盖超时时间，然后重新均衡分配集群的Worker，拓扑会返回到它原来的状态，即禁用的拓扑仍将禁用，激活的拓扑继续激活。  </p>\n<h3 id=\"h3-repl\"><a name=\"repl\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>repl</h3><p>语法：</p>\n<pre><code>storm repl\n</code></pre><p> 打开一个包含类路径中的jar文件和配置的Clojure REPL，以便调试时使用。  </p>\n<h3 id=\"h3-classpath\"><a name=\"classpath\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>classpath</h3><p>语法：</p>\n<pre><code>storm classpath\n</code></pre><p> 打印出Storm客户端运行命令时使用的类路径。  </p>\n<h3 id=\"h3-localconfvalue\"><a name=\"localconfvalue\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>localconfvalue</h3><p>语法：</p>\n<pre><code>storm localconfvalue conf-name\n</code></pre><p> 打印出本地Storm配置的conf-name的值。本地Storm配置是~/.storm/storm.yaml与defaults.yaml合并的结果。  </p>\n<h3 id=\"h3-remoteconfvalue\"><a name=\"remoteconfvalue\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>remoteconfvalue</h3><p>语法：</p>\n<pre><code>storm remoteconfvalue conf-name\n</code></pre><p> 打印出远程集群Storm配置的conf-name的值。集群Storm配置是$STORM-PATH/conf/storm.yaml与defaults.yaml合并的结果。该命令必须在集群节点上运行。  </p>\n<h3 id=\"h3-nimbus\"><a name=\"nimbus\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>nimbus</h3><p>语法：</p>\n<pre><code>storm nimbus\n</code></pre><p> 启动Nimbus守护进程。该命令应该使用daemontools或者monit工具监控运行。  </p>\n<h3 id=\"h3-supervisor\"><a name=\"supervisor\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>supervisor</h3><p>语法：</p>\n<pre><code>storm supervisor\n</code></pre><p> 启动Supervisor守护进程。该命令应该使用daemontools或者monit工具监控运行。  </p>\n<h3 id=\"h3-ui\"><a name=\"ui\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>ui</h3><p>语法：</p>\n<pre><code>storm ui\n</code></pre><p> 启动UI守护进程。UI为Storm集群提供了一个Web界面并显示运行拓扑的详细统计信息。该命令应该使用daemontools或者monit工具监控运行。  </p>\n<h3 id=\"h3-drpc\"><a name=\"drpc\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>drpc</h3><p>语法：</p>\n<pre><code>storm drpc\n</code></pre><p> 启动一个DRPC守护进程。该命令应该使用daemontools或者monit工具监控运行。  </p>\n<h3 id=\"h3-drpc\"><a name=\"drpc\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>drpc</h3><p>语法：</p>\n<pre><code>storm blobstore cmd\n</code></pre><pre><code>list [KEY...] \n列出blob存储区中当前的blob。\n\ncat [-f FILE] KEY\n读取blob，然后将其写入文件或标准输出（需要读取访问）。  \n\ncreate [-f FILE] [-a ACL ...] [--replication-factor NUMBER] KEY\n创建一个新的 blob。内容来自文件或输入的输入。ACL 在表单中: [用户名]: [r] [w] [a-] 可以是以逗号分隔的列表。  \n\nupdate [-f FILE] KEY\n更新 [-f 文件] 密钥-更新 blob 的内容。内容来自文件或输入的输入 (需要写访问)。  \n\ndelete KEY\n从blob存储区中删除条目 (需要写访问权限)。  \n\nset-acl [-s ACL] KEY\nacl 在表单中[uo]: [username]: [r] [w] [a-] 可以是逗号分隔列表 (需要管理员访问)。  \n\nreplication --read KEY\n用于读取 blob 的复制因子。  \n\nreplication --update --replication-factor NUMBER KEY where NUMBER &gt; 0\n用于更新 blob 的复制因子。  \n\n例如, 以下内容将使用存储在数据中的数据来创建 mytopo:data.tgz 密钥. tgz用户alice将有完全访问, bob将有读/写访问和其他人将有读取访问。  \n\nStorm blobstore 创建 mytopo:data.tgz data.tgz -a u:alice:rwa, u:bob:rw, o::r.\n</code></pre><h3 id=\"h3-dev-zookeeper\"><a name=\"dev-zookeeper\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>dev-zookeeper</h3><p>语法：</p>\n<pre><code>storm dev-zookeeper\n</code></pre><p> 以dev.zookeeper.path配置的值作为本地目录，以storm.zookeeper.port配置的值作为端口，启动一个新的ZooKeeper服务，仅用来开发/测试。  </p>\n<h3 id=\"h3-get-errors\"><a name=\"get-errors\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>get-errors</h3><p>语法：</p>\n<pre><code>storm get-errors\n</code></pre><p> 从运行的topology中获取最新的错误。返回的结果包含组件名称和组件的键值对，结果以 json 格式返回。  </p>\n<h3 id=\"h3-heartbeats\"><a name=\"heartbeats\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>heartbeats</h3><p>语法：</p>\n<pre><code>storm heartbeats [cmd]\n</code></pre><pre><code>list PATH\n 列出 ClusterState 中当前路径下的心跳节点。 \n\nget PATH\n 在路径上获取心跳数据。\n</code></pre><h3 id=\"h3-kill_workers\"><a name=\"kill_workers\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>kill_workers</h3><p>语法：</p>\n<pre><code>storm kill_workers\n</code></pre><p> kill掉Supervisor上运行的worker。这个命令应该运行在Supervisor的节点上。如果群集在安全模式下运行, 则用户需要在节点上具有管理员权限才能成功地kill所有worker。  </p>\n<h3 id=\"h3-list\"><a name=\"list\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>list</h3><p>语法：</p>\n<pre><code>storm list\n</code></pre><p>列出正在运行的topologies及其状态。  </p>\n<h3 id=\"h3-logviewer\"><a name=\"logviewer\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>logviewer</h3><p>语法：</p>\n<pre><code>storm logviewer\n</code></pre><p> 启动Logviewer守护进程。Logviewer提供一个Web接口查看Storm日志文件。该命令应该使用daemontools或者monit工具监控运行。  </p>\n<h3 id=\"h3-monitor\"><a name=\"monitor\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>monitor</h3><p>语法：</p>\n<pre><code>storm monitor topology-name [-i interval-secs] [-m component-id] [-s stream-id] [-w [emitted | transferred]]\n</code></pre><p> 以交互方式监视给定topology的吞吐量。可以指定轮询间隔、组件id、流id、监视项 [emitted | transferred] 默认情况下, 轮询间隔为4秒;所有组件id 将被列出;流id为默认;观察状态是’emitted’。  </p>\n<h3 id=\"h3-node-health-check\"><a name=\"node-health-check\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>node-health-check</h3><p>语法：</p>\n<pre><code>storm node-health-check\n</code></pre><p>检查运行在本地的Supervisor的健康状态。  </p>\n<h3 id=\"h3-pacemaker\"><a name=\"pacemaker\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>pacemaker</h3><p>语法：</p>\n<pre><code>storm pacemaker\n</code></pre><p>启动Pacemaker守护程序。此命令应在 daemontools 或monit工具的监督下运行。  </p>\n<h3 id=\"h3-set_log_level\"><a name=\"set_log_level\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>set_log_level</h3><p>语法：</p>\n<pre><code>storm set_log_level -l [logger name]=[log level][:optional timeout] -r [logger name] topology-name\n</code></pre><p>动态更改拓扑日志级别<br>日志级别为： 所有、跟踪、调试、信息、警告、错误、致命、关闭和超时是整数秒。  </p>\n<pre><code>./bin/storm set_log_level -l ROOT=DEBUG:30 topology-name\n将根记录器的级别设置为调试30秒\n\n./bin/storm set_log_level -l com.myapp=WARN topology-name\n设置com.myapp的级别为WARn=N, 警告30秒\n\n./bin/storm set_log_level -l com.myapp=WARN -l com.myOtherLogger=ERROR:123 topology-name\n将com.myapp的级别设置为警告不定期的, 并在123秒认定com.myOtherLogger错误\n\n./bin/storm set_log_level -r com.myOtherLogger topology-name\n清除设置, 重置回原始级别\n</code></pre><h3 id=\"h3-shell\"><a name=\"shell\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>shell</h3><p>语法：</p>\n<pre><code>storm shell resourcesdir command args\n</code></pre><p>执行Shell脚本。</p>\n<pre><code>eg: storm shell resources/ python topology.py arg1 arg2\n</code></pre><h3 id=\"h3-upload-credentials\"><a name=\"upload-credentials\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>upload-credentials</h3><p>语法：</p>\n<pre><code>storm upload_credentials topology-name [credkey credvalue]*\n</code></pre><p>将一组新的整数上载到运行的topology中。  </p>\n<h3 id=\"h3-version\"><a name=\"version\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>version</h3><p>语法：</p>\n<pre><code>storm version\n</code></pre><p>打印当前Storm的版本号。  </p>\n<h3 id=\"h3-help\"><a name=\"help\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>help</h3><p>语法：</p>\n<pre><code>storm help\n</code></pre><p>打印一条帮助消息或可用命令列表。        </p>\n');
INSERT INTO `tbl_archive` VALUES ('11', '0', 'hadoop3.0新特性之Erasure Coding小窥', '23', '2018-01-25 14:25:22', 'hadoop3.0新特性之Erasure Coding小窥', null, '0', '263', null, null, '2018-01-25 14:25:22', null, null, null, '0', '0', '0', '0', '#### 前言\n在HDFS中默认的3x副本方案在存储空间和其他资源上有200%的开销，这对数据存储来说代价是昂贵的。然而对于访问量较低的数据其他副本，仍然消耗与第一个副本相同的资源。对于这样的一个问题hadoop3.0提供了Erasure Coding（EC）来代替副本。EC提供了相同的容错级别，而存储空间占用的相对较少。在EC设置中，存储开销不超过50%。\n#### 背景\n在存储系统中，EC最引人注目的用法是廉价磁盘冗余阵列(RAID)。RAID通过栅格（striping）实现EC，它有将逻辑顺序数据(例如文件)划分为更小的单元(如位、字节或块)，\n并在不同的磁盘上存储连续的单元。栅格化分布的单元被称为栅格单元。对于原始数据的栅格单元，计算并存储一定数量的奇偶性单元格称为编码过程。任何栅格单元的错误都可以基于存活数据和奇偶校验单元的解码计算来恢复。\n\nEC和HDFS的集成可以提高存储效率，同时提供与传统基于副本的HDFS相同的数据持久性。如：一个有6个块的3x副本文件将消耗6个3=18个磁盘空间。但是对于EC(6个数据，3个奇偶校验)部署，它只会消耗9个磁盘空间。\n\n#### EC架构\n在EC的环境中栅格有几个突出的优点：首先，它支持在线EC(以EC格式立即写入数据)，避免转换阶段，并立即节省存储空间。在线EC还可以通过并行地利用多个disk spindles来提高连续的input/output性能;其次，它自然地将一个小文件分发给多个DataNodes，并消除了将多个文件绑定到单个编码组的需要。这极大地简化了文件操作。\n\nEC对HDFS做了许多的扩展，如：\nNameNode扩展：栅格 HDFS文件在逻辑上是由块组组成的，每个组包含一定数量的内部块。为了减少这些额外块的NameNode内存消耗，引入了一个新的分层块命名协议。块组的ID可以从它的任何内部块的ID中推断出来。这允许在块组的级别上进行管理。\nClient 扩展：增加Client read和write路径，以便在块组中的多个内部块上工作。在output/write路径上，DFSStripedOutputStream管理一组数据流，每个DataNode在当前块组中存储一个内部块。\nstreamer主要是异步工作的。一个协调器负责整个块组的操作，包括结束当前的块组，分配一个新的块组，等等\n在input/read路径上，DFSStripedInputStream将一个请求的逻辑字节转换为存储在DataNodes上的内部块。然后，它会并行地发出read请求。在失败时，它会发出额外的read请求来解码。\nErasure coding策略：为了适应异构的工作负载，我们允许HDFS集群中的文件和目录具有不同的副本和EC策略。EC策略封装了如何对文件进行编码/解码。每个策略都由以下定义\n1.EC模式:这包括一个EC组中的数据和奇偶校验块(例如，6+3)，以及编解码算法。\n2.一个 栅格单元的大小。这决定了栅格读取和写入的粒度，包括缓冲区大小和编码工作。\n类似于HDFS存储策略，EC在目录上设置了EC策略。当创建一个文件时，它将继承其最近的父目录的EC策略。\n目录级EC策略只会影响目录中创建的新文件。一旦创建了一个文件，它的EC策略可以被查询，但不会改变。\n如果一个EC文件被重命名为具有不同EC策略的目录，那么该文件保留其现有的EC策略。\n将文件转换为不同的EC策略需要重写它的数据;通过复制文件(例如通过distcp)来完成这个工作，而不是重新命名它。\n\nDataNode 扩展：DataNode运行一个额外的ErasureCodingWorker(ECWorker)任务，用于对失败的EC块进行后台恢复。由NameNode检测到失败的EC块，然后选择一个DataNode来执行恢复工作。恢复任务作为心跳响应传递。这个过程类似于副本块在失败时如何被恢复。恢复完成了三个关键任务:\n1. 从源节点读取数据:使用专用的线程池从源节点并行读取输入数据。根据EC策略，它将read请求调度到所有源目标，并且只read用于恢复的输入块。\n2. 解码数据并生成输出数据：新的数据和奇偶校验块从输入数据中解码。所有丢失的数据和奇偶校验块一起被解码。\n3. 将生成的数据块传输到目标节点:解码完成后，已恢复的块被传输到目标DataNodes。\n\n', '0', '<h4 id=\"h4-u524Du8A00\"><a name=\"前言\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>前言</h4><p>在HDFS中默认的3x副本方案在存储空间和其他资源上有200%的开销，这对数据存储来说代价是昂贵的。然而对于访问量较低的数据其他副本，仍然消耗与第一个副本相同的资源。对于这样的一个问题hadoop3.0提供了Erasure Coding（EC）来代替副本。EC提供了相同的容错级别，而存储空间占用的相对较少。在EC设置中，存储开销不超过50%。</p>\n<h4 id=\"h4-u80CCu666F\"><a name=\"背景\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>背景</h4><p>在存储系统中，EC最引人注目的用法是廉价磁盘冗余阵列(RAID)。RAID通过栅格（striping）实现EC，它有将逻辑顺序数据(例如文件)划分为更小的单元(如位、字节或块)，<br>并在不同的磁盘上存储连续的单元。栅格化分布的单元被称为栅格单元。对于原始数据的栅格单元，计算并存储一定数量的奇偶性单元格称为编码过程。任何栅格单元的错误都可以基于存活数据和奇偶校验单元的解码计算来恢复。</p>\n<p>EC和HDFS的集成可以提高存储效率，同时提供与传统基于副本的HDFS相同的数据持久性。如：一个有6个块的3x副本文件将消耗6个3=18个磁盘空间。但是对于EC(6个数据，3个奇偶校验)部署，它只会消耗9个磁盘空间。</p>\n<h4 id=\"h4-ec-\"><a name=\"EC架构\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>EC架构</h4><p>在EC的环境中栅格有几个突出的优点：首先，它支持在线EC(以EC格式立即写入数据)，避免转换阶段，并立即节省存储空间。在线EC还可以通过并行地利用多个disk spindles来提高连续的input/output性能;其次，它自然地将一个小文件分发给多个DataNodes，并消除了将多个文件绑定到单个编码组的需要。这极大地简化了文件操作。</p>\n<p>EC对HDFS做了许多的扩展，如：<br>NameNode扩展：栅格 HDFS文件在逻辑上是由块组组成的，每个组包含一定数量的内部块。为了减少这些额外块的NameNode内存消耗，引入了一个新的分层块命名协议。块组的ID可以从它的任何内部块的ID中推断出来。这允许在块组的级别上进行管理。<br>Client 扩展：增加Client read和write路径，以便在块组中的多个内部块上工作。在output/write路径上，DFSStripedOutputStream管理一组数据流，每个DataNode在当前块组中存储一个内部块。<br>streamer主要是异步工作的。一个协调器负责整个块组的操作，包括结束当前的块组，分配一个新的块组，等等<br>在input/read路径上，DFSStripedInputStream将一个请求的逻辑字节转换为存储在DataNodes上的内部块。然后，它会并行地发出read请求。在失败时，它会发出额外的read请求来解码。<br>Erasure coding策略：为了适应异构的工作负载，我们允许HDFS集群中的文件和目录具有不同的副本和EC策略。EC策略封装了如何对文件进行编码/解码。每个策略都由以下定义<br>1.EC模式:这包括一个EC组中的数据和奇偶校验块(例如，6+3)，以及编解码算法。<br>2.一个 栅格单元的大小。这决定了栅格读取和写入的粒度，包括缓冲区大小和编码工作。<br>类似于HDFS存储策略，EC在目录上设置了EC策略。当创建一个文件时，它将继承其最近的父目录的EC策略。<br>目录级EC策略只会影响目录中创建的新文件。一旦创建了一个文件，它的EC策略可以被查询，但不会改变。<br>如果一个EC文件被重命名为具有不同EC策略的目录，那么该文件保留其现有的EC策略。<br>将文件转换为不同的EC策略需要重写它的数据;通过复制文件(例如通过distcp)来完成这个工作，而不是重新命名它。</p>\n<p>DataNode 扩展：DataNode运行一个额外的ErasureCodingWorker(ECWorker)任务，用于对失败的EC块进行后台恢复。由NameNode检测到失败的EC块，然后选择一个DataNode来执行恢复工作。恢复任务作为心跳响应传递。这个过程类似于副本块在失败时如何被恢复。恢复完成了三个关键任务:</p>\n<ol>\n<li>从源节点读取数据:使用专用的线程池从源节点并行读取输入数据。根据EC策略，它将read请求调度到所有源目标，并且只read用于恢复的输入块。</li><li>解码数据并生成输出数据：新的数据和奇偶校验块从输入数据中解码。所有丢失的数据和奇偶校验块一起被解码。</li><li>将生成的数据块传输到目标节点:解码完成后，已恢复的块被传输到目标DataNodes。</li></ol>\n');
INSERT INTO `tbl_archive` VALUES ('12', '0', 'CRH5.1适配Power9以及Hadoop功能测试', '18', '2018-01-25 14:49:30', '在Power9上使用CRH5.1安装Hadoop和zookeeper，并且进行了Hadoop的一些基本功能测试', null, '0', '638', null, null, '2018-01-25 14:49:30', null, null, null, '0', '0', '0', '0', '# 一、安装\n## 1.1安装环境\n### 1.1.1 java环境的配置\n#### 1.1.1.1查看已经安装的java (CRH5.1所支持的jdk版本1.8)\n```\nrpm -qa |grep java\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/1.png)\n\n#### 1.1.1.2如果没有安装使用yum 安装\n#### 1.1.1.3配置环境变量\n```\nVim /etc/profile.d/java.sh 添加java的安装路径 如下图：\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/2.png)\n#### 1.1.1.4 刷新环境变量 查看配置是否生效\n```\nSource /etc/profile\n```\n### 1.1.2 关闭防火墙、selinux\n#### 1.1.2.1关闭防火墙\n```\nsystemctl disable direwalld.service\nsystemctl stop direwalld.service\n```\n#### 1.1.2.2关闭selinux\n```\n临时关闭使用 setenforce 0  （不需要重启机器）\n永久关闭 vim /etc/selinux/config\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/3.png)\n\n### 1.1.3 修改主机名和IP地址的映射\n```\nVim /etc/hosts\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/4.png)\n### 1.1.4 配置ssh免密码登录\n#### 1.1.4.1 生成密钥文件\n```\nssh-keygen 连按几次Enter\n```\n#### 1.1.4.2 将生成密钥拷贝给需要信任的主机\n\n```\n‘ssh-copy-id P9-CentOS74\n```\n## 1.2.本地源配置\n### 1.2.1搭建http服务器\n#### 1.2.1.1 安装启动http\n```\n安装 yum install -y httpd\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/5.png)\n```\n启动 systemctl start httpd.service\n查看状态 systemctl status httpd.service\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/6.png)\n### 1.2.2拷贝源到本地目录 创建repo文件\n#### 1.2.2.1 将CRH5.1 ppc64le 的所有包拷贝到/var/www/html文件下\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/7.png)\n#### 1.2.2.2 在/var/www/html/CRH5.1/ppc64le 执行createrpo ./ 生成repodata文件\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/8.png)\n#### 1.2.2.3编辑/etc/yum.repos.d/ambari.repo文件添加一下内容\n\n```\n[redoop-crh5.1]\n #Packages for Redoop\'s Distribution for Hadoop, Version 5, on RedHat	or CentOS 7 ppc64le\nname=Redoop\'s Distribution for Hadoop, Version 5.1\nbaseurl=http://192.*.*.*/CRH5.1/ppc64le\ngpgcheck=0\nenabaled=1\n```\n#### 1.2.2.4 刷新所有源文件\n```\nYum clean all\n```\n#### 1.2.2.5 检验本地源是否成功\n```\nYum search ambary-server\n```\n ![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/11.png)\n\n## 1.3.安装配置ambari\n### 1.3.1安装ambari\n#### 1.3.1.1使用yum install -y ambary-server \n ![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/12.png)\n### 1.3.2初始化ambari\n#### 1.3.2.1 ambari-server setup\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/13.png)\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/14.png)\n### 1.3.3启动ambari-server \n#### 1.3.3.1 ambari-server start\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/15.png)\n### 1.3.4 访问8080端口进入管理界面\n#### 1.3.4.1在浏览器访问IP:8080\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/16.png)\n#### 1.3.4.2 输入用户名和密码登录 （默认都为admin）\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/17.png)\n#### 1.3.4.3点击向导输入系群名 点击下一步\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/18.png)\n#### 1.3.4.4 集群安装向导：选择软件包\n```\n选择系统默认的软件包CRH5.1，选择OS为redhat7-ppc7，\n路径为：/etc/yum.repo.d/ambary.repo配置路径\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/19.png)\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/20.png)\n#### 1.3.4.5填入主机名，复制主机秘钥，到输入框，注册主机\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/21.png)\n#### 1.3.4.6 等待机器的安装与检测\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/22.png)\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/23.png)\n## 1.4.Hadoop和zookeeper的安装\n### 1.4.1安装hadoop和zookeeper\n在选择服务中选择需要安装的服务\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/24.png)\n点击下一步\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/25.png)\n查看服务分配的主机\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/26.png)\n在此界面可以更改一些配置\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/27.png)\n经过引导界面等待 安装完成\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/28.png)\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/29.png)\n# 二 Hadoop基本测试\n## 2.1基本功能测试\n### 2.1.1,hdfs put上传文件\n#### 2.1.1.1创建文件并插入数据\n\n```\n[root@P9-CentOS74 opt]# vim demo\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/30.png)\n#### 2.1.1.2把创建好的文件上传至hdfs的/input目录下\n```\nhdfs dfs -put ./demo /input\n```\n2.1.1.3查看文件是否上传成功\n\n```\nhdfs dfs -ls /input\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/31.png)\n\n#### 2.1.1.4 hdfs get 文件到本地\n\n```\nhdfs dfs -get /input/demo \n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/32.png)\n### 2.1.2执行wordcount程序验证hadoop功能\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/33.png)\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/34.png)\n### 2.1.3执行Hadoop TestDFSIO\n#### 2.1.3.1 Write\nTestDFSIO  write\nTestDFSIO 用于测试hdfs的IO性能，使用一个mapReduce作业来并发的执行读写操作，每个map任务用于读或写每个文件，map的输出用于手机与处理文件相关的统计信息，Reduce用于累积和统计信息，并产生summary。\n```\n写入1个1000MB的文件:\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 1 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/35.png)\n\n```\n写入5个1000MB的文件:\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 5 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/36.png)\n```\n写入10个1000MB文件(可根据机器改变文件大小)：\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 10 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/37.png)\n```\n写入15个1000MB文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 15 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/38.png)\n```\n写入20个1000MB文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 20 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/39.png)\n \n#### 2.1.3.2 Read\n```\n读取1个1000MB的文件:\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 1 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/40.png)\n```\n读取5个1000MB的文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 5 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/41.png)\n```\n读取10个1000M的文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 10 -size 1000\n```\n!image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/42.png)\n\n```\n读取15个1000M的文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 15 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/43.png)\n\n```\n读取20个1000M的文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 20 -size 1000\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/44.png)\n \n#### 2.1.3.3 Clean\n```\n清空测试数据\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -clean\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/45.png)\n \n## 2.2压力测试\n### 2.2.1 nnbench测试\nnnbench用于测试NameNode的负载，他会产生很多余HDFS相关的请求，给NameNode施加较大的压力。这个测试能在hdfs上模拟创建，读取，重命名和删除文件等操作。Nnbench的用法如下：\n\n```\n下面是使用12个mapper和6个Reduce来创建1000个文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar nnbench -operation create_write -maps 12 -reduces 6 -blockSize 1 -bytesToWrite 0 -numberOfFiles 1000 -replicationFactorPerFile 3 -readFileAfterOpen true -baseDir /benchmarks/NNBench-`hostname -s`\n```\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/46.png)\n\n### 2.2.2mrbench测试\nmrbench会多次重复一个小作业，用于检查在集群上小作业的是否可重复以及运行是否可高效，用法如下：\n\n```\n运行一个小作业一共50次\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar mrbench -numRuns 50\n```\n最终结果\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/47.png)\n \n\n# 三 结果统计\n## 3.1 Ambari 安装测试报告\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/48.png)\n \n## 3.2 Hadoop 功能测试报告\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/49.png)\n## 3.3 TestDFSIO性能测试展\n![image](http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/50.png)\n\n \n\n \n\n\n\n\n\n \n\n\n\n\n\n', '0', '<h1 id=\"h1--\"><a name=\"一、安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>一、安装</h1><h2 id=\"h2-1-1-\"><a name=\"1.1安装环境\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1安装环境</h2><h3 id=\"h3-1-1-1-java-\"><a name=\"1.1.1 java环境的配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.1 java环境的配置</h3><h4 id=\"h4-1-1-1-1-java-crh5-1-jdk-1-8-\"><a name=\"1.1.1.1查看已经安装的java (CRH5.1所支持的jdk版本1.8)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.1.1查看已经安装的java (CRH5.1所支持的jdk版本1.8)</h4><pre><code>rpm -qa |grep java\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/1.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-1-1-2-yum-\"><a name=\"1.1.1.2如果没有安装使用yum 安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.1.2如果没有安装使用yum 安装</h4><h4 id=\"h4-1-1-1-3-\"><a name=\"1.1.1.3配置环境变量\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.1.3配置环境变量</h4><pre><code>Vim /etc/profile.d/java.sh 添加java的安装路径 如下图：\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/2.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-1-1-4-\"><a name=\"1.1.1.4 刷新环境变量 查看配置是否生效\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.1.4 刷新环境变量 查看配置是否生效</h4><pre><code>Source /etc/profile\n</code></pre><h3 id=\"h3-1-1-2-selinux\"><a name=\"1.1.2 关闭防火墙、selinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.2 关闭防火墙、selinux</h3><h4 id=\"h4-1-1-2-1-\"><a name=\"1.1.2.1关闭防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.2.1关闭防火墙</h4><pre><code>systemctl disable direwalld.service\nsystemctl stop direwalld.service\n</code></pre><h4 id=\"h4-1-1-2-2-selinux\"><a name=\"1.1.2.2关闭selinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.2.2关闭selinux</h4><pre><code>临时关闭使用 setenforce 0  （不需要重启机器）\n永久关闭 vim /etc/selinux/config\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/3.png\" alt=\"image\"></p>\n<h3 id=\"h3-1-1-3-ip-\"><a name=\"1.1.3 修改主机名和IP地址的映射\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.3 修改主机名和IP地址的映射</h3><pre><code>Vim /etc/hosts\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/4.png\" alt=\"image\"></p>\n<h3 id=\"h3-1-1-4-ssh-\"><a name=\"1.1.4 配置ssh免密码登录\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.4 配置ssh免密码登录</h3><h4 id=\"h4-1-1-4-1-\"><a name=\"1.1.4.1 生成密钥文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.4.1 生成密钥文件</h4><pre><code>ssh-keygen 连按几次Enter\n</code></pre><h4 id=\"h4-1-1-4-2-\"><a name=\"1.1.4.2 将生成密钥拷贝给需要信任的主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.4.2 将生成密钥拷贝给需要信任的主机</h4><pre><code>‘ssh-copy-id P9-CentOS74\n</code></pre><h2 id=\"h2-1-2-\"><a name=\"1.2.本地源配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.本地源配置</h2><h3 id=\"h3-1-2-1-http-\"><a name=\"1.2.1搭建http服务器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.1搭建http服务器</h3><h4 id=\"h4-1-2-1-1-http\"><a name=\"1.2.1.1 安装启动http\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.1.1 安装启动http</h4><pre><code>安装 yum install -y httpd\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/5.png\" alt=\"image\"></p>\n<pre><code>启动 systemctl start httpd.service\n查看状态 systemctl status httpd.service\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/6.png\" alt=\"image\"></p>\n<h3 id=\"h3-1-2-2-repo-\"><a name=\"1.2.2拷贝源到本地目录 创建repo文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.2拷贝源到本地目录 创建repo文件</h3><h4 id=\"h4-1-2-2-1-crh5-1-ppc64le-var-www-html-\"><a name=\"1.2.2.1 将CRH5.1 ppc64le 的所有包拷贝到/var/www/html文件下\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.2.1 将CRH5.1 ppc64le 的所有包拷贝到/var/www/html文件下</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/7.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-2-2-2-var-www-html-crh5-1-ppc64le-createrpo-repodata-\"><a name=\"1.2.2.2 在/var/www/html/CRH5.1/ppc64le 执行createrpo ./ 生成repodata文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.2.2 在/var/www/html/CRH5.1/ppc64le 执行createrpo ./ 生成repodata文件</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/8.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-2-2-3-etc-yum-repos-d-ambari-repo-\"><a name=\"1.2.2.3编辑/etc/yum.repos.d/ambari.repo文件添加一下内容\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.2.3编辑/etc/yum.repos.d/ambari.repo文件添加一下内容</h4><pre><code>[redoop-crh5.1]\n #Packages for Redoop&#39;s Distribution for Hadoop, Version 5, on RedHat    or CentOS 7 ppc64le\nname=Redoop&#39;s Distribution for Hadoop, Version 5.1\nbaseurl=http://192.*.*.*/CRH5.1/ppc64le\ngpgcheck=0\nenabaled=1\n</code></pre><h4 id=\"h4-1-2-2-4-\"><a name=\"1.2.2.4 刷新所有源文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.2.4 刷新所有源文件</h4><pre><code>Yum clean all\n</code></pre><h4 id=\"h4-1-2-2-5-\"><a name=\"1.2.2.5 检验本地源是否成功\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.2.5 检验本地源是否成功</h4><pre><code>Yum search ambary-server\n</code></pre><p> <img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/11.png\" alt=\"image\"></p>\n<h2 id=\"h2-1-3-ambari\"><a name=\"1.3.安装配置ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.安装配置ambari</h2><h3 id=\"h3-1-3-1-ambari\"><a name=\"1.3.1安装ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.1安装ambari</h3><h4 id=\"h4-1-3-1-1-yum-install-y-ambary-server\"><a name=\"1.3.1.1使用yum install -y ambary-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.1.1使用yum install -y ambary-server</h4><p> <img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/12.png\" alt=\"image\"></p>\n<h3 id=\"h3-1-3-2-ambari\"><a name=\"1.3.2初始化ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.2初始化ambari</h3><h4 id=\"h4-1-3-2-1-ambari-server-setup\"><a name=\"1.3.2.1 ambari-server setup\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.2.1 ambari-server setup</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/13.png\" alt=\"image\"><br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/14.png\" alt=\"image\"></p>\n<h3 id=\"h3-1-3-3-ambari-server\"><a name=\"1.3.3启动ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.3启动ambari-server</h3><h4 id=\"h4-1-3-3-1-ambari-server-start\"><a name=\"1.3.3.1 ambari-server start\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.3.1 ambari-server start</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/15.png\" alt=\"image\"></p>\n<h3 id=\"h3-1-3-4-8080-\"><a name=\"1.3.4 访问8080端口进入管理界面\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.4 访问8080端口进入管理界面</h3><h4 id=\"h4-1-3-4-1-ip-8080\"><a name=\"1.3.4.1在浏览器访问IP:8080\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.4.1在浏览器访问IP:8080</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/16.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-3-4-2-admin-\"><a name=\"1.3.4.2 输入用户名和密码登录 （默认都为admin）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.4.2 输入用户名和密码登录 （默认都为admin）</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/17.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-3-4-3-\"><a name=\"1.3.4.3点击向导输入系群名 点击下一步\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.4.3点击向导输入系群名 点击下一步</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/18.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-3-4-4-\"><a name=\"1.3.4.4 集群安装向导：选择软件包\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.4.4 集群安装向导：选择软件包</h4><pre><code>选择系统默认的软件包CRH5.1，选择OS为redhat7-ppc7，\n路径为：/etc/yum.repo.d/ambary.repo配置路径\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/19.png\" alt=\"image\"><br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/20.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-3-4-5-\"><a name=\"1.3.4.5填入主机名，复制主机秘钥，到输入框，注册主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.4.5填入主机名，复制主机秘钥，到输入框，注册主机</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/21.png\" alt=\"image\"></p>\n<h4 id=\"h4-1-3-4-6-\"><a name=\"1.3.4.6 等待机器的安装与检测\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.4.6 等待机器的安装与检测</h4><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/22.png\" alt=\"image\"><br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/23.png\" alt=\"image\"></p>\n<h2 id=\"h2-1-4-hadoop-zookeeper-\"><a name=\"1.4.Hadoop和zookeeper的安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4.Hadoop和zookeeper的安装</h2><h3 id=\"h3-1-4-1-hadoop-zookeeper\"><a name=\"1.4.1安装hadoop和zookeeper\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4.1安装hadoop和zookeeper</h3><p>在选择服务中选择需要安装的服务<br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/24.png\" alt=\"image\"><br>点击下一步<br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/25.png\" alt=\"image\"><br>查看服务分配的主机<br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/26.png\" alt=\"image\"><br>在此界面可以更改一些配置<br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/27.png\" alt=\"image\"><br>经过引导界面等待 安装完成<br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/28.png\" alt=\"image\"><br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/29.png\" alt=\"image\"></p>\n<h1 id=\"h1--hadoop-\"><a name=\"二 Hadoop基本测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>二 Hadoop基本测试</h1><h2 id=\"h2-2-1-\"><a name=\"2.1基本功能测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1基本功能测试</h2><h3 id=\"h3-2-1-1-hdfs-put-\"><a name=\"2.1.1,hdfs put上传文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.1,hdfs put上传文件</h3><h4 id=\"h4-2-1-1-1-\"><a name=\"2.1.1.1创建文件并插入数据\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.1.1创建文件并插入数据</h4><pre><code>[root@P9-CentOS74 opt]# vim demo\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/30.png\" alt=\"image\"></p>\n<h4 id=\"h4-2-1-1-2-hdfs-input-\"><a name=\"2.1.1.2把创建好的文件上传至hdfs的/input目录下\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.1.2把创建好的文件上传至hdfs的/input目录下</h4><pre><code>hdfs dfs -put ./demo /input\n</code></pre><p>2.1.1.3查看文件是否上传成功</p>\n<pre><code>hdfs dfs -ls /input\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/31.png\" alt=\"image\"></p>\n<h4 id=\"h4-2-1-1-4-hdfs-get-\"><a name=\"2.1.1.4 hdfs get 文件到本地\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.1.4 hdfs get 文件到本地</h4><pre><code>hdfs dfs -get /input/demo\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/32.png\" alt=\"image\"></p>\n<h3 id=\"h3-2-1-2-wordcount-hadoop-\"><a name=\"2.1.2执行wordcount程序验证hadoop功能\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.2执行wordcount程序验证hadoop功能</h3><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/33.png\" alt=\"image\"><br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/34.png\" alt=\"image\"></p>\n<h3 id=\"h3-2-1-3-hadoop-testdfsio\"><a name=\"2.1.3执行Hadoop TestDFSIO\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.3执行Hadoop TestDFSIO</h3><h4 id=\"h4-2-1-3-1-write\"><a name=\"2.1.3.1 Write\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.3.1 Write</h4><p>TestDFSIO  write<br>TestDFSIO 用于测试hdfs的IO性能，使用一个mapReduce作业来并发的执行读写操作，每个map任务用于读或写每个文件，map的输出用于手机与处理文件相关的统计信息，Reduce用于累积和统计信息，并产生summary。</p>\n<pre><code>写入1个1000MB的文件:\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 1 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/35.png\" alt=\"image\"></p>\n<pre><code>写入5个1000MB的文件:\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 5 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/36.png\" alt=\"image\"></p>\n<pre><code>写入10个1000MB文件(可根据机器改变文件大小)：\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 10 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/37.png\" alt=\"image\"></p>\n<pre><code>写入15个1000MB文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 15 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/38.png\" alt=\"image\"></p>\n<pre><code>写入20个1000MB文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -write -nrFiles 20 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/39.png\" alt=\"image\"></p>\n<h4 id=\"h4-2-1-3-2-read\"><a name=\"2.1.3.2 Read\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.3.2 Read</h4><pre><code>读取1个1000MB的文件:\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 1 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/40.png\" alt=\"image\"></p>\n<pre><code>读取5个1000MB的文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 5 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/41.png\" alt=\"image\"></p>\n<pre><code>读取10个1000M的文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 10 -size 1000\n</code></pre><p>!image](<a href=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/42.png\">http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/42.png</a>)</p>\n<pre><code>读取15个1000M的文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 15 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/43.png\" alt=\"image\"></p>\n<pre><code>读取20个1000M的文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -read -nrFiles 20 -size 1000\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/44.png\" alt=\"image\"></p>\n<h4 id=\"h4-2-1-3-3-clean\"><a name=\"2.1.3.3 Clean\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.3.3 Clean</h4><pre><code>清空测试数据\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar TestDFSIO -clean\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/45.png\" alt=\"image\"></p>\n<h2 id=\"h2-2-2-\"><a name=\"2.2压力测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2压力测试</h2><h3 id=\"h3-2-2-1-nnbench-\"><a name=\"2.2.1 nnbench测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2.1 nnbench测试</h3><p>nnbench用于测试NameNode的负载，他会产生很多余HDFS相关的请求，给NameNode施加较大的压力。这个测试能在hdfs上模拟创建，读取，重命名和删除文件等操作。Nnbench的用法如下：</p>\n<pre><code>下面是使用12个mapper和6个Reduce来创建1000个文件\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar nnbench -operation create_write -maps 12 -reduces 6 -blockSize 1 -bytesToWrite 0 -numberOfFiles 1000 -replicationFactorPerFile 3 -readFileAfterOpen true -baseDir /benchmarks/NNBench-`hostname -s`\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/46.png\" alt=\"image\"></p>\n<h3 id=\"h3-2-2-2mrbench-\"><a name=\"2.2.2mrbench测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2.2mrbench测试</h3><p>mrbench会多次重复一个小作业，用于检查在集群上小作业的是否可重复以及运行是否可高效，用法如下：</p>\n<pre><code>运行一个小作业一共50次\nyarn jar /usr/crh/5.1.2.6-1048/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar mrbench -numRuns 50\n</code></pre><p>最终结果<br><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/47.png\" alt=\"image\"></p>\n<h1 id=\"h1--\"><a name=\"三 结果统计\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>三 结果统计</h1><h2 id=\"h2-3-1-ambari-\"><a name=\"3.1 Ambari 安装测试报告\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.1 Ambari 安装测试报告</h2><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/48.png\" alt=\"image\"></p>\n<h2 id=\"h2-3-2-hadoop-\"><a name=\"3.2 Hadoop 功能测试报告\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2 Hadoop 功能测试报告</h2><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/49.png\" alt=\"image\"></p>\n<h2 id=\"h2-3-3-testdfsio-\"><a name=\"3.3 TestDFSIO性能测试展\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3 TestDFSIO性能测试展</h2><p><img src=\"http://www.redhub.io/DOC/CRH/raw/master/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/power9/50.png\" alt=\"image\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('13', '0', 'CRH平台服务集设想', '13', '2018-01-26 10:06:19', '本篇描述对重组CRH产品结构的一个设想，其设想基于成熟的技术，具有很高的可行性。', null, '0', '462', null, null, '2018-01-26 10:06:19', '2018-01-26 11:13:45', null, null, '0', '0', '0', '0', '## 背景\n当前的CRH平台，众多服务集中在一起，服务列表太长，在选择安装时，不方便查找，而且针对不同的场景，服务需求本就不同，所以没必要将服务全部列举在默认服务列表中，这就产生了针对服务性质进行分类的设想。\n\n在服务分类之后，我们将每一类都称为一个服务集，一个服务集里包含多个服务，这多个服务之间的关联比较紧密或者作用相辅相成(比如安全服务集，暂且称之为GuarderSet-mpack，寓意守卫者，其包括Kerberos，Ranger以及Knox等安全服务)。针对于同的场景，我们只需将相关服务集添加到基础服务集(以Hadoop为核心的服务集)上即可，这样不相关的服务就不会显示在服务列表上，从而在选择服务的时候更加明确，场景针对性更强。\n\n\n## 服务集\n这里的服务集使用ambari的management pack(mpack)功能实现，我们将分类好的每一个服务集都制作成一个单独的mpack。\n\n在初始安装CRH平台时，默认安装列表只有以Hadoop为核心的基础服务集(我们暂且称之为BaseSet)，之后根据不同的场景需求，我们选择相应的服务集进行添加，添加服务集之后，安装列表上就会出现新的服务，这时就可以安装这些服务了。\n\n例如，假设当前已经安装了BaseSet，但是场景有一个集群安全的需求，而服务安装列表没有相关服务可以选择，这时我们就可以将安全服务集(GuarderSet-mpack)添加进去，然后再次添加服务，就可以看到相关服务并进行添加了。\n\n下面是我对服务的一个简单分类，暂定有以下服务集：\n\n- BaseSet——HDFS，YARN，MapReduce，zookeeper，sqoop等；\n- DBSet——HBase，Phoenix等；\n- DWSet——Hive，Tez，Pig，datafu，HAWQ等；\n- ComputeSet——Spark，livy等；\n- StreamSet——Flume，Kafka，Storm，NiFi/MiNifi，Druid等；\n- MLSet——XLearning，Tensorflow，Caffe等；\n- GuarderSet-mpack——Kerberos，Ranger，Knox等；\n- MonitorSet-mpack——Ambari-Metrics，Logsearch，Openfalcon等；\n\n在上面，其实StreamSet与RDF有重合，或者说，StreamSet和RDF就是同一个服务集，这样将RDF作为其中一个服务集，不仅降低了代码开发与维护成本，而且整个产品的完整度提高，使用更加方便灵活。\n\n\n## 研发展望\n当我们开始做分类之后，我们产品的各个组成部分也渐渐明确，这样在开发时，我们就可以灵活的投入人力，侧重研发。一旦我们形成基础的一些服务集，我们可以在原有的服务集上进行丰富，更可以添加新的服务集。这样就可以针对不同的需求，对不同的服务集进行研发。我想，那时，我们会形成其他多个像RDF以及ML这样的单独研发组，每个服务集研发组专注研发自己的服务，在这种各个研发组专注特定场景的研发下，整个CRH定会出现极大的改观。', '2', '<h2 id=\"h2-u80CCu666F\"><a name=\"背景\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>背景</h2><p>当前的CRH平台，众多服务集中在一起，服务列表太长，在选择安装时，不方便查找，而且针对不同的场景，服务需求本就不同，所以没必要将服务全部列举在默认服务列表中，这就产生了针对服务性质进行分类的设想。</p>\n<p>在服务分类之后，我们将每一类都称为一个服务集，一个服务集里包含多个服务，这多个服务之间的关联比较紧密或者作用相辅相成(比如安全服务集，暂且称之为GuarderSet-mpack，寓意守卫者，其包括Kerberos，Ranger以及Knox等安全服务)。针对于同的场景，我们只需将相关服务集添加到基础服务集(以Hadoop为核心的服务集)上即可，这样不相关的服务就不会显示在服务列表上，从而在选择服务的时候更加明确，场景针对性更强。</p>\n<h2 id=\"h2-u670Du52A1u96C6\"><a name=\"服务集\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>服务集</h2><p>这里的服务集使用ambari的management pack(mpack)功能实现，我们将分类好的每一个服务集都制作成一个单独的mpack。</p>\n<p>在初始安装CRH平台时，默认安装列表只有以Hadoop为核心的基础服务集(我们暂且称之为BaseSet)，之后根据不同的场景需求，我们选择相应的服务集进行添加，添加服务集之后，安装列表上就会出现新的服务，这时就可以安装这些服务了。</p>\n<p>例如，假设当前已经安装了BaseSet，但是场景有一个集群安全的需求，而服务安装列表没有相关服务可以选择，这时我们就可以将安全服务集(GuarderSet-mpack)添加进去，然后再次添加服务，就可以看到相关服务并进行添加了。</p>\n<p>下面是我对服务的一个简单分类，暂定有以下服务集：</p>\n<ul>\n<li>BaseSet——HDFS，YARN，MapReduce，zookeeper，sqoop等；</li><li>DBSet——HBase，Phoenix等；</li><li>DWSet——Hive，Tez，Pig，datafu，HAWQ等；</li><li>ComputeSet——Spark，livy等；</li><li>StreamSet——Flume，Kafka，Storm，NiFi/MiNifi，Druid等；</li><li>MLSet——XLearning，Tensorflow，Caffe等；</li><li>GuarderSet-mpack——Kerberos，Ranger，Knox等；</li><li>MonitorSet-mpack——Ambari-Metrics，Logsearch，Openfalcon等；</li></ul>\n<p>在上面，其实StreamSet与RDF有重合，或者说，StreamSet和RDF就是同一个服务集，这样将RDF作为其中一个服务集，不仅降低了代码开发与维护成本，而且整个产品的完整度提高，使用更加方便灵活。</p>\n<h2 id=\"h2-u7814u53D1u5C55u671B\"><a name=\"研发展望\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>研发展望</h2><p>当我们开始做分类之后，我们产品的各个组成部分也渐渐明确，这样在开发时，我们就可以灵活的投入人力，侧重研发。一旦我们形成基础的一些服务集，我们可以在原有的服务集上进行丰富，更可以添加新的服务集。这样就可以针对不同的需求，对不同的服务集进行研发。我想，那时，我们会形成其他多个像RDF以及ML这样的单独研发组，每个服务集研发组专注研发自己的服务，在这种各个研发组专注特定场景的研发下，整个CRH定会出现极大的改观。</p>\n');
INSERT INTO `tbl_archive` VALUES ('14', '0', '大数据、人工智能等技术如何颠覆石油行业', '21', '2018-01-26 11:29:49', '来源：Forbes', null, '0', '258', null, null, '2018-01-26 11:29:49', '2018-01-26 11:49:59', null, null, '0', '0', '0', '0', '# 大数据、人工智能等技术如何颠覆石油行业\n 来源：Forbes\n`原油价格在2008年达到了创纪录的高点，每桶原油的价格冲到了150美元以上，刺激了投资者的淘金热，这些投资者一直在投资这个前景无限的行业，依靠价格的起起落落获利。然而，困扰着埃克森美孚、壳牌以及英国石油公司等全球能源公司的现实证明结论与现状恰恰相反。`\n![](/upload/images/20180126//90c8a2f6-a87b-4a92-b4d9-1359917410bf.jpg)\n`大数据`\n　　`虽然经历了价格上涨带来的资金流入和现金流增加，但是这些庞大的行业巨头在2005至2014年期间，还是经历了长达十年的衰退。这种衰退主要是由于税收、服务成本和开发费用的上涨导致的运营成本上升造成的。因此，有超过25万名石油工人失去了他们的工作，超过三分之二的石油钻井平台已经退役，而一大堆顶级玩家则发现自己只能申请破产。`\n\n　　`随着规模化挑战的不断持续，大型石油公司也遭受了严重的功能性和结构性低效。使用过时的技术和方法来衡量生产力推迟了很多必要的内部增长。每年损失数十亿美元，石油公司现在就需要能够立竿见影的解决方案，以便更聪明地工作，收复失地并提高收入。`\n\n　　`在今天这样一个向着太阳能和绿色能源大踏步迈进的时代里，对气候变化和全球经济转变的讨论也在为这种趋势推波助澜——可是石油和天然气行业仍然是一个庞大的市场，负责产生世界上举足轻重的一部分财富。`\n\n　　`成立于2009年的Seven Lakes Technologies是一家为上游石油和天然气公司提供智能解决方案的企业软件公司。这家创业企业打造了个性化的数据解决方案和技术，被用于跟踪关键指标并发现运营效率低下。他们的目标非常简单：降低生产成本、提高生产力并建立高效的工作流程。`\n\n　　`Seven Lakes公司的首席执行官Shiva Rajagopalan在一次采访中谈到了新兴的趋势，新技术的采用以及这些转变在2018年将如何塑造大型石油和天然气公司的未来。`\n\n　　`请描述一下石油行业目前的状况，以及为什么说现在是颠覆这个领域的最佳时机?`\n\n　　`Shiva Rajagopalan:石油和天然气公司经历了市场的动荡，现在有了经过精细调整的精益团队，并确切地知道该在哪里用力。尽管有了所有的这些改变，实现生产目标仍然是一种非常模糊而神秘的行为。这种情况必须改变。培养一大批人来解决这个问题是不会成功的。 我们现在必须用容易使用的预测技术——例如人工智能等拥抱了颠覆性的技术——来武装员工。`\n\n　　`人工智能等新兴技术将会如何塑造石油和天然气行业的未来?`\n\n　　`Shiva Rajagopalan ： 人工智能技术有望给现场以时间，以便他们可以缩短意外停机时间。与许多其他的行业一样，人工智能也会自动执行单调的任务。 人工智能允许司泵专注于高价值的问题，而不是陷入数据查找任务。 人工智能可以识别钻井数据中的细微模式，并有助于在每个钻井在问题真正出现之前很久，就预测出需要的维修。人工智能石油和天然气系统能够逐渐地理解每个运营要素，随着时间的推移，这种理解会变得越来越深入，这让它能够快速识别模式，并且——也更为重要的是——能够更好地生成即时和持续的预测结果。 有了足够的正确数据，我们可以仔细观察油井的性能，确定潜在的高压点，并进行推算。 用同样的方式，我们可以确定一口井何时需要人工举升，并提供进行举升所需的计算。通过建立人工智能系统，机组成员可以快速反应，并积极开展工作，大大缩短停机时间。`\n\n　　`困扰石油天然气行业的最大盲点或挑战是什么?新技术如何解决这些问题?`\n\n　　`Shiva Rajagopalan:石油和天然气行业很大程度上是建立在企业家精神之上的，白手起家从零到数十亿美元的规模。没有先进的技术、系统和流程，这一切都是不可能的。石油和天然气行业的IT部门都知道这一点，但是他们所做的只是拼凑各种技术，却没有真正理解整套装备看起来应该是什么样子。无法实时可视化油田正在发生的情况。油价的持续走低以及随后出现的市场下滑导致了数量巨大的裁员、投资减少以及利润日益趋紧。石油和天然气行业已经日益精益，利用现有的资源尽可能地优化业绩，以保持盈利能力和产品目标。 现在，每一家主流的石油和天然气公司都希望在不增加资源的前提下提高产量。 同时，每一家供应商都希望为他们提供最新的生产优化软件。双方都听说过人工智能的潜力，即加快流程、降低成本，但他们才刚刚开始了解这种现代技术的能力。`\n\n　　`这将对全球的石油和天然气市场产生什么样的直接影响?`\n\n　　`Shiva Rajagopalan ： 在石油天然气领域拥抱颠覆性技术方面，美国一直是领导者。 随着人工智能在生产计划和优化方面的整合，我们只会看到对这种技术的应用普及开来。 人工智能支持的优化将提高全球石油和天然气储量的开采和生产效率，在为世界提供所需的能源的同时，保护自然资源和环境，产生改变游戏规则的影响。`\n\n　　`考虑到所有正在发生的变化和趋势——你如何看到石油和天然气行业在未来两至五年内的发展?`\n\n　　`Shiva Rajagopalan ： 我们现在已经看到出现了三个重大的转变，这将改变我们所知道的石油和天然气业务的未来。\n`\n#### 1. 动态路由司泵，以解决价值最高的问题\n\n　　`通过使用人工智能，聚焦那些目前需要注意的高生产资产，而不是在所有的钻井上花费大致相同的时间，动态路由已经让E&P公司掌握了主动权。例如，如果一家租赁公司正在维修15口油井，其中有12口油井运行顺畅，而3口井出现了故障，优先处理出现了故障的钻井对于提高整体产量来说是非常有意义的。`\n\n####2. 实时的油运收据　　\n\n　　`想想看围绕着传统手写油运收据(流动票据)然后再手工将其录入到Excel电子表格这项工作的低效率吧。简单的数据录入错误到处都是，可能会导致重大的问题，而手工双重检查则会浪费宝贵的时间，从几个月到几年。通过开发人工智能系统，将现场工作人员和位于角落的经理办公室连接起来，我们可以对石油和天然气公司的生产情况有一个完整而准确的观察。尽管大多数SaaS供应商只是获得了基本流动票据图片的能力，但是自2012年以来我们已经证明，使用我们的移动现场数据采集软件来解读手写票的准确率有可能达到99%，直接导致同比产量增加了2%至4%。`\n\n####3. 在恰当的时机让钻井上线\n\n　　`我们经常会说风险巨大是这个行业DNA中写就的特点。然而，为了充分地从这些风险中获得回报，这个行业的公司的发展就不能仅仅局限在钻井方面。 为了让项目保持在预算之内，并且能够准时完成而且有利可图，我们进行了很多不必要的挣扎，必须停止这种挣扎。 随着当前集成工作流程管理方面的创新，我们不再受到传统系统彼此之间无法轻松对话的束缚。这意味着更好的预算预测和工作流程，这对于石油和天然气公司适当扩大资本预算并保持项目按时进行来说，是至关重要的。`', '0', '<h1 id=\"h1--\"><a name=\"大数据、人工智能等技术如何颠覆石油行业\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>大数据、人工智能等技术如何颠覆石油行业</h1><p> 来源：Forbes<br><code>原油价格在2008年达到了创纪录的高点，每桶原油的价格冲到了150美元以上，刺激了投资者的淘金热，这些投资者一直在投资这个前景无限的行业，依靠价格的起起落落获利。然而，困扰着埃克森美孚、壳牌以及英国石油公司等全球能源公司的现实证明结论与现状恰恰相反。</code><br><img src=\"/upload/images/20180126//90c8a2f6-a87b-4a92-b4d9-1359917410bf.jpg\" alt=\"\"><br><code>大数据</code><br>　　<code>虽然经历了价格上涨带来的资金流入和现金流增加，但是这些庞大的行业巨头在2005至2014年期间，还是经历了长达十年的衰退。这种衰退主要是由于税收、服务成本和开发费用的上涨导致的运营成本上升造成的。因此，有超过25万名石油工人失去了他们的工作，超过三分之二的石油钻井平台已经退役，而一大堆顶级玩家则发现自己只能申请破产。</code></p>\n<p>　　<code>随着规模化挑战的不断持续，大型石油公司也遭受了严重的功能性和结构性低效。使用过时的技术和方法来衡量生产力推迟了很多必要的内部增长。每年损失数十亿美元，石油公司现在就需要能够立竿见影的解决方案，以便更聪明地工作，收复失地并提高收入。</code></p>\n<p>　　<code>在今天这样一个向着太阳能和绿色能源大踏步迈进的时代里，对气候变化和全球经济转变的讨论也在为这种趋势推波助澜——可是石油和天然气行业仍然是一个庞大的市场，负责产生世界上举足轻重的一部分财富。</code></p>\n<p>　　<code>成立于2009年的Seven Lakes Technologies是一家为上游石油和天然气公司提供智能解决方案的企业软件公司。这家创业企业打造了个性化的数据解决方案和技术，被用于跟踪关键指标并发现运营效率低下。他们的目标非常简单：降低生产成本、提高生产力并建立高效的工作流程。</code></p>\n<p>　　<code>Seven Lakes公司的首席执行官Shiva Rajagopalan在一次采访中谈到了新兴的趋势，新技术的采用以及这些转变在2018年将如何塑造大型石油和天然气公司的未来。</code></p>\n<p>　　<code>请描述一下石油行业目前的状况，以及为什么说现在是颠覆这个领域的最佳时机?</code></p>\n<p>　　<code>Shiva Rajagopalan:石油和天然气公司经历了市场的动荡，现在有了经过精细调整的精益团队，并确切地知道该在哪里用力。尽管有了所有的这些改变，实现生产目标仍然是一种非常模糊而神秘的行为。这种情况必须改变。培养一大批人来解决这个问题是不会成功的。 我们现在必须用容易使用的预测技术——例如人工智能等拥抱了颠覆性的技术——来武装员工。</code></p>\n<p>　　<code>人工智能等新兴技术将会如何塑造石油和天然气行业的未来?</code></p>\n<p>　　<code>Shiva Rajagopalan ： 人工智能技术有望给现场以时间，以便他们可以缩短意外停机时间。与许多其他的行业一样，人工智能也会自动执行单调的任务。 人工智能允许司泵专注于高价值的问题，而不是陷入数据查找任务。 人工智能可以识别钻井数据中的细微模式，并有助于在每个钻井在问题真正出现之前很久，就预测出需要的维修。人工智能石油和天然气系统能够逐渐地理解每个运营要素，随着时间的推移，这种理解会变得越来越深入，这让它能够快速识别模式，并且——也更为重要的是——能够更好地生成即时和持续的预测结果。 有了足够的正确数据，我们可以仔细观察油井的性能，确定潜在的高压点，并进行推算。 用同样的方式，我们可以确定一口井何时需要人工举升，并提供进行举升所需的计算。通过建立人工智能系统，机组成员可以快速反应，并积极开展工作，大大缩短停机时间。</code></p>\n<p>　　<code>困扰石油天然气行业的最大盲点或挑战是什么?新技术如何解决这些问题?</code></p>\n<p>　　<code>Shiva Rajagopalan:石油和天然气行业很大程度上是建立在企业家精神之上的，白手起家从零到数十亿美元的规模。没有先进的技术、系统和流程，这一切都是不可能的。石油和天然气行业的IT部门都知道这一点，但是他们所做的只是拼凑各种技术，却没有真正理解整套装备看起来应该是什么样子。无法实时可视化油田正在发生的情况。油价的持续走低以及随后出现的市场下滑导致了数量巨大的裁员、投资减少以及利润日益趋紧。石油和天然气行业已经日益精益，利用现有的资源尽可能地优化业绩，以保持盈利能力和产品目标。 现在，每一家主流的石油和天然气公司都希望在不增加资源的前提下提高产量。 同时，每一家供应商都希望为他们提供最新的生产优化软件。双方都听说过人工智能的潜力，即加快流程、降低成本，但他们才刚刚开始了解这种现代技术的能力。</code></p>\n<p>　　<code>这将对全球的石油和天然气市场产生什么样的直接影响?</code></p>\n<p>　　<code>Shiva Rajagopalan ： 在石油天然气领域拥抱颠覆性技术方面，美国一直是领导者。 随着人工智能在生产计划和优化方面的整合，我们只会看到对这种技术的应用普及开来。 人工智能支持的优化将提高全球石油和天然气储量的开采和生产效率，在为世界提供所需的能源的同时，保护自然资源和环境，产生改变游戏规则的影响。</code></p>\n<p>　　<code>考虑到所有正在发生的变化和趋势——你如何看到石油和天然气行业在未来两至五年内的发展?</code></p>\n<p>　　<code>Shiva Rajagopalan ： 我们现在已经看到出现了三个重大的转变，这将改变我们所知道的石油和天然气业务的未来。</code></p>\n<h4 id=\"h4-1-\"><a name=\"1. 动态路由司泵，以解决价值最高的问题\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. 动态路由司泵，以解决价值最高的问题</h4><p>　　<code>通过使用人工智能，聚焦那些目前需要注意的高生产资产，而不是在所有的钻井上花费大致相同的时间，动态路由已经让E&amp;P公司掌握了主动权。例如，如果一家租赁公司正在维修15口油井，其中有12口油井运行顺畅，而3口井出现了故障，优先处理出现了故障的钻井对于提高整体产量来说是非常有意义的。</code></p>\n<h4 id=\"h4-2-\"><a name=\"2. 实时的油运收据\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2. 实时的油运收据　　</h4><p>　　<code>想想看围绕着传统手写油运收据(流动票据)然后再手工将其录入到Excel电子表格这项工作的低效率吧。简单的数据录入错误到处都是，可能会导致重大的问题，而手工双重检查则会浪费宝贵的时间，从几个月到几年。通过开发人工智能系统，将现场工作人员和位于角落的经理办公室连接起来，我们可以对石油和天然气公司的生产情况有一个完整而准确的观察。尽管大多数SaaS供应商只是获得了基本流动票据图片的能力，但是自2012年以来我们已经证明，使用我们的移动现场数据采集软件来解读手写票的准确率有可能达到99%，直接导致同比产量增加了2%至4%。</code></p>\n<h4 id=\"h4-3-\"><a name=\"3. 在恰当的时机让钻井上线\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3. 在恰当的时机让钻井上线</h4><p>　　<code>我们经常会说风险巨大是这个行业DNA中写就的特点。然而，为了充分地从这些风险中获得回报，这个行业的公司的发展就不能仅仅局限在钻井方面。 为了让项目保持在预算之内，并且能够准时完成而且有利可图，我们进行了很多不必要的挣扎，必须停止这种挣扎。 随着当前集成工作流程管理方面的创新，我们不再受到传统系统彼此之间无法轻松对话的束缚。这意味着更好的预算预测和工作流程，这对于石油和天然气公司适当扩大资本预算并保持项目按时进行来说，是至关重要的。</code></p>\n');
INSERT INTO `tbl_archive` VALUES ('17', '0', 'CRF3.0部署手册', '25', '2018-02-03 17:04:09', 'CRF3.0部署手册 ', null, '0', '1293', '', '', '2018-02-03 17:04:09', '2018-04-28 10:46:53', null, null, '0', '0', '0', '0', '# CRF3.0部署手册\n\n\n\n\n\n\n# 安装环境推荐\n\n## 1.1 硬件环境要求\n|   推荐 |小规模硬件推荐：4-10个节点 |  中等规模硬件配置推荐：20+个节点 | 大规模硬件配置推荐：100节点以上 | \n| --------  | :----:  |  :----: |  :----:  \n| 处理器cpu    | 2路 8核心XeonE5处理器(3.8GHz)| 2路 10核心XeonE5处理器(3.8GHz)   |  2路 10核心 XeonE7处理器(3.8GHz)\n| 内存        |   64G或者以上内存，DDR3L，RRECC   |   128G或者以上内存，DDR3L,RRECC  | 128G或者以上内存，DDR3L,RRECC\n| 系统盘        |    2*500G SSD  |  2*500G SSD  |2*500G SSD\n|  磁盘接口   |   SAS 6GB/s  |  SAS 6GB/s  |SAS 6GB/s\n|     磁盘    |     12个2T或者6T 7200RPM SATA硬盘  |  12个4T或者6T 7200RPM  |12个6T  7200RPM SATA\n|硬盘     |  SATA硬盘  | SATA硬盘 |SATA硬盘\n| Raid卡  |   1G缓存支持RAIDO,1,5  |  1G缓存支持RAIDO,1,5  |1G缓存支持RAIDO,1,5\n| 网络       |   10Gb以太网和千兆以太网    |  10Gb以太网和千兆以太网  |10Gb以太网和千兆以太网\n|电源     |   1+1冗余电源   |  1+1冗余电源  |1+1冗余电源\n\n\n## 1.2 操作系统要求\n\n|   系统版本 |  CentOS release 7 \n| --------  | :----:  |  :----: |  :----:  \n|内核版本   |    3.10.0-327.13.1.el7.x86_64\n## 1.3 Java环境要求\n如果您的集群的机器上还没有安装JDK，请自主下载安装JDK 1.8（Oracle版本）。\n\n```\n[root@crf1 jvm]# java  -version \njava version \"1.8.0_144\"\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n```\n## 1.4 支持的浏览器\n   | 浏览器                   |    版本\n | --------         |  :----:  |  :----: |   :----:  \n| Internet Explorer |          8.0 以上\n| Chrome|   23.0 以上\n\n\n\n# 安装基础环境准备\n### 2.1 修改主机名\n>主机名即计算机的名字（计算机名），主机名有时称为域名。主机名映射到 IP 地址，但是主机名和 IP 地址之间没有一对一关系。对于用户来说，主机名比数字 IP 地址更方便。所以会选择其主机名，用户能很容易地记住这些主机名。\n\n本次测试建立于三台服务器的基础上演示\n\n192.168.0.245  crf1\n\n192.168.0.246   crf2\n\n192.168.0.247   crf3\n\n修改每台主机的主机名\n```\n\n[root@crf1 ~]# vi /etc/hostname\ncrf1\n\n[root@crf2 ~]# vi /etc/hostname\ncrf2\n\n[root@crf3 ~]# vi /etc/hostname\ncrf3\n```\n## 2.2 主机与IP映射\n> hosts文件是Linux系统中一个负责IP地址与域名快速解析的文件，一般会保存在“/etc”目录下，文件名为“hosts”（不同的linux版本，这个配置文件也可能不同）。hosts文件是一个用于存储计算机网络中节点信息的文件，它可以将主机名映射到相应的IP地址，在没有域名服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的IP地址，否则就需要使用DNS服务程序来解决。通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。\n\n三台服务器均配置hosts文件\n```\ncrf1\n[root@crf1 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n-----------------------------------------------------------------------------\ncrf3\n[root@crf3 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n```\n## 2.3 安全设置\n\n### 2.3.1 关闭SElinux\n```\ncrf1\n[root@crf1 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf2\n[root@crf2 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf3\n[root@crf3 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n```\n### 2.3.2 关闭防火墙\n> 防火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。\n\n```\ncrf1\n[root@crf1 ~]# systemctl stop firewalld\n\ncrf2\n[root@nx-2 ~]# systemctl stop firewalld\n\ncrf3\n[root@nx-3 ~]# systemctl stop firewalld\n```\n## 2.4 免密码登录\n> 为了方便用户使用，一般会设置免密码登录，当Linux设置免密码登录后，节点跳转时SSH不会询问密码。\n\n### 2.4.1 生成私钥和公钥\n```\ncrf1\n[root@crf1 ~]# ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n01:f7:8d:da:63:cc:cc:26:6a:ee:82:6c:1e:bd:21:5c root@crf1\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|      . .        |\n|       o . o     |\n|        . o .    |\n|         O       |\n|    E   S X      |\n| . o   . + .     |\n| .+.o o          |\n|  +o.=           |\n| o. .oo          |\n+-----------------+\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n4d:16:c2:15:99:31:f6:87:57:83:12:52:ff:e9:2c:92 root@crf2\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|       ..oOB. ...|\n|        .o+=.o ..|\n|          o +.o  |\n|         +   o. .|\n|        S .    o |\n|            . o  |\n|           E . o |\n|            . .  |\n|                 |\n+-----------------+\n---------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd5:fb:e3:fe:11:a9:6c:0a:69:15:46:e1:79:5d:e7:2c root@crf3\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|           o.   o|\n|          o.. .oo|\n|          .=..E.o|\n|         .. o. ..|\n|        S  ..  o |\n|          o ... .|\n|         +   +o. |\n|        . . o. ..|\n|           . .o..|\n+-----------------+\n```\n### 2.4.2 将公钥复制到远程主机\n在服务器中的每一台服务器建立服务器之间的ssh免密码登陆。在系统询问Are you sure you want to continue connecting (yes/no)?时输入yes并按回车，在系统询问root@crf1\'s password:时输入密码（注意：密码输入时，密码不显示）。\n```\ncrf1\n[root@crf1 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf1 ~]# ssh-copy-id crf2\nThe authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf1 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf2\n2The authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n-------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf3 ~]# ssh-copy-id crf2\nThe authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf3 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n```\n### 2.5 配置源\nrepo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用！\n```\n[root@crf1 ~]# cd /etc/yum.repos.d\n\n[root@crf1 yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/ambari/ambari.repo\n\n[root@crf1 yum.repos.d]# cat ambari.repo \n[redoop-crf3.0]\nName=Redoop’s Distribution for crf, Version 3.0.0\nBaseurl= http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/ambari\ngpgcheck=0\nenabaled=1\n\n[root@crf1 yum.repos.d]# yum clean all\n\nLoaded plugins: fastestmirror\nLoaded plugins: fastestmirror\nCleaning repos: ambari-2.5.1.0 base extras updates\nCleaning up everything\nCleaning up list of fastest mirrors\n```\n#  安装ambari和mysql\nAmbari的Server程序，主要管理部署在每个节点上的管理监控程序\n## 3.1 安装ambari-server\n```\ncrf1\n[root@crf1 ~]# yum install -y ambari-server\n\nLoaded plugins: fastestmirror\nambari-2.5.1.0                                                       | 2.9 kB  00:00:00\nbase                                                                 | 3.6 kB  00:00:00\nextras                                                               | 3.4 kB  00:00:00\nupdates                                                              | 3.4 kB  00:00:00\n(1/5): ambari-2.5.1.0/primary_db                                     | 8.7 kB  00:00:00\n(2/5): base/7/x86_64/group_gz                                        | 156 kB  00:00:00\n(3/5): extras/7/x86_64/primary_db                                    | 166 kB  00:00:00\n(4/5): base/7/x86_64/primary_db                                      | 5.7 MB  00:00:07\n(5/5): updates/7/x86_64/primary_db                                   | 6.0 MB  00:00:23\nDetermining fastest mirrors\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies........\nInstalled:\n  ambari-server.x86_64 0:2.5.1.0-159\nDependency Installed:\n  postgresql.x86_64 0:9.2.23-3.el7_4            postgresql-libs.x86_64 0:9.2.23-3.el7_4\n  postgresql-server.x86_64 0:9.2.23-3.el7_4\nComplete!   \n```\n## 3.2 安装mysql将ambari关联mysql数据库\n```\n[root@crf1 ~]# yum install mysql-connector-java* -y\n\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies\n--> Running transaction check\n    ..................................\n\nDependency Updated:\n  chkconfig.x86_64 0:1.7.4-1.el7                  nspr.x86_64 0:4.13.1-1.0.el7_3\n  nss.x86_64 0:3.28.4-15.el7_4                    nss-softokn.x86_64 0:3.28.3-8.el7_4\n  nss-softokn-freebl.x86_64 0:3.28.3-8.el7_4      nss-sysinit.x86_64 0:3.28.4-15.el7_4\n  nss-tools.x86_64 0:3.28.4-15.el7_4              nss-util.x86_64 0:3.28.4-3.el7\n\nComplete!\n\n[root@crf1~]#sudo ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n\n[root@crf1~]# cd /etc/yum.repos.d/\n[root@crf1~yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/utils/mysql/mysql_57.repo\n\n[root@crf1 yum.repos.d]# ls                    \nambari.repo            CentOS-Media.repo\nCentOS-Base.repo       CentOS-Sources.repo\nCentOS-CR.repo         CentOS-Vault.repo\nCentOS-Debuginfo.repo  mysql_57.repo\nCentOS-fasttrack.repo\n \n [root@crf1yum.repos.d]# yum clean all\nLoaded plugins: fastestmirror\nCleaning repos: base extras mysql-5.7\n              : redoop-crf3.0 updates\nCleaning up everything\nCleaning up list of fastest mirrors\n\n\n[root@crf1 yum.repos.d]# yum install mysql-community-server –y\n\nWarning: RPMDB altered outside of yum.\n  Installing : mysql-community-common-5.7.21-1.el7.x86_64                               1/7\n      ..............................\n\nInstalled:\n  mysql-community-libs.x86_64 0:5.7.21-1.el7\n  mysql-community-libs-compat.x86_64 0:5.7.21-1.el7\n  mysql-community-server.x86_64 0:5.7.21-1.el7\nDependency Installed:\n  \n  mysql-community-client.x86_64 0:5.7.21-1.el7 mysql-community-common.x86_64 0:5.7.21-1.el7\n  net-tools.x86_64 0:2.0-0.22.20131004git.el7\n\nReplaced:\n  mariadb-libs.x86_64 1:5.5.44-2.el7.centos\n\nComplete!\n```\n## 3.3启动mysql\n```\n[root@crf1 ~]# systemctl  start   mysqld.service\n[root@crf1 ~]# systemctl  enable   mysqld.service\n```\n## 3.4给mysql用户更改密码和配置mysql\n```\n[root@crf1 yum.repos.d]# grep \'A temporary password is generated for root@localhost\' /var/log/mysqld.log |tail -1\n\n2018-02-02T06:01:02.850616Z 1 [Note] A temporary password is generated for root@localhost: `Jl-l.%hNl4Po`  //红色部分为初始密码\n\n[root@crf1 ~]# # mysqladmin -u root -p password \"Redoop123$%^\"\nEnter password: Jl-l.%hNl4Po  // 红色为新更改密码\n\n[root@crf1 yum.repos.d]# mysql -u root -p\nEnter password: Redoop123$%^\n\nelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 14\nServer version: 5.7.21\n\nmysql> create database registry;\n\nmysql> create database streamline;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE USER \'registry\'@\'%\' IDENTIFIED BY \'R12$%34qw\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE USER \'streamline\'@\'%\' IDENTIFIED BY \'R12$%34qw\';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> GRANT ALL PRIVILEGES ON registry.* TO \'registry\'@\'%\' WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON streamline.* TO \'streamline\'@\'%\' WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> commit;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE DATABASE druid DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE DATABASE superset DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE USER \'druid\'@\'%\' IDENTIFIED BY \'9oNio)ex1ndL\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE USER \'superset\'@\'%\' IDENTIFIED BY \'9oNio)ex1ndL\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON *.* TO \'druid\'@\'%\' WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON *.* TO \'superset\'@\'%\' WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> commit;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> exit;\nBye\n```\n## 3.5安装CRF版mpack\n```\n[root@crf1~]#cd /opt/\n\n[root@crf1 opt~]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/mpack/crf-ambari-mpack-3.0.0.0-512.tar.gz\n\n--2018-02-0214:22:37-- http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/mpack/crf-ambari-mpack-3.0.0.tar.gz\nConnecting to 192.168.0.220:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 56231837 (54M) [application/x-gzip]\nSaving to: ‘CRF-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz’\n100%[==================================================>] 56,231,837   118MB/s   in 0.5s\n2018-02-02 14:22:37 (118 MB/s) - ‘CRF-ambari-mpack-3.0.0.tar.gz’ saved [56231837/56231837]\n\n[root@crf1 opt]# ls\ncrf-ambari-mpack-3.0.0.tar.gz\n\n[root@crf1opt]#ambari-server install-mpack --mpack=/opt/crf-ambari-mpack-3.0.0.0-512.tar.gz --purge --verbose\n\nUsing python  /usr/bin/python\nInstalling management pack\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Installing management pack /opt/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Download management pack to temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Expand management pack at temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512/\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nLooking for available JDKs at /usr/jdk64\nFound: []\nCAUTION: You have specified the --purge option with --purge-list=[\'stack-definitions\', \'mpacks\']. This will replace all existing stack definitions, management packs currently installed.\nAre you absolutely sure you want to perform the purge [yes/no]? (no)\"yes\"\n . ......\nINFO: Management pack crf-ambari-mpack-0.1.0.0.3.0.0-512 successfully installed! Please restart ambari-server.\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nAmbari Server \'install-mpack\' completed successfully.\n```\n## 3.6 初始化ambari\n下载JDK\n\n待安装完成后，便需要对 Ambari Server 做一个简单的配置。执行下面的命令。\n```\n[root@crf1 opt]# cd /var/lib/ambari-server/resources/\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jce_policy-8.zip\n\nSaving to: ‘jce_policy-8.zip’\n100%[==================================================>] 8,409       --.-K/s   in 0s\n2018-02-03 00:18:44 (32.0 MB/s) - ‘jce_policy-8.zip’ saved [8409/8409]\n\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jdk-8u112-linux-x64.tar.gz\n\nSaving to: ‘jdk-8u112-linux-x64.tar.gz’\n100%[==================================================>] 183,212,596 11.1MB/s   in 16s\n2018-02-03 00:19:11 (11.1 MB/s) - ‘jdk-8u112-linux-x64.tar.gz’ saved [183212596/183212596]\n\n[root@crf1 ~]# ambari-server setup\n\n\nUsing python  /usr/bin/python\nSetup ambari-server\nChecking SELinux...\nSELinux status is \'disabled\'\nCustomize user account for ambari-server daemon [y/n] （点击回车键）\nAdjusting ambari-server permissions and ownership...\nChecking firewall status...\nChecking JDK...\n[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8\n[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7\n[3] Custom JDK\n==============================================================================\nEnter choice (1): \"点击回车键\"\nJDK already exists, using /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz\nInstalling JDK to /usr/jdk64/\nSuccessfully installed JDK to /usr/jdk64/\nJCE Policy archive already exists, using /var/lib/ambari-server/resources/jce_policy-8.zip\nInstalling JCE policy...\nCompleting setup...\nConfiguring database...\nEnter advanced database configuration [y/n] (点击回车键)\nConfiguring database...\nChecking PostgreSQL...\nRunning initdb: This may take up to a minute.\nInitializing database ... OK\n...........\nAdjusting ambari-server permissions and ownership...\nAmbari Server \'setup\' completed successfully.\n```\n## 3.6启动ambari\n```\n[root@crf1 ~]# ambari-server start\n\nUsing python  /usr/bin/python\nStarting ambari-server\nAmbari Server running with administrator privileges.\nOrganizing resource files at /var/lib/ambari-server/resources...\nAmbari database consistency check started...\nServer PID at: /var/run/ambari-server/ambari-server.pid\nServer out at: /var/log/ambari-server/ambari-server.out\nServer log at: /var/log/ambari-server/ambari-server.log\nWaiting for server start........................\nServer started listening on 8080\n\n```\n## 3.7检测ambari-server端口\n> 注意：要没有lsof服务记得安装，yum -y install lsof \n```\n[root@crf1 ~]#  lsof -i :8080\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\njava    3921 root 1435u  IPv6  24888      0t0  TCP *:webcache (LISTEN)\n```\n# 安装部署集群	\n## 4.1 配置集群\n打开客户端浏览器（推荐使用Google 浏览器），输入安装好的管理节点IP或DNS地址，比如http:// 192.168.0.245:8080/(192.168.0.245是管理节点的IP地址)。访问这个地址，您会看到下面的集群登录页面。以admin的身份登录，密码也是admin。\n\n> 注意事项：以下组件依赖于mysql  \nregistry  streamline  druid   superset\n\n\n![](/upload/images/20180203//5de26234-9333-49ae-8716-6795471b9100.png)\n\n\n\n## 4.2 安装crf组件\n第一次进入的时候需要我们自己创建一个集群，点击Launch Install Wizard进行创建进入集群创建向导。\n\n![](/upload/images/20180203//43297fe9-e20a-4392-b5f0-e8c63800b9c6.png)\n\n集群安装向导：开始\n为集群取一名字：CRF，输入集群名字后点击“下一步”进入选择安装包\n\n![](/upload/images/20180203//6ff15a22-ef96-465b-bebd-4ebbb32ee417.png)\n\n集群安装向导：选择软件包\n选择系统默认的软件包crf3.0，选择OS为redhat7，\n路径为：http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/\n\n![](/upload/images/20180203//384143a6-f2d1-4b0a-86ff-18f9e01a75eb.png)\n\n特别注意源的选择，需要把地址链接复制进去\n\n![](/upload/images/20180203//d2bff5b3-e2a2-4208-9832-1603346a2fbd.png)\n\n\n点击下一步\n填入主机名，复制主机秘钥，到输入框，注册主机\n如下图：\n\n![](/upload/images/20180203//df13d12f-b950-40c9-b85a-3d2706c1b3af.png)\n\n点击“注册并确认”\n\n![](/upload/images/20180203//1c26e646-4a0e-4284-8c94-70cd5f50bcc6.png)\n\n点击“OK”\n\n\n![](/upload/images/20180203//0016ab0d-24c3-4b17-a707-1becb189bfc0.png)\n\n主机安装成功，点击“下一步”\n\n集群安装向导：选择服务\n\n选择需要安装的服务，选择服务时会根据服务\n分配Master角色\n![](/upload/images/20180203//59f5541e-c137-4ca9-a790-02519aafa781.png)\n\n点击“下一步”继续安装\n\n特别注意：\"NIFI 和 superset 不能装在同一台机器上\"\n\n集群安装向导:分配Slaves和Clients,点击下一步\n\n![](/upload/images/20180203//8c69a365-8e86-4112-9537-f37d09e0d456.png)\n\n集群安装向导：定制服务\n\n![](/upload/images/20180203//d6736459-3f0e-4699-b5b8-e483c2530c9c.png)\n\n\n\nAmbari-Metrics組件密码列：123456/ 这样形式来填写\n\n![](/upload/images/20180203//e6b04dd1-6220-4c27-8976-3fd7b2e6d977.png)\n\nLogsearch組件密码列：123456/ 这样形式来填写\n\n![](/upload/images/20180203//d0cca700-5de7-418b-82f0-6b1624da3c14.png)\n\n![](/upload/images/20180203//d0c4e363-134d-4eff-8fc7-7973e7572ad7.png)\n![](/upload/images/20180203//5992cba8-9128-4a40-840e-d20d438d0324.png)\n\nNifi组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//fcad373f-5393-493b-b1a8-df6d757cacd2.png)\n\n\nRegistry 这个密码比较特殊，这个密码是给mysql用户授权的密码 \n密码：R12$%34qw\n\n\n![](/upload/images/20180203//b26bdf66-4069-4021-a725-ecdec4b9e33f.png)\n![](/upload/images/20180322//a332c704-c2cd-4aaf-adb1-8e5104ba2e9f.png)\n![](/upload/images/20180203//68ad30d1-99bb-47a0-9221-a352ce421ada.png)\n\nStreamline组件 和Registry组件 一样 都是需要mysql 给用户授权的那个密码\n密码R12$%34qw\n\n![](/upload/images/20180203//6687fc57-42b0-4ea8-a6f1-a5c4d157ee6c.png)\n![](/upload/images/20180322//2bbf28a0-e519-4685-a613-b20915d53167.png)\n\n![](/upload/images/20180203//314d4443-a8d6-4083-a0f0-9e6cf66b7ecc.png)\nSuperset组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//b5a67a6a-249d-4e41-81dd-fa11201a4353.png)\n![](/upload/images/20180424//f0171731-37f4-40a0-bae5-a448851eae67.png)\nSuperset组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//3beb7fe2-683e-4e44-9376-c92437b8428b.png)\n注意：单节点安装Superset和NiFi 要更改Superset端口号，否则会和NiFi端口冲突（如下图更改端口号）\n![](/upload/images/20180413//4617cb9c-ce6f-44b5-886e-20428315aca2.png)\n点击“继续执行”\n![](/upload/images/20180203//7b234518-5ec2-450a-9837-f77cfc6e8f99.png)\n\n检查安装配置\n\n![](/upload/images/20180203//9d5567c6-a1cc-47a3-a86b-3faae0f97dcb.png)\n\n点击“部署”，开始部署组件\n\n![](/upload/images/20180203//2baa3f8b-2c23-41a0-a44f-f9f1a64c9cb0.png)\n\n集群安装向导：安装、启动并测试\n\n\n![](/upload/images/20180203//78ccdb62-86c9-4a91-814b-68d4397d5c34.png)\n\n等待安装完成 \n\n![](/upload/images/20180203//614fdf35-b532-4bef-a5fe-cdc6d8bb5568.png)\n\n点击下一步\n![](/upload/images/20180203//c676a7e1-8884-4fcc-944a-ab59ea296b51.png)\n\n查看服务概要\n\n![](/upload/images/20180203//374ca460-6a2e-4143-b3a7-1f6b8919e31e.png)\n\n点击“完成”\n\n安装成功，查看界面\n\n![](/upload/images/20180203//30c4ffaa-ea15-4c35-b620-ed95c21035d1.png)', '3', '<h1 id=\"h1-crf3-0-\"><a name=\"CRF3.0部署手册\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>CRF3.0部署手册</h1><h1 id=\"h1-u5B89u88C5u73AFu5883u63A8u8350\"><a name=\"安装环境推荐\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装环境推荐</h1><h2 id=\"h2-1-1-\"><a name=\"1.1 硬件环境要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1 硬件环境要求</h2><table>\n<thead>\n<tr>\n<th>推荐</th>\n<th style=\"text-align:center\">小规模硬件推荐：4-10个节点</th>\n<th style=\"text-align:center\">中等规模硬件配置推荐：20+个节点</th>\n<th style=\"text-align:center\">大规模硬件配置推荐：100节点以上</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>处理器cpu</td>\n<td style=\"text-align:center\">2路 8核心XeonE5处理器(3.8GHz)</td>\n<td style=\"text-align:center\">2路 10核心XeonE5处理器(3.8GHz)</td>\n<td style=\"text-align:center\">2路 10核心 XeonE7处理器(3.8GHz)</td>\n</tr>\n<tr>\n<td>内存</td>\n<td style=\"text-align:center\">64G或者以上内存，DDR3L，RRECC</td>\n<td style=\"text-align:center\">128G或者以上内存，DDR3L,RRECC</td>\n<td style=\"text-align:center\">128G或者以上内存，DDR3L,RRECC</td>\n</tr>\n<tr>\n<td>系统盘</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n</tr>\n<tr>\n<td>磁盘接口</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n</tr>\n<tr>\n<td>磁盘</td>\n<td style=\"text-align:center\">12个2T或者6T 7200RPM SATA硬盘</td>\n<td style=\"text-align:center\">12个4T或者6T 7200RPM</td>\n<td style=\"text-align:center\">12个6T  7200RPM SATA</td>\n</tr>\n<tr>\n<td>硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n</tr>\n<tr>\n<td>Raid卡</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n</tr>\n<tr>\n<td>网络</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n</tr>\n<tr>\n<td>电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"h2-1-2-\"><a name=\"1.2 操作系统要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2 操作系统要求</h2><table>\n<thead>\n<tr>\n<th>系统版本</th>\n<th style=\"text-align:center\">CentOS release 7 </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>内核版本</td>\n<td style=\"text-align:center\">3.10.0-327.13.1.el7.x86_64</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"h2-1-3-java-\"><a name=\"1.3 Java环境要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3 Java环境要求</h2><p>如果您的集群的机器上还没有安装JDK，请自主下载安装JDK 1.8（Oracle版本）。</p>\n<pre><code>[root@crf1 jvm]# java  -version \njava version &quot;1.8.0_144&quot;\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n</code></pre><h2 id=\"h2-1-4-\"><a name=\"1.4 支持的浏览器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4 支持的浏览器</h2><table>\n<thead>\n<tr>\n<th>浏览器</th>\n<th style=\"text-align:center\">版本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Internet Explorer</td>\n<td style=\"text-align:center\">8.0 以上</td>\n</tr>\n<tr>\n<td>Chrome</td>\n<td style=\"text-align:center\">23.0 以上</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"h1-u5B89u88C5u57FAu7840u73AFu5883u51C6u5907\"><a name=\"安装基础环境准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装基础环境准备</h1><h3 id=\"h3-2-1-\"><a name=\"2.1 修改主机名\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1 修改主机名</h3><blockquote>\n<p>主机名即计算机的名字（计算机名），主机名有时称为域名。主机名映射到 IP 地址，但是主机名和 IP 地址之间没有一对一关系。对于用户来说，主机名比数字 IP 地址更方便。所以会选择其主机名，用户能很容易地记住这些主机名。</p>\n</blockquote>\n<p>本次测试建立于三台服务器的基础上演示</p>\n<p>192.168.0.245  crf1</p>\n<p>192.168.0.246   crf2</p>\n<p>192.168.0.247   crf3</p>\n<p>修改每台主机的主机名</p>\n<pre><code>\n[root@crf1 ~]# vi /etc/hostname\ncrf1\n\n[root@crf2 ~]# vi /etc/hostname\ncrf2\n\n[root@crf3 ~]# vi /etc/hostname\ncrf3\n</code></pre><h2 id=\"h2-2-2-ip-\"><a name=\"2.2 主机与IP映射\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2 主机与IP映射</h2><blockquote>\n<p>hosts文件是Linux系统中一个负责IP地址与域名快速解析的文件，一般会保存在“/etc”目录下，文件名为“hosts”（不同的linux版本，这个配置文件也可能不同）。hosts文件是一个用于存储计算机网络中节点信息的文件，它可以将主机名映射到相应的IP地址，在没有域名服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的IP地址，否则就需要使用DNS服务程序来解决。通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。</p>\n</blockquote>\n<p>三台服务器均配置hosts文件</p>\n<pre><code>crf1\n[root@crf1 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n-----------------------------------------------------------------------------\ncrf3\n[root@crf3 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n</code></pre><h2 id=\"h2-2-3-\"><a name=\"2.3 安全设置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3 安全设置</h2><h3 id=\"h3-2-3-1-selinux\"><a name=\"2.3.1 关闭SElinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.1 关闭SElinux</h3><pre><code>crf1\n[root@crf1 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf2\n[root@crf2 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf3\n[root@crf3 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n</code></pre><h3 id=\"h3-2-3-2-\"><a name=\"2.3.2 关闭防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.2 关闭防火墙</h3><blockquote>\n<p>防火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。</p>\n</blockquote>\n<pre><code>crf1\n[root@crf1 ~]# systemctl stop firewalld\n\ncrf2\n[root@nx-2 ~]# systemctl stop firewalld\n\ncrf3\n[root@nx-3 ~]# systemctl stop firewalld\n</code></pre><h2 id=\"h2-2-4-\"><a name=\"2.4 免密码登录\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4 免密码登录</h2><blockquote>\n<p>为了方便用户使用，一般会设置免密码登录，当Linux设置免密码登录后，节点跳转时SSH不会询问密码。</p>\n</blockquote>\n<h3 id=\"h3-2-4-1-\"><a name=\"2.4.1 生成私钥和公钥\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.1 生成私钥和公钥</h3><pre><code>crf1\n[root@crf1 ~]# ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n01:f7:8d:da:63:cc:cc:26:6a:ee:82:6c:1e:bd:21:5c root@crf1\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|      . .        |\n|       o . o     |\n|        . o .    |\n|         O       |\n|    E   S X      |\n| . o   . + .     |\n| .+.o o          |\n|  +o.=           |\n| o. .oo          |\n+-----------------+\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n4d:16:c2:15:99:31:f6:87:57:83:12:52:ff:e9:2c:92 root@crf2\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|       ..oOB. ...|\n|        .o+=.o ..|\n|          o +.o  |\n|         +   o. .|\n|        S .    o |\n|            . o  |\n|           E . o |\n|            . .  |\n|                 |\n+-----------------+\n---------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd5:fb:e3:fe:11:a9:6c:0a:69:15:46:e1:79:5d:e7:2c root@crf3\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|           o.   o|\n|          o.. .oo|\n|          .=..E.o|\n|         .. o. ..|\n|        S  ..  o |\n|          o ... .|\n|         +   +o. |\n|        . . o. ..|\n|           . .o..|\n+-----------------+\n</code></pre><h3 id=\"h3-2-4-2-\"><a name=\"2.4.2 将公钥复制到远程主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.2 将公钥复制到远程主机</h3><p>在服务器中的每一台服务器建立服务器之间的ssh免密码登陆。在系统询问Are you sure you want to continue connecting (yes/no)?时输入yes并按回车，在系统询问root<a href=\"https://github.com/crf1\" title=\"&#64;crf1\" class=\"at-link\">@crf1</a>’s password:时输入密码（注意：密码输入时，密码不显示）。</p>\n<pre><code>crf1\n[root@crf1 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf1 ~]# ssh-copy-id crf2\nThe authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf1 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf2\n2The authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n-------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf3 ~]# ssh-copy-id crf2\nThe authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf3 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n</code></pre><h3 id=\"h3-2-5-\"><a name=\"2.5 配置源\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.5 配置源</h3><p>repo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用！</p>\n<pre><code>[root@crf1 ~]# cd /etc/yum.repos.d\n\n[root@crf1 yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/ambari/ambari.repo\n\n[root@crf1 yum.repos.d]# cat ambari.repo \n[redoop-crf3.0]\nName=Redoop’s Distribution for crf, Version 3.0.0\nBaseurl= http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/ambari\ngpgcheck=0\nenabaled=1\n\n[root@crf1 yum.repos.d]# yum clean all\n\nLoaded plugins: fastestmirror\nLoaded plugins: fastestmirror\nCleaning repos: ambari-2.5.1.0 base extras updates\nCleaning up everything\nCleaning up list of fastest mirrors\n</code></pre><h1 id=\"h1--ambari-mysql\"><a name=\"安装ambari和mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装ambari和mysql</h1><p>Ambari的Server程序，主要管理部署在每个节点上的管理监控程序</p>\n<h2 id=\"h2-3-1-ambari-server\"><a name=\"3.1 安装ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.1 安装ambari-server</h2><pre><code>crf1\n[root@crf1 ~]# yum install -y ambari-server\n\nLoaded plugins: fastestmirror\nambari-2.5.1.0                                                       | 2.9 kB  00:00:00\nbase                                                                 | 3.6 kB  00:00:00\nextras                                                               | 3.4 kB  00:00:00\nupdates                                                              | 3.4 kB  00:00:00\n(1/5): ambari-2.5.1.0/primary_db                                     | 8.7 kB  00:00:00\n(2/5): base/7/x86_64/group_gz                                        | 156 kB  00:00:00\n(3/5): extras/7/x86_64/primary_db                                    | 166 kB  00:00:00\n(4/5): base/7/x86_64/primary_db                                      | 5.7 MB  00:00:07\n(5/5): updates/7/x86_64/primary_db                                   | 6.0 MB  00:00:23\nDetermining fastest mirrors\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies........\nInstalled:\n  ambari-server.x86_64 0:2.5.1.0-159\nDependency Installed:\n  postgresql.x86_64 0:9.2.23-3.el7_4            postgresql-libs.x86_64 0:9.2.23-3.el7_4\n  postgresql-server.x86_64 0:9.2.23-3.el7_4\nComplete!\n</code></pre><h2 id=\"h2-3-2-mysql-ambari-mysql-\"><a name=\"3.2 安装mysql将ambari关联mysql数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2 安装mysql将ambari关联mysql数据库</h2><pre><code>[root@crf1 ~]# yum install mysql-connector-java* -y\n\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies\n--&gt; Running transaction check\n    ..................................\n\nDependency Updated:\n  chkconfig.x86_64 0:1.7.4-1.el7                  nspr.x86_64 0:4.13.1-1.0.el7_3\n  nss.x86_64 0:3.28.4-15.el7_4                    nss-softokn.x86_64 0:3.28.3-8.el7_4\n  nss-softokn-freebl.x86_64 0:3.28.3-8.el7_4      nss-sysinit.x86_64 0:3.28.4-15.el7_4\n  nss-tools.x86_64 0:3.28.4-15.el7_4              nss-util.x86_64 0:3.28.4-3.el7\n\nComplete!\n\n[root@crf1~]#sudo ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n\n[root@crf1~]# cd /etc/yum.repos.d/\n[root@crf1~yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/utils/mysql/mysql_57.repo\n\n[root@crf1 yum.repos.d]# ls                    \nambari.repo            CentOS-Media.repo\nCentOS-Base.repo       CentOS-Sources.repo\nCentOS-CR.repo         CentOS-Vault.repo\nCentOS-Debuginfo.repo  mysql_57.repo\nCentOS-fasttrack.repo\n\n [root@crf1yum.repos.d]# yum clean all\nLoaded plugins: fastestmirror\nCleaning repos: base extras mysql-5.7\n              : redoop-crf3.0 updates\nCleaning up everything\nCleaning up list of fastest mirrors\n\n\n[root@crf1 yum.repos.d]# yum install mysql-community-server –y\n\nWarning: RPMDB altered outside of yum.\n  Installing : mysql-community-common-5.7.21-1.el7.x86_64                               1/7\n      ..............................\n\nInstalled:\n  mysql-community-libs.x86_64 0:5.7.21-1.el7\n  mysql-community-libs-compat.x86_64 0:5.7.21-1.el7\n  mysql-community-server.x86_64 0:5.7.21-1.el7\nDependency Installed:\n\n  mysql-community-client.x86_64 0:5.7.21-1.el7 mysql-community-common.x86_64 0:5.7.21-1.el7\n  net-tools.x86_64 0:2.0-0.22.20131004git.el7\n\nReplaced:\n  mariadb-libs.x86_64 1:5.5.44-2.el7.centos\n\nComplete!\n</code></pre><h2 id=\"h2-3-3-mysql\"><a name=\"3.3启动mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3启动mysql</h2><pre><code>[root@crf1 ~]# systemctl  start   mysqld.service\n[root@crf1 ~]# systemctl  enable   mysqld.service\n</code></pre><h2 id=\"h2-3-4-mysql-mysql\"><a name=\"3.4给mysql用户更改密码和配置mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.4给mysql用户更改密码和配置mysql</h2><pre><code>[root@crf1 yum.repos.d]# grep &#39;A temporary password is generated for root@localhost&#39; /var/log/mysqld.log |tail -1\n\n2018-02-02T06:01:02.850616Z 1 [Note] A temporary password is generated for root@localhost: `Jl-l.%hNl4Po`  //红色部分为初始密码\n\n[root@crf1 ~]# # mysqladmin -u root -p password &quot;Redoop123$%^&quot;\nEnter password: Jl-l.%hNl4Po  // 红色为新更改密码\n\n[root@crf1 yum.repos.d]# mysql -u root -p\nEnter password: Redoop123$%^\n\nelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 14\nServer version: 5.7.21\n\nmysql&gt; create database registry;\n\nmysql&gt; create database streamline;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;registry&#39;@&#39;%&#39; IDENTIFIED BY &#39;R12$%34qw&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;streamline&#39;@&#39;%&#39; IDENTIFIED BY &#39;R12$%34qw&#39;;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON registry.* TO &#39;registry&#39;@&#39;%&#39; WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON streamline.* TO &#39;streamline&#39;@&#39;%&#39; WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; commit;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE DATABASE druid DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE DATABASE superset DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;druid&#39;@&#39;%&#39; IDENTIFIED BY &#39;9oNio)ex1ndL&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;superset&#39;@&#39;%&#39; IDENTIFIED BY &#39;9oNio)ex1ndL&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;druid&#39;@&#39;%&#39; WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;superset&#39;@&#39;%&#39; WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; commit;\nQuery OK, 0 rows affected (0.00 sec)\nmysql&gt; exit;\nBye\n</code></pre><h2 id=\"h2-3-5-crf-mpack\"><a name=\"3.5安装CRF版mpack\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.5安装CRF版mpack</h2><pre><code>[root@crf1~]#cd /opt/\n\n[root@crf1 opt~]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/mpack/crf-ambari-mpack-3.0.0.0-512.tar.gz\n\n--2018-02-0214:22:37-- http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/mpack/crf-ambari-mpack-3.0.0.tar.gz\nConnecting to 192.168.0.220:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 56231837 (54M) [application/x-gzip]\nSaving to: ‘CRF-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz’\n100%[==================================================&gt;] 56,231,837   118MB/s   in 0.5s\n2018-02-02 14:22:37 (118 MB/s) - ‘CRF-ambari-mpack-3.0.0.tar.gz’ saved [56231837/56231837]\n\n[root@crf1 opt]# ls\ncrf-ambari-mpack-3.0.0.tar.gz\n\n[root@crf1opt]#ambari-server install-mpack --mpack=/opt/crf-ambari-mpack-3.0.0.0-512.tar.gz --purge --verbose\n\nUsing python  /usr/bin/python\nInstalling management pack\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Installing management pack /opt/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Download management pack to temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Expand management pack at temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512/\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nLooking for available JDKs at /usr/jdk64\nFound: []\nCAUTION: You have specified the --purge option with --purge-list=[&#39;stack-definitions&#39;, &#39;mpacks&#39;]. This will replace all existing stack definitions, management packs currently installed.\nAre you absolutely sure you want to perform the purge [yes/no]? (no)&quot;yes&quot;\n . ......\nINFO: Management pack crf-ambari-mpack-0.1.0.0.3.0.0-512 successfully installed! Please restart ambari-server.\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nAmbari Server &#39;install-mpack&#39; completed successfully.\n</code></pre><h2 id=\"h2-3-6-ambari\"><a name=\"3.6 初始化ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.6 初始化ambari</h2><p>下载JDK</p>\n<p>待安装完成后，便需要对 Ambari Server 做一个简单的配置。执行下面的命令。</p>\n<pre><code>[root@crf1 opt]# cd /var/lib/ambari-server/resources/\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jce_policy-8.zip\n\nSaving to: ‘jce_policy-8.zip’\n100%[==================================================&gt;] 8,409       --.-K/s   in 0s\n2018-02-03 00:18:44 (32.0 MB/s) - ‘jce_policy-8.zip’ saved [8409/8409]\n\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jdk-8u112-linux-x64.tar.gz\n\nSaving to: ‘jdk-8u112-linux-x64.tar.gz’\n100%[==================================================&gt;] 183,212,596 11.1MB/s   in 16s\n2018-02-03 00:19:11 (11.1 MB/s) - ‘jdk-8u112-linux-x64.tar.gz’ saved [183212596/183212596]\n\n[root@crf1 ~]# ambari-server setup\n\n\nUsing python  /usr/bin/python\nSetup ambari-server\nChecking SELinux...\nSELinux status is &#39;disabled&#39;\nCustomize user account for ambari-server daemon [y/n] （点击回车键）\nAdjusting ambari-server permissions and ownership...\nChecking firewall status...\nChecking JDK...\n[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8\n[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7\n[3] Custom JDK\n==============================================================================\nEnter choice (1): &quot;点击回车键&quot;\nJDK already exists, using /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz\nInstalling JDK to /usr/jdk64/\nSuccessfully installed JDK to /usr/jdk64/\nJCE Policy archive already exists, using /var/lib/ambari-server/resources/jce_policy-8.zip\nInstalling JCE policy...\nCompleting setup...\nConfiguring database...\nEnter advanced database configuration [y/n] (点击回车键)\nConfiguring database...\nChecking PostgreSQL...\nRunning initdb: This may take up to a minute.\nInitializing database ... OK\n...........\nAdjusting ambari-server permissions and ownership...\nAmbari Server &#39;setup&#39; completed successfully.\n</code></pre><h2 id=\"h2-3-6-ambari\"><a name=\"3.6启动ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.6启动ambari</h2><pre><code>[root@crf1 ~]# ambari-server start\n\nUsing python  /usr/bin/python\nStarting ambari-server\nAmbari Server running with administrator privileges.\nOrganizing resource files at /var/lib/ambari-server/resources...\nAmbari database consistency check started...\nServer PID at: /var/run/ambari-server/ambari-server.pid\nServer out at: /var/log/ambari-server/ambari-server.out\nServer log at: /var/log/ambari-server/ambari-server.log\nWaiting for server start........................\nServer started listening on 8080\n</code></pre><h2 id=\"h2-3-7-ambari-server-\"><a name=\"3.7检测ambari-server端口\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.7检测ambari-server端口</h2><blockquote>\n<p>注意：要没有lsof服务记得安装，yum -y install lsof </p>\n<pre><code>[root@crf1 ~]#  lsof -i :8080\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\njava    3921 root 1435u  IPv6  24888      0t0  TCP *:webcache (LISTEN)\n</code></pre><h1 id=\"h1-u5B89u88C5u90E8u7F72u96C6u7FA4\"><a name=\"安装部署集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装部署集群</h1><h2 id=\"h2-4-1-\"><a name=\"4.1 配置集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.1 配置集群</h2><p>打开客户端浏览器（推荐使用Google 浏览器），输入安装好的管理节点IP或DNS地址，比如http:// 192.168.0.245:8080/(192.168.0.245是管理节点的IP地址)。访问这个地址，您会看到下面的集群登录页面。以admin的身份登录，密码也是admin。</p>\n<p>注意事项：以下组件依赖于mysql<br>registry  streamline  druid   superset</p>\n</blockquote>\n<p><img src=\"/upload/images/20180203//5de26234-9333-49ae-8716-6795471b9100.png\" alt=\"\"></p>\n<h2 id=\"h2-4-2-crf-\"><a name=\"4.2 安装crf组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.2 安装crf组件</h2><p>第一次进入的时候需要我们自己创建一个集群，点击Launch Install Wizard进行创建进入集群创建向导。</p>\n<p><img src=\"/upload/images/20180203//43297fe9-e20a-4392-b5f0-e8c63800b9c6.png\" alt=\"\"></p>\n<p>集群安装向导：开始<br>为集群取一名字：CRF，输入集群名字后点击“下一步”进入选择安装包</p>\n<p><img src=\"/upload/images/20180203//6ff15a22-ef96-465b-bebd-4ebbb32ee417.png\" alt=\"\"></p>\n<p>集群安装向导：选择软件包<br>选择系统默认的软件包crf3.0，选择OS为redhat7，<br>路径为：<a href=\"http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/\">http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/</a></p>\n<p><img src=\"/upload/images/20180203//384143a6-f2d1-4b0a-86ff-18f9e01a75eb.png\" alt=\"\"></p>\n<p>特别注意源的选择，需要把地址链接复制进去</p>\n<p><img src=\"/upload/images/20180203//d2bff5b3-e2a2-4208-9832-1603346a2fbd.png\" alt=\"\"></p>\n<p>点击下一步<br>填入主机名，复制主机秘钥，到输入框，注册主机<br>如下图：</p>\n<p><img src=\"/upload/images/20180203//df13d12f-b950-40c9-b85a-3d2706c1b3af.png\" alt=\"\"></p>\n<p>点击“注册并确认”</p>\n<p><img src=\"/upload/images/20180203//1c26e646-4a0e-4284-8c94-70cd5f50bcc6.png\" alt=\"\"></p>\n<p>点击“OK”</p>\n<p><img src=\"/upload/images/20180203//0016ab0d-24c3-4b17-a707-1becb189bfc0.png\" alt=\"\"></p>\n<p>主机安装成功，点击“下一步”</p>\n<p>集群安装向导：选择服务</p>\n<p>选择需要安装的服务，选择服务时会根据服务<br>分配Master角色<br><img src=\"/upload/images/20180203//59f5541e-c137-4ca9-a790-02519aafa781.png\" alt=\"\"></p>\n<p>点击“下一步”继续安装</p>\n<p>特别注意：”NIFI 和 superset 不能装在同一台机器上”</p>\n<p>集群安装向导:分配Slaves和Clients,点击下一步</p>\n<p><img src=\"/upload/images/20180203//8c69a365-8e86-4112-9537-f37d09e0d456.png\" alt=\"\"></p>\n<p>集群安装向导：定制服务</p>\n<p><img src=\"/upload/images/20180203//d6736459-3f0e-4699-b5b8-e483c2530c9c.png\" alt=\"\"></p>\n<p>Ambari-Metrics組件密码列：123456/ 这样形式来填写</p>\n<p><img src=\"/upload/images/20180203//e6b04dd1-6220-4c27-8976-3fd7b2e6d977.png\" alt=\"\"></p>\n<p>Logsearch組件密码列：123456/ 这样形式来填写</p>\n<p><img src=\"/upload/images/20180203//d0cca700-5de7-418b-82f0-6b1624da3c14.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180203//d0c4e363-134d-4eff-8fc7-7973e7572ad7.png\" alt=\"\"><br><img src=\"/upload/images/20180203//5992cba8-9128-4a40-840e-d20d438d0324.png\" alt=\"\"></p>\n<p>Nifi组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//fcad373f-5393-493b-b1a8-df6d757cacd2.png\" alt=\"\"></p>\n<p>Registry 这个密码比较特殊，这个密码是给mysql用户授权的密码<br>密码：R12$%34qw</p>\n<p><img src=\"/upload/images/20180203//b26bdf66-4069-4021-a725-ecdec4b9e33f.png\" alt=\"\"><br><img src=\"/upload/images/20180322//a332c704-c2cd-4aaf-adb1-8e5104ba2e9f.png\" alt=\"\"><br><img src=\"/upload/images/20180203//68ad30d1-99bb-47a0-9221-a352ce421ada.png\" alt=\"\"></p>\n<p>Streamline组件 和Registry组件 一样 都是需要mysql 给用户授权的那个密码<br>密码R12$%34qw</p>\n<p><img src=\"/upload/images/20180203//6687fc57-42b0-4ea8-a6f1-a5c4d157ee6c.png\" alt=\"\"><br><img src=\"/upload/images/20180322//2bbf28a0-e519-4685-a613-b20915d53167.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180203//314d4443-a8d6-4083-a0f0-9e6cf66b7ecc.png\" alt=\"\"><br>Superset组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//b5a67a6a-249d-4e41-81dd-fa11201a4353.png\" alt=\"\"><br><img src=\"/upload/images/20180424//f0171731-37f4-40a0-bae5-a448851eae67.png\" alt=\"\"><br>Superset组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//3beb7fe2-683e-4e44-9376-c92437b8428b.png\" alt=\"\"><br>注意：单节点安装Superset和NiFi 要更改Superset端口号，否则会和NiFi端口冲突（如下图更改端口号）<br><img src=\"/upload/images/20180413//4617cb9c-ce6f-44b5-886e-20428315aca2.png\" alt=\"\"><br>点击“继续执行”<br><img src=\"/upload/images/20180203//7b234518-5ec2-450a-9837-f77cfc6e8f99.png\" alt=\"\"></p>\n<p>检查安装配置</p>\n<p><img src=\"/upload/images/20180203//9d5567c6-a1cc-47a3-a86b-3faae0f97dcb.png\" alt=\"\"></p>\n<p>点击“部署”，开始部署组件</p>\n<p><img src=\"/upload/images/20180203//2baa3f8b-2c23-41a0-a44f-f9f1a64c9cb0.png\" alt=\"\"></p>\n<p>集群安装向导：安装、启动并测试</p>\n<p><img src=\"/upload/images/20180203//78ccdb62-86c9-4a91-814b-68d4397d5c34.png\" alt=\"\"></p>\n<p>等待安装完成 </p>\n<p><img src=\"/upload/images/20180203//614fdf35-b532-4bef-a5fe-cdc6d8bb5568.png\" alt=\"\"></p>\n<p>点击下一步<br><img src=\"/upload/images/20180203//c676a7e1-8884-4fcc-944a-ab59ea296b51.png\" alt=\"\"></p>\n<p>查看服务概要</p>\n<p><img src=\"/upload/images/20180203//374ca460-6a2e-4143-b3a7-1f6b8919e31e.png\" alt=\"\"></p>\n<p>点击“完成”</p>\n<p>安装成功，查看界面</p>\n<p><img src=\"/upload/images/20180203//30c4ffaa-ea15-4c35-b620-ed95c21035d1.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('18', '0', 'Oracle VM VirtualBox 使用教程 （Windows 版）', '25', '2018-02-05 17:19:27', 'Oracle VM VirtualBox 使用教程 （Windows 版）', null, '0', '253', null, null, '2018-02-05 17:19:27', '2018-04-08 10:58:21', null, null, '0', '0', '0', '0', '# Oracle VM VirtualBox 使用教程 （Windows 版）\n\n## Oracle VM VirtualBox 简介\n#### irtualBox是一款功能强大的x86和AMD64 / Intel64 虚拟化产品，适用于企业以及家庭使用。VirtualBox不仅是一款功能非常丰富，性能卓越的企业用户产品，它还是唯一一款专业的解决方案，可以在GNU通用公共许可证（GPL）版本2的条款下作为开源软件免费获得。请参阅“ 关于VirtualBox “作介绍。\n\n#### 目前，VirtualBox可在Windows，Linux，Macintosh和Solaris主机上运行，​​并支持大量客户操作系统，包括但不限于Windows（NT 4.0,2000，XP，Server 2003，Vista，Windows 7，Windows 8，Windows 10 ），DOS / Windows 3.x，Linux（2.4,2.6,3.x和4.x），Solaris和OpenSolaris，OS / 2和OpenBSD。\n\n#### VirtualBox正在积极开发频繁的版本，并且有越来越多的功能，支持的客户操作系统和平台运行。VirtualBox是由一个专门的公司支持的社区努力：鼓励每个人贡献，而Oracle确保产品始终符合专业质量标准。\n\n## Oracle VM VirtualBox 下载\n### 下载地址\n#### https://www.virtualbox.org/wiki/Downloads\n\n#### 点击Windows主机\n\n![](/upload/images/20180205//60e0dbb2-33b8-427e-99e9-ed2dbeaf0ae0.png)\n### 注意事项\n#### 注意不要安装到系统盘 （C盘）\n\n#### 建议装到别的盘\n\n#### 列：\n\n![](/upload/images/20180205//14078762-430c-412b-82b6-bc6ed74e0b43.png)\n\n## 安装 VirtualBox\n\n#### 默认是装在 C盘的\n\n![](/upload/images/20180205//7c5d2950-1080-4f48-812e-b0ee83055d6b.png)\n\n#### 点击浏览 选择你要装的盘 \n\n![](/upload/images/20180205//e7b7b550-c49b-4fde-b940-a7ebf62e3f42.png)\n\n#### 点击“下一步”\n \n![](/upload/images/20180205//ddca909d-e100-48f2-b8e3-bf9fdf1a3af6.png)\n \n #### 点击”下一步“ \n \n![](/upload/images/20180205//0380129f-24b9-4052-8619-8adbda9767c1.png)\n \n #### 点击“是”\n \n![](/upload/images/20180205//22f58543-41e5-4e7f-a6b1-9d5621927663.png)\n \n #### 点击“安装”\n \n![](/upload/images/20180205//a937d343-7cdf-493e-a96c-1dbe5ba5384d.png)\n \n #### 等待安装成功就好了\n \n![](/upload/images/20180205//0e4f16eb-d2eb-4a0f-a6d4-4bb5066b6336.png)\n \n ## 用VirtualBox 创建一个虚拟linux机器\n \n #### 页面\n \n![](/upload/images/20180205//55cf5475-8d3a-4aa0-84bf-af68bc392672.png)\n \n #### 点击“新建”\n \n![](/upload/images/20180205//43b3bab9-eb44-436d-a186-9adaf482832b.png)\n \n #### 名称 随便 \n ####列 ：rdf\n #### 类型 Linux\n #### 版本 2.6-4.0\n \n![](/upload/images/20180205//ae6a1689-4551-4cf3-bbde-9ffea87d958f.png)\n \n > 点击“下一步”\n \n![](/upload/images/20180205//739e2b88-d7aa-4a8f-9a4e-47b3d7750dc0.png)\n \n > 内存根据自己的需求给予\n \n![](/upload/images/20180205//92dabe16-56f3-4d5c-a1d6-0b66c63d3fda.png)\n \n > 点击“下一步”\n \n![](/upload/images/20180205//1cdc0134-b85f-4c69-878f-72262c093e0c.png)\n \n > 创建硬盘根据自己的需求来创建 \n \n![](/upload/images/20180205//bac5dacc-3b40-4b29-b1f9-c3777ecda183.png)\n \n > 点击\"创建\"\n \n![](/upload/images/20180205//20c70b15-b8f7-4e43-ac1d-2832f4383e46.png)\n \n > 创建虚拟硬盘 保持默认就可以 “点击下一步”\n \n![](/upload/images/20180205//6a4e4b0c-697d-4655-ac1a-d80072a206db.png)\n > 根据自己的需求来选择 \n \n![](/upload/images/20180205//5d3959b9-04b1-4850-b223-4244b313aa4d.png)\n \n \n > 点击创建 \n \n![](/upload/images/20180205//45b5a84e-e0c3-4ed2-8b32-b578bab5fdad.png)\n \n## 挂系统镜像  \n \n#### 点击 “设置-存储”\n\n\n![](/upload/images/20180205//3ce4bf7b-94ac-4228-8927-71dcb7a92bdd.png)\n\n#### 然后点击启动就好了\n\n#### 后面的操作和装linux操作系统一样，就不演示了\n \n \n ## 配置 \n \n #### 点击-设置-常规-高级\n \n #### 把备份的位置换盘，不要存储在C盘占用系统盘，如下图\n \n ![](/upload/images/20180205//90d048a0-2b5a-4e63-97e3-bc65a0f91e13.png)\n \n #### 点击oK，就好了。\n \n \n\n\n', '1', '<h1 id=\"h1-oracle-vm-virtualbox-windows-\"><a name=\"Oracle VM VirtualBox 使用教程 （Windows 版）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Oracle VM VirtualBox 使用教程 （Windows 版）</h1><h2 id=\"h2-oracle-vm-virtualbox-\"><a name=\"Oracle VM VirtualBox 简介\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Oracle VM VirtualBox 简介</h2><h4 id=\"h4-irtualbox-x86-amd64-intel64-virtualbox-gnu-gpl-2-virtualbox-\"><a name=\"irtualBox是一款功能强大的x86和AMD64 / Intel64 虚拟化产品，适用于企业以及家庭使用。VirtualBox不仅是一款功能非常丰富，性能卓越的企业用户产品，它还是唯一一款专业的解决方案，可以在GNU通用公共许可证（GPL）版本2的条款下作为开源软件免费获得。请参阅“ 关于VirtualBox “作介绍。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>irtualBox是一款功能强大的x86和AMD64 / Intel64 虚拟化产品，适用于企业以及家庭使用。VirtualBox不仅是一款功能非常丰富，性能卓越的企业用户产品，它还是唯一一款专业的解决方案，可以在GNU通用公共许可证（GPL）版本2的条款下作为开源软件免费获得。请参阅“ 关于VirtualBox “作介绍。</h4><h4 id=\"h4--virtualbox-windows-linux-macintosh-solaris-windows-nt-4-0-2000-xp-server-2003-vista-windows-7-windows-8-windows-10-dos-windows-3-x-linux-2-4-2-6-3-x-4-x-solaris-opensolaris-os-2-openbsd-\"><a name=\"目前，VirtualBox可在Windows，Linux，Macintosh和Solaris主机上运行，​​并支持大量客户操作系统，包括但不限于Windows（NT 4.0,2000，XP，Server 2003，Vista，Windows 7，Windows 8，Windows 10 ），DOS / Windows 3.x，Linux（2.4,2.6,3.x和4.x），Solaris和OpenSolaris，OS / 2和OpenBSD。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>目前，VirtualBox可在Windows，Linux，Macintosh和Solaris主机上运行，​​并支持大量客户操作系统，包括但不限于Windows（NT 4.0,2000，XP，Server 2003，Vista，Windows 7，Windows 8，Windows 10 ），DOS / Windows 3.x，Linux（2.4,2.6,3.x和4.x），Solaris和OpenSolaris，OS / 2和OpenBSD。</h4><h4 id=\"h4-virtualbox-virtualbox-oracle-\"><a name=\"VirtualBox正在积极开发频繁的版本，并且有越来越多的功能，支持的客户操作系统和平台运行。VirtualBox是由一个专门的公司支持的社区努力：鼓励每个人贡献，而Oracle确保产品始终符合专业质量标准。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>VirtualBox正在积极开发频繁的版本，并且有越来越多的功能，支持的客户操作系统和平台运行。VirtualBox是由一个专门的公司支持的社区努力：鼓励每个人贡献，而Oracle确保产品始终符合专业质量标准。</h4><h2 id=\"h2-oracle-vm-virtualbox-\"><a name=\"Oracle VM VirtualBox 下载\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Oracle VM VirtualBox 下载</h2><h3 id=\"h3-u4E0Bu8F7Du5730u5740\"><a name=\"下载地址\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>下载地址</h3><h4 id=\"h4-https-www-virtualbox-org-wiki-downloads\"><a name=\"https://www.virtualbox.org/wiki/Downloads\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><a href=\"https://www.virtualbox.org/wiki/Downloads\">https://www.virtualbox.org/wiki/Downloads</a></h4><h4 id=\"h4--windows-\"><a name=\"点击Windows主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击Windows主机</h4><p><img src=\"/upload/images/20180205//60e0dbb2-33b8-427e-99e9-ed2dbeaf0ae0.png\" alt=\"\"></p>\n<h3 id=\"h3-u6CE8u610Fu4E8Bu9879\"><a name=\"注意事项\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>注意事项</h3><h4 id=\"h4--c-\"><a name=\"注意不要安装到系统盘 （C盘）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>注意不要安装到系统盘 （C盘）</h4><h4 id=\"h4-u5EFAu8BAEu88C5u5230u522Bu7684u76D8\"><a name=\"建议装到别的盘\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>建议装到别的盘</h4><h4 id=\"h4--\"><a name=\"列：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>列：</h4><p><img src=\"/upload/images/20180205//14078762-430c-412b-82b6-bc6ed74e0b43.png\" alt=\"\"></p>\n<h2 id=\"h2--virtualbox\"><a name=\"安装 VirtualBox\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装 VirtualBox</h2><h4 id=\"h4--c-\"><a name=\"默认是装在 C盘的\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>默认是装在 C盘的</h4><p><img src=\"/upload/images/20180205//7c5d2950-1080-4f48-812e-b0ee83055d6b.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"点击浏览 选择你要装的盘\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击浏览 选择你要装的盘</h4><p><img src=\"/upload/images/20180205//e7b7b550-c49b-4fde-b940-a7ebf62e3f42.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"点击“下一步”\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击“下一步”</h4><p><img src=\"/upload/images/20180205//ddca909d-e100-48f2-b8e3-bf9fdf1a3af6.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"点击”下一步“\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击”下一步“</h4><p><img src=\"/upload/images/20180205//0380129f-24b9-4052-8619-8adbda9767c1.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"点击“是”\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击“是”</h4><p><img src=\"/upload/images/20180205//22f58543-41e5-4e7f-a6b1-9d5621927663.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"点击“安装”\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击“安装”</h4><p><img src=\"/upload/images/20180205//a937d343-7cdf-493e-a96c-1dbe5ba5384d.png\" alt=\"\"></p>\n<h4 id=\"h4-u7B49u5F85u5B89u88C5u6210u529Fu5C31u597Du4E86\"><a name=\"等待安装成功就好了\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>等待安装成功就好了</h4><p><img src=\"/upload/images/20180205//0e4f16eb-d2eb-4a0f-a6d4-4bb5066b6336.png\" alt=\"\"></p>\n<h2 id=\"h2--virtualbox-linux-\"><a name=\"用VirtualBox 创建一个虚拟linux机器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>用VirtualBox 创建一个虚拟linux机器</h2><h4 id=\"h4-u9875u9762\"><a name=\"页面\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>页面</h4><p><img src=\"/upload/images/20180205//55cf5475-8d3a-4aa0-84bf-af68bc392672.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"点击“新建”\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击“新建”</h4><p><img src=\"/upload/images/20180205//43b3bab9-eb44-436d-a186-9adaf482832b.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"名称 随便\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>名称 随便</h4><h4 id=\"h4--rdf\"><a name=\"列 ：rdf\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>列 ：rdf</h4><h4 id=\"h4--linux\"><a name=\"类型 Linux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>类型 Linux</h4><h4 id=\"h4--2-6-4-0\"><a name=\"版本 2.6-4.0\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>版本 2.6-4.0</h4><p><img src=\"/upload/images/20180205//ae6a1689-4551-4cf3-bbde-9ffea87d958f.png\" alt=\"\"></p>\n<blockquote>\n<p>点击“下一步”</p>\n</blockquote>\n<p><img src=\"/upload/images/20180205//739e2b88-d7aa-4a8f-9a4e-47b3d7750dc0.png\" alt=\"\"></p>\n<blockquote>\n<p>内存根据自己的需求给予</p>\n</blockquote>\n<p><img src=\"/upload/images/20180205//92dabe16-56f3-4d5c-a1d6-0b66c63d3fda.png\" alt=\"\"></p>\n<blockquote>\n<p>点击“下一步”</p>\n</blockquote>\n<p><img src=\"/upload/images/20180205//1cdc0134-b85f-4c69-878f-72262c093e0c.png\" alt=\"\"></p>\n<blockquote>\n<p>创建硬盘根据自己的需求来创建 </p>\n</blockquote>\n<p><img src=\"/upload/images/20180205//bac5dacc-3b40-4b29-b1f9-c3777ecda183.png\" alt=\"\"></p>\n<blockquote>\n<p>点击”创建”</p>\n</blockquote>\n<p><img src=\"/upload/images/20180205//20c70b15-b8f7-4e43-ac1d-2832f4383e46.png\" alt=\"\"></p>\n<blockquote>\n<p>创建虚拟硬盘 保持默认就可以 “点击下一步”</p>\n</blockquote>\n<p><img src=\"/upload/images/20180205//6a4e4b0c-697d-4655-ac1a-d80072a206db.png\" alt=\"\"></p>\n<blockquote>\n<p>根据自己的需求来选择 </p>\n</blockquote>\n<p><img src=\"/upload/images/20180205//5d3959b9-04b1-4850-b223-4244b313aa4d.png\" alt=\"\"></p>\n<blockquote>\n<p>点击创建 </p>\n</blockquote>\n<p><img src=\"/upload/images/20180205//45b5a84e-e0c3-4ed2-8b32-b578bab5fdad.png\" alt=\"\"></p>\n<h2 id=\"h2-u6302u7CFBu7EDFu955Cu50CF\"><a name=\"挂系统镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>挂系统镜像</h2><h4 id=\"h4--\"><a name=\"点击 “设置-存储”\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击 “设置-存储”</h4><p><img src=\"/upload/images/20180205//3ce4bf7b-94ac-4228-8927-71dcb7a92bdd.png\" alt=\"\"></p>\n<h4 id=\"h4-u7136u540Eu70B9u51FBu542Fu52A8u5C31u597Du4E86\"><a name=\"然后点击启动就好了\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>然后点击启动就好了</h4><h4 id=\"h4--linux-\"><a name=\"后面的操作和装linux操作系统一样，就不演示了\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>后面的操作和装linux操作系统一样，就不演示了</h4><h2 id=\"h2-u914Du7F6E\"><a name=\"配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置</h2><h4 id=\"h4--\"><a name=\"点击-设置-常规-高级\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击-设置-常规-高级</h4><h4 id=\"h4--c-\"><a name=\"把备份的位置换盘，不要存储在C盘占用系统盘，如下图\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>把备份的位置换盘，不要存储在C盘占用系统盘，如下图</h4><p> <img src=\"/upload/images/20180205//90d048a0-2b5a-4e63-97e3-bc65a0f91e13.png\" alt=\"\"></p>\n<h4 id=\"h4--ok-\"><a name=\"点击oK，就好了。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击oK，就好了。</h4>');
INSERT INTO `tbl_archive` VALUES ('19', '0', 'Centos7.3 部署openstack ocata版本', '25', '2018-02-09 16:48:08', 'Centos7.3 部署openstack ocata版本', null, '0', '371', null, null, '2018-02-09 16:48:08', '2018-04-08 10:57:59', null, null, '0', '0', '0', '0', '# Centos7.3 部署openstack  ocata版本\n## openstack 介绍\n\n> OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。\nOpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。\n\n> OpenStack是一个旨在为公共及私有云的建设与管理提供软件的开源项目。它的社区拥有超过130家企业及1350位开发者，这些机构与个人都将OpenStack作为基础设施即服务（IaaS）资源的通用前端。OpenStack项目的首要任务是简化云的部署过程并为其带来良好的可扩展性。本文希望通过提供必要的指导信息，帮助大家利用OpenStack前端来设置及管理自己的公共云或私有云。\n\n> OpenStack云计算平台，帮助服务商和企业内部实现类似于 Amazon EC2 和 S3 的云基础架构服务(Infrastructure as a Service, IaaS)。OpenStack 包含两个主要模块：Nova 和 Swift，前者是 NASA 开发的虚拟服务器部署和业务计算模块；后者是 Rackspace开发的分布式云存储模块，两者可以一起用，也可以分开单独用。OpenStack除了有 Rackspace 和 NASA 的大力支持外，还有包括 Dell、Citrix、 Cisco、 Canonical等重量级公司的贡献和支持，发展速度非常快，有取代另一个业界领先开源云平台 Eucalyptus 的态势。\n\n> Openstack 组件分类\n\n![](/upload/images/20180209//20803372-1d70-4898-af21-1ee2aee20c1d.png)\n\n> https://docs.openstack.org/ocata/install-guide-rdo/glance-install.html\n官方文档地址\n\n\n\n## 基础环境\n> 系统版本： Centos7.3  两块网卡(eth0,eth1)\n\n> 机器的配置： 4G 50G硬盘 4个CPU\n\n> 机器名： linux-node1（计算节点）\n\n> 机器名： linux-node2（控制节点）\n\n> Node2 IP：eth0 192.168.57.145， eth1:192.168.57.146\n\n> Node1IP:  eth0: 192.168.57.142  eth1:192.168.57.143\n\n> 主控制节点主要安装如下：（keystone、Glance、nova、networking、Dashboard）\n\n> 计算节点主要安装如下：（nova、networking）\n\n### 2.1 时间同步（node1 +node2 操作）\n\n> https://docs.openstack.org/ocata/install-guide-rdo/glance-install.html\n\n> node1 \n\n```\n# yum install chrony\nvim /etc/chrony.conf\n设置\nallow 192.168.57.0/24\n####启动\n[root@linux-node2 ~]# systemctl enable chronyd.service\n[root@linux-node2 ~]#systemctl start chronyd.service\n########node1 的时间先同步一下标准时间\n[root@linux-node2 ~]# ntpdate pool.ntp.org\n# chronyc sources\n\nnode2 \n修改主配置文件\nvim /etc/chrony.conf\n把所有行去掉\n添加一行\nServer 192.168.57.145 iburst\n[root@linux-node2 ~]#systemctl start chronyd.service\n# chronyc sources\n```\n### 2.2 安装mysql（node2主控制节点操作）\n\n> 配置一下mysql\n\n```\n添加文件/etc/my.cnf.d/openstack.cnf 内容如下：\n [mysqld]\nbind-address = 192.168.57.145\ndefault-storage-engine = innodb\ninnodb_file_per_table\ncollation-server =utf8_general_ci\ninit-connect = \'SET NAMES utf8\'\ncharacter-set-server = utf8\n重启一下mysql\n[root@linux-node2 ~]# systemctl enable mariadb.service\n[root@linux-node2 ~]# systemctl start mariadb.service\n设置root密码\n[root@linux-node2 ~]# mysql_secure_installation\n创建数据库\n[root@linux-node2 ~]# mysql -uroot -p123456 -e \"Create database keystone;\"\n[root@linux-node2 ~]# mysql -uroot -p123456 -e \"grant all privileges on keystone.* to \'keystone\'@\'%\' identified by \'keystone\'\"\n[root@linux-node2 ~]# mysql -uroot -p123456 -e \"grant all privileges on keystone.* to \'keystone\'@\'localhost\' identified by \'keystone\'\"\n\n```\n\n### 2.3 安装消息队列（node2控制节点操作）\n```\n#yum install rabbitmq-server\n启动\n# systemctl enable rabbitmq-server.service\n# systemctl start rabbitmq-server.service\n新建用户\n# rabbitmqctl add_user openstack openstack\n对用户授权\nrabbitmqctl set_permissions openstack \".*\" \".*\" \".*\"\n查看插件\n[root@linux-node2 ~]# rabbitmq-plugins list\n[ ] amqp_client                       3.3.5\n[ ] cowboy                            0.5.0-rmq3.3.5-git4b93c2d\n[ ] eldap                             3.3.5-gite309de4\n[ ] mochiweb                          2.7.0-rmq3.3.5-git680dba8\n[ ] rabbitmq_amqp1_0                  3.3.5\n[ ] rabbitmq_auth_backend_ldap        3.3.5\n[ ] rabbitmq_auth_mechanism_ssl       3.3.5\n[ ] rabbitmq_consistent_hash_exchange 3.3.5\n[ ] rabbitmq_federation               3.3.5\n[ ] rabbitmq_federation_management    3.3.5\n[ ] rabbitmq_management               3.3.5\n[ ] rabbitmq_management_agent         3.3.5\n[ ] rabbitmq_management_visualiser    3.3.5\n[ ] rabbitmq_mqtt                     3.3.5\n[ ] rabbitmq_shovel                   3.3.5\n[ ] rabbitmq_shovel_management        3.3.5\n[ ] rabbitmq_stomp                    3.3.5\n[ ] rabbitmq_test                     3.3.5\n[ ] rabbitmq_tracing                  3.3.5\n[ ] rabbitmq_web_dispatch             3.3.5\n[ ] rabbitmq_web_stomp                3.3.5\n[ ] rabbitmq_web_stomp_examples       3.3.5\n[ ] sockjs                            0.3.4-rmq3.3.5-git3132eb9\n[ ] webmachine                        1.10.3-rmq3.3.5-gite9359c7\n启用web插件\n [root@linux-node2 ~]# rabbitmq-plugins enable rabbitmq_management\n重启一下\n[root@linux-node2 ~]# systemctl restart rabbitmq-server.service\n检查是否启动成功\n[root@linux-node2 ~]# netstat -nltp |grep 5672\ntcp        0      0 0.0.0.0:15672           0.0.0.0:*               LISTEN      16686/beam.smp      \ntcp        0      0 0.0.0.0:25672           0.0.0.0:*               LISTEN      16686/beam.smp      \ntcp6       0      0 :::5672                 :::*                    LISTEN      16686/beam.smp      \n[root@linux-node2 ~]#\nWeb访问\nhttp://192.168.57.138:15672/#/\n用户名密码为guest\n\n```\n![](/upload/images/20180209//95ac3aeb-7f17-41a1-bd77-eb6a932d32a6.png)\n\n## 搭建openstack \n\n### 3.1 安装keystone 组件介绍\n\n![](/upload/images/20180209//80692e30-faa2-4587-93f2-4eab1e5eeaba.png)\n> Keystone功能：\n\n> 1.用户与认证: 用户权限与用户行为跟踪\n\n> 2.服务目录：提供一个服务目录、包括所有服务项与相关API的端点\n\n> Keystone名词：\n\n> User： 用户\n\n> Tenant： 租户/项目\n\n> Token： 令牌\n\n> Role： 角色\n\n> Service： 服务\n\n> Endpoint： 端点\n\n## 3.2 安装keystone 组件（node2 主控制节点操作）\n\n> 安装openstack最新的源：\n　　　　\n\n> yum install centos-release-openstack-ocata \n　　　　\n\n> yum install https://rdoproject.org/repos/rdo-release.rpm \n　　　　\n\n> yum upgrade                                               (在主机上升级包）\n\n\n> yum install python-openstackclient            （安装opentack必须的插件）\n\n\n> yum install openstack-selinux                    （可选则安装这个插件，我直接关闭了selinux，因为不熟，对后续不会有影响）\n\n>  [root@linux-node1 home]# yum install openstack-keystone httpd mod_wsgi \n\n### 3.2.1修改配置文件\n```\nvim /etc/keystone/keystone.conf\n[database]\nconnection = mysql://keystone:keystone@192.168.57.141/keystone \n[token]\nprovider = fernet\n```\n### 3.2.2同步数据库\n```\nsu -s /bin/sh -c \"keystone-manage db_sync\" keystone\n###为什么需要su 一下呢？因为在写日志的时候文件是放在/var/log/keystone \n这个下面如果是root用户执行的话。那么写日志的时候就会写不进去。\n验证一下是否成功。进入数据库查看有没有表的建立。\n\n MariaDB [keystone]> show tables;\n\n+------------------------+\n| Tables_in_keystone     |\n初始化\n# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone\n# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone\n\n\n\n引导身份信息\nkeystone-manage bootstrap --bootstrap-password ADMIN_PASS \\\n  --bootstrap-admin-url http://linux-node2:35357/v3/ \\\n  --bootstrap-internal-url http://linux-node2:5000/v3/ \\\n  --bootstrap-public-url http://controller:5000/v3/ \\\n  --bootstrap-region-id RegionOne\n ```\n### 3.2.3配置memcache的配置 （/etc/sysconfig/memcached）\n```\nvim /etc/sysconfig/memcached\nOPTIONS=\"-l 127.0.0.1,::1,192.168.57.141\"\n```\n### 3.2.4启动memcache\n```\n[root@linux-node2 ~]# systemctl start memcached.service\n [root@linux-node2 ~]# netstat -nltp|grep 121\ntcp        0      0 0.0.0.0:11211           0.0.0.0:*               LISTEN      20054/memcached     \ntcp6       0      0 :::11211                :::*                    LISTEN      20054/memcached\n```\n### 3.2.5设置apache\n```\nln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/\n3.2.6修改主apache的主配置文件\nvim /etc/httpd/conf/httpd.conf\n配置一下Servername\nServerName 192.168.57.138:80\n``` \n### 3.2.7启动apache\n```\nsystemctl enable httpd.service\nsystemctl start httpd.service\n```\n### 3.2.8检查一下是否启动成功了\n```\n[root@linux-node2 conf.d]# netstat -nltp|grep httpd\ntcp6       0      0 :::80                   :::*                    LISTEN      20253/httpd         \ntcp6       0      0 :::35357                :::*                    LISTEN      20253/httpd         \ntcp6       0      0 :::5000                 :::*                    LISTEN      20253/httpd         \n[root@linux-node2 conf.d]#\n```\n## 3.3   keystone 用户权限\n### 3.3.1 设置环境变量\n```\n$ export OS_USERNAME=admin\n$ export OS_PASSWORD=ADMIN_PASS\n$ export OS_PROJECT_NAME=admin\n$ export OS_USER_DOMAIN_NAME=Default\n$ export OS_PROJECT_DOMAIN_NAME=Default\n$ export OS_AUTH_URL=http://linux-node2:35357/v3\n$ export OS_IDENTITY_API_VERSION=3\n``` \n### 3.3.2创建域、项目、用户和角色\n```\n创建服务\n[root@linux-node2 ~]# openstack project create --domain default --description \"Service Project\" service\n创建demo项目\n [root@linux-node2 ~]# openstack project create --domain default \\\n> --description \"Demo Project\" demo\n设置demo密码\n[root@linux-node2 ~]# openstack user create --domain default \\\n> --password-prompt demo\n创建用户组\n [root@linux-node2 ~]# openstack role create user\n加入用户组\n [root@linux-node2 ~]# openstack role add --project demo --user demo user\n```\n### 3.3.3验证操作\n``` \n1.出于安全原因，请禁用临时身份验证令牌机制：\n编辑/etc/keystone/keystone-paste.ini 文件并删除admin_token_auth从 [pipeline:public_api]，[pipeline:admin_api]和[pipeline:api_v3]段。\n\n2、取消设置临时 变量OS_AUTH_URL和OS_PASSWORD环境变量：\n[root@linux-node2 ~]#  unset OS_AUTH_URL OS_PASSWORD\n3、作为admin 、请求身份验证令牌\n$ openstack --os-auth-url http://linux-node2:35357/v3 \\\n  --os-project-domain-name default --os-user-domain-name default \\\n  --os-project-name admin --os-username admin token issue\nPassword:\n+------------+-----------------------------------------------------------------+\n| Field      | Value                                                           |\n+------------+-----------------------------------------------------------------+\n| expires    | 2016-02-12T20:14:07.056119Z                                     |\n| id         | gAAAAABWvi7_B8kKQD9wdXac8MoZiQldmjEO643d-e_j-XXq9AmIegIbA7UHGPv |\n|            | atnN21qtOMjCFWX7BReJEQnVOAj3nclRQgAYRsfSU_MrsuWb4EDtnjU7HEpoBb4 |\n|            | o6ozsA_NmFWEpLeKy0uNn_WeKbAhYygrsmQGA49dclHVnz-OMVLiyM9ws       |\n| project_id | 343d245e850143a096806dfaefa9afdc                                |\n| user_id    | ac3377633149401296f6c0d92d79dc16                                |\n+------------+-----------------------------------------------------------------+\n\n4、用demo用户、请求验证令牌\n$ openstack --os-auth-url http://linux-node2:5000/v3 \\\n  --os-project-domain-name default --os-user-domain-name default \\\n  --os-project-name demo --os-username demo token issue\nPassword:\n+------------+-----------------------------------------------------------------+\n| Field      | Value                                                           |\n+------------+-----------------------------------------------------------------+\n| expires    | 2016-02-12T20:15:39.014479Z                                     |\n| id         | gAAAAABWvi9bsh7vkiby5BpCCnc-JkbGhm9wH3fabS_cY7uabOubesi-Me6IGWW |\n|            | yQqNegDDZ5jw7grI26vvgy1J5nCVwZ_zFRqPiz_qhbq29mgbQLglbkq6FQvzBRQ |\n|            | JcOzq3uwhzNxszJWmzGC7rJE_H0A_a3UFhqv8M4zMRYSbS2YF0MyFmp_U       |\n| project_id | ed0b60bf607743088218b0a533d5943f                                |\n| user_id    | 58126687cbcc4888bfa9ab73a2256f27                                |\n``` \n### 3.3.4创建 OpenStack 客户端环境脚本\n```\nvi admin-openrc 加入如下：\nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_NAME=admin\nexport OS_USERNAME=admin\nexport OS_PASSWORD=ADMIN_PASS\nexport OS_AUTH_URL=http://linux-node2:35357/v3\nexport OS_IDENTITY_API_VERSION=3\nexport OS_IMAGE_API_VERSION=2\n#vi demo-openrc 加入：\n[root@linux-node2 ~]# cat demo-openrc \nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_NAME=demo\nexport OS_USERNAME=demo\nexport OS_PASSWORD=demo\nexport OS_AUTH_URL=http://linux-node2:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nexport OS_IMAGE_API_VERSION=2\n```\n## 镜像服务Glance（node2 主控制节点操作）\n### 4.1 Glance 介绍\n> Glance 主要由三个部分构成： glance-api、glance-registry 以 image stroe\n  \n> Glance-api：接受云系统镜像创建、删除、读取请求\n   \n> Glance-Registry： 云系统镜像注册服务\n \n![](/upload/images/20180209//1a8e98c4-eecd-453b-83d1-885ccbf7d00c.png)![](/upload/images/20180209//e63280d9-60a1-4eab-ab47-7ed373be010e.png)\n \n \n \n \n### 4.2 mysql 配置\n```\n$ mysql -u root –p\nMariaDB [(none)]> CREATE DATABASE glance;\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON glance.* TO \'glance\'@\'localhost\' \\\n  IDENTIFIED BY \'glance\';\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON glance.* TO \'glance\'@\'%\' \\\n  IDENTIFIED BY \'glance\';\n```\n### 4.3 Glance安装\n```\n#yum install openstack-glance\n```\n\n### 4.4修改主配置文件/etc/glance/glance-api.conf \n\n```\n[database]\n# ...\nconnection = mysql://glance:glance@192.168.57.145/glance\n在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问：\n[keystone_authtoken] \nauth_uri  =  http://linux-node2:5000\nauth_url  =  http://linux-node2:35357\nmemcached_servers  =  linux-node2:11211\nauth_type  =  password\nproject_domain_name  =  default\nuser_domain_name  =  default\nproject_name  =  service\nusername  =  glance\npassword  =  glance    #########这里的密码就是下面的新建 API  glance用户的密码\n＃... \n[paste_deploy]\nflavor  =  keystone\n[glance_store]\n# ...\nstores = file,http\ndefault_store = file\nfilesystem_store_datadir = /var/lib/glance/images/\n```\n### 4.5 修改主配置文件/etc/glance/glance-registry.conf\n```\n[database]\n# ...\nconnection = mysql://glance:glance@192.168.57.145/glance\n在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问：\n[keystone_authtoken] \nauth_uri  =  http://linux-node2:5000\nauth_url  =  http://linux-node2:35357\nmemcached_servers  =  linux-node2:11211\nauth_type  =  password\nproject_domain_name  =  default\nuser_domain_name  =  default\nproject_name  =  service\nusername  =  glance\npassword  =  glance  #########这里的密码就是下面的新建 API  glance用户的密码\n＃... \n[paste_deploy]\nflavor  =  keystone\n```\n### 4.6 设置数据库\n```\n# su -s /bin/sh -c \"glance-manage db_sync\" glance\n```\n### 4.7创建镜像服务的API服务\n```\n$ openstack user create --domain default --password-prompt glance\n$ openstack role add --project service --user glance admin\n$ openstack service create --name glance \\\n  --description \"OpenStack Image\" image\n$ openstack endpoint create --region RegionOne \\\n  image public http://linux-node2:9292\n$ openstack endpoint create --region RegionOne \\\n  image internal http://linux-node2:9292\n$ openstack endpoint create --region RegionOne \\\n  image admin http://linux-node2:9292\n```\n### 4.8 启动服务\n```\n# systemctl enable openstack-glance-api.service \\\n  openstack-glance-registry.service\n# systemctl start openstack-glance-api.service \\\n  openstack-glance-registry.service\n```\n### 4.9验证\n```\n运行环境变量：\n　　#. admin-openrc\n　　下载一个比较小的镜像：\n　　#wget http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img\n一、上传文件\n$ openstack image create \"cirros\" \\\n  --file cirros-0.3.5-x86_64-disk.img \\\n  --disk-format qcow2 --container-format bare \\\n  --public\n+------------------+------------------------------------------------------+\n| Field            | Value                                                |\n+------------------+------------------------------------------------------+\n| checksum         | 133eae9fb1c98f45894a4e60d8736619                     |\n| container_format | bare                                                 |\n| created_at       | 2015-03-26T16:52:10Z                                 |\n| disk_format      | qcow2                                                |\n| file             | /v2/images/cc5c6982-4910-471e-b864-1098015901b5/file |\n| id               | cc5c6982-4910-471e-b864-1098015901b5                 |\n| min_disk         | 0                                                    |\n| min_ram          | 0                                                    |\n| name             | cirros                                               |\n| owner            | ae7a98326b9c455588edd2656d723b9d                     |\n| protected        | False                                                |\n| schema           | /v2/schemas/image                                    |\n| size             | 13200896                                             |\n| status           | active                                               |\n| tags             |                                                      |\n| updated_at       | 2015-03-26T16:52:10Z                                 |\n| virtual_size     | None                                                 |\n| visibility       | public                                               |\n+------------------+------------------------------------------------------+\n二、查看\n$ openstack image list\n\n+--------------------------------------+--------+--------+\n| ID                                   | Name   | Status |\n+--------------------------------------+--------+--------+\n| 38047887-61a7-41ea-9b49-27987d5e8bb9 | cirros | active |\n+--------------------------------------+--------+--------+\n有输出证明glance配置正确\n\n```\n\n\n## 计算服务一 nova（node2控制节点操作）\n### Nova 作用\n> 1.API :负责接收和相应外部请求、支持 openstack API Ec2API\n\n> 2.Cert：负责身份认证\n\n> 3.Scheduler：用于云主机调度\n\n> 4.Conductor： 计算节点访问数据的中间件\n\n> 5.Consoleaut：用于控制台的授权验证\n\n> 6.NovncProxy： VNC代理\n\n### 5.1 新建数据库\n```\n$ mysql -u root –p\nMariaDB [(none)]> CREATE DATABASE nova_api;\nMariaDB [(none)]> CREATE DATABASE nova;\nMariaDB [(none)]> CREATE DATABASE nova_cell0;\n新建用户\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_api.* TO \'nova\'@\'localhost\' \\\n  IDENTIFIED BY \'nova_api\';\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_api.* TO \'nova\'@\'%\' \\\n  IDENTIFIED BY \'nova\';\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON nova.* TO \'nova\'@\'localhost\' \\\n  IDENTIFIED BY \'nova\';\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON nova.* TO \'nova\'@\'%\' \\\n  IDENTIFIED BY \'nova\';\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_cell0.* TO \'nova\'@\'localhost\' \\\n  IDENTIFIED BY \'nova\';\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_cell0.* TO \'nova\'@\'%\' \\\n  IDENTIFIED BY \'nova\';\n```\n### 5.2创建nova用户：\n```\n# . admin-openrc\n\nopenstack user create --domain default --password-prompt nova\nUser Password: nova\nRepeat User Password: nova\nThe passwords entered were not the same\nUser Password: nova\nRepeat User Password:  nova\n+---------------------+----------------------------------+\n| Field               | Value                            |\n+---------------------+----------------------------------+\n| domain_id           | default                          |\n| enabled             | True                             |\n| id                  | b9878680c70a4a678fd9a7a580706ccf |\n| name                | nova                             |\n| options             | {}                               |\n| password_expires_at | None                             |\n+---------------------+----------------------------------+\n[root@linux-node2 ~]#\n加入组\n[root@linux-node2 ~]#  openstack role add --project service --user nova admin\n```\n### 5.3创建nova服务实体\n```\n$ openstack service create --name nova \\\n  --description \"OpenStack Compute\" compute\n\n+-------------+----------------------------------+\n| Field       | Value                            |\n+-------------+----------------------------------+\n| description | OpenStack Compute                |\n| enabled     | True                             |\n| id          | 060d59eac51b4594815603d75a00aba2 |\n| name        | nova                             |\n| type        | compute                          |\n+-------------+----------------------------------+\n```\n### 5.4创建服务API\n```\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\\n>   compute public http://linux-node2:8774/v2.1\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | b6ebf975780344a597a65650eafdf67a |\n| interface    | public                           |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | d6a1591a15944bea85ab1e203af6732c |\n| service_name | nova                             |\n| service_type | compute                          |\n| url          | http://linux-node2:8774/v2.1     |\n+--------------+----------------------------------+\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\\n>   compute internal http://linux-node2:8774/v2.1\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | a2c1af804a31484cb3d82017b15fa47f |\n| interface    | internal                         |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | d6a1591a15944bea85ab1e203af6732c |\n| service_name | nova                             |\n| service_type | compute                          |\n| url          | http://linux-node2:8774/v2.1     |\n+--------------+----------------------------------+\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\\n>   compute admin http://linux-node2:8774/v2.1\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | 0304b6e92bf049d09e7d28bacfb1ed16 |\n| interface    | admin                            |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | d6a1591a15944bea85ab1e203af6732c |\n| service_name | nova                             |\n| service_type | compute                          |\n| url          | http://linux-node2:8774/v2.1     |\n+--------------+----------------------------------+\n``` \n### 5.5新建另一个用户\n```\n[root@linux-node2 ~]# openstack user create --domain default --password-prompt placement\nUser Password: nova \nRepeat User Password: nova\n+---------------------+----------------------------------+\n| Field               | Value                            |\n+---------------------+----------------------------------+\n| domain_id           | default                          |\n| enabled             | True                             |\n| id                  | 1654b6d199bf4fc582d1e70db802a31a |\n| name                | placement                        |\n| options             | {}                               |\n| password_expires_at | None                             |\n+---------------------+----------------------------------+\n[root@linux-node2 ~]#\n加入管理员组\n[root@linux-node2 ~]# openstack role add --project service --user placement admin\n```\n### 5.6在服务目录中创建Placement API条目：\n```\n$ openstack service create --name placement --description \"Placement API\" placement\n+-------------+----------------------------------+\n| Field       | Value                            |\n+-------------+----------------------------------+\n| description | Placement API                    |\n| enabled     | True                             |\n| id          | 2d1a27022e6e4185b86adac4444c495f |\n| name        | placement                        |\n| type        | placement                        |\n+-------------+----------------------------------+\n````\n### 5.7创建Placement API服务端点：\n```\n[root@linux-node2 ~]#  openstack endpoint create --region RegionOne placement public http://linux-node2:8778\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | 4b82fb4b30de4228982dea8c663f6d26 |\n| interface    | public                           |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | ba2a8b23524a4635af583cbfc80abd91 |\n| service_name | placement                        |\n| service_type | placement                        |\n| url          | http://linux-node2:8778          |\n+--------------+----------------------------------+\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne placement internal http://linux-node2:8778\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | bea3dbb6003d4cea802527de411f8cde |\n| interface    | internal                         |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | ba2a8b23524a4635af583cbfc80abd91 |\n| service_name | placement                        |\n| service_type | placement                        |\n| url          | http://linux-node2:8778          |\n+--------------+----------------------------------+\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne placement admin http://linux-node2:8778\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | b5d6d62d8f3f4e7c9ee2d6241b832bc5 |\n| interface    | admin                            |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | ba2a8b23524a4635af583cbfc80abd91 |\n| service_name | placement                        |\n| service_type | placement                        |\n| url          | http://linux-node2:8778          |\n+--------------+----------------------------------+\n```\n### 5.8安装和配置的部件\n```\n# yum install openstack-nova-api openstack-nova-conductor \\\n  openstack-nova-console openstack-nova-novncproxy \\\n  openstack-nova-scheduler openstack-nova-placement-api\n```\n### 5.9修改配置文件 /etc/nova/nova.conf\n```\n[DEFAULT]\n# ...\nenabled_apis = osapi_compute,metadata\n [api_database]\nconnection=mysql://nova:nova_api@192.168.57.145/nova_api\n[database]\nconnection=connection=mysql://nova:nova@192.168.57.145/nova\n[DEFAULT]\n# ...\ntransport_url = rabbit://openstack:openstack@192.168.57.145\n```\n### 5.10设置api和连接信息\n```\n[api]\n# ...\nauth_strategy = keystone\n[keystone_authtoken]\n# ...\nauth_uri = http://linux-node2:5000\nauth_url = http://linux-node2:35357\nmemcached_servers = linux-node2:11211 \nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = nova\npassword = nova\n\n设置IP\n[DEFAULT]\n# ...\nmy_ip = 192.168.57.145\n[DEFAULT]\n# ...\nuse_neutron = True\nfirewall_driver = nova.virt.firewall.NoopFirewallDriver\n[vnc]\nenabled = true\n# ...\nvncserver_listen = $my_ip\nvncserver_proxyclient_address = $my_ip\n```\n### 5.11设置glance\n```\n[glance]\n# ...\napi_servers = http://linux-node2:9292\n```\n### 5.12设置[oslo_concurrency]\n```\n[oslo_concurrency]\n# ...\nlock_path = /var/lib/nova/tmp\n```\n### 5.13设置[placement] \n```\n[placement]\n# ...\n os_region_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://linux-node2:35357/v3\nusername = placement\npassword = nova\n```\n### 5.14设置apache\n```\nvim  /etc/httpd/conf.d/00-nova-placement-api.conf:\n<Directory /usr/bin>\n   <IfVersion >= 2.4>\n      Require all granted\n   </IfVersion>\n   <IfVersion < 2.4>\n      Order allow,deny\n      Allow from all\n   </IfVersion>\n</Directory>\n```\n### 5.15重启apache \n```\n# systemctl restart httpd\n填充nova-api数据库：\n# su -s /bin/sh -c \"nova-manage api_db sync\" nova\n注册cell0数据库：\n# su -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova\n创建cell1单元格：\n# su -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova\n109e1d4b-536a-40d0-83c6-5f121b82b650\n填充nova数据库：\n# su -s /bin/sh -c \"nova-manage db sync\" nova\n```\n### 5.16验证\n```\n验证nova cell0和cell1是否正确注册：\n＃ nova-manage cell_v2 list_cells\n + ------- + ----------------------------------- --- + \n| 名称| UUID | \n+ ------- + -------------------------------------- + \n| cell1 | 109e1d4b-536a-40d0-83c6-5f121b82b650 | \n| cell0 | 00000000-0000-0000-0000-000000000000 | \n+ ------- + -------------------------------------- +\n设置开机自启动\n[root@linux-node2 nova]# systemctl enable openstack-nova-api.service\n[root@linux-node2 nova]# systemctl enable openstack-nova-consoleauth.service\n[root@linux-node2 nova]# systemctl enable openstack-nova-scheduler.service\n[root@linux-node2 nova]# systemctl enable openstack-nova-conductor.service \n[root@linux-node2 nova]# systemctl enable openstack-nova-novncproxy.service\n[root@linux-node2 nova]#\n启动服务\n[root@linux-node2 nova]# systemctl start openstack-nova-api.service\n[root@linux-node2 nova]# systemctl start openstack-nova-consoleauth.service\n[root@linux-node2 nova]# systemctl start openstack-nova-scheduler.service\n[root@linux-node2 nova]# systemctl start openstack-nova-conductor.service \n[root@linux-node2 nova]# systemctl start openstack-nova-novncproxy.service\n```\n## 计算服务二  nova（node1计算节点操作）\n### 6.1安装nova-compute\n> yum install openstack-nova-compute\n### 6.2配置主配置文件（/etc/nova/nova.conf）\n\n```\n[DEFAULT]\n# ...\nenabled_apis = osapi_compute,metadata\n[DEFAULT]\n# ...\ntransport_url = rabbit://openstack:openstack@192.168.57.145\n[api]\n# ...\nauth_strategy = keystone\n\n[keystone_authtoken]\n# ...\nauth_uri = http://linux-node2:5000\nauth_url = http://linux-node2:35357\nmemcached_servers = linux-node2:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = nova\npassword = nova\n[DEFAULT]\n# ...\nmy_ip = 192.168.57.142  ########这个是本机IP\n[DEFAULT]\n# ...\nuse_neutron = True\nfirewall_driver = nova.virt.firewall.NoopFirewallDriver\n[vnc]\n# ...\nenabled = True\nvncserver_listen = 0.0.0.0\nvncserver_proxyclient_address = $my_ip\nnovncproxy_base_url = http://linux-node2:6080/vnc_auto.html\n[glance]\n# ...\napi_servers = http://linux-node2:9292\n[oslo_concurrency]\n# ...\nlock_path = /var/lib/nova/tmp\n[placement]\n# ...\nos_region_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://linux-node2:35357/v3\nusername = placement\npassword = nova\n```\n### 检查是否需要硬件加速\n```\n$ egrep -c \'(vmx|svm)\' /proc/cpuinfo\n如果为0则需要修改#vi /etc/nova/nova.conf\n[libvirt]\n# ...\nvirt_type = qemu\n```\n### 6.4启动服务\n```\n# systemctl enable libvirtd.service openstack-nova-compute.service\n# systemctl start libvirtd.service openstack-nova-compute.service\n```\n### 6.5验证(node2 主节点操作)\n```\n将计算节点添加到单元数据库¶（在主节点操作）\nsu -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\n\nFound 2 cell mappings.\nSkipping cell0 since it does not contain hosts.\nGetting compute nodes from cell \'cell1\': ad5a5985-a719-4567-98d8-8d148aaae4bc\nFound 1 computes in cell: ad5a5985-a719-4567-98d8-8d148aaae4bc\nChecking host mapping for compute host \'linux-node1\': fe58ddc1-1d65-4f87-9456-bc040dc106b3\nCreating host mapping for compute host \'linux-node1\': fe58ddc1-1d65-4f87-9456-bc040dc106b3\n查看comput节点\n$ openstack compute service list\n\n+----+--------------------+------------+----------+---------+-------+----------------------------+\n| Id | Binary             | Host       | Zone     | Status  | State | Updated At                 |\n+----+--------------------+------------+----------+---------+-------+----------------------------+\n|  1 | nova-consoleauth   | controller | internal | enabled | up    | 2016-02-09T23:11:15.000000 |\n|  2 | nova-scheduler     | controller | internal | enabled | up    | 2016-02-09T23:11:15.000000 |\n|  3 | nova-conductor     | controller | internal | enabled | up    | 2016-02-09T23:11:16.000000 |\n|  4 | nova-compute       | compute1   | nova     | enabled | up    | 2016-02-09T23:11:20.000000 |\n+----+--------------------+------------+----------+---------+-------+----------------------------+\n查看catalog\n$ openstack catalog list\n+-----------+-----------+-----------------------------------------+\n| Name      | Type      | Endpoints                               |\n+-----------+-----------+-----------------------------------------+\n| keystone  | identity  | RegionOne                               |\n|           |           |   public: http://linux-node2:5000/v3/    |\n|           |           | RegionOne                               |\n|           |           |   internal: http://linux-node2:5000/v3/  |\n|           |           | RegionOne                               |\n|           |           |   admin: http://linux-node2:35357/v3/    |\n|           |           |                                         |\n| glance    | image     | RegionOne                               |\n|           |           |   admin: http://linux-node2:9292         |\n|           |           | RegionOne                               |\n|           |           |   public: http://linux-node2:9292        |\n|           |           | RegionOne                               |\n|           |           |   internal: http://linux-node2:9292      |\n|           |           |                                         |\n| nova      | compute   | RegionOne                               |\n|           |           |   admin: h http://linux-node2:8774/v2.1    |\n|           |           | RegionOne                               |\n|           |           |   internal: http://linux-node2:8774/v2.1 |\n|           |           | RegionOne                               |\n|           |           |   public: http://linux-node2:8774/v2.1   |\n|           |           |                                         |\n| placement | placement | RegionOne                               |\n|           |           |   public: http://linux-node2:8778        |\n|           |           | RegionOne                               |\n|           |           |   admin: http://linux-node2:8778         |\n|           |           | RegionOne                               |\n|           |           |   internal: http://linux-node2:8778      |\n|           |           |                                         |\n+-----------+-----------+-----------------------------------------+\n\n列出Image服务中的图像以验证与Image服务的连接性：\n$ openstack image list\n\n+--------------------------------------+-------------+-------------+\n| ID                                   | Name        | Status      |\n+--------------------------------------+-------------+-------------+\n| 9a76d9f9-9620-4f2e-8c69-6c5691fae163 | cirros      | active      |\n+--------------------------------------+-------------+-------------+\n检查单元格和放置API正在成功工作：\n# nova-status upgrade check\n\n+---------------------------+\n| Upgrade Check Results     |\n+---------------------------+\n| Check: Cells v2           |\n| Result: Success           |\n| Details: None             |\n+---------------------------+\n| Check: Placement API      |\n| Result: Success           |\n| Details: None             |\n+---------------------------+\n| Check: Resource Providers |\n| Result: Success           |\n| Details: None             |\n+---------------------------+\n```\n## 网络节点一（node2 主控制节点操作）\n### 7.1 设置mysql\n```\n$ mysql -u root –p\nMariaDB [（none）] CREATE DATABASE neutron;\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.* TO \'neutron\'@\'localhost\' \\\n  IDENTIFIED BY \'neutron\';\nMariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.* TO \'neutron\'@\'%\' \\\n  IDENTIFIED BY \'neutron\';\n```\n### 7.2创建服务凭据\n```\n在admin的环境下\n$ . admin-openrc\n$ openstack user create --domain default --password-prompt neutron\n\nUser Password: neutron  #密码\nRepeat User Password: neutron  #密码\n+---------------------+----------------------------------+\n| Field               | Value                            |\n+---------------------+----------------------------------+\n| domain_id           | default                          |\n| enabled             | True                             |\n| id                  | fdb0f541e28141719b6a43c8944bf1fb |\n| name                | neutron                          |\n| options             | {}                               |\n| password_expires_at | None                             |\n+---------------------+----------------------------------+\n\n加入到admin组\n$ openstack role add --project service --user neutron admin\n创建neutron 服务实体\n$ openstack service create --name neutron \\\n  --description \"OpenStack Networking\" network\n创建neutron API\n$ openstack endpoint create --region RegionOne \\\n  network public http://linux-node2:9696\n$ openstack endpoint create --region RegionOne \\\n  network internal http://linux-node2:9696\n$ openstack endpoint create --region RegionOne \\\n  network admin http://linux-node2:9696\n```\n### 7.3配置网络选项（这里我选用的是网络1 的配置）\n```\n您可以使用选项1和2所代表的两种体系结构之一来部署网络服务。\n选项1部署了最简单的架构，只支持将实例连接到提供者（外部）网络。没有自助服务（专用）网络，路由器或浮动IP地址。只有admin或其他特权用户才能管理提供商网络。\n选项2增加了选项1，其中第三层服务支持将实例附加到自助服务网络。这个demo或其他非特权用户可以管理自助服务网络，包括在自助服务和提供商网络之间提供连接的路由器。此外，浮动IP地址还提供与使用来自外部网络（如Internet）的自助服务网络的实例的连接。\n自助服务网络通常使用覆盖网络。覆盖网络协议（如VXLAN）包含额外的标头，这些标头会增加开销并减少有效负载或用户数据的可用空间。在不了解虚拟网络基础架构的情况下，实例将尝试使用1500字节的默认以太网最大传输单元（MTU）发送数据包。网络服务通过DHCP自动为实例提供正确的MTU值。但是，某些云图像不使用DHCP或忽略DHCP MTU选项并需要使用元数据或脚本进行配置。\n```\n### 7.4 安装网络openstack-neutron\n```\n# yum install openstack-neutron openstack-neutron-ml2 \\\n  openstack-neutron-linuxbridge ebtables\n```\n### 7.5 编辑/etc/neutron/neutron.conf\n```\n[database]\n# ...\nconnection = mysql://neutron:neutron@linux-node2/neutron\n[DEFAULT]\n# ...\ncore_plugin = ml2\nservice_plugins =\ntransport_url = rabbit://openstack:openstack@linux-node2\nauth_strategy = keystone\nnotify_nova_on_port_status_changes = true\nnotify_nova_on_port_data_changes = true\n[keystone_authtoken]\n# ...\nauth_uri = http://linux-node2:5000\nauth_url = http://linux-node2:35357\nmemcached_servers = linux-node2:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = neutron  ######这个密码是上面设置的密码\n[nova]\n# ...\nauth_url = http://controller:35357\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = nova\npassword = nova  ####注意这个是nova设置的密码\n[oslo_concurrency]\n# ...\nlock_path = /var/lib/neutron/tmp\n```\n### 7.6配置模块化层2（ML2）插件（/etc/neutron/plugins/ml2/ml2_conf.ini）\n\n```\n编辑配置文件设置如下：\n[ml2]\ntype_drivers = flat,vlan\ntenant_network_types =\nmechanism_drivers = linuxbridge\n[ml2_type_flat]\nflat_networks = provider\n[securitygroup]\nenable_ipset = true\n```\n### 7.7配置Linux网桥代理（/etc/neutron/plugins/ml2/linuxbridge_agent.ini）\n```\n编辑配置文件设置如下：\n[linux_bridge]\nphysical_interface_mappings = provider:eth1  ####这个是为底层实现网络的网络接口（我这里用了eth1）\n[vxlan]\nenable_vxlan = false\n[securitygroup]\n# ...\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\n```\n\n### 7.8配置DHCP代理（/etc/neutron/dhcp_agent.ini）\n```\n[DEFAULT] \n＃... \ninterface_driver  =  linuxbridge \ndhcp_driver  =  neutron.agent.linux.dhcp.Dnsmasq \nenable_isolated_metadata  =  true\n```\n### 7.9配置计算服务以使用网络服务（/etc/nova/nova.conf）\n```\n在该[neutron]部分中，配置访问参数，启用元数据代理并配置密钥：\n[neutron] \n＃... \nurl  =  http：//linux-node2：9696 \nauth_url  =  http：//linux-node2：35357 \nauth_type  =  password \nproject_domain_name  =  default \nuser_domain_name  =  default \nregion_name  =  RegionOne \nproject_name  =  service \nusername  =  neutron \npassword  = neutron      ###在身份识别服务中为用户选择的密码。\nservice_metadata_proxy  =  true \nmetadata_proxy_shared_secret  =  neutron     #  #为元数据代理选择的密码。\n创建扩展链接\n# ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini\n```\n### 7.10同步数据库\n```\n# su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\\n  --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron\n```\n### 7.11 启动服务\n```\n重新启动计算API服务：\n# systemctl restart openstack-nova-api.service\n启动网络服务并将其配置为在系统引导时启动。\n# systemctl enable neutron-server.service \\\n  neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\\n  neutron-metadata-agent.service\n# systemctl start neutron-server.service \\\n  neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\\n  neutron-metadata-agent.service\n``` \n## 网络节点二、（node1 计算节点操作）\n### 8.1 安装openstack-neutron\n> yum install openstack-neutron-linuxbridge ebtables ipset\n### 8.2配置通用组件（/etc/neutron/neutron.conf）\n\n```\n修改如下配置文件：\n[DEFAULT]\ntransport_url = rabbit://openstack:openstack@linux-node2\nauth_strategy = keystone\n[keystone_authtoken]\n# ...\nauth_uri = http://linux-node2:5000\nauth_url = http://linux-node2:35357\nmemcached_servers =linux-node2:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = neutron\n[oslo_concurrency]\n# ...\nlock_path = /var/lib/neutron/tmp\n```\n### 8.3配置计算服务以使用网络服务（/etc/nova/nova.conf）\n```\n在该[neutron]部分中，配置访问参数：\n[neutron] \n＃... \nurl  =  http：//linux-node2：9696 \nauth_url  =  http：//linux-node2：35357 \nauth_type  =  password \nproject_domain_name  =  default \nuser_domain_name  =  default \nregion_name  =  RegionOne \nproject_name  =  service \nusername  =  neutron \npassword  =  neutron\n```\n### 8.4配置Linux网桥代理（/etc/neutron/plugins/ml2/linuxbridge_agent.ini）\n```\n编辑文件修改如下配置：\n[linux_bridge]\nphysical_interface_mappings = provider:eht1 #这里是为底层服务的网卡名称\n[vxlan]\nenable_vxlan = false\n[securitygroup]\n# ...\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\n```\n### 8.5 启动服务\n````\n重启一下openstack-nova-compute\n# systemctl restart openstack-nova-compute.service\n启动Linux桥代理并将其配置为在系统引导时启动：\n# systemctl enable neutron-linuxbridge-agent.service\n# systemctl start neutron-linuxbridge-agent.service\n```\n### 8.6 验证操作\n```\n1.运行管理员环境\n$ . admin-openrc\n2.查看网络\n$ openstack extension list --network\n\n+---------------------------+---------------------------+----------------------------+\n| Name                      | Alias                     | Description                |\n+---------------------------+---------------------------+----------------------------+\n| Default Subnetpools       | default-subnetpools       | Provides ability to mark   |\n|                           |                           | and use a subnetpool as    |\n|                           |                           | the default                |\n| Availability Zone         | availability_zone         | The availability zone      |\n|                           |                           | extension.                 |\n| Network Availability Zone | network_availability_zone | Availability zone support  |\n|                           |                           | for network.               |\n| Port Binding              | binding                   | Expose port bindings of a  |\n|                           |                           | virtual port to external   |\n|                           |                           | application                |\n| agent                     | agent                     | The agent management       |\n|                           |                           | extension.                 |\n| Subnet Allocation         | subnet_allocation         | Enables allocation of      |\n|                           |                           | subnets from a subnet pool |\n| DHCP Agent Scheduler      | dhcp_agent_scheduler      | Schedule networks among    |\n|                           |                           | dhcp agents                |\n| Tag support               | tag                       | Enables to set tag on      |\n|                           |                           | resources.                 |\n| Neutron external network  | external-net              | Adds external network      |\n|                           |                           | attribute to network       |\n|                           |                           | resource.                  |\n| Neutron Service Flavors   | flavors                   | Flavor specification for   |\n|                           |                           | Neutron advanced services  |\n| Network MTU               | net-mtu                   | Provides MTU attribute for |\n|                           |                           | a network resource.        |\n| Network IP Availability   | network-ip-availability   | Provides IP availability   |\n|                           |                           | data for each network and  |\n|                           |                           | subnet.                    |\n| Quota management support  | quotas                    | Expose functions for       |\n|                           |                           | quotas management per      |\n|                           |                           | tenant                     |\n| Provider Network          | provider                  | Expose mapping of virtual  |\n|                           |                           | networks to physical       |\n|                           |                           | networks                   |\n| Multi Provider Network    | multi-provider            | Expose mapping of virtual  |\n|                           |                           | networks to multiple       |\n|                           |                           | physical networks          |\n| Address scope             | address-scope             | Address scopes extension.  |\n| Subnet service types      | subnet-service-types      | Provides ability to set    |\n|                           |                           | the subnet service_types   |\n|                           |                           | field                      |\n| Resource timestamps       | standard-attr-timestamp   | Adds created_at and        |\n|                           |                           | updated_at fields to all   |\n|                           |                           | Neutron resources that     |\n|                           |                           | have Neutron standard      |\n|                           |                           | attributes.                |\n| Neutron Service Type      | service-type              | API for retrieving service |\n| Management                |                           | providers for Neutron      |\n|                           |                           | advanced services          |\n| Tag support for           | tag-ext                   | Extends tag support to     |\n| resources: subnet,        |                           | more L2 and L3 resources.  |\n| subnetpool, port, router  |                           |                            |\n| Neutron Extra DHCP opts   | extra_dhcp_opt            | Extra options              |\n|                           |                           | configuration for DHCP.    |\n|                           |                           | For example PXE boot       |\n|                           |                           | options to DHCP clients    |\n|                           |                           | can be specified (e.g.     |\n|                           |                           | tftp-server, server-ip-    |\n|                           |                           | address, bootfile-name)    |\n| Resource revision numbers | standard-attr-revisions   | This extension will        |\n|                           |                           | display the revision       |\n|                           |                           | number of neutron          |\n|                           |                           | resources.                 |\n| Pagination support        | pagination                | Extension that indicates   |\n|                           |                           | that pagination is         |\n|                           |                           | enabled.                   |\n| Sorting support           | sorting                   | Extension that indicates   |\n|                           |                           | that sorting is enabled.   |\n| security-group            | security-group            | The security groups        |\n|                           |                           | extension.                 |\n| RBAC Policies             | rbac-policies             | Allows creation and        |\n|                           |                           | modification of policies   |\n|                           |                           | that control tenant access |\n|                           |                           | to resources.              |\n| standard-attr-description | standard-attr-description | Extension to add           |\n|                           |                           | descriptions to standard   |\n|                           |                           | attributes                 |\n| Port Security             | port-security             | Provides port security     |\n| Allowed Address Pairs     | allowed-address-pairs     | Provides allowed address   |\n|                           |                           | pairs                      |\n| project_id field enabled  | project-id                | Extension that indicates   |\n|                           |                           | that project_id field is   |\n|                           |                           | enabled.                   |\n+---------------------------+---------------------------+----------------------------+\n2.查看网络\n3.$ openstack network agent list\n4.\n5.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+\n6.| ID                                   | Agent Type         | Host       | Availability Zone | Alive | State | Binary                    |\n7.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+\n8.| 0400c2f6-4d3b-44bc-89fa-99093432f3bf | Metadata agent     | controller | None              | True  | UP    | neutron-metadata-agent    |\n9.| 83cf853d-a2f2-450a-99d7-e9c6fc08f4c3 | DHCP agent         | controller | nova              | True  | UP    | neutron-dhcp-agent        |\n10.| ec302e51-6101-43cf-9f19-88a78613cbee | Linux bridge agent | compute    | None              | True  | UP    | neutron-linuxbridge-agent |\n11.| fcb9bc6e-22b1-43bc-9054-272dd517d025 | Linux bridge agent | controller | None              | True  | UP    | neutron-linuxbridge-agent |\n12.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+\n````\n## Dashboard（node2控制节点操作）\n### 9.1 安装\n> yum install openstack-dashboard\n\n### 9.2配置主配置文件（/etc/openstack-dashboard/local_settings）\n```\nOPENSTACK_HOST = \"linux-node2\"\nALLOWED_HOSTS = [\'*\']\nSESSION_ENGINE = \'django.contrib.sessions.backends.cache\'\n\nCACHES = {\n    \'default\': {\n         \'BACKEND\': \'django.core.cache.backends.memcached.MemcachedCache\',\n         \'LOCATION\': \'controller:11211\',\n    }\n}\nOPENSTACK_KEYSTONE_URL = \"http://%s:5000/v3\" % OPENSTACK_HOST\nOPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True\n\n\n\nOPENSTACK_API_VERSIONS = {\n    \"identity\": 3,\n    \"image\": 2,\n    \"volume\": 2,\n}\nOPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \"Default\"\nOPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\"\nOPENSTACK_NEUTRON_NETWORK = {\n    ...\n    \'enable_router\': False,\n    \'enable_quotas\': False,\n    \'enable_distributed_router\': False,\n    \'enable_ha_router\': False,\n    \'enable_lb\': False,\n    \'enable_firewall\': False,\n    \'enable_vpn\': False,\n    \'enable_fip_topology_check\': False,\n}\nTIME_ZONE = \"UTC\"\n```\n### 9.4重启服务\n> systemctl restart httpd.service memcached.service\n### 9.5 访问openstack \nhttp://192.168.57.145/dashboard/auth/login/\n\n![](/upload/images/20180209//112741a6-116b-4979-af0b-e45d11ea8f68.png)\n\n![](/upload/images/20180209//e14940a8-073f-401a-a5f3-b02ee0bdbc18.png)\n', '2', '<h1 id=\"h1-centos7-3-openstack-ocata-\"><a name=\"Centos7.3 部署openstack  ocata版本\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Centos7.3 部署openstack  ocata版本</h1><h2 id=\"h2-openstack-\"><a name=\"openstack 介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>openstack 介绍</h2><blockquote>\n<p>OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。<br>OpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。</p>\n<p>OpenStack是一个旨在为公共及私有云的建设与管理提供软件的开源项目。它的社区拥有超过130家企业及1350位开发者，这些机构与个人都将OpenStack作为基础设施即服务（IaaS）资源的通用前端。OpenStack项目的首要任务是简化云的部署过程并为其带来良好的可扩展性。本文希望通过提供必要的指导信息，帮助大家利用OpenStack前端来设置及管理自己的公共云或私有云。</p>\n<p>OpenStack云计算平台，帮助服务商和企业内部实现类似于 Amazon EC2 和 S3 的云基础架构服务(Infrastructure as a Service, IaaS)。OpenStack 包含两个主要模块：Nova 和 Swift，前者是 NASA 开发的虚拟服务器部署和业务计算模块；后者是 Rackspace开发的分布式云存储模块，两者可以一起用，也可以分开单独用。OpenStack除了有 Rackspace 和 NASA 的大力支持外，还有包括 Dell、Citrix、 Cisco、 Canonical等重量级公司的贡献和支持，发展速度非常快，有取代另一个业界领先开源云平台 Eucalyptus 的态势。</p>\n<p>Openstack 组件分类</p>\n</blockquote>\n<p><img src=\"/upload/images/20180209//20803372-1d70-4898-af21-1ee2aee20c1d.png\" alt=\"\"></p>\n<blockquote>\n<p><a href=\"https://docs.openstack.org/ocata/install-guide-rdo/glance-install.html\">https://docs.openstack.org/ocata/install-guide-rdo/glance-install.html</a><br>官方文档地址</p>\n</blockquote>\n<h2 id=\"h2-u57FAu7840u73AFu5883\"><a name=\"基础环境\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>基础环境</h2><blockquote>\n<p>系统版本： Centos7.3  两块网卡(eth0,eth1)</p>\n<p>机器的配置： 4G 50G硬盘 4个CPU</p>\n<p>机器名： linux-node1（计算节点）</p>\n<p>机器名： linux-node2（控制节点）</p>\n<p>Node2 IP：eth0 192.168.57.145， eth1:192.168.57.146</p>\n<p>Node1IP:  eth0: 192.168.57.142  eth1:192.168.57.143</p>\n<p>主控制节点主要安装如下：（keystone、Glance、nova、networking、Dashboard）</p>\n<p>计算节点主要安装如下：（nova、networking）</p>\n</blockquote>\n<h3 id=\"h3-2-1-node1-node2-\"><a name=\"2.1 时间同步（node1 +node2 操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1 时间同步（node1 +node2 操作）</h3><blockquote>\n<p><a href=\"https://docs.openstack.org/ocata/install-guide-rdo/glance-install.html\">https://docs.openstack.org/ocata/install-guide-rdo/glance-install.html</a></p>\n<p>node1 </p>\n</blockquote>\n<pre><code># yum install chrony\nvim /etc/chrony.conf\n设置\nallow 192.168.57.0/24\n####启动\n[root@linux-node2 ~]# systemctl enable chronyd.service\n[root@linux-node2 ~]#systemctl start chronyd.service\n########node1 的时间先同步一下标准时间\n[root@linux-node2 ~]# ntpdate pool.ntp.org\n# chronyc sources\n\nnode2 \n修改主配置文件\nvim /etc/chrony.conf\n把所有行去掉\n添加一行\nServer 192.168.57.145 iburst\n[root@linux-node2 ~]#systemctl start chronyd.service\n# chronyc sources\n</code></pre><h3 id=\"h3-2-2-mysql-node2-\"><a name=\"2.2 安装mysql（node2主控制节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2 安装mysql（node2主控制节点操作）</h3><blockquote>\n<p>配置一下mysql</p>\n</blockquote>\n<pre><code>添加文件/etc/my.cnf.d/openstack.cnf 内容如下：\n [mysqld]\nbind-address = 192.168.57.145\ndefault-storage-engine = innodb\ninnodb_file_per_table\ncollation-server =utf8_general_ci\ninit-connect = &#39;SET NAMES utf8&#39;\ncharacter-set-server = utf8\n重启一下mysql\n[root@linux-node2 ~]# systemctl enable mariadb.service\n[root@linux-node2 ~]# systemctl start mariadb.service\n设置root密码\n[root@linux-node2 ~]# mysql_secure_installation\n创建数据库\n[root@linux-node2 ~]# mysql -uroot -p123456 -e &quot;Create database keystone;&quot;\n[root@linux-node2 ~]# mysql -uroot -p123456 -e &quot;grant all privileges on keystone.* to &#39;keystone&#39;@&#39;%&#39; identified by &#39;keystone&#39;&quot;\n[root@linux-node2 ~]# mysql -uroot -p123456 -e &quot;grant all privileges on keystone.* to &#39;keystone&#39;@&#39;localhost&#39; identified by &#39;keystone&#39;&quot;\n</code></pre><h3 id=\"h3-2-3-node2-\"><a name=\"2.3 安装消息队列（node2控制节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3 安装消息队列（node2控制节点操作）</h3><pre><code>#yum install rabbitmq-server\n启动\n# systemctl enable rabbitmq-server.service\n# systemctl start rabbitmq-server.service\n新建用户\n# rabbitmqctl add_user openstack openstack\n对用户授权\nrabbitmqctl set_permissions openstack &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;\n查看插件\n[root@linux-node2 ~]# rabbitmq-plugins list\n[ ] amqp_client                       3.3.5\n[ ] cowboy                            0.5.0-rmq3.3.5-git4b93c2d\n[ ] eldap                             3.3.5-gite309de4\n[ ] mochiweb                          2.7.0-rmq3.3.5-git680dba8\n[ ] rabbitmq_amqp1_0                  3.3.5\n[ ] rabbitmq_auth_backend_ldap        3.3.5\n[ ] rabbitmq_auth_mechanism_ssl       3.3.5\n[ ] rabbitmq_consistent_hash_exchange 3.3.5\n[ ] rabbitmq_federation               3.3.5\n[ ] rabbitmq_federation_management    3.3.5\n[ ] rabbitmq_management               3.3.5\n[ ] rabbitmq_management_agent         3.3.5\n[ ] rabbitmq_management_visualiser    3.3.5\n[ ] rabbitmq_mqtt                     3.3.5\n[ ] rabbitmq_shovel                   3.3.5\n[ ] rabbitmq_shovel_management        3.3.5\n[ ] rabbitmq_stomp                    3.3.5\n[ ] rabbitmq_test                     3.3.5\n[ ] rabbitmq_tracing                  3.3.5\n[ ] rabbitmq_web_dispatch             3.3.5\n[ ] rabbitmq_web_stomp                3.3.5\n[ ] rabbitmq_web_stomp_examples       3.3.5\n[ ] sockjs                            0.3.4-rmq3.3.5-git3132eb9\n[ ] webmachine                        1.10.3-rmq3.3.5-gite9359c7\n启用web插件\n [root@linux-node2 ~]# rabbitmq-plugins enable rabbitmq_management\n重启一下\n[root@linux-node2 ~]# systemctl restart rabbitmq-server.service\n检查是否启动成功\n[root@linux-node2 ~]# netstat -nltp |grep 5672\ntcp        0      0 0.0.0.0:15672           0.0.0.0:*               LISTEN      16686/beam.smp      \ntcp        0      0 0.0.0.0:25672           0.0.0.0:*               LISTEN      16686/beam.smp      \ntcp6       0      0 :::5672                 :::*                    LISTEN      16686/beam.smp      \n[root@linux-node2 ~]#\nWeb访问\nhttp://192.168.57.138:15672/#/\n用户名密码为guest\n</code></pre><p><img src=\"/upload/images/20180209//95ac3aeb-7f17-41a1-bd77-eb6a932d32a6.png\" alt=\"\"></p>\n<h2 id=\"h2--openstack\"><a name=\"搭建openstack\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>搭建openstack</h2><h3 id=\"h3-3-1-keystone-\"><a name=\"3.1 安装keystone 组件介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.1 安装keystone 组件介绍</h3><p><img src=\"/upload/images/20180209//80692e30-faa2-4587-93f2-4eab1e5eeaba.png\" alt=\"\"></p>\n<blockquote>\n<p>Keystone功能：</p>\n<p>1.用户与认证: 用户权限与用户行为跟踪</p>\n<p>2.服务目录：提供一个服务目录、包括所有服务项与相关API的端点</p>\n<p>Keystone名词：</p>\n<p>User： 用户</p>\n<p>Tenant： 租户/项目</p>\n<p>Token： 令牌</p>\n<p>Role： 角色</p>\n<p>Service： 服务</p>\n<p>Endpoint： 端点</p>\n</blockquote>\n<h2 id=\"h2-3-2-keystone-node2-\"><a name=\"3.2 安装keystone 组件（node2 主控制节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2 安装keystone 组件（node2 主控制节点操作）</h2><blockquote>\n<p>安装openstack最新的源：\n　　　　</p>\n<p>yum install centos-release-openstack-ocata \n　　　　</p>\n<p>yum install <a href=\"https://rdoproject.org/repos/rdo-release.rpm\">https://rdoproject.org/repos/rdo-release.rpm</a> \n　　　　</p>\n<p>yum upgrade                                               (在主机上升级包）</p>\n<p>yum install python-openstackclient            （安装opentack必须的插件）</p>\n<p>yum install openstack-selinux                    （可选则安装这个插件，我直接关闭了selinux，因为不熟，对后续不会有影响）</p>\n<p> [root<a href=\"https://github.com/linux\" title=\"&#64;linux\" class=\"at-link\">@linux</a>-node1 home]# yum install openstack-keystone httpd mod_wsgi </p>\n</blockquote>\n<h3 id=\"h3-3-2-1-\"><a name=\"3.2.1修改配置文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2.1修改配置文件</h3><pre><code>vim /etc/keystone/keystone.conf\n[database]\nconnection = mysql://keystone:keystone@192.168.57.141/keystone \n[token]\nprovider = fernet\n</code></pre><h3 id=\"h3-3-2-2-\"><a name=\"3.2.2同步数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2.2同步数据库</h3><pre><code>su -s /bin/sh -c &quot;keystone-manage db_sync&quot; keystone\n###为什么需要su 一下呢？因为在写日志的时候文件是放在/var/log/keystone \n这个下面如果是root用户执行的话。那么写日志的时候就会写不进去。\n验证一下是否成功。进入数据库查看有没有表的建立。\n\n MariaDB [keystone]&gt; show tables;\n\n+------------------------+\n| Tables_in_keystone     |\n初始化\n# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone\n# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone\n\n\n\n引导身份信息\nkeystone-manage bootstrap --bootstrap-password ADMIN_PASS \\\n  --bootstrap-admin-url http://linux-node2:35357/v3/ \\\n  --bootstrap-internal-url http://linux-node2:5000/v3/ \\\n  --bootstrap-public-url http://controller:5000/v3/ \\\n  --bootstrap-region-id RegionOne\n</code></pre><h3 id=\"h3-3-2-3-memcache-etc-sysconfig-memcached-\"><a name=\"3.2.3配置memcache的配置 （/etc/sysconfig/memcached）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2.3配置memcache的配置 （/etc/sysconfig/memcached）</h3><pre><code>vim /etc/sysconfig/memcached\nOPTIONS=&quot;-l 127.0.0.1,::1,192.168.57.141&quot;\n</code></pre><h3 id=\"h3-3-2-4-memcache\"><a name=\"3.2.4启动memcache\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2.4启动memcache</h3><pre><code>[root@linux-node2 ~]# systemctl start memcached.service\n [root@linux-node2 ~]# netstat -nltp|grep 121\ntcp        0      0 0.0.0.0:11211           0.0.0.0:*               LISTEN      20054/memcached     \ntcp6       0      0 :::11211                :::*                    LISTEN      20054/memcached\n</code></pre><h3 id=\"h3-3-2-5-apache\"><a name=\"3.2.5设置apache\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2.5设置apache</h3><pre><code>ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/\n3.2.6修改主apache的主配置文件\nvim /etc/httpd/conf/httpd.conf\n配置一下Servername\nServerName 192.168.57.138:80\n</code></pre><h3 id=\"h3-3-2-7-apache\"><a name=\"3.2.7启动apache\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2.7启动apache</h3><pre><code>systemctl enable httpd.service\nsystemctl start httpd.service\n</code></pre><h3 id=\"h3-3-2-8-\"><a name=\"3.2.8检查一下是否启动成功了\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2.8检查一下是否启动成功了</h3><pre><code>[root@linux-node2 conf.d]# netstat -nltp|grep httpd\ntcp6       0      0 :::80                   :::*                    LISTEN      20253/httpd         \ntcp6       0      0 :::35357                :::*                    LISTEN      20253/httpd         \ntcp6       0      0 :::5000                 :::*                    LISTEN      20253/httpd         \n[root@linux-node2 conf.d]#\n</code></pre><h2 id=\"h2-3-3-keystone-\"><a name=\"3.3   keystone 用户权限\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3   keystone 用户权限</h2><h3 id=\"h3-3-3-1-\"><a name=\"3.3.1 设置环境变量\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3.1 设置环境变量</h3><pre><code>$ export OS_USERNAME=admin\n$ export OS_PASSWORD=ADMIN_PASS\n$ export OS_PROJECT_NAME=admin\n$ export OS_USER_DOMAIN_NAME=Default\n$ export OS_PROJECT_DOMAIN_NAME=Default\n$ export OS_AUTH_URL=http://linux-node2:35357/v3\n$ export OS_IDENTITY_API_VERSION=3\n</code></pre><h3 id=\"h3-3-3-2-\"><a name=\"3.3.2创建域、项目、用户和角色\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3.2创建域、项目、用户和角色</h3><pre><code>创建服务\n[root@linux-node2 ~]# openstack project create --domain default --description &quot;Service Project&quot; service\n创建demo项目\n [root@linux-node2 ~]# openstack project create --domain default \\\n&gt; --description &quot;Demo Project&quot; demo\n设置demo密码\n[root@linux-node2 ~]# openstack user create --domain default \\\n&gt; --password-prompt demo\n创建用户组\n [root@linux-node2 ~]# openstack role create user\n加入用户组\n [root@linux-node2 ~]# openstack role add --project demo --user demo user\n</code></pre><h3 id=\"h3-3-3-3-\"><a name=\"3.3.3验证操作\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3.3验证操作</h3><pre><code>1.出于安全原因，请禁用临时身份验证令牌机制：\n编辑/etc/keystone/keystone-paste.ini 文件并删除admin_token_auth从 [pipeline:public_api]，[pipeline:admin_api]和[pipeline:api_v3]段。\n\n2、取消设置临时 变量OS_AUTH_URL和OS_PASSWORD环境变量：\n[root@linux-node2 ~]#  unset OS_AUTH_URL OS_PASSWORD\n3、作为admin 、请求身份验证令牌\n$ openstack --os-auth-url http://linux-node2:35357/v3 \\\n  --os-project-domain-name default --os-user-domain-name default \\\n  --os-project-name admin --os-username admin token issue\nPassword:\n+------------+-----------------------------------------------------------------+\n| Field      | Value                                                           |\n+------------+-----------------------------------------------------------------+\n| expires    | 2016-02-12T20:14:07.056119Z                                     |\n| id         | gAAAAABWvi7_B8kKQD9wdXac8MoZiQldmjEO643d-e_j-XXq9AmIegIbA7UHGPv |\n|            | atnN21qtOMjCFWX7BReJEQnVOAj3nclRQgAYRsfSU_MrsuWb4EDtnjU7HEpoBb4 |\n|            | o6ozsA_NmFWEpLeKy0uNn_WeKbAhYygrsmQGA49dclHVnz-OMVLiyM9ws       |\n| project_id | 343d245e850143a096806dfaefa9afdc                                |\n| user_id    | ac3377633149401296f6c0d92d79dc16                                |\n+------------+-----------------------------------------------------------------+\n\n4、用demo用户、请求验证令牌\n$ openstack --os-auth-url http://linux-node2:5000/v3 \\\n  --os-project-domain-name default --os-user-domain-name default \\\n  --os-project-name demo --os-username demo token issue\nPassword:\n+------------+-----------------------------------------------------------------+\n| Field      | Value                                                           |\n+------------+-----------------------------------------------------------------+\n| expires    | 2016-02-12T20:15:39.014479Z                                     |\n| id         | gAAAAABWvi9bsh7vkiby5BpCCnc-JkbGhm9wH3fabS_cY7uabOubesi-Me6IGWW |\n|            | yQqNegDDZ5jw7grI26vvgy1J5nCVwZ_zFRqPiz_qhbq29mgbQLglbkq6FQvzBRQ |\n|            | JcOzq3uwhzNxszJWmzGC7rJE_H0A_a3UFhqv8M4zMRYSbS2YF0MyFmp_U       |\n| project_id | ed0b60bf607743088218b0a533d5943f                                |\n| user_id    | 58126687cbcc4888bfa9ab73a2256f27                                |\n</code></pre><h3 id=\"h3-3-3-4-openstack-\"><a name=\"3.3.4创建 OpenStack 客户端环境脚本\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3.4创建 OpenStack 客户端环境脚本</h3><pre><code>vi admin-openrc 加入如下：\nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_NAME=admin\nexport OS_USERNAME=admin\nexport OS_PASSWORD=ADMIN_PASS\nexport OS_AUTH_URL=http://linux-node2:35357/v3\nexport OS_IDENTITY_API_VERSION=3\nexport OS_IMAGE_API_VERSION=2\n#vi demo-openrc 加入：\n[root@linux-node2 ~]# cat demo-openrc \nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_NAME=demo\nexport OS_USERNAME=demo\nexport OS_PASSWORD=demo\nexport OS_AUTH_URL=http://linux-node2:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nexport OS_IMAGE_API_VERSION=2\n</code></pre><h2 id=\"h2--glance-node2-\"><a name=\"镜像服务Glance（node2 主控制节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>镜像服务Glance（node2 主控制节点操作）</h2><h3 id=\"h3-4-1-glance-\"><a name=\"4.1 Glance 介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.1 Glance 介绍</h3><blockquote>\n<p>Glance 主要由三个部分构成： glance-api、glance-registry 以 image stroe</p>\n<p>Glance-api：接受云系统镜像创建、删除、读取请求</p>\n<p>Glance-Registry： 云系统镜像注册服务</p>\n</blockquote>\n<p><img src=\"/upload/images/20180209//1a8e98c4-eecd-453b-83d1-885ccbf7d00c.png\" alt=\"\"><img src=\"/upload/images/20180209//e63280d9-60a1-4eab-ab47-7ed373be010e.png\" alt=\"\"></p>\n<h3 id=\"h3-4-2-mysql-\"><a name=\"4.2 mysql 配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.2 mysql 配置</h3><pre><code>$ mysql -u root –p\nMariaDB [(none)]&gt; CREATE DATABASE glance;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO &#39;glance&#39;@&#39;localhost&#39; \\\n  IDENTIFIED BY &#39;glance&#39;;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO &#39;glance&#39;@&#39;%&#39; \\\n  IDENTIFIED BY &#39;glance&#39;;\n</code></pre><h3 id=\"h3-4-3-glance-\"><a name=\"4.3 Glance安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.3 Glance安装</h3><pre><code>#yum install openstack-glance\n</code></pre><h3 id=\"h3-4-4-etc-glance-glance-api-conf\"><a name=\"4.4修改主配置文件/etc/glance/glance-api.conf\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.4修改主配置文件/etc/glance/glance-api.conf</h3><pre><code>[database]\n# ...\nconnection = mysql://glance:glance@192.168.57.145/glance\n在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问：\n[keystone_authtoken] \nauth_uri  =  http://linux-node2:5000\nauth_url  =  http://linux-node2:35357\nmemcached_servers  =  linux-node2:11211\nauth_type  =  password\nproject_domain_name  =  default\nuser_domain_name  =  default\nproject_name  =  service\nusername  =  glance\npassword  =  glance    #########这里的密码就是下面的新建 API  glance用户的密码\n＃... \n[paste_deploy]\nflavor  =  keystone\n[glance_store]\n# ...\nstores = file,http\ndefault_store = file\nfilesystem_store_datadir = /var/lib/glance/images/\n</code></pre><h3 id=\"h3-4-5-etc-glance-glance-registry-conf\"><a name=\"4.5 修改主配置文件/etc/glance/glance-registry.conf\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.5 修改主配置文件/etc/glance/glance-registry.conf</h3><pre><code>[database]\n# ...\nconnection = mysql://glance:glance@192.168.57.145/glance\n在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问：\n[keystone_authtoken] \nauth_uri  =  http://linux-node2:5000\nauth_url  =  http://linux-node2:35357\nmemcached_servers  =  linux-node2:11211\nauth_type  =  password\nproject_domain_name  =  default\nuser_domain_name  =  default\nproject_name  =  service\nusername  =  glance\npassword  =  glance  #########这里的密码就是下面的新建 API  glance用户的密码\n＃... \n[paste_deploy]\nflavor  =  keystone\n</code></pre><h3 id=\"h3-4-6-\"><a name=\"4.6 设置数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.6 设置数据库</h3><pre><code># su -s /bin/sh -c &quot;glance-manage db_sync&quot; glance\n</code></pre><h3 id=\"h3-4-7-api-\"><a name=\"4.7创建镜像服务的API服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.7创建镜像服务的API服务</h3><pre><code>$ openstack user create --domain default --password-prompt glance\n$ openstack role add --project service --user glance admin\n$ openstack service create --name glance \\\n  --description &quot;OpenStack Image&quot; image\n$ openstack endpoint create --region RegionOne \\\n  image public http://linux-node2:9292\n$ openstack endpoint create --region RegionOne \\\n  image internal http://linux-node2:9292\n$ openstack endpoint create --region RegionOne \\\n  image admin http://linux-node2:9292\n</code></pre><h3 id=\"h3-4-8-\"><a name=\"4.8 启动服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.8 启动服务</h3><pre><code># systemctl enable openstack-glance-api.service \\\n  openstack-glance-registry.service\n# systemctl start openstack-glance-api.service \\\n  openstack-glance-registry.service\n</code></pre><h3 id=\"h3-4-9-\"><a name=\"4.9验证\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.9验证</h3><pre><code>运行环境变量：\n　　#. admin-openrc\n　　下载一个比较小的镜像：\n　　#wget http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img\n一、上传文件\n$ openstack image create &quot;cirros&quot; \\\n  --file cirros-0.3.5-x86_64-disk.img \\\n  --disk-format qcow2 --container-format bare \\\n  --public\n+------------------+------------------------------------------------------+\n| Field            | Value                                                |\n+------------------+------------------------------------------------------+\n| checksum         | 133eae9fb1c98f45894a4e60d8736619                     |\n| container_format | bare                                                 |\n| created_at       | 2015-03-26T16:52:10Z                                 |\n| disk_format      | qcow2                                                |\n| file             | /v2/images/cc5c6982-4910-471e-b864-1098015901b5/file |\n| id               | cc5c6982-4910-471e-b864-1098015901b5                 |\n| min_disk         | 0                                                    |\n| min_ram          | 0                                                    |\n| name             | cirros                                               |\n| owner            | ae7a98326b9c455588edd2656d723b9d                     |\n| protected        | False                                                |\n| schema           | /v2/schemas/image                                    |\n| size             | 13200896                                             |\n| status           | active                                               |\n| tags             |                                                      |\n| updated_at       | 2015-03-26T16:52:10Z                                 |\n| virtual_size     | None                                                 |\n| visibility       | public                                               |\n+------------------+------------------------------------------------------+\n二、查看\n$ openstack image list\n\n+--------------------------------------+--------+--------+\n| ID                                   | Name   | Status |\n+--------------------------------------+--------+--------+\n| 38047887-61a7-41ea-9b49-27987d5e8bb9 | cirros | active |\n+--------------------------------------+--------+--------+\n有输出证明glance配置正确\n</code></pre><h2 id=\"h2--nova-node2-\"><a name=\"计算服务一 nova（node2控制节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>计算服务一 nova（node2控制节点操作）</h2><h3 id=\"h3-nova-\"><a name=\"Nova 作用\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Nova 作用</h3><blockquote>\n<p>1.API :负责接收和相应外部请求、支持 openstack API Ec2API</p>\n<p>2.Cert：负责身份认证</p>\n<p>3.Scheduler：用于云主机调度</p>\n<p>4.Conductor： 计算节点访问数据的中间件</p>\n<p>5.Consoleaut：用于控制台的授权验证</p>\n<p>6.NovncProxy： VNC代理</p>\n</blockquote>\n<h3 id=\"h3-5-1-\"><a name=\"5.1 新建数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.1 新建数据库</h3><pre><code>$ mysql -u root –p\nMariaDB [(none)]&gt; CREATE DATABASE nova_api;\nMariaDB [(none)]&gt; CREATE DATABASE nova;\nMariaDB [(none)]&gt; CREATE DATABASE nova_cell0;\n新建用户\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO &#39;nova&#39;@&#39;localhost&#39; \\\n  IDENTIFIED BY &#39;nova_api&#39;;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO &#39;nova&#39;@&#39;%&#39; \\\n  IDENTIFIED BY &#39;nova&#39;;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO &#39;nova&#39;@&#39;localhost&#39; \\\n  IDENTIFIED BY &#39;nova&#39;;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO &#39;nova&#39;@&#39;%&#39; \\\n  IDENTIFIED BY &#39;nova&#39;;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO &#39;nova&#39;@&#39;localhost&#39; \\\n  IDENTIFIED BY &#39;nova&#39;;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO &#39;nova&#39;@&#39;%&#39; \\\n  IDENTIFIED BY &#39;nova&#39;;\n</code></pre><h3 id=\"h3-5-2-nova-\"><a name=\"5.2创建nova用户：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.2创建nova用户：</h3><pre><code># . admin-openrc\n\nopenstack user create --domain default --password-prompt nova\nUser Password: nova\nRepeat User Password: nova\nThe passwords entered were not the same\nUser Password: nova\nRepeat User Password:  nova\n+---------------------+----------------------------------+\n| Field               | Value                            |\n+---------------------+----------------------------------+\n| domain_id           | default                          |\n| enabled             | True                             |\n| id                  | b9878680c70a4a678fd9a7a580706ccf |\n| name                | nova                             |\n| options             | {}                               |\n| password_expires_at | None                             |\n+---------------------+----------------------------------+\n[root@linux-node2 ~]#\n加入组\n[root@linux-node2 ~]#  openstack role add --project service --user nova admin\n</code></pre><h3 id=\"h3-5-3-nova-\"><a name=\"5.3创建nova服务实体\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.3创建nova服务实体</h3><pre><code>$ openstack service create --name nova \\\n  --description &quot;OpenStack Compute&quot; compute\n\n+-------------+----------------------------------+\n| Field       | Value                            |\n+-------------+----------------------------------+\n| description | OpenStack Compute                |\n| enabled     | True                             |\n| id          | 060d59eac51b4594815603d75a00aba2 |\n| name        | nova                             |\n| type        | compute                          |\n+-------------+----------------------------------+\n</code></pre><h3 id=\"h3-5-4-api\"><a name=\"5.4创建服务API\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.4创建服务API</h3><pre><code>[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\\n&gt;   compute public http://linux-node2:8774/v2.1\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | b6ebf975780344a597a65650eafdf67a |\n| interface    | public                           |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | d6a1591a15944bea85ab1e203af6732c |\n| service_name | nova                             |\n| service_type | compute                          |\n| url          | http://linux-node2:8774/v2.1     |\n+--------------+----------------------------------+\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\\n&gt;   compute internal http://linux-node2:8774/v2.1\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | a2c1af804a31484cb3d82017b15fa47f |\n| interface    | internal                         |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | d6a1591a15944bea85ab1e203af6732c |\n| service_name | nova                             |\n| service_type | compute                          |\n| url          | http://linux-node2:8774/v2.1     |\n+--------------+----------------------------------+\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne \\\n&gt;   compute admin http://linux-node2:8774/v2.1\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | 0304b6e92bf049d09e7d28bacfb1ed16 |\n| interface    | admin                            |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | d6a1591a15944bea85ab1e203af6732c |\n| service_name | nova                             |\n| service_type | compute                          |\n| url          | http://linux-node2:8774/v2.1     |\n+--------------+----------------------------------+\n</code></pre><h3 id=\"h3-5-5-\"><a name=\"5.5新建另一个用户\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.5新建另一个用户</h3><pre><code>[root@linux-node2 ~]# openstack user create --domain default --password-prompt placement\nUser Password: nova \nRepeat User Password: nova\n+---------------------+----------------------------------+\n| Field               | Value                            |\n+---------------------+----------------------------------+\n| domain_id           | default                          |\n| enabled             | True                             |\n| id                  | 1654b6d199bf4fc582d1e70db802a31a |\n| name                | placement                        |\n| options             | {}                               |\n| password_expires_at | None                             |\n+---------------------+----------------------------------+\n[root@linux-node2 ~]#\n加入管理员组\n[root@linux-node2 ~]# openstack role add --project service --user placement admin\n</code></pre><h3 id=\"h3-5-6-placement-api-\"><a name=\"5.6在服务目录中创建Placement API条目：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.6在服务目录中创建Placement API条目：</h3><pre><code>$ openstack service create --name placement --description &quot;Placement API&quot; placement\n+-------------+----------------------------------+\n| Field       | Value                            |\n+-------------+----------------------------------+\n| description | Placement API                    |\n| enabled     | True                             |\n| id          | 2d1a27022e6e4185b86adac4444c495f |\n| name        | placement                        |\n| type        | placement                        |\n+-------------+----------------------------------+\n`\n</code></pre><h3 id=\"h3-5-7-placement-api-\"><a name=\"5.7创建Placement API服务端点：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.7创建Placement API服务端点：</h3><pre><code>[root@linux-node2 ~]#  openstack endpoint create --region RegionOne placement public http://linux-node2:8778\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | 4b82fb4b30de4228982dea8c663f6d26 |\n| interface    | public                           |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | ba2a8b23524a4635af583cbfc80abd91 |\n| service_name | placement                        |\n| service_type | placement                        |\n| url          | http://linux-node2:8778          |\n+--------------+----------------------------------+\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne placement internal http://linux-node2:8778\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | bea3dbb6003d4cea802527de411f8cde |\n| interface    | internal                         |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | ba2a8b23524a4635af583cbfc80abd91 |\n| service_name | placement                        |\n| service_type | placement                        |\n| url          | http://linux-node2:8778          |\n+--------------+----------------------------------+\n[root@linux-node2 ~]# openstack endpoint create --region RegionOne placement admin http://linux-node2:8778\n+--------------+----------------------------------+\n| Field        | Value                            |\n+--------------+----------------------------------+\n| enabled      | True                             |\n| id           | b5d6d62d8f3f4e7c9ee2d6241b832bc5 |\n| interface    | admin                            |\n| region       | RegionOne                        |\n| region_id    | RegionOne                        |\n| service_id   | ba2a8b23524a4635af583cbfc80abd91 |\n| service_name | placement                        |\n| service_type | placement                        |\n| url          | http://linux-node2:8778          |\n+--------------+----------------------------------+\n</code></pre><h3 id=\"h3-5-8-\"><a name=\"5.8安装和配置的部件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.8安装和配置的部件</h3><pre><code># yum install openstack-nova-api openstack-nova-conductor \\\n  openstack-nova-console openstack-nova-novncproxy \\\n  openstack-nova-scheduler openstack-nova-placement-api\n</code></pre><h3 id=\"h3-5-9-etc-nova-nova-conf\"><a name=\"5.9修改配置文件 /etc/nova/nova.conf\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.9修改配置文件 /etc/nova/nova.conf</h3><pre><code>[DEFAULT]\n# ...\nenabled_apis = osapi_compute,metadata\n [api_database]\nconnection=mysql://nova:nova_api@192.168.57.145/nova_api\n[database]\nconnection=connection=mysql://nova:nova@192.168.57.145/nova\n[DEFAULT]\n# ...\ntransport_url = rabbit://openstack:openstack@192.168.57.145\n</code></pre><h3 id=\"h3-5-10-api-\"><a name=\"5.10设置api和连接信息\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.10设置api和连接信息</h3><pre><code>[api]\n# ...\nauth_strategy = keystone\n[keystone_authtoken]\n# ...\nauth_uri = http://linux-node2:5000\nauth_url = http://linux-node2:35357\nmemcached_servers = linux-node2:11211 \nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = nova\npassword = nova\n\n设置IP\n[DEFAULT]\n# ...\nmy_ip = 192.168.57.145\n[DEFAULT]\n# ...\nuse_neutron = True\nfirewall_driver = nova.virt.firewall.NoopFirewallDriver\n[vnc]\nenabled = true\n# ...\nvncserver_listen = $my_ip\nvncserver_proxyclient_address = $my_ip\n</code></pre><h3 id=\"h3-5-11-glance\"><a name=\"5.11设置glance\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.11设置glance</h3><pre><code>[glance]\n# ...\napi_servers = http://linux-node2:9292\n</code></pre><h3 id=\"h3-5-12-oslo_concurrency-\"><a name=\"5.12设置[oslo_concurrency]\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.12设置[oslo_concurrency]</h3><pre><code>[oslo_concurrency]\n# ...\nlock_path = /var/lib/nova/tmp\n</code></pre><h3 id=\"h3-5-13-placement-\"><a name=\"5.13设置[placement]\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.13设置[placement]</h3><pre><code>[placement]\n# ...\n os_region_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://linux-node2:35357/v3\nusername = placement\npassword = nova\n</code></pre><h3 id=\"h3-5-14-apache\"><a name=\"5.14设置apache\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.14设置apache</h3><pre><code>vim  /etc/httpd/conf.d/00-nova-placement-api.conf:\n&lt;Directory /usr/bin&gt;\n   &lt;IfVersion &gt;= 2.4&gt;\n      Require all granted\n   &lt;/IfVersion&gt;\n   &lt;IfVersion &lt; 2.4&gt;\n      Order allow,deny\n      Allow from all\n   &lt;/IfVersion&gt;\n&lt;/Directory&gt;\n</code></pre><h3 id=\"h3-5-15-apache\"><a name=\"5.15重启apache\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.15重启apache</h3><pre><code># systemctl restart httpd\n填充nova-api数据库：\n# su -s /bin/sh -c &quot;nova-manage api_db sync&quot; nova\n注册cell0数据库：\n# su -s /bin/sh -c &quot;nova-manage cell_v2 map_cell0&quot; nova\n创建cell1单元格：\n# su -s /bin/sh -c &quot;nova-manage cell_v2 create_cell --name=cell1 --verbose&quot; nova\n109e1d4b-536a-40d0-83c6-5f121b82b650\n填充nova数据库：\n# su -s /bin/sh -c &quot;nova-manage db sync&quot; nova\n</code></pre><h3 id=\"h3-5-16-\"><a name=\"5.16验证\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.16验证</h3><pre><code>验证nova cell0和cell1是否正确注册：\n＃ nova-manage cell_v2 list_cells\n + ------- + ----------------------------------- --- + \n| 名称| UUID | \n+ ------- + -------------------------------------- + \n| cell1 | 109e1d4b-536a-40d0-83c6-5f121b82b650 | \n| cell0 | 00000000-0000-0000-0000-000000000000 | \n+ ------- + -------------------------------------- +\n设置开机自启动\n[root@linux-node2 nova]# systemctl enable openstack-nova-api.service\n[root@linux-node2 nova]# systemctl enable openstack-nova-consoleauth.service\n[root@linux-node2 nova]# systemctl enable openstack-nova-scheduler.service\n[root@linux-node2 nova]# systemctl enable openstack-nova-conductor.service \n[root@linux-node2 nova]# systemctl enable openstack-nova-novncproxy.service\n[root@linux-node2 nova]#\n启动服务\n[root@linux-node2 nova]# systemctl start openstack-nova-api.service\n[root@linux-node2 nova]# systemctl start openstack-nova-consoleauth.service\n[root@linux-node2 nova]# systemctl start openstack-nova-scheduler.service\n[root@linux-node2 nova]# systemctl start openstack-nova-conductor.service \n[root@linux-node2 nova]# systemctl start openstack-nova-novncproxy.service\n</code></pre><h2 id=\"h2--nova-node1-\"><a name=\"计算服务二  nova（node1计算节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>计算服务二  nova（node1计算节点操作）</h2><h3 id=\"h3-6-1-nova-compute\"><a name=\"6.1安装nova-compute\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6.1安装nova-compute</h3><blockquote>\n<p>yum install openstack-nova-compute</p>\n<h3 id=\"h3-6-2-etc-nova-nova-conf-\"><a name=\"6.2配置主配置文件（/etc/nova/nova.conf）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6.2配置主配置文件（/etc/nova/nova.conf）</h3></blockquote>\n<pre><code>[DEFAULT]\n# ...\nenabled_apis = osapi_compute,metadata\n[DEFAULT]\n# ...\ntransport_url = rabbit://openstack:openstack@192.168.57.145\n[api]\n# ...\nauth_strategy = keystone\n\n[keystone_authtoken]\n# ...\nauth_uri = http://linux-node2:5000\nauth_url = http://linux-node2:35357\nmemcached_servers = linux-node2:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = nova\npassword = nova\n[DEFAULT]\n# ...\nmy_ip = 192.168.57.142  ########这个是本机IP\n[DEFAULT]\n# ...\nuse_neutron = True\nfirewall_driver = nova.virt.firewall.NoopFirewallDriver\n[vnc]\n# ...\nenabled = True\nvncserver_listen = 0.0.0.0\nvncserver_proxyclient_address = $my_ip\nnovncproxy_base_url = http://linux-node2:6080/vnc_auto.html\n[glance]\n# ...\napi_servers = http://linux-node2:9292\n[oslo_concurrency]\n# ...\nlock_path = /var/lib/nova/tmp\n[placement]\n# ...\nos_region_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://linux-node2:35357/v3\nusername = placement\npassword = nova\n</code></pre><h3 id=\"h3-u68C0u67E5u662Fu5426u9700u8981u786Cu4EF6u52A0u901F\"><a name=\"检查是否需要硬件加速\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>检查是否需要硬件加速</h3><pre><code>$ egrep -c &#39;(vmx|svm)&#39; /proc/cpuinfo\n如果为0则需要修改#vi /etc/nova/nova.conf\n[libvirt]\n# ...\nvirt_type = qemu\n</code></pre><h3 id=\"h3-6-4-\"><a name=\"6.4启动服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6.4启动服务</h3><pre><code># systemctl enable libvirtd.service openstack-nova-compute.service\n# systemctl start libvirtd.service openstack-nova-compute.service\n</code></pre><h3 id=\"h3-6-5-node2-\"><a name=\"6.5验证(node2 主节点操作)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6.5验证(node2 主节点操作)</h3><pre><code>将计算节点添加到单元数据库¶（在主节点操作）\nsu -s /bin/sh -c &quot;nova-manage cell_v2 discover_hosts --verbose&quot; nova\n\nFound 2 cell mappings.\nSkipping cell0 since it does not contain hosts.\nGetting compute nodes from cell &#39;cell1&#39;: ad5a5985-a719-4567-98d8-8d148aaae4bc\nFound 1 computes in cell: ad5a5985-a719-4567-98d8-8d148aaae4bc\nChecking host mapping for compute host &#39;linux-node1&#39;: fe58ddc1-1d65-4f87-9456-bc040dc106b3\nCreating host mapping for compute host &#39;linux-node1&#39;: fe58ddc1-1d65-4f87-9456-bc040dc106b3\n查看comput节点\n$ openstack compute service list\n\n+----+--------------------+------------+----------+---------+-------+----------------------------+\n| Id | Binary             | Host       | Zone     | Status  | State | Updated At                 |\n+----+--------------------+------------+----------+---------+-------+----------------------------+\n|  1 | nova-consoleauth   | controller | internal | enabled | up    | 2016-02-09T23:11:15.000000 |\n|  2 | nova-scheduler     | controller | internal | enabled | up    | 2016-02-09T23:11:15.000000 |\n|  3 | nova-conductor     | controller | internal | enabled | up    | 2016-02-09T23:11:16.000000 |\n|  4 | nova-compute       | compute1   | nova     | enabled | up    | 2016-02-09T23:11:20.000000 |\n+----+--------------------+------------+----------+---------+-------+----------------------------+\n查看catalog\n$ openstack catalog list\n+-----------+-----------+-----------------------------------------+\n| Name      | Type      | Endpoints                               |\n+-----------+-----------+-----------------------------------------+\n| keystone  | identity  | RegionOne                               |\n|           |           |   public: http://linux-node2:5000/v3/    |\n|           |           | RegionOne                               |\n|           |           |   internal: http://linux-node2:5000/v3/  |\n|           |           | RegionOne                               |\n|           |           |   admin: http://linux-node2:35357/v3/    |\n|           |           |                                         |\n| glance    | image     | RegionOne                               |\n|           |           |   admin: http://linux-node2:9292         |\n|           |           | RegionOne                               |\n|           |           |   public: http://linux-node2:9292        |\n|           |           | RegionOne                               |\n|           |           |   internal: http://linux-node2:9292      |\n|           |           |                                         |\n| nova      | compute   | RegionOne                               |\n|           |           |   admin: h http://linux-node2:8774/v2.1    |\n|           |           | RegionOne                               |\n|           |           |   internal: http://linux-node2:8774/v2.1 |\n|           |           | RegionOne                               |\n|           |           |   public: http://linux-node2:8774/v2.1   |\n|           |           |                                         |\n| placement | placement | RegionOne                               |\n|           |           |   public: http://linux-node2:8778        |\n|           |           | RegionOne                               |\n|           |           |   admin: http://linux-node2:8778         |\n|           |           | RegionOne                               |\n|           |           |   internal: http://linux-node2:8778      |\n|           |           |                                         |\n+-----------+-----------+-----------------------------------------+\n\n列出Image服务中的图像以验证与Image服务的连接性：\n$ openstack image list\n\n+--------------------------------------+-------------+-------------+\n| ID                                   | Name        | Status      |\n+--------------------------------------+-------------+-------------+\n| 9a76d9f9-9620-4f2e-8c69-6c5691fae163 | cirros      | active      |\n+--------------------------------------+-------------+-------------+\n检查单元格和放置API正在成功工作：\n# nova-status upgrade check\n\n+---------------------------+\n| Upgrade Check Results     |\n+---------------------------+\n| Check: Cells v2           |\n| Result: Success           |\n| Details: None             |\n+---------------------------+\n| Check: Placement API      |\n| Result: Success           |\n| Details: None             |\n+---------------------------+\n| Check: Resource Providers |\n| Result: Success           |\n| Details: None             |\n+---------------------------+\n</code></pre><h2 id=\"h2--node2-\"><a name=\"网络节点一（node2 主控制节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>网络节点一（node2 主控制节点操作）</h2><h3 id=\"h3-7-1-mysql\"><a name=\"7.1 设置mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.1 设置mysql</h3><pre><code>$ mysql -u root –p\nMariaDB [（none）] CREATE DATABASE neutron;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO &#39;neutron&#39;@&#39;localhost&#39; \\\n  IDENTIFIED BY &#39;neutron&#39;;\nMariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO &#39;neutron&#39;@&#39;%&#39; \\\n  IDENTIFIED BY &#39;neutron&#39;;\n</code></pre><h3 id=\"h3-7-2-\"><a name=\"7.2创建服务凭据\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.2创建服务凭据</h3><pre><code>在admin的环境下\n$ . admin-openrc\n$ openstack user create --domain default --password-prompt neutron\n\nUser Password: neutron  #密码\nRepeat User Password: neutron  #密码\n+---------------------+----------------------------------+\n| Field               | Value                            |\n+---------------------+----------------------------------+\n| domain_id           | default                          |\n| enabled             | True                             |\n| id                  | fdb0f541e28141719b6a43c8944bf1fb |\n| name                | neutron                          |\n| options             | {}                               |\n| password_expires_at | None                             |\n+---------------------+----------------------------------+\n\n加入到admin组\n$ openstack role add --project service --user neutron admin\n创建neutron 服务实体\n$ openstack service create --name neutron \\\n  --description &quot;OpenStack Networking&quot; network\n创建neutron API\n$ openstack endpoint create --region RegionOne \\\n  network public http://linux-node2:9696\n$ openstack endpoint create --region RegionOne \\\n  network internal http://linux-node2:9696\n$ openstack endpoint create --region RegionOne \\\n  network admin http://linux-node2:9696\n</code></pre><h3 id=\"h3-7-3-1-\"><a name=\"7.3配置网络选项（这里我选用的是网络1 的配置）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.3配置网络选项（这里我选用的是网络1 的配置）</h3><pre><code>您可以使用选项1和2所代表的两种体系结构之一来部署网络服务。\n选项1部署了最简单的架构，只支持将实例连接到提供者（外部）网络。没有自助服务（专用）网络，路由器或浮动IP地址。只有admin或其他特权用户才能管理提供商网络。\n选项2增加了选项1，其中第三层服务支持将实例附加到自助服务网络。这个demo或其他非特权用户可以管理自助服务网络，包括在自助服务和提供商网络之间提供连接的路由器。此外，浮动IP地址还提供与使用来自外部网络（如Internet）的自助服务网络的实例的连接。\n自助服务网络通常使用覆盖网络。覆盖网络协议（如VXLAN）包含额外的标头，这些标头会增加开销并减少有效负载或用户数据的可用空间。在不了解虚拟网络基础架构的情况下，实例将尝试使用1500字节的默认以太网最大传输单元（MTU）发送数据包。网络服务通过DHCP自动为实例提供正确的MTU值。但是，某些云图像不使用DHCP或忽略DHCP MTU选项并需要使用元数据或脚本进行配置。\n</code></pre><h3 id=\"h3-7-4-openstack-neutron\"><a name=\"7.4 安装网络openstack-neutron\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.4 安装网络openstack-neutron</h3><pre><code># yum install openstack-neutron openstack-neutron-ml2 \\\n  openstack-neutron-linuxbridge ebtables\n</code></pre><h3 id=\"h3-7-5-etc-neutron-neutron-conf\"><a name=\"7.5 编辑/etc/neutron/neutron.conf\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.5 编辑/etc/neutron/neutron.conf</h3><pre><code>[database]\n# ...\nconnection = mysql://neutron:neutron@linux-node2/neutron\n[DEFAULT]\n# ...\ncore_plugin = ml2\nservice_plugins =\ntransport_url = rabbit://openstack:openstack@linux-node2\nauth_strategy = keystone\nnotify_nova_on_port_status_changes = true\nnotify_nova_on_port_data_changes = true\n[keystone_authtoken]\n# ...\nauth_uri = http://linux-node2:5000\nauth_url = http://linux-node2:35357\nmemcached_servers = linux-node2:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = neutron  ######这个密码是上面设置的密码\n[nova]\n# ...\nauth_url = http://controller:35357\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = nova\npassword = nova  ####注意这个是nova设置的密码\n[oslo_concurrency]\n# ...\nlock_path = /var/lib/neutron/tmp\n</code></pre><h3 id=\"h3-7-6-2-ml2-etc-neutron-plugins-ml2-ml2_conf-ini-\"><a name=\"7.6配置模块化层2（ML2）插件（/etc/neutron/plugins/ml2/ml2_conf.ini）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.6配置模块化层2（ML2）插件（/etc/neutron/plugins/ml2/ml2_conf.ini）</h3><pre><code>编辑配置文件设置如下：\n[ml2]\ntype_drivers = flat,vlan\ntenant_network_types =\nmechanism_drivers = linuxbridge\n[ml2_type_flat]\nflat_networks = provider\n[securitygroup]\nenable_ipset = true\n</code></pre><h3 id=\"h3-7-7-linux-etc-neutron-plugins-ml2-linuxbridge_agent-ini-\"><a name=\"7.7配置Linux网桥代理（/etc/neutron/plugins/ml2/linuxbridge_agent.ini）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.7配置Linux网桥代理（/etc/neutron/plugins/ml2/linuxbridge_agent.ini）</h3><pre><code>编辑配置文件设置如下：\n[linux_bridge]\nphysical_interface_mappings = provider:eth1  ####这个是为底层实现网络的网络接口（我这里用了eth1）\n[vxlan]\nenable_vxlan = false\n[securitygroup]\n# ...\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\n</code></pre><h3 id=\"h3-7-8-dhcp-etc-neutron-dhcp_agent-ini-\"><a name=\"7.8配置DHCP代理（/etc/neutron/dhcp_agent.ini）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.8配置DHCP代理（/etc/neutron/dhcp_agent.ini）</h3><pre><code>[DEFAULT] \n＃... \ninterface_driver  =  linuxbridge \ndhcp_driver  =  neutron.agent.linux.dhcp.Dnsmasq \nenable_isolated_metadata  =  true\n</code></pre><h3 id=\"h3-7-9-etc-nova-nova-conf-\"><a name=\"7.9配置计算服务以使用网络服务（/etc/nova/nova.conf）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.9配置计算服务以使用网络服务（/etc/nova/nova.conf）</h3><pre><code>在该[neutron]部分中，配置访问参数，启用元数据代理并配置密钥：\n[neutron] \n＃... \nurl  =  http：//linux-node2：9696 \nauth_url  =  http：//linux-node2：35357 \nauth_type  =  password \nproject_domain_name  =  default \nuser_domain_name  =  default \nregion_name  =  RegionOne \nproject_name  =  service \nusername  =  neutron \npassword  = neutron      ###在身份识别服务中为用户选择的密码。\nservice_metadata_proxy  =  true \nmetadata_proxy_shared_secret  =  neutron     #  #为元数据代理选择的密码。\n创建扩展链接\n# ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini\n</code></pre><h3 id=\"h3-7-10-\"><a name=\"7.10同步数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.10同步数据库</h3><pre><code># su -s /bin/sh -c &quot;neutron-db-manage --config-file /etc/neutron/neutron.conf \\\n  --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head&quot; neutron\n</code></pre><h3 id=\"h3-7-11-\"><a name=\"7.11 启动服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.11 启动服务</h3><pre><code>重新启动计算API服务：\n# systemctl restart openstack-nova-api.service\n启动网络服务并将其配置为在系统引导时启动。\n# systemctl enable neutron-server.service \\\n  neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\\n  neutron-metadata-agent.service\n# systemctl start neutron-server.service \\\n  neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\\n  neutron-metadata-agent.service\n</code></pre><h2 id=\"h2--node1-\"><a name=\"网络节点二、（node1 计算节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>网络节点二、（node1 计算节点操作）</h2><h3 id=\"h3-8-1-openstack-neutron\"><a name=\"8.1 安装openstack-neutron\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>8.1 安装openstack-neutron</h3><blockquote>\n<p>yum install openstack-neutron-linuxbridge ebtables ipset</p>\n<h3 id=\"h3-8-2-etc-neutron-neutron-conf-\"><a name=\"8.2配置通用组件（/etc/neutron/neutron.conf）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>8.2配置通用组件（/etc/neutron/neutron.conf）</h3></blockquote>\n<pre><code>修改如下配置文件：\n[DEFAULT]\ntransport_url = rabbit://openstack:openstack@linux-node2\nauth_strategy = keystone\n[keystone_authtoken]\n# ...\nauth_uri = http://linux-node2:5000\nauth_url = http://linux-node2:35357\nmemcached_servers =linux-node2:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = neutron\n[oslo_concurrency]\n# ...\nlock_path = /var/lib/neutron/tmp\n</code></pre><h3 id=\"h3-8-3-etc-nova-nova-conf-\"><a name=\"8.3配置计算服务以使用网络服务（/etc/nova/nova.conf）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>8.3配置计算服务以使用网络服务（/etc/nova/nova.conf）</h3><pre><code>在该[neutron]部分中，配置访问参数：\n[neutron] \n＃... \nurl  =  http：//linux-node2：9696 \nauth_url  =  http：//linux-node2：35357 \nauth_type  =  password \nproject_domain_name  =  default \nuser_domain_name  =  default \nregion_name  =  RegionOne \nproject_name  =  service \nusername  =  neutron \npassword  =  neutron\n</code></pre><h3 id=\"h3-8-4-linux-etc-neutron-plugins-ml2-linuxbridge_agent-ini-\"><a name=\"8.4配置Linux网桥代理（/etc/neutron/plugins/ml2/linuxbridge_agent.ini）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>8.4配置Linux网桥代理（/etc/neutron/plugins/ml2/linuxbridge_agent.ini）</h3><pre><code>编辑文件修改如下配置：\n[linux_bridge]\nphysical_interface_mappings = provider:eht1 #这里是为底层服务的网卡名称\n[vxlan]\nenable_vxlan = false\n[securitygroup]\n# ...\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\n</code></pre><h3 id=\"h3-8-5-\"><a name=\"8.5 启动服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>8.5 启动服务</h3><pre><code>重启一下openstack-nova-compute\n# systemctl restart openstack-nova-compute.service\n启动Linux桥代理并将其配置为在系统引导时启动：\n# systemctl enable neutron-linuxbridge-agent.service\n# systemctl start neutron-linuxbridge-agent.service\n```\n### 8.6 验证操作\n```\n1.运行管理员环境\n$ . admin-openrc\n2.查看网络\n$ openstack extension list --network\n\n+---------------------------+---------------------------+----------------------------+\n| Name                      | Alias                     | Description                |\n+---------------------------+---------------------------+----------------------------+\n| Default Subnetpools       | default-subnetpools       | Provides ability to mark   |\n|                           |                           | and use a subnetpool as    |\n|                           |                           | the default                |\n| Availability Zone         | availability_zone         | The availability zone      |\n|                           |                           | extension.                 |\n| Network Availability Zone | network_availability_zone | Availability zone support  |\n|                           |                           | for network.               |\n| Port Binding              | binding                   | Expose port bindings of a  |\n|                           |                           | virtual port to external   |\n|                           |                           | application                |\n| agent                     | agent                     | The agent management       |\n|                           |                           | extension.                 |\n| Subnet Allocation         | subnet_allocation         | Enables allocation of      |\n|                           |                           | subnets from a subnet pool |\n| DHCP Agent Scheduler      | dhcp_agent_scheduler      | Schedule networks among    |\n|                           |                           | dhcp agents                |\n| Tag support               | tag                       | Enables to set tag on      |\n|                           |                           | resources.                 |\n| Neutron external network  | external-net              | Adds external network      |\n|                           |                           | attribute to network       |\n|                           |                           | resource.                  |\n| Neutron Service Flavors   | flavors                   | Flavor specification for   |\n|                           |                           | Neutron advanced services  |\n| Network MTU               | net-mtu                   | Provides MTU attribute for |\n|                           |                           | a network resource.        |\n| Network IP Availability   | network-ip-availability   | Provides IP availability   |\n|                           |                           | data for each network and  |\n|                           |                           | subnet.                    |\n| Quota management support  | quotas                    | Expose functions for       |\n|                           |                           | quotas management per      |\n|                           |                           | tenant                     |\n| Provider Network          | provider                  | Expose mapping of virtual  |\n|                           |                           | networks to physical       |\n|                           |                           | networks                   |\n| Multi Provider Network    | multi-provider            | Expose mapping of virtual  |\n|                           |                           | networks to multiple       |\n|                           |                           | physical networks          |\n| Address scope             | address-scope             | Address scopes extension.  |\n| Subnet service types      | subnet-service-types      | Provides ability to set    |\n|                           |                           | the subnet service_types   |\n|                           |                           | field                      |\n| Resource timestamps       | standard-attr-timestamp   | Adds created_at and        |\n|                           |                           | updated_at fields to all   |\n|                           |                           | Neutron resources that     |\n|                           |                           | have Neutron standard      |\n|                           |                           | attributes.                |\n| Neutron Service Type      | service-type              | API for retrieving service |\n| Management                |                           | providers for Neutron      |\n|                           |                           | advanced services          |\n| Tag support for           | tag-ext                   | Extends tag support to     |\n| resources: subnet,        |                           | more L2 and L3 resources.  |\n| subnetpool, port, router  |                           |                            |\n| Neutron Extra DHCP opts   | extra_dhcp_opt            | Extra options              |\n|                           |                           | configuration for DHCP.    |\n|                           |                           | For example PXE boot       |\n|                           |                           | options to DHCP clients    |\n|                           |                           | can be specified (e.g.     |\n|                           |                           | tftp-server, server-ip-    |\n|                           |                           | address, bootfile-name)    |\n| Resource revision numbers | standard-attr-revisions   | This extension will        |\n|                           |                           | display the revision       |\n|                           |                           | number of neutron          |\n|                           |                           | resources.                 |\n| Pagination support        | pagination                | Extension that indicates   |\n|                           |                           | that pagination is         |\n|                           |                           | enabled.                   |\n| Sorting support           | sorting                   | Extension that indicates   |\n|                           |                           | that sorting is enabled.   |\n| security-group            | security-group            | The security groups        |\n|                           |                           | extension.                 |\n| RBAC Policies             | rbac-policies             | Allows creation and        |\n|                           |                           | modification of policies   |\n|                           |                           | that control tenant access |\n|                           |                           | to resources.              |\n| standard-attr-description | standard-attr-description | Extension to add           |\n|                           |                           | descriptions to standard   |\n|                           |                           | attributes                 |\n| Port Security             | port-security             | Provides port security     |\n| Allowed Address Pairs     | allowed-address-pairs     | Provides allowed address   |\n|                           |                           | pairs                      |\n| project_id field enabled  | project-id                | Extension that indicates   |\n|                           |                           | that project_id field is   |\n|                           |                           | enabled.                   |\n+---------------------------+---------------------------+----------------------------+\n2.查看网络\n3.$ openstack network agent list\n4.\n5.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+\n6.| ID                                   | Agent Type         | Host       | Availability Zone | Alive | State | Binary                    |\n7.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+\n8.| 0400c2f6-4d3b-44bc-89fa-99093432f3bf | Metadata agent     | controller | None              | True  | UP    | neutron-metadata-agent    |\n9.| 83cf853d-a2f2-450a-99d7-e9c6fc08f4c3 | DHCP agent         | controller | nova              | True  | UP    | neutron-dhcp-agent        |\n10.| ec302e51-6101-43cf-9f19-88a78613cbee | Linux bridge agent | compute    | None              | True  | UP    | neutron-linuxbridge-agent |\n11.| fcb9bc6e-22b1-43bc-9054-272dd517d025 | Linux bridge agent | controller | None              | True  | UP    | neutron-linuxbridge-agent |\n12.+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+\n</code></pre><h2 id=\"h2-dashboard-node2-\"><a name=\"Dashboard（node2控制节点操作）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Dashboard（node2控制节点操作）</h2><h3 id=\"h3-9-1-\"><a name=\"9.1 安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>9.1 安装</h3><blockquote>\n<p>yum install openstack-dashboard</p>\n</blockquote>\n<h3 id=\"h3-9-2-etc-openstack-dashboard-local_settings-\"><a name=\"9.2配置主配置文件（/etc/openstack-dashboard/local_settings）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>9.2配置主配置文件（/etc/openstack-dashboard/local_settings）</h3><pre><code>OPENSTACK_HOST = &quot;linux-node2&quot;\nALLOWED_HOSTS = [&#39;*&#39;]\nSESSION_ENGINE = &#39;django.contrib.sessions.backends.cache&#39;\n\nCACHES = {\n    &#39;default&#39;: {\n         &#39;BACKEND&#39;: &#39;django.core.cache.backends.memcached.MemcachedCache&#39;,\n         &#39;LOCATION&#39;: &#39;controller:11211&#39;,\n    }\n}\nOPENSTACK_KEYSTONE_URL = &quot;http://%s:5000/v3&quot; % OPENSTACK_HOST\nOPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True\n\n\n\nOPENSTACK_API_VERSIONS = {\n    &quot;identity&quot;: 3,\n    &quot;image&quot;: 2,\n    &quot;volume&quot;: 2,\n}\nOPENSTACK_KEYSTONE_DEFAULT_DOMAIN = &quot;Default&quot;\nOPENSTACK_KEYSTONE_DEFAULT_ROLE = &quot;user&quot;\nOPENSTACK_NEUTRON_NETWORK = {\n    ...\n    &#39;enable_router&#39;: False,\n    &#39;enable_quotas&#39;: False,\n    &#39;enable_distributed_router&#39;: False,\n    &#39;enable_ha_router&#39;: False,\n    &#39;enable_lb&#39;: False,\n    &#39;enable_firewall&#39;: False,\n    &#39;enable_vpn&#39;: False,\n    &#39;enable_fip_topology_check&#39;: False,\n}\nTIME_ZONE = &quot;UTC&quot;\n</code></pre><h3 id=\"h3-9-4-\"><a name=\"9.4重启服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>9.4重启服务</h3><blockquote>\n<p>systemctl restart httpd.service memcached.service</p>\n<h3 id=\"h3-9-5-openstack\"><a name=\"9.5 访问openstack\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>9.5 访问openstack</h3><p><a href=\"http://192.168.57.145/dashboard/auth/login/\">http://192.168.57.145/dashboard/auth/login/</a></p>\n</blockquote>\n<p><img src=\"/upload/images/20180209//112741a6-116b-4979-af0b-e45d11ea8f68.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180209//e14940a8-073f-401a-a5f3-b02ee0bdbc18.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('20', '0', '汽车工业大数据实践系列（一）-西门子s7系列数据采集', '16', '2018-02-27 10:37:40', '需求：实时采集汽车工业生产线上数据，并进行数据持久化', null, '0', '352', null, null, '2018-02-27 10:37:40', '2018-02-28 11:20:04', null, null, '0', '0', '0', '0', '####背景\n因某汽车新厂区需要用大数据整合厂内产生的所有数据，对实时数据进行实时监控、预警，对历史数据进行计算分析。本帖针对生产线上实时数据采集开发进行总结。\n####使用技术\njava，opentsdb，mysql，tcp，http\n####程序设计\n![](/upload/images/20180227//43747243-f940-4de8-80c5-bb0a1106da3c.png)\n####实现\n#####封装opentsdb\n#####jdbc连接mysql\n#####连接plc数据\n\n\n', '1', '<h4 id=\"h4-u80CCu666F\"><a name=\"背景\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>背景</h4><p>因某汽车新厂区需要用大数据整合厂内产生的所有数据，对实时数据进行实时监控、预警，对历史数据进行计算分析。本帖针对生产线上实时数据采集开发进行总结。</p>\n<h4 id=\"h4-u4F7Fu7528u6280u672F\"><a name=\"使用技术\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>使用技术</h4><p>java，opentsdb，mysql，tcp，http</p>\n<h4 id=\"h4-u7A0Bu5E8Fu8BBEu8BA1\"><a name=\"程序设计\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>程序设计</h4><p><img src=\"/upload/images/20180227//43747243-f940-4de8-80c5-bb0a1106da3c.png\" alt=\"\"></p>\n<h4 id=\"h4-u5B9Eu73B0\"><a name=\"实现\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>实现</h4><h5 id=\"h5--opentsdb\"><a name=\"封装opentsdb\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>封装opentsdb</h5><h5 id=\"h5-jdbc-mysql\"><a name=\"jdbc连接mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>jdbc连接mysql</h5><h5 id=\"h5--plc-\"><a name=\"连接plc数据\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>连接plc数据</h5>');
INSERT INTO `tbl_archive` VALUES ('21', '0', '并行监控 CentOS6.5 安装文档', '11', '2018-02-27 10:38:12', '并行监控在 CentOS6.5系统中的简单安装部署', null, '0', '360', null, null, '2018-02-27 10:38:12', null, null, null, '0', '0', '0', '0', '####  解压rpm包（官网可下载试用版）\r\nrpm -ivh paramon-mgr-8.0.0-1007.el6.x86_64.rpm\r\n- 启动服务\r\n- service paramon-mgr start\r\n- 关iptables\r\n- service iptables stop\r\n#### 改配置文件  /etc/paratera\r\n	改成自己需要监控的ip\r\n- sed -i \"s/127.0.0.1/192.168.0.203/g\" pcnt*\r\n- sed -i \"s/127.0.0.1/192.168.0.203/g\" psvr*\r\n- 改完后重启服务\r\n- service paramon-mgr restart\r\n![01](/upload/images/20180227//4a0277e3-c21d-41fe-b6ea-f5bd25c5b645.png \"01\")\r\n\r\n#### 查看host\r\nnc 127.0.0.1 10091|grep HOST\r\n![02](/upload/images/20180227//c71cb4f6-e2e5-4975-9e86-d6ffa2dc962c.png \"02\")\r\n\r\n#### 新建203.pmon文本文件\r\n![03](/upload/images/20180227//ea69c5c0-66d0-4059-917d-dde446c87380.png \"03\")\r\n#### 单机就安装好了，，，，\r\n![04](/upload/images/20180227//15424399-392f-4d83-8b56-bd760f82026a.png \"04\")\r\n\r\n#### 多台机器\r\n每台机器 \r\n- 解压rpm 包\r\n- 把第一台作为客户端的pcnt*文件scp 到所有需要监控的机器\r\nscp /etc/paratera/pcnt*   hostname:/etc/paratera/\r\n- 开启所有机器的服务\r\n- 改.pmon文件\r\n- 例如有50台机器\r\n![05](/upload/images/20180227//e35bf9a4-47dc-4534-9b57-44d9629ebc17.png \"05\")\r\n\r\n\r\n', '1', '<h4 id=\"h4--rpm-\"><a name=\"解压rpm包（官网可下载试用版）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>解压rpm包（官网可下载试用版）</h4><p>rpm -ivh paramon-mgr-8.0.0-1007.el6.x86_64.rpm</p>\r\n<ul>\r\n<li>启动服务</li><li>service paramon-mgr start</li><li>关iptables</li><li>service iptables stop<h4 id=\"h4--etc-paratera\"><a name=\"改配置文件  /etc/paratera\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>改配置文件  /etc/paratera</h4>  改成自己需要监控的ip</li><li>sed -i “s/127.0.0.1/192.168.0.203/g” pcnt*</li><li>sed -i “s/127.0.0.1/192.168.0.203/g” psvr*</li><li>改完后重启服务</li><li>service paramon-mgr restart<br><img src=\"/upload/images/20180227//4a0277e3-c21d-41fe-b6ea-f5bd25c5b645.png\" alt=\"01\" title=\"01\"></li></ul>\r\n<h4 id=\"h4--host\"><a name=\"查看host\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>查看host</h4><p>nc 127.0.0.1 10091|grep HOST<br><img src=\"/upload/images/20180227//c71cb4f6-e2e5-4975-9e86-d6ffa2dc962c.png\" alt=\"02\" title=\"02\"></p>\r\n<h4 id=\"h4--203-pmon-\"><a name=\"新建203.pmon文本文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>新建203.pmon文本文件</h4><p><img src=\"/upload/images/20180227//ea69c5c0-66d0-4059-917d-dde446c87380.png\" alt=\"03\" title=\"03\"></p>\r\n<h4 id=\"h4--\"><a name=\"单机就安装好了，，，，\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>单机就安装好了，，，，</h4><p><img src=\"/upload/images/20180227//15424399-392f-4d83-8b56-bd760f82026a.png\" alt=\"04\" title=\"04\"></p>\r\n<h4 id=\"h4-u591Au53F0u673Au5668\"><a name=\"多台机器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>多台机器</h4><p>每台机器 </p>\r\n<ul>\r\n<li>解压rpm 包</li><li>把第一台作为客户端的pcnt<em>文件scp 到所有需要监控的机器<br>scp /etc/paratera/pcnt</em>   hostname:/etc/paratera/</li><li>开启所有机器的服务</li><li>改.pmon文件</li><li>例如有50台机器<br><img src=\"/upload/images/20180227//e35bf9a4-47dc-4534-9b57-44d9629ebc17.png\" alt=\"05\" title=\"05\"></li></ul>\r\n');
INSERT INTO `tbl_archive` VALUES ('22', '0', 'OpenTSDB结合Grafana视图展现', '22', '2018-02-27 10:45:21', 'OpenTSDB结合Grafana视图展现', null, '0', '1170', '', '', '2018-02-27 10:45:21', '2018-04-11 09:22:22', null, null, '0', '0', '0', '0', '## OpenTSDB结合Grafana视图展现\n------\n### 1.OpenTSDB介绍\n    opentsdb是基于Hbase的分布式的，可伸缩的时间序列数据库。\n    它支持秒级数据采集所有metrics，支持永久存储，可以做容量规划，并很容易的接入到现有的报警系统里。\n    OpenTSDB可以从大规模的集群（包括集 群中的网络设备、操作系统、应用程序）中获取相应的metrics并进行存储、索引以及服务，从而使得这些数据更容易让人理解，如web化、图形化等。\n####    1.1 OpenTSDB存储\nopentsdb存储采用的是Hbase后端存储，再安装opentsdb的前提下先在机器上安装hbase组件\n####    1.2 OpenTSDB查询\nOpenTSDB提供了许多提取，处理和分析数据的方法。数据可以通过`CLI`工具，一个`HTTP API`来查询，并被视为一个GnuPlot图形。开源工具，如`Grafana`和`Bosun`还可以访问TSDB数据。(本文会做OpenTSDB与Grafana进行视图展现)\n\n### 2.Grafana介绍 \n    Grafana是一个可视化面板（Dashboard）。它最常用于对基础设施和应用分析的时间序列数据进行可视化处理，但许多用于其他领域，包括工业传感器，家庭自动化，天气和过程控制。\n####    2.1 Grafana数据源\n    支持Graphite、zabbix、InfluxDB、Prometheus和OpenTSDB作为数据源。Grafana主要特性：灵活丰富的图形化选项；可以混合多种风格；支持白天和夜间模式；多个数据源。\n\n----\n### OpenTSDB结合Grafana的前提条件\n*  opentsdb环境搭配成功（本文是基于CRH5.1安装[>>CRH5.1安装地址][1]）\n*  Grafana Windows版本或者linux版本其一\n*  数据信息量\n\n**OpenTSDB本文不介绍不安装，只介绍Grafana Linux版本安装**\n   \n####     Grafana Linux版本安装\n1.yum安装grafana\n```\nsudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.6.3-1.x86_64.rpm\n```\n![](/upload/images/20180203//72acf097-7b23-40bb-a30b-6e43919f3a44.png)\n![](/upload/images/20180203//1294654e-1266-42aa-bc6a-6bb394e803c1.png)\n\n2.安装成功之后启动服务\n```\nsudo service grafana-server start\n\n```\n3.\n设置grafana服务在机器启动时自启\n```\nsudo systemctl enable grafana-server.service\n```\n\n4.查看启动是否成功\n\n```\nsystemctl status grafana-server\n```\n![](/upload/images/20180203//2d957209-9698-458a-8a91-1fa72b78247b.png)\n\n#####   访问Grafana WEB页面结合OpenTSDB进行视图展现\n>默认端口：3000\n\n>我这里修改了下端口为：`3002`\n\n* 1、访问地址:192.168.0.239:3302   (ip:3302)\n* 2、 默认用户`admin` 密码`admin`\n![](/upload/images/20180203//672f0f4c-5a9c-44c5-a333-7ed1bde4f9d0.png)\n\n* 3、创建一个连接库\n	`点击create your first data source创建连接库`\n![](/upload/images/20180203//9b6bc31f-c5f5-4464-82bb-0396dc3ef1e4.jpg)\n* 4、选择所需要的连接库\n![](/upload/images/20180203//68d67c89-42a5-44f5-abcb-149bdbfc5f0e.jpg)\n![](/upload/images/20180203//cae500be-d6ad-4e18-865d-a17b5917f0aa.jpg)\n`Name：库的名称;`\n`Type：选择所需要的库（这里选择OpenTSDB）`\n`Url：optsdb的http访问地址`\n`Version：选择<=2.1版本（根据安装的opentsdb进行选择）`\n\n* 5、保存信息\n![](/upload/images/20180203//0ee697bd-df19-4a12-a976-0253b8f703f2.jpg)\n\n* 6、创建视图\n	返回home，点击New dashboard创建视图\n![](/upload/images/20180203//65bd9483-e543-4d74-b73c-c2a5c164d191.jpg)\n	\n	选择其中的一个进行视图展示，这里选择Graph面板\n	\n	![](/upload/images/20180203//81768644-556d-4d31-9995-55a5b3a22e48.png)\n\n* 7、视图设置\n	选择时间段\n	![](/upload/images/20180203//355e3c8c-952f-43a5-8a33-bd6cc5598b25.png)\n	\n	点击panelTitle 选择Edit 出现 Graph选项\n	\n	![](/upload/images/20180203//77d33318-191d-44b9-9307-0e9c3c275f0b.png)\n\n* 8、选择数据库以及展现的信息设置\n\n	![](/upload/images/20180203//9d340c68-7015-4f2c-af96-f7cf4cb398d2.png)\n	`Data Source :选择我们所建的库的名称`\n	`Metric:选择我们在OpenTsdb中的查询值`\n	`Down sample:是采样品的时间设置`\n	`Tags:opentsdb的key，value值信息`\n	`Aggregator:聚合函数sum、avg、count...`\n	\n* 9、配置完成后展示最终视图\n	折线图展示，折线可以拉伸，\n	也可在右上角设置自动刷新时间（5S刷新一次，根据需求）\n	![](/upload/images/20180203//830e554b-48be-410d-af92-e91ec2ed1702.png)\n\n  [1]: http://www.redoop.com/front/productinformation\n  [2]: https://grafana.com/grafana/download', '0', '<h2 id=\"h2-opentsdb-grafana-\"><a name=\"OpenTSDB结合Grafana视图展现\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>OpenTSDB结合Grafana视图展现</h2><hr>\n<h3 id=\"h3-1-opentsdb-\"><a name=\"1.OpenTSDB介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.OpenTSDB介绍</h3><pre><code>opentsdb是基于Hbase的分布式的，可伸缩的时间序列数据库。\n它支持秒级数据采集所有metrics，支持永久存储，可以做容量规划，并很容易的接入到现有的报警系统里。\nOpenTSDB可以从大规模的集群（包括集 群中的网络设备、操作系统、应用程序）中获取相应的metrics并进行存储、索引以及服务，从而使得这些数据更容易让人理解，如web化、图形化等。\n</code></pre><h4 id=\"h4-1-1-opentsdb-\"><a name=\"1.1 OpenTSDB存储\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1 OpenTSDB存储</h4><p>opentsdb存储采用的是Hbase后端存储，再安装opentsdb的前提下先在机器上安装hbase组件</p>\n<h4 id=\"h4-1-2-opentsdb-\"><a name=\"1.2 OpenTSDB查询\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2 OpenTSDB查询</h4><p>OpenTSDB提供了许多提取，处理和分析数据的方法。数据可以通过<code>CLI</code>工具，一个<code>HTTP API</code>来查询，并被视为一个GnuPlot图形。开源工具，如<code>Grafana</code>和<code>Bosun</code>还可以访问TSDB数据。(本文会做OpenTSDB与Grafana进行视图展现)</p>\n<h3 id=\"h3-2-grafana-\"><a name=\"2.Grafana介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.Grafana介绍</h3><pre><code>Grafana是一个可视化面板（Dashboard）。它最常用于对基础设施和应用分析的时间序列数据进行可视化处理，但许多用于其他领域，包括工业传感器，家庭自动化，天气和过程控制。\n</code></pre><h4 id=\"h4-2-1-grafana-\"><a name=\"2.1 Grafana数据源\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1 Grafana数据源</h4><pre><code>支持Graphite、zabbix、InfluxDB、Prometheus和OpenTSDB作为数据源。Grafana主要特性：灵活丰富的图形化选项；可以混合多种风格；支持白天和夜间模式；多个数据源。\n</code></pre><hr>\n<h3 id=\"h3-opentsdb-grafana-\"><a name=\"OpenTSDB结合Grafana的前提条件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>OpenTSDB结合Grafana的前提条件</h3><ul>\n<li>opentsdb环境搭配成功（本文是基于CRH5.1安装<a href=\"http://www.redoop.com/front/productinformation\">&gt;&gt;CRH5.1安装地址</a>）</li><li>Grafana Windows版本或者linux版本其一</li><li>数据信息量</li></ul>\n<p><strong>OpenTSDB本文不介绍不安装，只介绍Grafana Linux版本安装</strong></p>\n<h4 id=\"h4-grafana-linux-\"><a name=\"Grafana Linux版本安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Grafana Linux版本安装</h4><p>1.yum安装grafana</p>\n<pre><code>sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.6.3-1.x86_64.rpm\n</code></pre><p><img src=\"/upload/images/20180203//72acf097-7b23-40bb-a30b-6e43919f3a44.png\" alt=\"\"><br><img src=\"/upload/images/20180203//1294654e-1266-42aa-bc6a-6bb394e803c1.png\" alt=\"\"></p>\n<p>2.安装成功之后启动服务</p>\n<pre><code>sudo service grafana-server start\n</code></pre><p>3.<br>设置grafana服务在机器启动时自启</p>\n<pre><code>sudo systemctl enable grafana-server.service\n</code></pre><p>4.查看启动是否成功</p>\n<pre><code>systemctl status grafana-server\n</code></pre><p><img src=\"/upload/images/20180203//2d957209-9698-458a-8a91-1fa72b78247b.png\" alt=\"\"></p>\n<h5 id=\"h5--grafana-web-opentsdb-\"><a name=\"访问Grafana WEB页面结合OpenTSDB进行视图展现\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>访问Grafana WEB页面结合OpenTSDB进行视图展现</h5><blockquote>\n<p>默认端口：3000</p>\n<p>我这里修改了下端口为：<code>3002</code></p>\n</blockquote>\n<ul>\n<li>1、访问地址:192.168.0.239:3302   (ip:3302)</li><li><p>2、 默认用户<code>admin</code> 密码<code>admin</code><br><img src=\"/upload/images/20180203//672f0f4c-5a9c-44c5-a333-7ed1bde4f9d0.png\" alt=\"\"></p>\n</li><li><p>3、创建一个连接库<br>  <code>点击create your first data source创建连接库</code><br><img src=\"/upload/images/20180203//9b6bc31f-c5f5-4464-82bb-0396dc3ef1e4.jpg\" alt=\"\"></p>\n</li><li><p>4、选择所需要的连接库<br><img src=\"/upload/images/20180203//68d67c89-42a5-44f5-abcb-149bdbfc5f0e.jpg\" alt=\"\"><br><img src=\"/upload/images/20180203//cae500be-d6ad-4e18-865d-a17b5917f0aa.jpg\" alt=\"\"><br><code>Name：库的名称;</code><br><code>Type：选择所需要的库（这里选择OpenTSDB）</code><br><code>Url：optsdb的http访问地址</code><br><code>Version：选择&lt;=2.1版本（根据安装的opentsdb进行选择）</code></p>\n</li><li><p>5、保存信息<br><img src=\"/upload/images/20180203//0ee697bd-df19-4a12-a976-0253b8f703f2.jpg\" alt=\"\"></p>\n</li><li><p>6、创建视图<br>  返回home，点击New dashboard创建视图<br><img src=\"/upload/images/20180203//65bd9483-e543-4d74-b73c-c2a5c164d191.jpg\" alt=\"\"></p>\n<p>  选择其中的一个进行视图展示，这里选择Graph面板</p>\n<p>  <img src=\"/upload/images/20180203//81768644-556d-4d31-9995-55a5b3a22e48.png\" alt=\"\"></p>\n</li><li><p>7、视图设置<br>  选择时间段<br>  <img src=\"/upload/images/20180203//355e3c8c-952f-43a5-8a33-bd6cc5598b25.png\" alt=\"\"></p>\n<p>  点击panelTitle 选择Edit 出现 Graph选项</p>\n<p>  <img src=\"/upload/images/20180203//77d33318-191d-44b9-9307-0e9c3c275f0b.png\" alt=\"\"></p>\n</li><li><p>8、选择数据库以及展现的信息设置</p>\n<p>  <img src=\"/upload/images/20180203//9d340c68-7015-4f2c-af96-f7cf4cb398d2.png\" alt=\"\"><br>  <code>Data Source :选择我们所建的库的名称</code><br>  <code>Metric:选择我们在OpenTsdb中的查询值</code><br>  <code>Down sample:是采样品的时间设置</code><br>  <code>Tags:opentsdb的key，value值信息</code><br>  <code>Aggregator:聚合函数sum、avg、count...</code></p>\n</li><li><p>9、配置完成后展示最终视图<br>  折线图展示，折线可以拉伸，<br>  也可在右上角设置自动刷新时间（5S刷新一次，根据需求）<br>  <img src=\"/upload/images/20180203//830e554b-48be-410d-af92-e91ec2ed1702.png\" alt=\"\"></p>\n</li></ul>\n');
INSERT INTO `tbl_archive` VALUES ('23', '0', 'Hbase调优', '19', '2018-02-27 15:37:12', '##数据块大小的配置随机查询：数据块越小，索引越大，占用内存也越大，加载进内存的数据小，查找性能更好顺序查询：更好的顺序扫描，需要更大的数据块```>create\"stu\",{NAME=>\"cf\",BLOCKSIZE=>\"65536\"}```##数据块缓存的配置如果经常顺序访问或很少被访问，可以关闭列族的缓存，列族缓存默认打开```>create\"stu\",{NAME=>\"cf\",BLOCKCAC', null, '0', '566', null, null, '2018-02-27 15:37:12', null, null, null, '0', '0', '0', '0', '## 数据块大小的配置\n随机查询：数据块越小，索引越大，占用内存也越大，加载进内存的数据小，查找性能更好\n顺序查询：更好的顺序扫描，需要更大的数据块\n```\n> create \"stu\",{NAME => \"cf\",BLOCKSIZE =>\"65536\"}\n```\n\n## 数据块缓存的配置\n如果经常顺序访问或很少被访问，可以关闭列族的缓存，列族缓存默认打开\n```\n> create \"stu\",{NAME => \"cf\",BLOCKCACHE =>\"false\"}\n```\n\n## 激进缓存的配置\n可以选择一个列族赋予更高的优先级缓存\n```\n> create \"stu\",{NAME => \"cf\",IN_MEMORY =>\"true\"}\n```\n\n## 布隆过滤器的配置\n减少硬盘读取数据带来的开销，对储存的数据块做反向测试，占用额外的空间\n```\n> create \"stu\",{NAME => \"cf\",BLOOMFILTER =>\"ROWCOL\"}\n```\n\n## 生存时间配置(TTL)\n超过这个时间设置的就会在下一次大合并中被删除\n```\n> create \"stu\",{NAME => \"cf\",TTL =>\"18000\"}\n```\n\n## 压缩\n压缩可以节省空间，读写数据会增加CPU的使用率 LZO，SNAPPY，GZIP\n```\n> create \"stu\",{NAME => \"cf\",COMPRESSION =>\"GZIP\"}\n```\n\n## 单元时间版本\n默认维护一个时间版本\n```\n> create \"stu\",{NAME =>\"cf\",VERSIONS =>5}\n```\n\n设置hdfs中data的存储路径为多路径\n\n修改hdfs-site.xml中的dfs.data.dir\n\n设置java垃圾回收时的heap\n\n修改hbase-env.sh中的HBASE_HEAPSIZE=8000\n\n修改RegionServer与Zookeeper间的连接超时时间\n\nzookeeper.session.timeout=180000\n\n## Hbase客户端优化\nAutoFlush\n\n将HTable的setAutoFlush设为false(默认是true)，可以支持客户端批量更新。即当Put填满客户端flush缓存时，才发送到服务端。\n\nScan Caching\n\nscanner一次缓存多少数据来scan（从服务端一次抓多少数据回来scan）。默认值是 1，一次只取一条。\n\nScan Attribute Selection\n\nscan时建议指定需要的Column Family，减少通信量，否则scan操作默认会返回整个row的所有数据（所有Coulmn Family）。\n\n机架感知配置\n\n修改对应的topology.data的路径\n\n增加执行权限\n\n配置core-site.xml\n\ntoploygy.script.file.name=/usr/local/.../toploygy.sh \n\n同步到集群其它节点\n\n增加区域服务器的处理线程数\n\n本质增大RPC数量hbase-site.xml\n```\n<property>\n  <name>hbase.regionserver.handler.count</name>\n  <value>40</value>\n</property>\n```', '2', '<h2 id=\"h2-u6570u636Eu5757u5927u5C0Fu7684u914Du7F6E\"><a name=\"数据块大小的配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>数据块大小的配置</h2><p>随机查询：数据块越小，索引越大，占用内存也越大，加载进内存的数据小，查找性能更好<br>顺序查询：更好的顺序扫描，需要更大的数据块</p>\n<pre><code>&gt; create &quot;stu&quot;,{NAME =&gt; &quot;cf&quot;,BLOCKSIZE =&gt;&quot;65536&quot;}\n</code></pre><h2 id=\"h2-u6570u636Eu5757u7F13u5B58u7684u914Du7F6E\"><a name=\"数据块缓存的配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>数据块缓存的配置</h2><p>如果经常顺序访问或很少被访问，可以关闭列族的缓存，列族缓存默认打开</p>\n<pre><code>&gt; create &quot;stu&quot;,{NAME =&gt; &quot;cf&quot;,BLOCKCACHE =&gt;&quot;false&quot;}\n</code></pre><h2 id=\"h2-u6FC0u8FDBu7F13u5B58u7684u914Du7F6E\"><a name=\"激进缓存的配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>激进缓存的配置</h2><p>可以选择一个列族赋予更高的优先级缓存</p>\n<pre><code>&gt; create &quot;stu&quot;,{NAME =&gt; &quot;cf&quot;,IN_MEMORY =&gt;&quot;true&quot;}\n</code></pre><h2 id=\"h2-u5E03u9686u8FC7u6EE4u5668u7684u914Du7F6E\"><a name=\"布隆过滤器的配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>布隆过滤器的配置</h2><p>减少硬盘读取数据带来的开销，对储存的数据块做反向测试，占用额外的空间</p>\n<pre><code>&gt; create &quot;stu&quot;,{NAME =&gt; &quot;cf&quot;,BLOOMFILTER =&gt;&quot;ROWCOL&quot;}\n</code></pre><h2 id=\"h2--ttl-\"><a name=\"生存时间配置(TTL)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>生存时间配置(TTL)</h2><p>超过这个时间设置的就会在下一次大合并中被删除</p>\n<pre><code>&gt; create &quot;stu&quot;,{NAME =&gt; &quot;cf&quot;,TTL =&gt;&quot;18000&quot;}\n</code></pre><h2 id=\"h2-u538Bu7F29\"><a name=\"压缩\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>压缩</h2><p>压缩可以节省空间，读写数据会增加CPU的使用率 LZO，SNAPPY，GZIP</p>\n<pre><code>&gt; create &quot;stu&quot;,{NAME =&gt; &quot;cf&quot;,COMPRESSION =&gt;&quot;GZIP&quot;}\n</code></pre><h2 id=\"h2-u5355u5143u65F6u95F4u7248u672C\"><a name=\"单元时间版本\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>单元时间版本</h2><p>默认维护一个时间版本</p>\n<pre><code>&gt; create &quot;stu&quot;,{NAME =&gt;&quot;cf&quot;,VERSIONS =&gt;5}\n</code></pre><p>设置hdfs中data的存储路径为多路径</p>\n<p>修改hdfs-site.xml中的dfs.data.dir</p>\n<p>设置java垃圾回收时的heap</p>\n<p>修改hbase-env.sh中的HBASE_HEAPSIZE=8000</p>\n<p>修改RegionServer与Zookeeper间的连接超时时间</p>\n<p>zookeeper.session.timeout=180000</p>\n<h2 id=\"h2-hbase-\"><a name=\"Hbase客户端优化\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Hbase客户端优化</h2><p>AutoFlush</p>\n<p>将HTable的setAutoFlush设为false(默认是true)，可以支持客户端批量更新。即当Put填满客户端flush缓存时，才发送到服务端。</p>\n<p>Scan Caching</p>\n<p>scanner一次缓存多少数据来scan（从服务端一次抓多少数据回来scan）。默认值是 1，一次只取一条。</p>\n<p>Scan Attribute Selection</p>\n<p>scan时建议指定需要的Column Family，减少通信量，否则scan操作默认会返回整个row的所有数据（所有Coulmn Family）。</p>\n<p>机架感知配置</p>\n<p>修改对应的topology.data的路径</p>\n<p>增加执行权限</p>\n<p>配置core-site.xml</p>\n<p>toploygy.script.file.name=/usr/local/…/toploygy.sh </p>\n<p>同步到集群其它节点</p>\n<p>增加区域服务器的处理线程数</p>\n<p>本质增大RPC数量hbase-site.xml</p>\n<pre><code>&lt;property&gt;\n  &lt;name&gt;hbase.regionserver.handler.count&lt;/name&gt;\n  &lt;value&gt;40&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('24', '0', 'IB网络的配置与IB网络测试调研', '18', '2018-02-27 15:53:14', '#一配置IB网络##1.1.将MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64.tgz上传到制定目录下解压```tar-zxvfMLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64.tgz```##1.2.进入MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64执行```./mlnxofedinst', null, '0', '618', null, null, '2018-02-27 15:53:14', null, null, null, '0', '0', '0', '0', '# 一 配置IB网络\n## 1.1.将MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64.tgz上传到制定目录下解压\n```\ntar -zxvf MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64.tgz\n```\n## 1.2.进入MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64执行\n\n```\n./mlnxofedinstall\n```\n## 1.3.在此操作中会有报错，根据错误信息安装依赖\n\n```\nyum install -y tcl\nyum install -y gcc-gfortran\nyum install -y tk\n```\n## 1.4.再次执行./mlnxofedinstall经过等待驱动安装成功\n\n## 1.5.在/etc/sysconfig/network-scripts/ifcfg-ib0配置：ifcfg-ib0\n\n```\nTYPE=\"Infiniband\"\nDEVICE=\"ib0\"\nONBOOT=\"yes\"\nIPADDR=\"10.10.10.1\"\nNETMASK=\"255.255.255.0\"\n```\n\n## 1.6.重启机器\n\n## 1.7.执行/etc/init.d/openibd restart\n# 二  测试IB网络\n## 2.1 网卡信息查看\n### ibnodes命令，会发现端口连接的信息\n\n```\n[root@test01 ~]# ibnodes\nCa  : 0x0002c903000ae254 ports 2 \"up75 HCA-1\"\nCa  : 0x0002c903000ec606 ports 2 \"m04 HCA-1\"\n```\n### 2.1.1 ifconfig会发现ib端口\n\n```\nib0       Link encap:UNSPEC  HWaddr A0-00-02-20-FE-80-00-00-00-00-00-00-00-00-00-00  \n          UP BROADCAST MULTICAST  MTU:4092  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:256 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nib1       Link encap:UNSPEC  HWaddr A0-00-03-00-FE-80-00-00-00-00-00-00-00-00-00-00  \n          inet addr:10.10.10.1  Bcast:10.10.10.255  Mask:255.255.255.0\n          inet6 addr: fe80::202:c903:e:c608/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:2044  Metric:1\n          RX packets:54575 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:67623 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:256 \n          RX bytes:3174514 (3.1 MB)  TX bytes:891903946 (891.9 MB)\n```\n\n### 2.1.2 ibstatus可以查看网卡状态\n\n```\n[root@test01 ~]# ibstatus\nInfiniband device \'mlx4_0\' port 1 status:\n    default gid:     fe80:0000:0000:0000:0002:c903:000e:c607\n    base lid:    0x0\n    sm lid:      0x0\n    state:       1: DOWN\n    phys state:  2: Polling\n    rate:        10 Gb/sec (4X)\n    link_layer:  InfiniBand\n\nInfiniband device \'mlx4_0\' port 2 status:\n    default gid:     fe80:0000:0000:0000:0002:c903:000e:c608\n    base lid:    0x1\n    sm lid:      0x1\n    state:       4: ACTIVE\n    phys state:  5: LinkUp\n    rate:        40 Gb/sec (4X QDR)\n    link_layer:  InfiniBand\n```\n## 2.2 2台机器无需交换机连通使用opensm(需root权限)\n\n```\n[root@test01 ~]# opensm\n-------------------------------------------------\nOpenSM 4.7.0.MLNX20160523.25f7c7a\nCommand Line Arguments:\n Log File: /var/log/opensm.log\n-------------------------------------------------\nOpenSM 4.7.0.MLNX20160523.25f7c7a\n\nUsing default GUID 0x2c903000ec608\nEntering DISCOVERING state\n\nEntering MASTER state\n```\n\n### 2.2.1 此时可以互ping：\n\n```\n[root@test01 ~]# ping 10.10.10.2\nPING 10.10.10.2 (10.10.0.2) 56(84) bytes of data.\n64 bytes from 10.10.10.2: icmp_seq=1 ttl=64 time=0.294 ms\n64 bytes from 10.10.10.2: icmp_seq=2 ttl=64 time=0.155 ms\n64 bytes from 10.10.10.2: icmp_seq=3 ttl=64 time=0.151 ms\n64 bytes from 10.10.10.2: icmp_seq=4 ttl=64 time=0.155 ms\n^C\n--- 10.0.0.2 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3000ms\nrtt min/avg/max/mdev = 0.151/0.188/0.294/0.063 ms\n```\n\n## 2.3 速度测试\n### 2.3.1 一台机器开启opensm(需root权限)，使用ib_send_bw\n### 2.3.2 把一台机器作为server：\n\n```\n[root@test01 ~]# ib_send_bw -a -c UD -d mlx_0 -i 2\n\n************************************\n* Waiting for client to connect... *\n************************************\n```\n\n### 2.3.3把另外一台机器作为client：\n\n```\n[root@test02 ~]# ib_send_bw -a -c UD -d mlx4_0 -i 2 10.10.10.1\n Max msg size in UD is MTU 4096\n Changing to this MTU\n---------------------------------------------------------------------------------------\n                    Send BW Test\n Dual-port       : OFF      Device         : mlx4_0\n Number of qps   : 1        Transport type : IB\n Connection type : UD       Using SRQ      : OFF\n TX depth        : 128\n CQ Moderation   : 100\n Mtu             : 4096[B]\n Link type       : IB\n Max inline data : 0[B]\n rdma_cm QPs     : OFF\n Data ex. method : Ethernet\n---------------------------------------------------------------------------------------\n local address: LID 0x02 QPN 0x0238 PSN 0xf162c2\n remote address: LID 0x01 QPN 0x021a PSN 0xbc213c\n---------------------------------------------------------------------------------------\n #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]\n 2          1000             5.72               5.20           2.727911\n 4          1000             11.49              11.34          2.972020\n 8          1000             22.99              22.61          2.963387\n 16         1000             45.98              45.31          2.969666\n 32         1000             91.70              90.55          2.967229\n 64         1000             183.14             180.77         2.961664\n 128        1000             366.79             361.35         2.960143\n 256        1000             727.44             718.16         2.941597\n 512        1000             1088.50            1044.70        2.139549\n 1024       1000             1264.96            1263.29        1.293610\n 2048       1000             1407.22            1406.43        0.720094\n 4096       1000             1492.93            1492.75        0.382143\n```\n## 2.4 延迟测试\n### 2.4.1 一台机器开启opensm(需root权限)，使用ib_send_lat\n###  2.4.2 把一台机器作为server：\n\n```\n[root@test01 ~]# ib_send_lat -a -c UD -d mlx4_0 -i 2\n\n************************************\n* Waiting for client to connect... *\n************************************\n```\n\n### 2.4.3 把另外一台机器作为client：\n\n```\n[root@test02 ~]# ib_send_lat -a -c UD -d mlx4_0 -i 2 10.10.10.1\n Max msg size in UD is MTU 4096\n Changing to this MTU\n---------------------------------------------------------------------------------------\n                    Send Latency Test\n Dual-port       : OFF      Device         : mlx4_0\n Number of qps   : 1        Transport type : IB\n Connection type : UD       Using SRQ      : OFF\n TX depth        : 1\n Mtu             : 4096[B]\n Link type       : IB\n Max inline data : 188[B]\n rdma_cm QPs     : OFF\n Data ex. method : Ethernet\n---------------------------------------------------------------------------------------\n local address: LID 0x02 QPN 0x0239 PSN 0x29d370\n remote address: LID 0x01 QPN 0x021b PSN 0xbc98c4\n---------------------------------------------------------------------------------------\n #bytes #iterations    t_min[usec]    t_max[usec]  t_typical[usec]\n 2       1000          1.25           14.72        1.34   \n 4       1000          1.24           88.94        1.27   \n 8       1000          1.20           77.49        1.22   \n 16      1000          1.21           66.69        1.23   \n 32      1000          1.23           61.58        1.25   \n 64      1000          1.27           12.92        1.30   \n 128     1000          1.42           6.98         1.44   \n 256     1000          1.94           173.62       1.97   \n 512     1000          2.22           41.65        2.25   \n 1024    1000          2.79           37.47        2.81   \n 2048    1000          3.91           18.85        3.94   \n 4096    1000          6.16           38.06        6.20   \n---------------------------------------------------------------------------------------\n```\n', '0', '<h1 id=\"h1--ib-\"><a name=\"一 配置IB网络\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>一 配置IB网络</h1><h2 id=\"h2-1-1-mlnx_ofed_linux-4-1-1-0-2-0-rhel7-2-x86_64-tgz-\"><a name=\"1.1.将MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64.tgz上传到制定目录下解压\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1.将MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64.tgz上传到制定目录下解压</h2><pre><code>tar -zxvf MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64.tgz\n</code></pre><h2 id=\"h2-1-2-mlnx_ofed_linux-4-1-1-0-2-0-rhel7-2-x86_64-\"><a name=\"1.2.进入MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64执行\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2.进入MLNX_OFED_LINUX-4.1-1.0.2.0-rhel7.2-x86_64执行</h2><pre><code>./mlnxofedinstall\n</code></pre><h2 id=\"h2-1-3-\"><a name=\"1.3.在此操作中会有报错，根据错误信息安装依赖\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3.在此操作中会有报错，根据错误信息安装依赖</h2><pre><code>yum install -y tcl\nyum install -y gcc-gfortran\nyum install -y tk\n</code></pre><h2 id=\"h2-1-4-mlnxofedinstall-\"><a name=\"1.4.再次执行./mlnxofedinstall经过等待驱动安装成功\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4.再次执行./mlnxofedinstall经过等待驱动安装成功</h2><h2 id=\"h2-1-5-etc-sysconfig-network-scripts-ifcfg-ib0-ifcfg-ib0\"><a name=\"1.5.在/etc/sysconfig/network-scripts/ifcfg-ib0配置：ifcfg-ib0\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.5.在/etc/sysconfig/network-scripts/ifcfg-ib0配置：ifcfg-ib0</h2><pre><code>TYPE=&quot;Infiniband&quot;\nDEVICE=&quot;ib0&quot;\nONBOOT=&quot;yes&quot;\nIPADDR=&quot;10.10.10.1&quot;\nNETMASK=&quot;255.255.255.0&quot;\n</code></pre><h2 id=\"h2-1-6-\"><a name=\"1.6.重启机器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.6.重启机器</h2><h2 id=\"h2-1-7-etc-init-d-openibd-restart\"><a name=\"1.7.执行/etc/init.d/openibd restart\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.7.执行/etc/init.d/openibd restart</h2><h1 id=\"h1--ib-\"><a name=\"二  测试IB网络\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>二  测试IB网络</h1><h2 id=\"h2-2-1-\"><a name=\"2.1 网卡信息查看\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1 网卡信息查看</h2><h3 id=\"h3-ibnodes-\"><a name=\"ibnodes命令，会发现端口连接的信息\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>ibnodes命令，会发现端口连接的信息</h3><pre><code>[root@test01 ~]# ibnodes\nCa  : 0x0002c903000ae254 ports 2 &quot;up75 HCA-1&quot;\nCa  : 0x0002c903000ec606 ports 2 &quot;m04 HCA-1&quot;\n</code></pre><h3 id=\"h3-2-1-1-ifconfig-ib-\"><a name=\"2.1.1 ifconfig会发现ib端口\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.1 ifconfig会发现ib端口</h3><pre><code>ib0       Link encap:UNSPEC  HWaddr A0-00-02-20-FE-80-00-00-00-00-00-00-00-00-00-00  \n          UP BROADCAST MULTICAST  MTU:4092  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:256 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nib1       Link encap:UNSPEC  HWaddr A0-00-03-00-FE-80-00-00-00-00-00-00-00-00-00-00  \n          inet addr:10.10.10.1  Bcast:10.10.10.255  Mask:255.255.255.0\n          inet6 addr: fe80::202:c903:e:c608/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:2044  Metric:1\n          RX packets:54575 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:67623 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:256 \n          RX bytes:3174514 (3.1 MB)  TX bytes:891903946 (891.9 MB)\n</code></pre><h3 id=\"h3-2-1-2-ibstatus-\"><a name=\"2.1.2 ibstatus可以查看网卡状态\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1.2 ibstatus可以查看网卡状态</h3><pre><code>[root@test01 ~]# ibstatus\nInfiniband device &#39;mlx4_0&#39; port 1 status:\n    default gid:     fe80:0000:0000:0000:0002:c903:000e:c607\n    base lid:    0x0\n    sm lid:      0x0\n    state:       1: DOWN\n    phys state:  2: Polling\n    rate:        10 Gb/sec (4X)\n    link_layer:  InfiniBand\n\nInfiniband device &#39;mlx4_0&#39; port 2 status:\n    default gid:     fe80:0000:0000:0000:0002:c903:000e:c608\n    base lid:    0x1\n    sm lid:      0x1\n    state:       4: ACTIVE\n    phys state:  5: LinkUp\n    rate:        40 Gb/sec (4X QDR)\n    link_layer:  InfiniBand\n</code></pre><h2 id=\"h2-2-2-2-opensm-root-\"><a name=\"2.2 2台机器无需交换机连通使用opensm(需root权限)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2 2台机器无需交换机连通使用opensm(需root权限)</h2><pre><code>[root@test01 ~]# opensm\n-------------------------------------------------\nOpenSM 4.7.0.MLNX20160523.25f7c7a\nCommand Line Arguments:\n Log File: /var/log/opensm.log\n-------------------------------------------------\nOpenSM 4.7.0.MLNX20160523.25f7c7a\n\nUsing default GUID 0x2c903000ec608\nEntering DISCOVERING state\n\nEntering MASTER state\n</code></pre><h3 id=\"h3-2-2-1-ping-\"><a name=\"2.2.1 此时可以互ping：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2.1 此时可以互ping：</h3><pre><code>[root@test01 ~]# ping 10.10.10.2\nPING 10.10.10.2 (10.10.0.2) 56(84) bytes of data.\n64 bytes from 10.10.10.2: icmp_seq=1 ttl=64 time=0.294 ms\n64 bytes from 10.10.10.2: icmp_seq=2 ttl=64 time=0.155 ms\n64 bytes from 10.10.10.2: icmp_seq=3 ttl=64 time=0.151 ms\n64 bytes from 10.10.10.2: icmp_seq=4 ttl=64 time=0.155 ms\n^C\n--- 10.0.0.2 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3000ms\nrtt min/avg/max/mdev = 0.151/0.188/0.294/0.063 ms\n</code></pre><h2 id=\"h2-2-3-\"><a name=\"2.3 速度测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3 速度测试</h2><h3 id=\"h3-2-3-1-opensm-root-ib_send_bw\"><a name=\"2.3.1 一台机器开启opensm(需root权限)，使用ib_send_bw\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.1 一台机器开启opensm(需root权限)，使用ib_send_bw</h3><h3 id=\"h3-2-3-2-server-\"><a name=\"2.3.2 把一台机器作为server：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.2 把一台机器作为server：</h3><pre><code>[root@test01 ~]# ib_send_bw -a -c UD -d mlx_0 -i 2\n\n************************************\n* Waiting for client to connect... *\n************************************\n</code></pre><h3 id=\"h3-2-3-3-client-\"><a name=\"2.3.3把另外一台机器作为client：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.3把另外一台机器作为client：</h3><pre><code>[root@test02 ~]# ib_send_bw -a -c UD -d mlx4_0 -i 2 10.10.10.1\n Max msg size in UD is MTU 4096\n Changing to this MTU\n---------------------------------------------------------------------------------------\n                    Send BW Test\n Dual-port       : OFF      Device         : mlx4_0\n Number of qps   : 1        Transport type : IB\n Connection type : UD       Using SRQ      : OFF\n TX depth        : 128\n CQ Moderation   : 100\n Mtu             : 4096[B]\n Link type       : IB\n Max inline data : 0[B]\n rdma_cm QPs     : OFF\n Data ex. method : Ethernet\n---------------------------------------------------------------------------------------\n local address: LID 0x02 QPN 0x0238 PSN 0xf162c2\n remote address: LID 0x01 QPN 0x021a PSN 0xbc213c\n---------------------------------------------------------------------------------------\n #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]\n 2          1000             5.72               5.20           2.727911\n 4          1000             11.49              11.34          2.972020\n 8          1000             22.99              22.61          2.963387\n 16         1000             45.98              45.31          2.969666\n 32         1000             91.70              90.55          2.967229\n 64         1000             183.14             180.77         2.961664\n 128        1000             366.79             361.35         2.960143\n 256        1000             727.44             718.16         2.941597\n 512        1000             1088.50            1044.70        2.139549\n 1024       1000             1264.96            1263.29        1.293610\n 2048       1000             1407.22            1406.43        0.720094\n 4096       1000             1492.93            1492.75        0.382143\n</code></pre><h2 id=\"h2-2-4-\"><a name=\"2.4 延迟测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4 延迟测试</h2><h3 id=\"h3-2-4-1-opensm-root-ib_send_lat\"><a name=\"2.4.1 一台机器开启opensm(需root权限)，使用ib_send_lat\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.1 一台机器开启opensm(需root权限)，使用ib_send_lat</h3><h3 id=\"h3-2-4-2-server-\"><a name=\"2.4.2 把一台机器作为server：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.2 把一台机器作为server：</h3><pre><code>[root@test01 ~]# ib_send_lat -a -c UD -d mlx4_0 -i 2\n\n************************************\n* Waiting for client to connect... *\n************************************\n</code></pre><h3 id=\"h3-2-4-3-client-\"><a name=\"2.4.3 把另外一台机器作为client：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.3 把另外一台机器作为client：</h3><pre><code>[root@test02 ~]# ib_send_lat -a -c UD -d mlx4_0 -i 2 10.10.10.1\n Max msg size in UD is MTU 4096\n Changing to this MTU\n---------------------------------------------------------------------------------------\n                    Send Latency Test\n Dual-port       : OFF      Device         : mlx4_0\n Number of qps   : 1        Transport type : IB\n Connection type : UD       Using SRQ      : OFF\n TX depth        : 1\n Mtu             : 4096[B]\n Link type       : IB\n Max inline data : 188[B]\n rdma_cm QPs     : OFF\n Data ex. method : Ethernet\n---------------------------------------------------------------------------------------\n local address: LID 0x02 QPN 0x0239 PSN 0x29d370\n remote address: LID 0x01 QPN 0x021b PSN 0xbc98c4\n---------------------------------------------------------------------------------------\n #bytes #iterations    t_min[usec]    t_max[usec]  t_typical[usec]\n 2       1000          1.25           14.72        1.34   \n 4       1000          1.24           88.94        1.27   \n 8       1000          1.20           77.49        1.22   \n 16      1000          1.21           66.69        1.23   \n 32      1000          1.23           61.58        1.25   \n 64      1000          1.27           12.92        1.30   \n 128     1000          1.42           6.98         1.44   \n 256     1000          1.94           173.62       1.97   \n 512     1000          2.22           41.65        2.25   \n 1024    1000          2.79           37.47        2.81   \n 2048    1000          3.91           18.85        3.94   \n 4096    1000          6.16           38.06        6.20   \n---------------------------------------------------------------------------------------\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('25', '0', 'XLearning在CRH平台定制软件包的自动化部署', '24', '2018-02-27 16:00:11', '#添加XLEARNING服务##1.修改CRHyarn配置，添加mapreduce相关jar的路径选中YARN组件，选择‘配置’选卡-‘Advanced’选项-高级yarn-site,在yarn.application.classpath属性框里，追加‘,/usr/crh/current/hadoop-mapreduce-client/*,/usr/crh/current/hadoop-mapre', null, '0', '510', null, null, '2018-02-27 16:00:11', '2018-06-12 10:46:39', null, null, '0', '0', '0', '0', '# 一. 添加XLEARNING服务\n## 1. 修改CRH yarn配置，添加mapreduce相关jar的路径\n选中YARN组件，选择‘配置’选卡-‘Advanced’选项-高级yarn-site,在yarn.application.classpath\n属性框里，追加下面内容，保存退出。重启Hadoop相关服务。\n```shell\n,/usr/crh/current/hadoop-mapreduce-client/*, /usr/crh/current/hadoop-mapreduce-client/lib/*\n```\n## 2. 拷贝XLEARNING包\n将XLEARNING包拷贝到/var/lib/ambari-server/resources/stacks/CRH/5.1/services/目录下。\n注：如果是CRH的其他版本，此目录会有变化，如果目录更改，需修改XLEARNING/package/scripts/jobhistory.py脚本中的相应路径。如下图\n![](/upload/images/20180313//13fd6f36-87f2-4645-9b20-d94f2b495d1e.png)\n## 3. 配置JAVA_HOME,HADOOP_CONF_DIR\n进入 xlearning-1.2/conf目录，编辑xlearning-env.sh文件，设置JAVA_HOME路径,如/usr/lib/jvm/jdk1.8.0_60;设置HADOOP_CONF_DIR路径，如/usr/crh/5.0.2.4-1136/hadoop/conf。\n```shell\nexport JAVA_HOME=/usr/lib/jvm/jdk1.8.0_60\nexport HADOOP_CONF_DIR=/usr/crh/5.0.2.4-1136/hadoop/conf\n```\n## 4. 修改主机名\n进入 xlearning-1.2/conf目录，编辑xlearning-site.xml文件，修改xlearning.history.webapp.address和xlearning.history.webapp.https.address属性值的主机名为本机主机名，如bogon\n![](/upload/images/20180313//fcff3b03-0f69-40d2-ab61-9c6e0492a6bf.png)\n## 5. 删除log文件\n删除xlearning-1.2下的log文件夹 rm -f log/\n\n# 二. 利用ambari向导安装XLEAENING组件\n## 1. 重启ambari server\n    ambari-server restart\n## 2. 添加xlearning组件\n行动-添加服务，打开添加服务向导，在选择服务页面，勾选xlearning，点击下一步，按照向导提示，点击下一步，在核查选项处，点击部署，安装，启动jobhistory。\n![](/upload/images/20180227//ae1f9550-06b2-4835-afd5-0fa48753419e.png)\n![](/upload/images/20180227//9dcabf46-0ad2-4461-9d85-b22580a555c6.png)\n![](/upload/images/20180227//b7737aa1-bd59-4bb0-a272-00af86836544.png)\n安装成功后，点击下一步，点击完成。\n![](/upload/images/20180227//3fe426e4-4f92-40c5-92f7-e08453f4cc42.png)\n## 3.使用caffe或TensorFlow运行示例\n### (1)配置XLEARNING_HOME\n```shell\nexport XLEARNING_HOME=/var/lib/ambari-server/resources/stacks/CRH/5.1/services/XLEARNING/xlearning-1.2\n```\n### (2)创建目录\n```shell\nhadoop fs -mkdir -p /tmp/XLearning/history\nhadoop fs -mkdir -p /tmp/XLearning/eventLog\nhadoop fs -mkdir -p /tmp/XLearning/staging\n```\n### (3)上传数据到HDFS\n```shell\nhadoop fs -put data /tmp/\n```\n### (4)执行示例\n```shell\ncd examples/tensorflow\nsh run.sh```\n![](/upload/images/20180227//8559d71c-619f-4bf6-ad01-381094310aa6.png)\n```shell\ncd examples/caffe\nsh run.sh\n```\n![](/upload/images/20180227//4206bf9e-9df4-4b44-97fb-27dff0fb4971.png)\n', '1', '<h1 id=\"h1--xlearning-\"><a name=\"一. 添加XLEARNING服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>一. 添加XLEARNING服务</h1><h2 id=\"h2-1-crh-yarn-mapreduce-jar-\"><a name=\"1. 修改CRH yarn配置，添加mapreduce相关jar的路径\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. 修改CRH yarn配置，添加mapreduce相关jar的路径</h2><p>选中YARN组件，选择‘配置’选卡-‘Advanced’选项-高级yarn-site,在yarn.application.classpath<br>属性框里，追加下面内容，保存退出。重启Hadoop相关服务。</p>\n<pre><code class=\"lang-shell\">,/usr/crh/current/hadoop-mapreduce-client/*, /usr/crh/current/hadoop-mapreduce-client/lib/*\n</code></pre>\n<h2 id=\"h2-2-xlearning-\"><a name=\"2. 拷贝XLEARNING包\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2. 拷贝XLEARNING包</h2><p>将XLEARNING包拷贝到/var/lib/ambari-server/resources/stacks/CRH/5.1/services/目录下。<br>注：如果是CRH的其他版本，此目录会有变化，如果目录更改，需修改XLEARNING/package/scripts/jobhistory.py脚本中的相应路径。如下图<br><img src=\"/upload/images/20180313//13fd6f36-87f2-4645-9b20-d94f2b495d1e.png\" alt=\"\"></p>\n<h2 id=\"h2-3-java_home-hadoop_conf_dir\"><a name=\"3. 配置JAVA_HOME,HADOOP_CONF_DIR\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3. 配置JAVA_HOME,HADOOP_CONF_DIR</h2><p>进入 xlearning-1.2/conf目录，编辑xlearning-env.sh文件，设置JAVA_HOME路径,如/usr/lib/jvm/jdk1.8.0_60;设置HADOOP_CONF_DIR路径，如/usr/crh/5.0.2.4-1136/hadoop/conf。</p>\n<pre><code class=\"lang-shell\">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_60\nexport HADOOP_CONF_DIR=/usr/crh/5.0.2.4-1136/hadoop/conf\n</code></pre>\n<h2 id=\"h2-4-\"><a name=\"4. 修改主机名\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4. 修改主机名</h2><p>进入 xlearning-1.2/conf目录，编辑xlearning-site.xml文件，修改xlearning.history.webapp.address和xlearning.history.webapp.https.address属性值的主机名为本机主机名，如bogon<br><img src=\"/upload/images/20180313//fcff3b03-0f69-40d2-ab61-9c6e0492a6bf.png\" alt=\"\"></p>\n<h2 id=\"h2-5-log-\"><a name=\"5. 删除log文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5. 删除log文件</h2><p>删除xlearning-1.2下的log文件夹 rm -f log/</p>\n<h1 id=\"h1--ambari-xleaening-\"><a name=\"二. 利用ambari向导安装XLEAENING组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>二. 利用ambari向导安装XLEAENING组件</h1><h2 id=\"h2-1-ambari-server\"><a name=\"1. 重启ambari server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. 重启ambari server</h2><pre><code>ambari-server restart\n</code></pre><h2 id=\"h2-2-xlearning-\"><a name=\"2. 添加xlearning组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2. 添加xlearning组件</h2><p>行动-添加服务，打开添加服务向导，在选择服务页面，勾选xlearning，点击下一步，按照向导提示，点击下一步，在核查选项处，点击部署，安装，启动jobhistory。<br><img src=\"/upload/images/20180227//ae1f9550-06b2-4835-afd5-0fa48753419e.png\" alt=\"\"><br><img src=\"/upload/images/20180227//9dcabf46-0ad2-4461-9d85-b22580a555c6.png\" alt=\"\"><br><img src=\"/upload/images/20180227//b7737aa1-bd59-4bb0-a272-00af86836544.png\" alt=\"\"><br>安装成功后，点击下一步，点击完成。<br><img src=\"/upload/images/20180227//3fe426e4-4f92-40c5-92f7-e08453f4cc42.png\" alt=\"\"></p>\n<h2 id=\"h2-3-caffe-tensorflow-\"><a name=\"3.使用caffe或TensorFlow运行示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.使用caffe或TensorFlow运行示例</h2><h3 id=\"h3--1-xlearning_home\"><a name=\"(1)配置XLEARNING_HOME\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>(1)配置XLEARNING_HOME</h3><pre><code class=\"lang-shell\">export XLEARNING_HOME=/var/lib/ambari-server/resources/stacks/CRH/5.1/services/XLEARNING/xlearning-1.2\n</code></pre>\n<h3 id=\"h3--2-\"><a name=\"(2)创建目录\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>(2)创建目录</h3><pre><code class=\"lang-shell\">hadoop fs -mkdir -p /tmp/XLearning/history\nhadoop fs -mkdir -p /tmp/XLearning/eventLog\nhadoop fs -mkdir -p /tmp/XLearning/staging\n</code></pre>\n<h3 id=\"h3--3-hdfs\"><a name=\"(3)上传数据到HDFS\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>(3)上传数据到HDFS</h3><pre><code class=\"lang-shell\">hadoop fs -put data /tmp/\n</code></pre>\n<h3 id=\"h3--4-\"><a name=\"(4)执行示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>(4)执行示例</h3><pre><code class=\"lang-shell\">cd examples/tensorflow\nsh run.sh\n</code></pre>\n<p><img src=\"/upload/images/20180227//8559d71c-619f-4bf6-ad01-381094310aa6.png\" alt=\"\"></p>\n<pre><code class=\"lang-shell\">cd examples/caffe\nsh run.sh\n</code></pre>\n<p><img src=\"/upload/images/20180227//4206bf9e-9df4-4b44-97fb-27dff0fb4971.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('26', '0', 'crh5.1与ssm单机整合', '10', '2018-02-27 16:52:03', 'crh5.1与ssm单机整合', null, '0', '304', null, null, '2018-02-27 16:52:03', '2018-02-27 16:59:23', null, null, '0', '0', '0', '0', '##  一、搭建crh5.1\n###  1、配置datanode路径要加异构存储标签\n[SSD]file:///mnt/ssd_1,[SSD]file:///mnt/ssd_2,[DISK]file:///mnt/sata_1,[DISK]file:///mnt/sata_2,[ARCHIVE]file:///mnt/archive_1,[ARCHIVE]file:///mnt/archive_2\n\n## 二、编译ssm\n### 1、ssm介绍：\n   https://github.com/Intel-bigdata/SSM\n### 2、编译方法参考：\nhttps://github.com/Intel-bigdata/SSM/blob/trunk/docs/ssm-deployment-guide.md\n\n## 三、安装mariadb\n1、文档推荐使用mysql或SSM-TiDB\n   因为使用的centos7系统，就用了mariadb，测试可用\n2、使用mariadb的话需要下载mariadb-java-client-1.7.2.jar放到ssm程序的lib下\n3、创建ssm数据库\n\n## 四、配置ssm与crh整合，启动\n### 1、配置方法参考：\n   https://github.com/Intel-bigdata/SSM/blob/trunk/docs/ssm-deployment-guide.md\n   配置core-site.xml和hadoop-env.sh\n### 2、出现问题\n报错：启动报错Access denied for user root. Superuser privilege is required\n解决：在程序目录bin路径下，启动环境配置common.sh添加：\n export HADOOP_USER_NAME=hdfs\n \n##  五、测试ssm\n访问ip：7045，添加rule\n   file: path matches \"/aaa/*\" | allssd\n   向/aaa路径下传个文件，查看数据目录如下：\n   \n   [root@node102 mnt]# du --max-depth=1 -h\n16K	./ssd_1\n16K	./ssd_2\n130M	./sata_1\n33M	./sata_2\n16K	./archive_2\n16K	./archive_1\n\n执行rule，再次查看：\n\n[root@node102 mnt]# du --max-depth=1 -h\n130M	./ssd_1\n33M	./ssd_2\n16K	./sata_1\n16K	./sata_2\n16K	./archive_2\n16K	./archive_1\n\n可以看到数据有sata目录被移动到了ssd目录，测试可用。', '1', '<h2 id=\"h2--crh5-1\"><a name=\"一、搭建crh5.1\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>一、搭建crh5.1</h2><h3 id=\"h3-1-datanode-\"><a name=\"1、配置datanode路径要加异构存储标签\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1、配置datanode路径要加异构存储标签</h3><p>[SSD]file:///mnt/ssd_1,[SSD]file:///mnt/ssd_2,[DISK]file:///mnt/sata_1,[DISK]file:///mnt/sata_2,[ARCHIVE]file:///mnt/archive_1,[ARCHIVE]file:///mnt/archive_2</p>\n<h2 id=\"h2--ssm\"><a name=\"二、编译ssm\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>二、编译ssm</h2><h3 id=\"h3-1-ssm-\"><a name=\"1、ssm介绍：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1、ssm介绍：</h3><p>   <a href=\"https://github.com/Intel-bigdata/SSM\">https://github.com/Intel-bigdata/SSM</a></p>\n<h3 id=\"h3-2-\"><a name=\"2、编译方法参考：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2、编译方法参考：</h3><p><a href=\"https://github.com/Intel-bigdata/SSM/blob/trunk/docs/ssm-deployment-guide.md\">https://github.com/Intel-bigdata/SSM/blob/trunk/docs/ssm-deployment-guide.md</a></p>\n<h2 id=\"h2--mariadb\"><a name=\"三、安装mariadb\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>三、安装mariadb</h2><p>1、文档推荐使用mysql或SSM-TiDB<br>   因为使用的centos7系统，就用了mariadb，测试可用<br>2、使用mariadb的话需要下载mariadb-java-client-1.7.2.jar放到ssm程序的lib下<br>3、创建ssm数据库</p>\n<h2 id=\"h2--ssm-crh-\"><a name=\"四、配置ssm与crh整合，启动\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>四、配置ssm与crh整合，启动</h2><h3 id=\"h3-1-\"><a name=\"1、配置方法参考：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1、配置方法参考：</h3><p>   <a href=\"https://github.com/Intel-bigdata/SSM/blob/trunk/docs/ssm-deployment-guide.md\">https://github.com/Intel-bigdata/SSM/blob/trunk/docs/ssm-deployment-guide.md</a><br>   配置core-site.xml和hadoop-env.sh</p>\n<h3 id=\"h3-2-\"><a name=\"2、出现问题\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2、出现问题</h3><p>报错：启动报错Access denied for user root. Superuser privilege is required<br>解决：在程序目录bin路径下，启动环境配置common.sh添加：<br> export HADOOP_USER_NAME=hdfs</p>\n<h2 id=\"h2--ssm\"><a name=\"五、测试ssm\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>五、测试ssm</h2><p>访问ip：7045，添加rule<br>   file: path matches “/aaa/*” | allssd<br>   向/aaa路径下传个文件，查看数据目录如下：</p>\n<p>   [root<a href=\"https://github.com/node102\" title=\"&#64;node102\" class=\"at-link\">@node102</a> mnt]# du —max-depth=1 -h<br>16K    ./ssd_1<br>16K    ./ssd_2<br>130M    ./sata_1<br>33M    ./sata_2<br>16K    ./archive_2<br>16K    ./archive_1</p>\n<p>执行rule，再次查看：</p>\n<p>[root<a href=\"https://github.com/node102\" title=\"&#64;node102\" class=\"at-link\">@node102</a> mnt]# du —max-depth=1 -h<br>130M    ./ssd_1<br>33M    ./ssd_2<br>16K    ./sata_1<br>16K    ./sata_2<br>16K    ./archive_2<br>16K    ./archive_1</p>\n<p>可以看到数据有sata目录被移动到了ssd目录，测试可用。</p>\n');
INSERT INTO `tbl_archive` VALUES ('28', '0', 'caffe安装中组件cuda和cudnn配置方法', '26', '2018-02-27 17:36:15', '在安装caffe时发现组件cuda版本不匹配，需要重装cuda和cudnn。', null, '0', '396', null, null, '2018-02-27 17:36:15', null, null, null, '0', '0', '0', '0', '首先卸载已经安装的cuda：\n```shell\nsudo yum remove /usr/local/cuda-7.5\n```\n查看信息1：\n```shell\nlspci | grep -i nvidia\n```\n查看信息2：\n```shell\nuname -m && cat /etc/*release\n```\n查看信息3：\n```shell\ngcc --version\n```\n查看信息4：\n```shell\nuname -r\n```\n查找cuda版本：\n```shell\nyum search cuda\n```\n# 安装对应版本的cuda：\n```shell\nyum install cuda-8-0\n```\n修改环境变量：\n```shell\n vim ~/.bashrc\n```\n在最后加入以下几行：\n```shell\nexport CUDA_HOME=/usr/local/cuda-8.0  \nexport PATH=/usr/local/cuda-8.0/bin:$PATH  \nexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH  \nexport LD_LIBRARY_PATH=\"/usr/local/cuda-8.0/lib:${LD_LIBRARY_PATH}\"\n```\n修改好之后查看：\n```shell\nnvcc -V\nnvidia-smi\n```\n# 安装cudnn\n从官网上下载对应的包：\nhttps://developer.nvidia.com/rdp/cudnn-download\n找到匹配cuda8.0的5.1版本，下载\n解压：\n```shell\ntar -xzvf cudnn-8.0-linux-x64-v5.1.tgz\ncp -P /usr/local/cuda/include/cudnn.h /usr/local/cuda-8.0/include\ncp -P /usr/local/cuda/lib64/libcudnn* /usr/local/cuda-8.0/lib64\nChmod a+r /usr/local/cuda-8.0/include/cudnn.h /usr/local/cuda-8.0/lib64/libcudnn*\n```\nPS：关于cuda和显卡的问题\n训练过程中发现问题：\n没有运行任何的程序 使用cuda7.5  发现但是GPU利用率为100%。\n解决办法：\n需要把驱动模式设置为常驻内存才可以，设置命令：\nnvidia-smi -pm 1', '1', '<p>首先卸载已经安装的cuda：</p>\n<pre><code class=\"lang-shell\">sudo yum remove /usr/local/cuda-7.5\n</code></pre>\n<p>查看信息1：</p>\n<pre><code class=\"lang-shell\">lspci | grep -i nvidia\n</code></pre>\n<p>查看信息2：</p>\n<pre><code class=\"lang-shell\">uname -m &amp;&amp; cat /etc/*release\n</code></pre>\n<p>查看信息3：</p>\n<pre><code class=\"lang-shell\">gcc --version\n</code></pre>\n<p>查看信息4：</p>\n<pre><code class=\"lang-shell\">uname -r\n</code></pre>\n<p>查找cuda版本：</p>\n<pre><code class=\"lang-shell\">yum search cuda\n</code></pre>\n<h1 id=\"h1--cuda-\"><a name=\"安装对应版本的cuda：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装对应版本的cuda：</h1><pre><code class=\"lang-shell\">yum install cuda-8-0\n</code></pre>\n<p>修改环境变量：</p>\n<pre><code class=\"lang-shell\"> vim ~/.bashrc\n</code></pre>\n<p>在最后加入以下几行：</p>\n<pre><code class=\"lang-shell\">export CUDA_HOME=/usr/local/cuda-8.0  \nexport PATH=/usr/local/cuda-8.0/bin:$PATH  \nexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH  \nexport LD_LIBRARY_PATH=&quot;/usr/local/cuda-8.0/lib:${LD_LIBRARY_PATH}&quot;\n</code></pre>\n<p>修改好之后查看：</p>\n<pre><code class=\"lang-shell\">nvcc -V\nnvidia-smi\n</code></pre>\n<h1 id=\"h1--cudnn\"><a name=\"安装cudnn\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装cudnn</h1><p>从官网上下载对应的包：<br><a href=\"https://developer.nvidia.com/rdp/cudnn-download\">https://developer.nvidia.com/rdp/cudnn-download</a><br>找到匹配cuda8.0的5.1版本，下载<br>解压：</p>\n<pre><code class=\"lang-shell\">tar -xzvf cudnn-8.0-linux-x64-v5.1.tgz\ncp -P /usr/local/cuda/include/cudnn.h /usr/local/cuda-8.0/include\ncp -P /usr/local/cuda/lib64/libcudnn* /usr/local/cuda-8.0/lib64\nChmod a+r /usr/local/cuda-8.0/include/cudnn.h /usr/local/cuda-8.0/lib64/libcudnn*\n</code></pre>\n<p>PS：关于cuda和显卡的问题<br>训练过程中发现问题：<br>没有运行任何的程序 使用cuda7.5  发现但是GPU利用率为100%。<br>解决办法：<br>需要把驱动模式设置为常驻内存才可以，设置命令：<br>nvidia-smi -pm 1</p>\n');
INSERT INTO `tbl_archive` VALUES ('29', '0', 'Yarn标签调度实验', '23', '2018-02-28 17:17:17', '对yarn标签调度简单做了一个小测试', null, '0', '648', null, null, '2018-02-28 17:17:17', null, null, null, '0', '0', '0', '0', '###### 1.环境准备：\r\n使用ambari装了有三个节点的集群，hadoop版本要2.6.0以上，本次测试的hadoop版本是2.7.1，具体的节点分配如下：\r\n![](/upload/images/20180228//97429c70-7a64-423c-acab-e94dbb9a978b.png)\r\n\r\n2.在ambari界面yarn配置页面打开yarn Node Labes功能，如下图：\r\n![](/upload/images/20180228//7ec691a4-a3e6-45b4-aef9-09f7026f8446.jpeg)\r\n![](/upload/images/20180228//025cf01f-9131-4c8c-aed5-28e71e151ff6.jpeg)\r\n\r\n保存修改的配置，重启yan服务\r\n \r\n3.添加标签\r\n所有的标签要先添加再使用，切换yarn用户，通过以下命令添加标签：\r\n\r\n\r\n    su – yarn\r\n    yarn rmadmin -addToClusterNodeLabels test_labe_1,test_labe_2\r\n添加两个标签test_labe_1,test_labe_2\r\n \r\n4.用命令查看标签\r\n\r\n\r\n    yarn cluster --list-node-labels\r\n\r\n \r\n![](/upload/images/20180228//b8fc0d70-b9a9-41d0-b2f6-37e3498152db.jpeg)\r\n5.给各个节点打上标签：\r\n\r\n\r\n    yarn rmadmin -replaceLabelsOnNode \"crh-1,test_labe_1\"\r\n    yarn rmadmin -replaceLabelsOnNode \"crh-2,test_labe_2\"\r\n    yarn rmadmin -replaceLabelsOnNode \"crh-3,test_labe_2\"\r\n \r\ncrh-1节点上带的是test_labe_1，crh-2、crh-2节点上带的是test_labe_2，可以通过yarn的resourcemanger UI界面查看标签的分配情况：\r\n![](/upload/images/20180228//b5755b67-c2ff-45fc-963d-8f04ec21ee32.jpeg)\r\n![](/upload/images/20180228//45ad45cc-0f94-4b5f-87cd-ad060f601061.jpeg)\r\n注：再给节点指定标签的时候resourcemanger会自动死掉，重启以后，继续指定，直到指定完成。\r\n6.设置，通过队列指定标签\r\n 目前还不支持提交应用程序时指定标签,只能通过指定队列，并设置队列的默认标签达到使用标签目的。\r\n添加的队列和标签,以及节点和标签的对应关系如下：\r\n![](/upload/images/20180228//00a098dd-d0f7-4913-881b-7063dcaecbf1.png)\r\n \r\n在yarn-site添加属性：\r\n\r\n\r\n    yarn.node-labels.manager-class=org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager\r\n设置队列，指定标签，在yarn配置的Scheduler选项中添加一下内容：\r\n\r\n\r\n\r\n    yarn.scheduler.capacity.root.queues=default,test_queue_1,test_queue_2,test_queue_3\r\n    yarn.scheduler.capacity.root.default.capacity=10\r\n    yarn.scheduler.capacity.root.test_queue_1.capacity=30\r\n    yarn.scheduler.capacity.root.test_queue_2.capacity=30\r\n    yarn.scheduler.capacity.root.test_queue_3.capacity=30\r\n    \r\n    yarn.scheduler.capacity.root.default.maximum-capacity=100\r\n    yarn.scheduler.capacity.root.test_queue_1.maximum-capacity=100\r\n    yarn.scheduler.capacity.root.test_queue_2.maximum-capacity=100\r\n    yarn.scheduler.capacity.root.test_queue_3.maximum-capacity=100\r\n    \r\n    //*表示所有标签\r\n    yarn.scheduler.capacity.root.accessible-node-labels=*\r\n    yarn.scheduler.capacity.root.test_queue_1.accessible-node-labels=test_labe_1\r\n    yarn.scheduler.capacity.root.test_queue_2.accessible-node-labels=test_labe_2\r\n     \r\n    yarn.scheduler.capacity.root.accessible-node-labels.test_labe_1.capacity=60\r\n    yarn.scheduler.capacity.root.accessible-node-labels.test_labe_2.capacity=40\r\n    yarn.scheduler.capacity.root.test_queue_1.accessible-node-labels.test_labe_1.capacity=100\r\n    yarn.scheduler.capacity.root.test_queue_2.accessible-node-labels.test_labe_2.capacity=100\r\n     \r\n    //注意:第一个逗号前的空格不可少,表示无标签\r\n    yarn.scheduler.capacity.root.default-node-label-expression= ,test_labe_1,test_labe_2\r\n    //注意:值是一个空格\r\n    yarn.scheduler.capacity.root.default.default-node-label-expression=\r\n    //注意:值是一个空格\r\n    yarn.scheduler.capacity.root.test_queue_3.default-node-label-expression=\r\n    yarn.scheduler.capacity.root.test_queue_1.default-node-label-expression=test_labe_1\r\n    yarn.scheduler.capacity.root.test_queue_2.default-node-label-expression=test_labe_2\r\n \r\n保存修改的配置重启yarn\r\n \r\n使用命令查看队列\r\n![](/upload/images/20180228//83f5bc9c-1055-4d2e-83f4-46d112d355dd.jpeg)\r\n\r\n7.测试：\r\n\r\n\r\n    hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi -Dmapreduce.job.queuename=test_ queue_1 1 1\r\n\r\n![](/upload/images/20180228//ded513b5-ecb4-4669-b83c-1ba80e331e95.jpeg)\r\n![](/upload/images/20180228//877a5b01-5b49-4e3c-8103-ed0fdcb4df5e.jpeg)\r\n\r\n\r\n    hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi -Dmapreduce.job.queuename=test_ queue_2 1 1\r\n\r\n![](/upload/images/20180228//f04e10c9-5737-40ff-87bb-095a69f093de.jpeg)\r\n![](/upload/images/20180228//4c70b63e-032b-42b5-93d0-bbe8e1de2e25.jpeg)\r\n\r\n\r\n    hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi -Dmapreduce.job.queuename=test_ queue_3 1 1\r\n![](/upload/images/20180228//a74f998d-fd1f-42d0-80e8-b9586ac8fb01.jpeg)\r\n\r\n\r\n    hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi 1 1\r\n![](/upload/images/20180228//b10af067-4968-402c-b1cc-0653471c33e5.jpeg)\r\n\r\n![](/upload/images/20180228//9ab04e5a-2057-40fe-adec-1a690ff640db.jpeg)\r\n\r\n \r\n注：\r\n在为节点指定标签的时候，不要把所有的节点都指定标签，否则在使用没有指定标签的队列（如本次测试的default，test_queue_3队列）在跑任务的时候，队列就没有资源可以利用，导致任务无法继续进行。这个要根据自己的需求来定\r\n使用以下命令，可以去掉节点上的标签：\r\n\r\n\r\n    yarn rmadmin -replaceLabelsOnNode \"crh-3,\"\r\n\r\n![](/upload/images/20180228//0da8f22e-1699-4d20-a41d-8d78e64cca1b.jpeg)\r\n![](/upload/images/20180228//0fdf9c26-3658-4319-a34c-7876f3c1efcb.jpeg)\r\n\r\n在使用default、test_queue_3队列跑任务就ok了\r\n\r\n\r\n    hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi  1 1\r\n![](/upload/images/20180228//622b9000-05cc-45a5-95ce-9e1cebaca548.jpeg)\r\n\r\n\r\n    hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi -Dmapreduce.job.queuename=test_queue_3 1 1\r\n![](/upload/images/20180228//410386f6-f477-4ffe-aa8f-5c1187d7d01f.jpeg)\r\n', '1', '<h6 id=\"h6-1-\"><a name=\"1.环境准备：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.环境准备：</h6><p>使用ambari装了有三个节点的集群，hadoop版本要2.6.0以上，本次测试的hadoop版本是2.7.1，具体的节点分配如下：<br><img src=\"/upload/images/20180228//97429c70-7a64-423c-acab-e94dbb9a978b.png\" alt=\"\"></p>\r\n<p>2.在ambari界面yarn配置页面打开yarn Node Labes功能，如下图：<br><img src=\"/upload/images/20180228//7ec691a4-a3e6-45b4-aef9-09f7026f8446.jpeg\" alt=\"\"><br><img src=\"/upload/images/20180228//025cf01f-9131-4c8c-aed5-28e71e151ff6.jpeg\" alt=\"\"></p>\r\n<p>保存修改的配置，重启yan服务</p>\r\n<p>3.添加标签<br>所有的标签要先添加再使用，切换yarn用户，通过以下命令添加标签：</p>\r\n<pre><code>su – yarn\r\nyarn rmadmin -addToClusterNodeLabels test_labe_1,test_labe_2\r\n</code></pre><p>添加两个标签test_labe_1,test_labe_2</p>\r\n<p>4.用命令查看标签</p>\r\n<pre><code>yarn cluster --list-node-labels\r\n</code></pre><p><img src=\"/upload/images/20180228//b8fc0d70-b9a9-41d0-b2f6-37e3498152db.jpeg\" alt=\"\"><br>5.给各个节点打上标签：</p>\r\n<pre><code>yarn rmadmin -replaceLabelsOnNode &quot;crh-1,test_labe_1&quot;\r\nyarn rmadmin -replaceLabelsOnNode &quot;crh-2,test_labe_2&quot;\r\nyarn rmadmin -replaceLabelsOnNode &quot;crh-3,test_labe_2&quot;\r\n</code></pre><p>crh-1节点上带的是test_labe_1，crh-2、crh-2节点上带的是test_labe_2，可以通过yarn的resourcemanger UI界面查看标签的分配情况：<br><img src=\"/upload/images/20180228//b5755b67-c2ff-45fc-963d-8f04ec21ee32.jpeg\" alt=\"\"><br><img src=\"/upload/images/20180228//45ad45cc-0f94-4b5f-87cd-ad060f601061.jpeg\" alt=\"\"><br>注：再给节点指定标签的时候resourcemanger会自动死掉，重启以后，继续指定，直到指定完成。<br>6.设置，通过队列指定标签<br> 目前还不支持提交应用程序时指定标签,只能通过指定队列，并设置队列的默认标签达到使用标签目的。<br>添加的队列和标签,以及节点和标签的对应关系如下：<br><img src=\"/upload/images/20180228//00a098dd-d0f7-4913-881b-7063dcaecbf1.png\" alt=\"\"></p>\r\n<p>在yarn-site添加属性：</p>\r\n<pre><code>yarn.node-labels.manager-class=org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager\r\n</code></pre><p>设置队列，指定标签，在yarn配置的Scheduler选项中添加一下内容：</p>\r\n<pre><code>yarn.scheduler.capacity.root.queues=default,test_queue_1,test_queue_2,test_queue_3\r\nyarn.scheduler.capacity.root.default.capacity=10\r\nyarn.scheduler.capacity.root.test_queue_1.capacity=30\r\nyarn.scheduler.capacity.root.test_queue_2.capacity=30\r\nyarn.scheduler.capacity.root.test_queue_3.capacity=30\r\n\r\nyarn.scheduler.capacity.root.default.maximum-capacity=100\r\nyarn.scheduler.capacity.root.test_queue_1.maximum-capacity=100\r\nyarn.scheduler.capacity.root.test_queue_2.maximum-capacity=100\r\nyarn.scheduler.capacity.root.test_queue_3.maximum-capacity=100\r\n\r\n//*表示所有标签\r\nyarn.scheduler.capacity.root.accessible-node-labels=*\r\nyarn.scheduler.capacity.root.test_queue_1.accessible-node-labels=test_labe_1\r\nyarn.scheduler.capacity.root.test_queue_2.accessible-node-labels=test_labe_2\r\n\r\nyarn.scheduler.capacity.root.accessible-node-labels.test_labe_1.capacity=60\r\nyarn.scheduler.capacity.root.accessible-node-labels.test_labe_2.capacity=40\r\nyarn.scheduler.capacity.root.test_queue_1.accessible-node-labels.test_labe_1.capacity=100\r\nyarn.scheduler.capacity.root.test_queue_2.accessible-node-labels.test_labe_2.capacity=100\r\n\r\n//注意:第一个逗号前的空格不可少,表示无标签\r\nyarn.scheduler.capacity.root.default-node-label-expression= ,test_labe_1,test_labe_2\r\n//注意:值是一个空格\r\nyarn.scheduler.capacity.root.default.default-node-label-expression=\r\n//注意:值是一个空格\r\nyarn.scheduler.capacity.root.test_queue_3.default-node-label-expression=\r\nyarn.scheduler.capacity.root.test_queue_1.default-node-label-expression=test_labe_1\r\nyarn.scheduler.capacity.root.test_queue_2.default-node-label-expression=test_labe_2\r\n</code></pre><p>保存修改的配置重启yarn</p>\r\n<p>使用命令查看队列<br><img src=\"/upload/images/20180228//83f5bc9c-1055-4d2e-83f4-46d112d355dd.jpeg\" alt=\"\"></p>\r\n<p>7.测试：</p>\r\n<pre><code>hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi -Dmapreduce.job.queuename=test_ queue_1 1 1\r\n</code></pre><p><img src=\"/upload/images/20180228//ded513b5-ecb4-4669-b83c-1ba80e331e95.jpeg\" alt=\"\"><br><img src=\"/upload/images/20180228//877a5b01-5b49-4e3c-8103-ed0fdcb4df5e.jpeg\" alt=\"\"></p>\r\n<pre><code>hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi -Dmapreduce.job.queuename=test_ queue_2 1 1\r\n</code></pre><p><img src=\"/upload/images/20180228//f04e10c9-5737-40ff-87bb-095a69f093de.jpeg\" alt=\"\"><br><img src=\"/upload/images/20180228//4c70b63e-032b-42b5-93d0-bbe8e1de2e25.jpeg\" alt=\"\"></p>\r\n<pre><code>hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi -Dmapreduce.job.queuename=test_ queue_3 1 1\r\n</code></pre><p><img src=\"/upload/images/20180228//a74f998d-fd1f-42d0-80e8-b9586ac8fb01.jpeg\" alt=\"\"></p>\r\n<pre><code>hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi 1 1\r\n</code></pre><p><img src=\"/upload/images/20180228//b10af067-4968-402c-b1cc-0653471c33e5.jpeg\" alt=\"\"></p>\r\n<p><img src=\"/upload/images/20180228//9ab04e5a-2057-40fe-adec-1a690ff640db.jpeg\" alt=\"\"></p>\r\n<p>注：<br>在为节点指定标签的时候，不要把所有的节点都指定标签，否则在使用没有指定标签的队列（如本次测试的default，test_queue_3队列）在跑任务的时候，队列就没有资源可以利用，导致任务无法继续进行。这个要根据自己的需求来定<br>使用以下命令，可以去掉节点上的标签：</p>\r\n<pre><code>yarn rmadmin -replaceLabelsOnNode &quot;crh-3,&quot;\r\n</code></pre><p><img src=\"/upload/images/20180228//0da8f22e-1699-4d20-a41d-8d78e64cca1b.jpeg\" alt=\"\"><br><img src=\"/upload/images/20180228//0fdf9c26-3658-4319-a34c-7876f3c1efcb.jpeg\" alt=\"\"></p>\r\n<p>在使用default、test_queue_3队列跑任务就ok了</p>\r\n<pre><code>hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi  1 1\r\n</code></pre><p><img src=\"/upload/images/20180228//622b9000-05cc-45a5-95ce-9e1cebaca548.jpeg\" alt=\"\"></p>\r\n<pre><code>hadoop jar /usr/crh/5.0.2.4-1136/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi -Dmapreduce.job.queuename=test_queue_3 1 1\r\n</code></pre><p><img src=\"/upload/images/20180228//410386f6-f477-4ffe-aa8f-5c1187d7d01f.jpeg\" alt=\"\"></p>\r\n');
INSERT INTO `tbl_archive` VALUES ('30', '0', 'KDC Server 安装', '14', '2018-03-01 14:26:00', '1、安装最新版的KDCserver​```yuminstallkrb5-serverkrb5-libskrb5-workstation```>注：KDC(KeyDistributionCenter）密匙分配中心,其在kerberos中通常提供两种服务：>1.AuthenticationService(AS)：认证服务　　>2.Ticket-GrantingService(TGS)：授予票据服务2、', null, '0', '411', null, null, '2018-03-01 14:26:00', null, null, null, '0', '0', '0', '0', '1、安装最新版的KDC server\n​\n\n  \n```\nyum install krb5-server krb5-libs krb5-workstation\n```\n\n\n>     注：KDC (Key Distribution Center）密匙分配中心, 其在kerberos中通常提供两种服务：\n>     1.Authentication Service (AS)：认证服务 　　\n>     2.Ticket-Granting Service (TGS)：授予票据服务\n\n2、编辑配置文件\n\n\n```\nvi /etc/krb5.conf \n\n[libdefaults]\n  renew_lifetime = 7d\n  forwardable = true\n  default_realm = DATAPLAT.COM.CN\n  ticket_lifetime = 24h\n  dns_lookup_realm = false\n  dns_lookup_kdc = false\n  default_ccache_name = /tmp/krb5cc_%{uid}\n  #default_tgs_enctypes = aes des3-cbc-sha1 rc4 des-cbc-md5\n  #default_tkt_enctypes = aes des3-cbc-sha1 rc4 des-cbc-md5\n\n[logging]\n  default = FILE:/var/log/krb5kdc.log\n  admin_server = FILE:/var/log/kadmind.log\n  kdc = FILE:/var/log/krb5kdc.log\n\n[realms]\n  BIGDATA.ORG.CN = {\n    admin_server = 10.123.12.7\n    kdc = 10.123.12.7\n  }\n\n[domain_realm]\n .bigdata.org.cn =  DATAPLAT.COM.CN\n bigdata.org.cn =  DATAPLAT.COM.CN\n```\n\n\n\n> 注：修改[realms]与添加[domain_realm] ,[libdefaults]对应的default_realm的值\n\n3、使用 kdb5_util 创建Kerberos数据库(*注：会提醒你输入密码,要记好密码)\n\n\n```\nkdb5_util create -s\n\nEnter KDC database master key:xxxxxx\n```\n\n\n4、启动KDC服务\n\n\n```\n/etc/rc.d/init.d/krb5kdc start\n/etc/rc.d/init.d/kadmin start\n```\n\n\n\n5、设置KDC服务开机启动\n\n\n```\nchkconfig krb5kdc on\nchkconfig kadmin on\n```\n\n\n6、创建Kerberos管理员（根据提示输入密码）\n\n\n```\nkadmin.local -q \"addprinc root/root\" \nEnter password for principal \"root/root@DATAPLAT.COM.CN\":xxxxxxxxxx\n```\n\n\n7、查看KDC ACL权限文件并确保kadm5.acl文件中，有你刚才定义的[realm]信息，无则补上\n\n\n```\nvi /var/kerberos/krb5kdc/kadm5.acl \n*/root@EXAMPLE.COM *\n*/root@DATAPLAT.COM.CN     *\n```\n\n\n> 注：其中 /root@DATAPLAT.COM.CN 即为需要添加的信息\n\n8、重启kadmin进程\n\n\n```\n/etc/rc.d/init.d/kadmin restart\n```\n', '0', '<p>1、安装最新版的KDC server<br>​</p>\n<pre><code>yum install krb5-server krb5-libs krb5-workstation\n</code></pre><blockquote>\n<pre><code>注：KDC (Key Distribution Center）密匙分配中心, 其在kerberos中通常提供两种服务：\n1.Authentication Service (AS)：认证服务 　　\n2.Ticket-Granting Service (TGS)：授予票据服务\n</code></pre></blockquote>\n<p>2、编辑配置文件</p>\n<pre><code>vi /etc/krb5.conf \n\n[libdefaults]\n  renew_lifetime = 7d\n  forwardable = true\n  default_realm = DATAPLAT.COM.CN\n  ticket_lifetime = 24h\n  dns_lookup_realm = false\n  dns_lookup_kdc = false\n  default_ccache_name = /tmp/krb5cc_%{uid}\n  #default_tgs_enctypes = aes des3-cbc-sha1 rc4 des-cbc-md5\n  #default_tkt_enctypes = aes des3-cbc-sha1 rc4 des-cbc-md5\n\n[logging]\n  default = FILE:/var/log/krb5kdc.log\n  admin_server = FILE:/var/log/kadmind.log\n  kdc = FILE:/var/log/krb5kdc.log\n\n[realms]\n  BIGDATA.ORG.CN = {\n    admin_server = 10.123.12.7\n    kdc = 10.123.12.7\n  }\n\n[domain_realm]\n .bigdata.org.cn =  DATAPLAT.COM.CN\n bigdata.org.cn =  DATAPLAT.COM.CN\n</code></pre><blockquote>\n<p>注：修改[realms]与添加[domain_realm] ,[libdefaults]对应的default_realm的值</p>\n</blockquote>\n<p>3、使用 kdb5_util 创建Kerberos数据库(*注：会提醒你输入密码,要记好密码)</p>\n<pre><code>kdb5_util create -s\n\nEnter KDC database master key:xxxxxx\n</code></pre><p>4、启动KDC服务</p>\n<pre><code>/etc/rc.d/init.d/krb5kdc start\n/etc/rc.d/init.d/kadmin start\n</code></pre><p>5、设置KDC服务开机启动</p>\n<pre><code>chkconfig krb5kdc on\nchkconfig kadmin on\n</code></pre><p>6、创建Kerberos管理员（根据提示输入密码）</p>\n<pre><code>kadmin.local -q &quot;addprinc root/root&quot; \nEnter password for principal &quot;root/root@DATAPLAT.COM.CN&quot;:xxxxxxxxxx\n</code></pre><p>7、查看KDC ACL权限文件并确保kadm5.acl文件中，有你刚才定义的[realm]信息，无则补上</p>\n<pre><code>vi /var/kerberos/krb5kdc/kadm5.acl \n*/root@EXAMPLE.COM *\n*/root@DATAPLAT.COM.CN     *\n</code></pre><blockquote>\n<p>注：其中 /<a href=\"mailto:root@DATAPLAT.COM.CN\">root@DATAPLAT.COM.CN</a> 即为需要添加的信息</p>\n</blockquote>\n<p>8、重启kadmin进程</p>\n<pre><code>/etc/rc.d/init.d/kadmin restart\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('31', '0', 'ambari-views在arm架构centos7.4系统下异常', '19', '2018-03-02 16:11:44', '系统版本：CentOSLinuxrelease7.4.1708(AltArch)错误信息：```Failedtoexecutegoalorg.apache.maven.plugins:maven-surefire-plugin:2.19:test(default-test)onprojectambari-views:Unabletoparseconfigurationofmojoorg.apach', null, '0', '511', null, null, '2018-03-02 16:11:44', '2018-03-05 15:13:57', null, null, '0', '0', '0', '0', '系统版本：\n	CentOS Linux release 7.4.1708 (AltArch)\n\n错误信息：\n```\nFailed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19:test (default-test) on project ambari-views: Unable to parse configuration of mojo org.apache.maven.plugins:maven-surefire-plugin:2.19:test for parameter projectArtifactMap: Cannot set \'projectArtifactMap\' in class org.apache.maven.plugin.surefire.SurefirePlugin: IncompatibleClassChangeError -> [Help 1]\n```\n\n解决方法：\n替换jdk版本。\n系统提供jdk版本为：openjdk1.8(maven打包时造成错误的原因)\n替换后的版本:[jdk-8u161-linux-arm64-vfp-hflt.tar.gz](http://download.oracle.com/otn-pub/java/jdk/8u161-b12/2f38c3b165be4555a1fa6e98c45e0808/jdk-8u161-linux-arm64-vfp-hflt.tar.gz\")\n替换之后问题解决。', '0', '<p>系统版本：<br>    CentOS Linux release 7.4.1708 (AltArch)</p>\n<p>错误信息：</p>\n<pre><code>Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19:test (default-test) on project ambari-views: Unable to parse configuration of mojo org.apache.maven.plugins:maven-surefire-plugin:2.19:test for parameter projectArtifactMap: Cannot set &#39;projectArtifactMap&#39; in class org.apache.maven.plugin.surefire.SurefirePlugin: IncompatibleClassChangeError -&gt; [Help 1]\n</code></pre><p>解决方法：<br>替换jdk版本。<br>系统提供jdk版本为：openjdk1.8(maven打包时造成错误的原因)<br>替换后的版本:<a href=\"http://download.oracle.com/otn-pub/java/jdk/8u161-b12/2f38c3b165be4555a1fa6e98c45e0808/jdk-8u161-linux-arm64-vfp-hflt.tar.gz&quot;\">jdk-8u161-linux-arm64-vfp-hflt.tar.gz</a><br>替换之后问题解决。</p>\n');
INSERT INTO `tbl_archive` VALUES ('32', '0', '利用caffe在mnist上训练和测试LeNet网络', '24', '2018-03-02 16:22:38', '#1.LeNet简介：MNIST分类模型LeNet网络能很好地执行数字分类任务。本文使用了一个轻量级的不同于原始LeNet的版本实现，在神经网络中，使用线性修正单元激活函数ReLU取代sigmoid函数。LeNet的设计包括CNNS。概括来说，它的组成包含一个卷积层，紧跟一个池化层，另一个卷积层紧跟一个池化层，然后是两个全连接层类似于卷积多层感知器。层的定义是在$CAFFE_ROOT/exampl', null, '0', '757', null, null, '2018-03-02 16:22:38', '2018-03-09 15:43:56', null, null, '0', '0', '0', '0', '# 1. LeNet简介：MNIST分类模型\nLeNet网络能很好地执行数字分类任务。本文使用了一个轻量级的不同于原始LeNet的版本实现，在神经网络中，使用线性修正单元激活函数ReLU取代sigmoid函数。\nLeNet的设计包括CNNS。概括来说，它的组成包含一个卷积层，紧跟一个池化层，另一个卷积层紧跟一个池化层，然后是两个全连接层类似于卷积多层感知器。层的定义是在$CAFFE_ROOT/examples/mnist/lenet_train_test.prototxt里。\n# 2. 准备数据集\n从MNIST网站下载和转换数据格式。\n```shell\ncd $CAFFE_ROOT\n./data/mnist/get_mnist.sh\n./examples/mnist/create_mnist.sh\n```\n脚本执行后，生成两个数据集 mnist_train_lmdb和 mnist_test_lmdb\n# 3. 定义MNIST网络\nlenet_train_test.prototxt 的模型定义指定了MNIST手写体分类的LeNet模型。Caffe使用的protobuf定义文件在$CAFFE_ROOT/src/caffe/proto/caffe.proto。写一个 caffe::NetParameter的protobuf，给网络起一个名字，然后开始：\nname: \"LeNet\"\n## 3.1 数据层\n   这个例子，从之前创建的lmdb读取MNIST数据，一个数据层的定义如下：\n   ```shell\nlayer {\n  name: \"mnist\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TRAIN\n  }\n  transform_param {\n    scale: 0.00390625\n  }\n  data_param {\n    source: \"./mnist_train_lmdb\"\n    batch_size: 64\n    backend: LMDB\n  }\n}\n```\n这个层的名字是mnist,类型是data。从给定的lmdb源中读取数据。使用的批尺寸是64，对传入的像素点进行缩放使之在[0,1)范围内。\n这层只包含于TRAIN阶段，如果修改TRAIN为TEST，这层就会只用于test阶段。\n## 3.2 卷积层\n定义第一个卷积层：\n```shell\nlayer {\n  name: \"conv1\"\n  type: \"Convolution\"\n  bottom: \"data\"\n  top: \"conv1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  convolution_param {\n    num_output: 20\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\n```\n这一层输入data blob（由数据层提供），产生conv1层。产生20通道的输出，卷积核尺寸是5，步长是1。\n填充器允许任意初始化权重和偏置值。对于权重填充，使用基于输入和输出神经元数量的xavier算法自动确定初始化的scale。对于偏置填充器，简单的初始化为常数，默认的填充值是 0。\nlr_mult是学习率调整图层的学习参数。在这种情况下，我们将把权值学习速率设置为与运行时解决器所给出的学习速率相同，并且偏置学习速率是该算法的两倍，这通常会导致更好的收敛速度。\n## 3.3 池化层\n定义第一个池化层：\n```shell\nlayer {\n  name: \"pool1\"\n  type: \"Pooling\"\n  bottom: \"conv1\"\n  top: \"pool1\"\n  pooling_param {\n    pool: MAX\n    kernel_size: 2\n    stride: 2\n  }\n}\n```\n执行一个最大池化，池化核尺寸为2步长为2（相邻池化区域间没有重叠）。\n类似的，可以写第二个卷积和池化层。具体可以查看 \n$CAFFE_ROOT/examples/mnist/lenet_train_test.prototxt 文件。\n## 3.4 全连接层\n定义一个500个输出的全连接层（在Caffe中为InnerProduct层）。\n```shell\nlayer {\n  name: \"ip1\"\n  type: \"InnerProduct\"\n  bottom: \"pool2\"\n  top: \"ip1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 500\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\n```\n## 3.5 ReLU激活层\n```shell\nlayer {\n  name: \"relu1\"\n  type: \"ReLU\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n}\n```\nReLU在in-place操作节省一些内存。这是通过简单地给底部和顶部的blobs提供相同的名称来实现的。\nReLU层之后，写另外的innerproduct 层：\n```shell\nlayer {\n  name: \"ip2\"\n  type: \"InnerProduct\"\n  bottom: \"ip1\"\n  top: \"ip2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 10\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\n```\n## 3.6 Accuracy层\n输出分类（预测）精确度，只有test阶段才有，因此需要加入include参数。\n```shell\nlayer {\n  name: \"accuracy\"\n  type: \"Accuracy\"\n  bottom: \"ip2\"\n  bottom: \"label\"\n  top: \"accuracy\"\n  include {\n    phase: TEST\n  }\n}\n```\n## 3.7 损失层\n```shell\nlayer {\n  name: \"loss\"\n  type: \"SoftmaxWithLoss\"\n  bottom: \"ip2\"\n  bottom: \"label\"\n  top: \"loss\"\n}\n```\nsoftmax_loss层实现了softmax和多项式对数损失（节省时间和提高数值计算的稳定性）。它需要两个blobs，第一个是预测，第二个是数据层提供的标签。它不产生任何输出，只是计算损失函数值。\n# 4. MNIST solver定义\nsolver配置文件的主要作用就是交替调用前向（forward)算法和后向（backward)算法来更新参数，从而最小化loss，实际上就是一种迭代的优化算法。结合loss，用gradient更新weights。\ncaffe提供了六种优化算法来求解最优参数，在solver配置文件中，通过设置type类型来选择。\nlenet_solver.prototxt代码\n```shell\n# The train/test net protocol buffer definition\nnet: \"./lenet_train_test.prototxt\"\n# test_iter specifies how many forward passes the test should carry out.\n# In the case of MNIST, we have test batch size 100 and 100 test iterations,\n# covering the full 10,000 testing images.\ntest_iter: 100\n# Carry out testing every 500 training iterations.\ntest_interval: 500\n# The base learning rate, momentum and the weight decay of the network.\nbase_lr: 0.01\nmomentum: 0.9\nweight_decay: 0.0005\n# The learning rate policy\nlr_policy: \"inv\"\ngamma: 0.0001\npower: 0.75\n# Display every 100 iterations\ndisplay: 100\n# The maximum number of iterations\nmax_iter: 10000\n# snapshot intermediate results\nsnapshot: 5000\nsnapshot_prefix: \"model/lenet\"\n# solver mode: CPU or GPU\nsolver_mode: CPU\n```\n# 5.训练模型\n在写完了lenet_solver.prototxt和lenet_train_test.prototxt文件后，运行caffe训练模型命令，solver.prototxt文本文件作为参数\n```shell\n./caffe/build/tools/caffe train --solver=./lenet_solver.prototxt\n```\n在使用xlearning运行之前，要安装caffe及其依赖的环境。\n安装caffe环境依赖包\n```shell\nyum install protobuf-devel leveldb-devel snappy-devel opencv-devel boost-devel hdf5-devel -y \nyum install gflags-devel glog-devel lmdb-devel openblas-devel -y\n```\n若集群未事先装有caffe模块，可利用cacheArchive参数特性进行配置。如：--cacheArchive /tmp/data/caffe/caffe.zip#caffe\n\nrun.sh脚本\n```shell\n#!/bin/sh\n$XLEARNING_HOME/bin/xl-submit \\\n   --app-type \"caffe\" \\\n   --app-name \"caffe_demo\" \\\n   --input /tmp/data/caffe/mnist_train_lmdb#mnist_train_lmdb \\\n   --input /tmp/data/caffe/mnist_test_lmdb#mnist_test_lmdb \\\n   --output /tmp/caffe_output#model \\\n   --files lenet_train_test.prototxt,lenet_solver.prototxt \\\n   --cacheArchive /tmp/data/caffe/caffe.zip#caffe \\\n   --launch-cmd \"./caffe/build/tools/caffe train --solver=./lenet_solver.prototxt\" \\\n   --worker-memory 2G \\\n   --worker-cores 2 \\\n   --queue default \\\n```\n当运行脚本时，会看到很多诸如下面的信息：\n![](/upload/images/20180302//929ac650-dd39-4d28-9db4-1bf92467bf47.png)\n这些信息告诉你每层的细节，它的连接，输出维度，这会在调试时很有用。初始化之后，训练将会开始：\n![](/upload/images/20180302//ef08c4fd-257b-4714-8810-66600f1ece27.png)\n基于solver的设置，每100迭代会打印出训练的损失函数，每500迭代测试网络。将会看到诸如下面的信息：\n![](/upload/images/20180302//435c5a82-fe0a-4b6c-acd2-9c00e6e0da83.png)\n...\n![](/upload/images/20180302//488a270f-83e3-4a72-a825-9d4b781794a9.png)\n\n对于每个训练迭代，lr是学习率，loss是训练函数。对于测试阶段的输出，score 0是准确率，score 1 是测试损失函数。\n数分钟后，训练结束！\n![](/upload/images/20180302//001fe9aa-7b4d-4adb-bcdd-e527cfaf4efd.png)\n最后的模型，保存为一个二进制protobuf文件，保存在lenet_iter_10000.caffemodel里。\n![](/upload/images/20180302//7137b226-c3f0-4c01-8dc7-8a797639ad88.png)\n# 6. 测试模型\n使用\n```shell\n$ ./build/tools/caffe.bin test \\\n-model examples/mnist/lenet_train_test.prototxt \\\n-weights examples/mnist/lenet_iter_10000.caffemodel \\\n-iterations 100\n```\n命令来测试训练好的网络。这主要用于测试网络的准确率。\n\n', '1', '<h1 id=\"h1-1-lenet-mnist-\"><a name=\"1. LeNet简介：MNIST分类模型\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. LeNet简介：MNIST分类模型</h1><p>LeNet网络能很好地执行数字分类任务。本文使用了一个轻量级的不同于原始LeNet的版本实现，在神经网络中，使用线性修正单元激活函数ReLU取代sigmoid函数。<br>LeNet的设计包括CNNS。概括来说，它的组成包含一个卷积层，紧跟一个池化层，另一个卷积层紧跟一个池化层，然后是两个全连接层类似于卷积多层感知器。层的定义是在$CAFFE_ROOT/examples/mnist/lenet_train_test.prototxt里。</p>\n<h1 id=\"h1-2-\"><a name=\"2. 准备数据集\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2. 准备数据集</h1><p>从MNIST网站下载和转换数据格式。</p>\n<pre><code class=\"lang-shell\">cd $CAFFE_ROOT\n./data/mnist/get_mnist.sh\n./examples/mnist/create_mnist.sh\n</code></pre>\n<p>脚本执行后，生成两个数据集 mnist_train_lmdb和 mnist_test_lmdb</p>\n<h1 id=\"h1-3-mnist-\"><a name=\"3. 定义MNIST网络\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3. 定义MNIST网络</h1><p>lenet_train_test.prototxt 的模型定义指定了MNIST手写体分类的LeNet模型。Caffe使用的protobuf定义文件在$CAFFE_ROOT/src/caffe/proto/caffe.proto。写一个 caffe::NetParameter的protobuf，给网络起一个名字，然后开始：<br>name: “LeNet”</p>\n<h2 id=\"h2-3-1-\"><a name=\"3.1 数据层\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.1 数据层</h2><p>   这个例子，从之前创建的lmdb读取MNIST数据，一个数据层的定义如下：</p>\n<pre><code class=\"lang-shell\">layer {\n  name: &quot;mnist&quot;\n  type: &quot;Data&quot;\n  top: &quot;data&quot;\n  top: &quot;label&quot;\n  include {\n    phase: TRAIN\n  }\n  transform_param {\n    scale: 0.00390625\n  }\n  data_param {\n    source: &quot;./mnist_train_lmdb&quot;\n    batch_size: 64\n    backend: LMDB\n  }\n}\n</code></pre>\n<p>这个层的名字是mnist,类型是data。从给定的lmdb源中读取数据。使用的批尺寸是64，对传入的像素点进行缩放使之在[0,1)范围内。<br>这层只包含于TRAIN阶段，如果修改TRAIN为TEST，这层就会只用于test阶段。</p>\n<h2 id=\"h2-3-2-\"><a name=\"3.2 卷积层\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2 卷积层</h2><p>定义第一个卷积层：</p>\n<pre><code class=\"lang-shell\">layer {\n  name: &quot;conv1&quot;\n  type: &quot;Convolution&quot;\n  bottom: &quot;data&quot;\n  top: &quot;conv1&quot;\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  convolution_param {\n    num_output: 20\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: &quot;xavier&quot;\n    }\n    bias_filler {\n      type: &quot;constant&quot;\n    }\n  }\n}\n</code></pre>\n<p>这一层输入data blob（由数据层提供），产生conv1层。产生20通道的输出，卷积核尺寸是5，步长是1。<br>填充器允许任意初始化权重和偏置值。对于权重填充，使用基于输入和输出神经元数量的xavier算法自动确定初始化的scale。对于偏置填充器，简单的初始化为常数，默认的填充值是 0。<br>lr_mult是学习率调整图层的学习参数。在这种情况下，我们将把权值学习速率设置为与运行时解决器所给出的学习速率相同，并且偏置学习速率是该算法的两倍，这通常会导致更好的收敛速度。</p>\n<h2 id=\"h2-3-3-\"><a name=\"3.3 池化层\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3 池化层</h2><p>定义第一个池化层：</p>\n<pre><code class=\"lang-shell\">layer {\n  name: &quot;pool1&quot;\n  type: &quot;Pooling&quot;\n  bottom: &quot;conv1&quot;\n  top: &quot;pool1&quot;\n  pooling_param {\n    pool: MAX\n    kernel_size: 2\n    stride: 2\n  }\n}\n</code></pre>\n<p>执行一个最大池化，池化核尺寸为2步长为2（相邻池化区域间没有重叠）。<br>类似的，可以写第二个卷积和池化层。具体可以查看<br>$CAFFE_ROOT/examples/mnist/lenet_train_test.prototxt 文件。</p>\n<h2 id=\"h2-3-4-\"><a name=\"3.4 全连接层\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.4 全连接层</h2><p>定义一个500个输出的全连接层（在Caffe中为InnerProduct层）。</p>\n<pre><code class=\"lang-shell\">layer {\n  name: &quot;ip1&quot;\n  type: &quot;InnerProduct&quot;\n  bottom: &quot;pool2&quot;\n  top: &quot;ip1&quot;\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 500\n    weight_filler {\n      type: &quot;xavier&quot;\n    }\n    bias_filler {\n      type: &quot;constant&quot;\n    }\n  }\n}\n</code></pre>\n<h2 id=\"h2-3-5-relu-\"><a name=\"3.5 ReLU激活层\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.5 ReLU激活层</h2><pre><code class=\"lang-shell\">layer {\n  name: &quot;relu1&quot;\n  type: &quot;ReLU&quot;\n  bottom: &quot;ip1&quot;\n  top: &quot;ip1&quot;\n}\n</code></pre>\n<p>ReLU在in-place操作节省一些内存。这是通过简单地给底部和顶部的blobs提供相同的名称来实现的。<br>ReLU层之后，写另外的innerproduct 层：</p>\n<pre><code class=\"lang-shell\">layer {\n  name: &quot;ip2&quot;\n  type: &quot;InnerProduct&quot;\n  bottom: &quot;ip1&quot;\n  top: &quot;ip2&quot;\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 10\n    weight_filler {\n      type: &quot;xavier&quot;\n    }\n    bias_filler {\n      type: &quot;constant&quot;\n    }\n  }\n}\n</code></pre>\n<h2 id=\"h2-3-6-accuracy-\"><a name=\"3.6 Accuracy层\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.6 Accuracy层</h2><p>输出分类（预测）精确度，只有test阶段才有，因此需要加入include参数。</p>\n<pre><code class=\"lang-shell\">layer {\n  name: &quot;accuracy&quot;\n  type: &quot;Accuracy&quot;\n  bottom: &quot;ip2&quot;\n  bottom: &quot;label&quot;\n  top: &quot;accuracy&quot;\n  include {\n    phase: TEST\n  }\n}\n</code></pre>\n<h2 id=\"h2-3-7-\"><a name=\"3.7 损失层\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.7 损失层</h2><pre><code class=\"lang-shell\">layer {\n  name: &quot;loss&quot;\n  type: &quot;SoftmaxWithLoss&quot;\n  bottom: &quot;ip2&quot;\n  bottom: &quot;label&quot;\n  top: &quot;loss&quot;\n}\n</code></pre>\n<p>softmax_loss层实现了softmax和多项式对数损失（节省时间和提高数值计算的稳定性）。它需要两个blobs，第一个是预测，第二个是数据层提供的标签。它不产生任何输出，只是计算损失函数值。</p>\n<h1 id=\"h1-4-mnist-solver-\"><a name=\"4. MNIST solver定义\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4. MNIST solver定义</h1><p>solver配置文件的主要作用就是交替调用前向（forward)算法和后向（backward)算法来更新参数，从而最小化loss，实际上就是一种迭代的优化算法。结合loss，用gradient更新weights。<br>caffe提供了六种优化算法来求解最优参数，在solver配置文件中，通过设置type类型来选择。<br>lenet_solver.prototxt代码</p>\n<pre><code class=\"lang-shell\"># The train/test net protocol buffer definition\nnet: &quot;./lenet_train_test.prototxt&quot;\n# test_iter specifies how many forward passes the test should carry out.\n# In the case of MNIST, we have test batch size 100 and 100 test iterations,\n# covering the full 10,000 testing images.\ntest_iter: 100\n# Carry out testing every 500 training iterations.\ntest_interval: 500\n# The base learning rate, momentum and the weight decay of the network.\nbase_lr: 0.01\nmomentum: 0.9\nweight_decay: 0.0005\n# The learning rate policy\nlr_policy: &quot;inv&quot;\ngamma: 0.0001\npower: 0.75\n# Display every 100 iterations\ndisplay: 100\n# The maximum number of iterations\nmax_iter: 10000\n# snapshot intermediate results\nsnapshot: 5000\nsnapshot_prefix: &quot;model/lenet&quot;\n# solver mode: CPU or GPU\nsolver_mode: CPU\n</code></pre>\n<h1 id=\"h1-5-\"><a name=\"5.训练模型\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.训练模型</h1><p>在写完了lenet_solver.prototxt和lenet_train_test.prototxt文件后，运行caffe训练模型命令，solver.prototxt文本文件作为参数</p>\n<pre><code class=\"lang-shell\">./caffe/build/tools/caffe train --solver=./lenet_solver.prototxt\n</code></pre>\n<p>在使用xlearning运行之前，要安装caffe及其依赖的环境。<br>安装caffe环境依赖包</p>\n<pre><code class=\"lang-shell\">yum install protobuf-devel leveldb-devel snappy-devel opencv-devel boost-devel hdf5-devel -y \nyum install gflags-devel glog-devel lmdb-devel openblas-devel -y\n</code></pre>\n<p>若集群未事先装有caffe模块，可利用cacheArchive参数特性进行配置。如：—cacheArchive /tmp/data/caffe/caffe.zip#caffe</p>\n<p>run.sh脚本</p>\n<pre><code class=\"lang-shell\">#!/bin/sh\n$XLEARNING_HOME/bin/xl-submit \\\n   --app-type &quot;caffe&quot; \\\n   --app-name &quot;caffe_demo&quot; \\\n   --input /tmp/data/caffe/mnist_train_lmdb#mnist_train_lmdb \\\n   --input /tmp/data/caffe/mnist_test_lmdb#mnist_test_lmdb \\\n   --output /tmp/caffe_output#model \\\n   --files lenet_train_test.prototxt,lenet_solver.prototxt \\\n   --cacheArchive /tmp/data/caffe/caffe.zip#caffe \\\n   --launch-cmd &quot;./caffe/build/tools/caffe train --solver=./lenet_solver.prototxt&quot; \\\n   --worker-memory 2G \\\n   --worker-cores 2 \\\n   --queue default \\\n</code></pre>\n<p>当运行脚本时，会看到很多诸如下面的信息：<br><img src=\"/upload/images/20180302//929ac650-dd39-4d28-9db4-1bf92467bf47.png\" alt=\"\"><br>这些信息告诉你每层的细节，它的连接，输出维度，这会在调试时很有用。初始化之后，训练将会开始：<br><img src=\"/upload/images/20180302//ef08c4fd-257b-4714-8810-66600f1ece27.png\" alt=\"\"><br>基于solver的设置，每100迭代会打印出训练的损失函数，每500迭代测试网络。将会看到诸如下面的信息：<br><img src=\"/upload/images/20180302//435c5a82-fe0a-4b6c-acd2-9c00e6e0da83.png\" alt=\"\"><br>…<br><img src=\"/upload/images/20180302//488a270f-83e3-4a72-a825-9d4b781794a9.png\" alt=\"\"></p>\n<p>对于每个训练迭代，lr是学习率，loss是训练函数。对于测试阶段的输出，score 0是准确率，score 1 是测试损失函数。<br>数分钟后，训练结束！<br><img src=\"/upload/images/20180302//001fe9aa-7b4d-4adb-bcdd-e527cfaf4efd.png\" alt=\"\"><br>最后的模型，保存为一个二进制protobuf文件，保存在lenet_iter_10000.caffemodel里。<br><img src=\"/upload/images/20180302//7137b226-c3f0-4c01-8dc7-8a797639ad88.png\" alt=\"\"></p>\n<h1 id=\"h1-6-\"><a name=\"6. 测试模型\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6. 测试模型</h1><p>使用</p>\n<pre><code class=\"lang-shell\">$ ./build/tools/caffe.bin test \\\n-model examples/mnist/lenet_train_test.prototxt \\\n-weights examples/mnist/lenet_iter_10000.caffemodel \\\n-iterations 100\n</code></pre>\n<p>命令来测试训练好的网络。这主要用于测试网络的准确率。</p>\n');
INSERT INTO `tbl_archive` VALUES ('33', '0', 'Hadoop3.0在ppc64le上编译失败', '13', '2018-03-07 11:49:28', 'Hadoop3.0  ppc64le', null, '0', '448', null, null, '2018-03-07 11:49:28', null, null, null, '0', '0', '0', '0', '## 问题描述\n### 使用apache社区release的Hadoop-3.0.0在ppc64le(centos7.4)环境下编译失败，失败信息如下：\n\n```\n[WARNING] [ 72%] Linking CXX static library libgtest.a\n[WARNING] /usr/local/bin/cmake -P CMakeFiles/gtest.dir/cmake_clean_target.cmake\n[WARNING] /usr/local/bin/cmake -E cmake_link_script CMakeFiles/gtest.dir/link.txt --verbose=1\n[WARNING] /usr/bin/ar qc libgtest.a  CMakeFiles/gtest.dir/build-data/workspace/hadoop-3.0.0-beta/build/hadoop/rpm/BUILD/hadoop-3.0.0-src/hadoop-common-project/hadoop-common/src/main/native/gtest/gtest-all.cc.o\n[WARNING] /usr/bin/ranlib libgtest.a\n[WARNING] make[2]: Leaving directory `/build-data/workspace/hadoop-3.0.0-beta/build/hadoop/rpm/BUILD/hadoop-3.0.0-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native\'\n[WARNING] [ 72%] Built target gtest\n[WARNING] make[1]: Leaving directory `/build-data/workspace/hadoop-3.0.0-beta/build/hadoop/rpm/BUILD/hadoop-3.0.0-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native\'\n[WARNING] /tmp/ccgwlPQH.s: Assembler messages:\n[WARNING] /tmp/ccgwlPQH.s:536: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:617: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:627: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:708: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:718: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:822: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:832: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:917: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:927: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:1056: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccgwlPQH.s:1066: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/lib/SpillInfo.cc.o] Error 1\n[WARNING] make[2]: *** Waiting for unfinished jobs....\n[WARNING] /tmp/ccv6BetQ.s: Assembler messages:\n[WARNING] /tmp/ccv6BetQ.s:523: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:603: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:613: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:694: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:704: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:808: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:818: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:903: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:913: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:1043: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccv6BetQ.s:1053: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/lib/SpillInfo.cc.o] Error 1\n[WARNING] make[2]: *** Waiting for unfinished jobs....\n[WARNING] /tmp/ccQdGDON.s: Assembler messages:\n[WARNING] /tmp/ccQdGDON.s:2100: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccQdGDON.s:2125: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/codec/Lz4Codec.cc.o] Error 1\n[WARNING] /tmp/ccODk3CH.s: Assembler messages:\n[WARNING] /tmp/ccODk3CH.s:2100: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccODk3CH.s:2125: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccnLoCPN.s: Assembler messages:\n[WARNING] /tmp/ccnLoCPN.s:3069: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccnLoCPN.s:3094: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/codec/Lz4Codec.cc.o] Error 1\n[WARNING] /tmp/ccFSNYHH.s: Assembler messages:\n[WARNING] /tmp/ccFSNYHH.s:2237: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccFSNYHH.s:2251: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/codec/BlockCodec.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/codec/SnappyCodec.cc.o] Error 1\n[WARNING] /tmp/cc9v7eRH.s: Assembler messages:\n[WARNING] /tmp/cc9v7eRH.s:3054: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/cc9v7eRH.s:3079: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccfnpGIN.s: Assembler messages:\n[WARNING] /tmp/ccfnpGIN.s:2237: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccfnpGIN.s:2251: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s: Assembler messages:\n[WARNING] /tmp/ccJblCYF.s:1286: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1295: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1379: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1439: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1476: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1513: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1704: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1714: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1791: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:1924: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:2596: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:2700: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:2710: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:4019: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:4042: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:4301: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccJblCYF.s:5332: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/codec/BlockCodec.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/util/WritableUtils.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/codec/SnappyCodec.cc.o] Error 1\n[WARNING] /tmp/ccn8U7jG.s: Assembler messages:\n[WARNING] /tmp/ccn8U7jG.s:3317: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccn8U7jG.s:3327: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccn8U7jG.s:3336: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccCNSLfF.s: Assembler messages:\n[WARNING] /tmp/ccCNSLfF.s:3440: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccCNSLfF.s:3450: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccCNSLfF.s:3459: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/handler/MCollectorOutputHandler.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/handler/MCollectorOutputHandler.cc.o] Error 1\n[WARNING] /tmp/ccf3hdFH.s: Assembler messages:\n[WARNING] /tmp/ccf3hdFH.s:1052: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccf3hdFH.s:1137: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccIfaM9L.s: Assembler messages:\n[WARNING] /tmp/ccIfaM9L.s:1047: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccIfaM9L.s:1132: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/lib/Merge.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/lib/Merge.cc.o] Error 1\n[WARNING] /tmp/ccrQPmHF.s: Assembler messages:\n[WARNING] /tmp/ccrQPmHF.s:1092: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccrQPmHF.s:1176: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccrQPmHF.s:3452: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccrQPmHF.s:4376: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccKh4mrI.s: Assembler messages:\n[WARNING] /tmp/ccKh4mrI.s:1092: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccKh4mrI.s:1176: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccKh4mrI.s:3449: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccKh4mrI.s:4359: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s: Assembler messages:\n[WARNING] /tmp/ccjUETWF.s:2478: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s:4517: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s:4569: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s:4848: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s:4888: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/lib/IFile.cc.o] Error 1\n[WARNING] /tmp/ccjUETWF.s:5045: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s:5167: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s:5176: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s:5956: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccjUETWF.s:5966: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/lib/IFile.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/handler/CombineHandler.cc.o] Error 1\n[WARNING] /tmp/ccthyFZE.s: Assembler messages:\n[WARNING] /tmp/ccthyFZE.s:2925: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:4972: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:5024: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:5306: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:5346: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:5505: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:5627: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:5636: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:6471: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccthyFZE.s:6481: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/handler/CombineHandler.cc.o] Error 1\n[WARNING] /tmp/ccLyikpd.s: Assembler messages:\n[WARNING] /tmp/ccLyikpd.s:1286: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1295: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1379: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1439: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1476: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1513: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1703: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1713: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1790: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:1923: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:2083: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:2645: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:2748: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:2758: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:4056: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:4079: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:4337: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccLyikpd.s:5358: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/util/WritableUtils.cc.o] Error 1\n[WARNING] /tmp/ccEEXsIH.s: Assembler messages:\n[WARNING] /tmp/ccEEXsIH.s:202: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:211: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:360: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:369: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:491: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:501: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:525: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:535: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:609: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:619: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:643: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:653: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:1655: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:1667: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:1893: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:1903: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:1927: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:1937: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:2156: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:2166: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:2257: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:2267: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:2291: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccEEXsIH.s:2300: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s: Assembler messages:\n[WARNING] /tmp/ccDAlVGO.s:202: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:211: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:360: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:369: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:491: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:501: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:525: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:535: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:609: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:619: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:643: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:653: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:1655: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:1667: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:1893: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:1903: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:1927: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:1937: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:2156: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:2166: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:2257: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:2267: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:2291: Error: unrecognized opcode: `bswap\'\n[WARNING] /tmp/ccDAlVGO.s:2300: Error: unrecognized opcode: `bswap\'\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/lib/NativeObjectFactory.cc.o] Error 1\n[WARNING] make[1]: *** [CMakeFiles/nativetask.dir/all] Error 2\n[WARNING] make[1]: *** Waiting for unfinished jobs....\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/lib/NativeObjectFactory.cc.o] Error 1\n[WARNING] make[1]: *** [CMakeFiles/nativetask_static.dir/all] Error 2\n[WARNING] make: *** [all] Error 2\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Apache Hadoop Main ................................. SUCCESS [ 10.454 s]\n[INFO] Apache Hadoop Build Tools .......................... SUCCESS [  0.982 s]\n[INFO] Apache Hadoop Project POM .......................... SUCCESS [  1.979 s]\n[INFO] Apache Hadoop Annotations .......................... SUCCESS [  4.839 s]\n[INFO] Apache Hadoop Assemblies ........................... SUCCESS [  1.045 s]\n[INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [  2.402 s]\n[INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [  7.111 s]\n[INFO] Apache Hadoop MiniKDC .............................. SUCCESS [  3.420 s]\n[INFO] Apache Hadoop Auth ................................. SUCCESS [  9.036 s]\n[INFO] Apache Hadoop Auth Examples ........................ SUCCESS [  4.227 s]\n[INFO] Apache Hadoop Common ............................... SUCCESS [01:03 min]\n[INFO] Apache Hadoop NFS .................................. SUCCESS [  7.314 s]\n[INFO] Apache Hadoop KMS .................................. SUCCESS [  7.006 s]\n[INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.816 s]\n[INFO] Apache Hadoop HDFS Client .......................... SUCCESS [ 26.398 s]\n[INFO] Apache Hadoop HDFS ................................. SUCCESS [01:00 min]\n[INFO] Apache Hadoop HDFS Native Client ................... SUCCESS [  8.394 s]\n[INFO] Apache Hadoop HttpFS ............................... SUCCESS [  9.756 s]\n[INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  6.132 s]\n[INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.840 s]\n[INFO] Apache Hadoop YARN ................................. SUCCESS [  0.833 s]\n[INFO] Apache Hadoop YARN API ............................. SUCCESS [ 16.479 s]\n[INFO] Apache Hadoop YARN Common .......................... SUCCESS [ 36.507 s]\n[INFO] Apache Hadoop YARN Server .......................... SUCCESS [  0.848 s]\n[INFO] Apache Hadoop YARN Server Common ................... SUCCESS [ 13.710 s]\n[INFO] Apache Hadoop YARN Registry ........................ SUCCESS [  7.205 s]\n[INFO] Apache Hadoop YARN NodeManager ..................... SUCCESS [ 31.546 s]\n[INFO] Apache Hadoop YARN Web Proxy ....................... SUCCESS [  6.425 s]\n[INFO] Apache Hadoop YARN ApplicationHistoryService ....... SUCCESS [  8.641 s]\n[INFO] Apache Hadoop YARN Timeline Service ................ SUCCESS [  7.530 s]\n[INFO] Apache Hadoop YARN ResourceManager ................. SUCCESS [ 22.262 s]\n[INFO] Apache Hadoop YARN Server Tests .................... SUCCESS [  3.400 s]\n[INFO] Apache Hadoop YARN Client .......................... SUCCESS [  8.326 s]\n[INFO] Apache Hadoop YARN SharedCacheManager .............. SUCCESS [  6.180 s]\n[INFO] Apache Hadoop YARN Timeline Plugin Storage ......... SUCCESS [  6.191 s]\n[INFO] Apache Hadoop YARN TimelineService HBase Backend ... SUCCESS [  9.158 s]\n[INFO] Apache Hadoop YARN Timeline Service HBase tests .... SUCCESS [  4.497 s]\n[INFO] Apache Hadoop YARN Router .......................... SUCCESS [  7.390 s]\n[INFO] Apache Hadoop YARN Applications .................... SUCCESS [  0.857 s]\n[INFO] Apache Hadoop YARN DistributedShell ................ SUCCESS [  5.445 s]\n[INFO] Apache Hadoop YARN Unmanaged Am Launcher ........... SUCCESS [  5.537 s]\n[INFO] Apache Hadoop YARN Site ............................ SUCCESS [  0.829 s]\n[INFO] Apache Hadoop YARN UI .............................. SUCCESS [  0.829 s]\n[INFO] Apache Hadoop YARN Project ......................... SUCCESS [ 12.333 s]\n[INFO] Apache Hadoop MapReduce Client ..................... SUCCESS [  1.839 s]\n[INFO] Apache Hadoop MapReduce Core ....................... SUCCESS [ 17.559 s]\n[INFO] Apache Hadoop MapReduce Common ..................... SUCCESS [ 15.645 s]\n[INFO] Apache Hadoop MapReduce Shuffle .................... SUCCESS [  7.498 s]\n[INFO] Apache Hadoop MapReduce App ........................ SUCCESS [ 10.849 s]\n[INFO] Apache Hadoop MapReduce HistoryServer .............. SUCCESS [  8.433 s]\n[INFO] Apache Hadoop MapReduce JobClient .................. SUCCESS [  8.381 s]\n[INFO] Apache Hadoop MapReduce HistoryServer Plugins ...... SUCCESS [  4.548 s]\n[INFO] Apache Hadoop MapReduce NativeTask ................. FAILURE [ 15.875 s]\n[INFO] Apache Hadoop MapReduce Examples ................... SKIPPED\n[INFO] Apache Hadoop MapReduce ............................ SKIPPED\n[INFO] Apache Hadoop MapReduce Streaming .................. SKIPPED\n[INFO] Apache Hadoop Distributed Copy ..................... SKIPPED\n[INFO] Apache Hadoop Archives ............................. SKIPPED\n[INFO] Apache Hadoop Archive Logs ......................... SKIPPED\n[INFO] Apache Hadoop Rumen ................................ SKIPPED\n[INFO] Apache Hadoop Gridmix .............................. SKIPPED\n[INFO] Apache Hadoop Data Join ............................ SKIPPED\n[INFO] Apache Hadoop Extras ............................... SKIPPED\n[INFO] Apache Hadoop Pipes ................................ SKIPPED\n[INFO] Apache Hadoop OpenStack support .................... SKIPPED\n[INFO] Apache Hadoop Amazon Web Services support .......... SKIPPED\n[INFO] Apache Hadoop Kafka Library support ................ SKIPPED\n[INFO] Apache Hadoop Azure support ........................ SKIPPED\n[INFO] Apache Hadoop Aliyun OSS support ................... SKIPPED\n[INFO] Apache Hadoop Client Aggregator .................... SKIPPED\n[INFO] Apache Hadoop Mini-Cluster ......................... SKIPPED\n[INFO] Apache Hadoop Scheduler Load Simulator ............. SKIPPED\n[INFO] Apache Hadoop Resource Estimator Service ........... SKIPPED\n[INFO] Apache Hadoop Azure Data Lake support .............. SKIPPED\n[INFO] Apache Hadoop Tools Dist ........................... SKIPPED\n[INFO] Apache Hadoop Tools ................................ SKIPPED\n[INFO] Apache Hadoop Client API ........................... SKIPPED\n[INFO] Apache Hadoop Client Runtime ....................... SKIPPED\n[INFO] Apache Hadoop Client Packaging Invariants .......... SKIPPED\n[INFO] Apache Hadoop Client Test Minicluster .............. SKIPPED\n[INFO] Apache Hadoop Client Packaging Invariants for Test . SKIPPED\n[INFO] Apache Hadoop Client Packaging Integration Tests ... SKIPPED\n[INFO] Apache Hadoop Distribution ......................... SKIPPED\n[INFO] Apache Hadoop Client Modules ....................... SKIPPED\n[INFO] Apache Hadoop Cloud Storage ........................ SKIPPED\n[INFO] Apache Hadoop Cloud Storage Project ................ SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 09:13 min\n[INFO] Finished at: 2018-03-07T09:33:16+08:00\n[INFO] Final Memory: 278M/800M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.hadoop:hadoop-maven-plugins:3.0.0:cmake-compile (cmake-compile) on project hadoop-mapreduce-client-nativetask: make failed with error code 2 -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :hadoop-mapreduce-client-nativetask\nerror: Bad exit status from /var/tmp/rpm-tmp.JQgxkQ (%build)\n\n```\n\n## 问题分析及解决\n#### 此版本代码在x86架构上编译是没问题的，而且出错部分是C++代码，所以极有可能是代码中缺少ppc64le架构的代码逻辑，在代码中发现[primitives.h](https://github.com/apache/hadoop/blob/release-3.0.0-beta1-RC0/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/primitives.h)文件有以下相关逻辑：\n\n```\n/**\n * little-endian to big-endian or vice versa\n */\ninline uint32_t bswap(uint32_t val) {\n#ifdef __aarch64__\n  __asm__(\"rev %w[dst], %w[src]\" : [dst]\"=r\"(val) : [src]\"r\"(val));\n#else\n  __asm__(\"bswap %0\" : \"=r\" (val) : \"0\" (val));\n#endif\n  return val;\n}\n\ninline uint64_t bswap64(uint64_t val) {\n#ifdef __aarch64__\n  __asm__(\"rev %[dst], %[src]\" : [dst]\"=r\"(val) : [src]\"r\"(val));\n#else\n#ifdef __X64\n  __asm__(\"bswapq %0\" : \"=r\" (val) : \"0\" (val));\n#else\n\n  uint64_t lower = val & 0xffffffffU;\n  uint32_t higher = (val >> 32) & 0xffffffffU;\n\n  lower = bswap(lower);\n  higher = bswap(higher);\n\n  return (lower << 32) + higher;\n\n#endif\n#endif\n  return val;\n}\n```\n#### 可以看出，由于这里没有关于ppc64le架构的bswap返回值，所以编译出错，但这块涉及到C++和汇编语言，非本人所擅长，于是搜索社区，惊喜发现已有人提供解决方法\n\n#### 问题解决方法，请参考[HADOOP-14922](https://issues.apache.org/jira/browse/HADOOP-14922)\n\n\n', '0', '<h2 id=\"h2-u95EEu9898u63CFu8FF0\"><a name=\"问题描述\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问题描述</h2><h3 id=\"h3--apache-release-hadoop-3-0-0-ppc64le-centos7-4-\"><a name=\"使用apache社区release的Hadoop-3.0.0在ppc64le(centos7.4)环境下编译失败，失败信息如下：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>使用apache社区release的Hadoop-3.0.0在ppc64le(centos7.4)环境下编译失败，失败信息如下：</h3><pre><code>[WARNING] [ 72%] Linking CXX static library libgtest.a\n[WARNING] /usr/local/bin/cmake -P CMakeFiles/gtest.dir/cmake_clean_target.cmake\n[WARNING] /usr/local/bin/cmake -E cmake_link_script CMakeFiles/gtest.dir/link.txt --verbose=1\n[WARNING] /usr/bin/ar qc libgtest.a  CMakeFiles/gtest.dir/build-data/workspace/hadoop-3.0.0-beta/build/hadoop/rpm/BUILD/hadoop-3.0.0-src/hadoop-common-project/hadoop-common/src/main/native/gtest/gtest-all.cc.o\n[WARNING] /usr/bin/ranlib libgtest.a\n[WARNING] make[2]: Leaving directory `/build-data/workspace/hadoop-3.0.0-beta/build/hadoop/rpm/BUILD/hadoop-3.0.0-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native&#39;\n[WARNING] [ 72%] Built target gtest\n[WARNING] make[1]: Leaving directory `/build-data/workspace/hadoop-3.0.0-beta/build/hadoop/rpm/BUILD/hadoop-3.0.0-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/native&#39;\n[WARNING] /tmp/ccgwlPQH.s: Assembler messages:\n[WARNING] /tmp/ccgwlPQH.s:536: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:617: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:627: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:708: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:718: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:822: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:832: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:917: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:927: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:1056: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccgwlPQH.s:1066: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/lib/SpillInfo.cc.o] Error 1\n[WARNING] make[2]: *** Waiting for unfinished jobs....\n[WARNING] /tmp/ccv6BetQ.s: Assembler messages:\n[WARNING] /tmp/ccv6BetQ.s:523: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:603: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:613: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:694: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:704: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:808: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:818: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:903: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:913: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:1043: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccv6BetQ.s:1053: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/lib/SpillInfo.cc.o] Error 1\n[WARNING] make[2]: *** Waiting for unfinished jobs....\n[WARNING] /tmp/ccQdGDON.s: Assembler messages:\n[WARNING] /tmp/ccQdGDON.s:2100: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccQdGDON.s:2125: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/codec/Lz4Codec.cc.o] Error 1\n[WARNING] /tmp/ccODk3CH.s: Assembler messages:\n[WARNING] /tmp/ccODk3CH.s:2100: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccODk3CH.s:2125: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccnLoCPN.s: Assembler messages:\n[WARNING] /tmp/ccnLoCPN.s:3069: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccnLoCPN.s:3094: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/codec/Lz4Codec.cc.o] Error 1\n[WARNING] /tmp/ccFSNYHH.s: Assembler messages:\n[WARNING] /tmp/ccFSNYHH.s:2237: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccFSNYHH.s:2251: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/codec/BlockCodec.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/codec/SnappyCodec.cc.o] Error 1\n[WARNING] /tmp/cc9v7eRH.s: Assembler messages:\n[WARNING] /tmp/cc9v7eRH.s:3054: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/cc9v7eRH.s:3079: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccfnpGIN.s: Assembler messages:\n[WARNING] /tmp/ccfnpGIN.s:2237: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccfnpGIN.s:2251: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s: Assembler messages:\n[WARNING] /tmp/ccJblCYF.s:1286: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1295: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1379: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1439: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1476: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1513: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1704: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1714: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1791: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:1924: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:2596: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:2700: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:2710: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:4019: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:4042: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:4301: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccJblCYF.s:5332: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/codec/BlockCodec.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/util/WritableUtils.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/codec/SnappyCodec.cc.o] Error 1\n[WARNING] /tmp/ccn8U7jG.s: Assembler messages:\n[WARNING] /tmp/ccn8U7jG.s:3317: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccn8U7jG.s:3327: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccn8U7jG.s:3336: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccCNSLfF.s: Assembler messages:\n[WARNING] /tmp/ccCNSLfF.s:3440: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccCNSLfF.s:3450: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccCNSLfF.s:3459: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/handler/MCollectorOutputHandler.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/handler/MCollectorOutputHandler.cc.o] Error 1\n[WARNING] /tmp/ccf3hdFH.s: Assembler messages:\n[WARNING] /tmp/ccf3hdFH.s:1052: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccf3hdFH.s:1137: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccIfaM9L.s: Assembler messages:\n[WARNING] /tmp/ccIfaM9L.s:1047: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccIfaM9L.s:1132: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/lib/Merge.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/lib/Merge.cc.o] Error 1\n[WARNING] /tmp/ccrQPmHF.s: Assembler messages:\n[WARNING] /tmp/ccrQPmHF.s:1092: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccrQPmHF.s:1176: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccrQPmHF.s:3452: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccrQPmHF.s:4376: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccKh4mrI.s: Assembler messages:\n[WARNING] /tmp/ccKh4mrI.s:1092: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccKh4mrI.s:1176: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccKh4mrI.s:3449: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccKh4mrI.s:4359: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s: Assembler messages:\n[WARNING] /tmp/ccjUETWF.s:2478: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s:4517: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s:4569: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s:4848: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s:4888: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/lib/IFile.cc.o] Error 1\n[WARNING] /tmp/ccjUETWF.s:5045: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s:5167: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s:5176: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s:5956: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccjUETWF.s:5966: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/lib/IFile.cc.o] Error 1\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/handler/CombineHandler.cc.o] Error 1\n[WARNING] /tmp/ccthyFZE.s: Assembler messages:\n[WARNING] /tmp/ccthyFZE.s:2925: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:4972: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:5024: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:5306: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:5346: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:5505: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:5627: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:5636: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:6471: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccthyFZE.s:6481: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/handler/CombineHandler.cc.o] Error 1\n[WARNING] /tmp/ccLyikpd.s: Assembler messages:\n[WARNING] /tmp/ccLyikpd.s:1286: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1295: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1379: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1439: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1476: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1513: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1703: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1713: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1790: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:1923: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:2083: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:2645: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:2748: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:2758: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:4056: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:4079: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:4337: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccLyikpd.s:5358: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/util/WritableUtils.cc.o] Error 1\n[WARNING] /tmp/ccEEXsIH.s: Assembler messages:\n[WARNING] /tmp/ccEEXsIH.s:202: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:211: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:360: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:369: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:491: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:501: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:525: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:535: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:609: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:619: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:643: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:653: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:1655: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:1667: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:1893: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:1903: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:1927: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:1937: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:2156: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:2166: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:2257: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:2267: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:2291: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccEEXsIH.s:2300: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s: Assembler messages:\n[WARNING] /tmp/ccDAlVGO.s:202: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:211: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:360: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:369: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:491: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:501: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:525: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:535: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:609: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:619: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:643: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:653: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:1655: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:1667: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:1893: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:1903: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:1927: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:1937: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:2156: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:2166: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:2257: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:2267: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:2291: Error: unrecognized opcode: `bswap&#39;\n[WARNING] /tmp/ccDAlVGO.s:2300: Error: unrecognized opcode: `bswap&#39;\n[WARNING] make[2]: *** [CMakeFiles/nativetask.dir/main/native/src/lib/NativeObjectFactory.cc.o] Error 1\n[WARNING] make[1]: *** [CMakeFiles/nativetask.dir/all] Error 2\n[WARNING] make[1]: *** Waiting for unfinished jobs....\n[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/main/native/src/lib/NativeObjectFactory.cc.o] Error 1\n[WARNING] make[1]: *** [CMakeFiles/nativetask_static.dir/all] Error 2\n[WARNING] make: *** [all] Error 2\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Apache Hadoop Main ................................. SUCCESS [ 10.454 s]\n[INFO] Apache Hadoop Build Tools .......................... SUCCESS [  0.982 s]\n[INFO] Apache Hadoop Project POM .......................... SUCCESS [  1.979 s]\n[INFO] Apache Hadoop Annotations .......................... SUCCESS [  4.839 s]\n[INFO] Apache Hadoop Assemblies ........................... SUCCESS [  1.045 s]\n[INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [  2.402 s]\n[INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [  7.111 s]\n[INFO] Apache Hadoop MiniKDC .............................. SUCCESS [  3.420 s]\n[INFO] Apache Hadoop Auth ................................. SUCCESS [  9.036 s]\n[INFO] Apache Hadoop Auth Examples ........................ SUCCESS [  4.227 s]\n[INFO] Apache Hadoop Common ............................... SUCCESS [01:03 min]\n[INFO] Apache Hadoop NFS .................................. SUCCESS [  7.314 s]\n[INFO] Apache Hadoop KMS .................................. SUCCESS [  7.006 s]\n[INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.816 s]\n[INFO] Apache Hadoop HDFS Client .......................... SUCCESS [ 26.398 s]\n[INFO] Apache Hadoop HDFS ................................. SUCCESS [01:00 min]\n[INFO] Apache Hadoop HDFS Native Client ................... SUCCESS [  8.394 s]\n[INFO] Apache Hadoop HttpFS ............................... SUCCESS [  9.756 s]\n[INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  6.132 s]\n[INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.840 s]\n[INFO] Apache Hadoop YARN ................................. SUCCESS [  0.833 s]\n[INFO] Apache Hadoop YARN API ............................. SUCCESS [ 16.479 s]\n[INFO] Apache Hadoop YARN Common .......................... SUCCESS [ 36.507 s]\n[INFO] Apache Hadoop YARN Server .......................... SUCCESS [  0.848 s]\n[INFO] Apache Hadoop YARN Server Common ................... SUCCESS [ 13.710 s]\n[INFO] Apache Hadoop YARN Registry ........................ SUCCESS [  7.205 s]\n[INFO] Apache Hadoop YARN NodeManager ..................... SUCCESS [ 31.546 s]\n[INFO] Apache Hadoop YARN Web Proxy ....................... SUCCESS [  6.425 s]\n[INFO] Apache Hadoop YARN ApplicationHistoryService ....... SUCCESS [  8.641 s]\n[INFO] Apache Hadoop YARN Timeline Service ................ SUCCESS [  7.530 s]\n[INFO] Apache Hadoop YARN ResourceManager ................. SUCCESS [ 22.262 s]\n[INFO] Apache Hadoop YARN Server Tests .................... SUCCESS [  3.400 s]\n[INFO] Apache Hadoop YARN Client .......................... SUCCESS [  8.326 s]\n[INFO] Apache Hadoop YARN SharedCacheManager .............. SUCCESS [  6.180 s]\n[INFO] Apache Hadoop YARN Timeline Plugin Storage ......... SUCCESS [  6.191 s]\n[INFO] Apache Hadoop YARN TimelineService HBase Backend ... SUCCESS [  9.158 s]\n[INFO] Apache Hadoop YARN Timeline Service HBase tests .... SUCCESS [  4.497 s]\n[INFO] Apache Hadoop YARN Router .......................... SUCCESS [  7.390 s]\n[INFO] Apache Hadoop YARN Applications .................... SUCCESS [  0.857 s]\n[INFO] Apache Hadoop YARN DistributedShell ................ SUCCESS [  5.445 s]\n[INFO] Apache Hadoop YARN Unmanaged Am Launcher ........... SUCCESS [  5.537 s]\n[INFO] Apache Hadoop YARN Site ............................ SUCCESS [  0.829 s]\n[INFO] Apache Hadoop YARN UI .............................. SUCCESS [  0.829 s]\n[INFO] Apache Hadoop YARN Project ......................... SUCCESS [ 12.333 s]\n[INFO] Apache Hadoop MapReduce Client ..................... SUCCESS [  1.839 s]\n[INFO] Apache Hadoop MapReduce Core ....................... SUCCESS [ 17.559 s]\n[INFO] Apache Hadoop MapReduce Common ..................... SUCCESS [ 15.645 s]\n[INFO] Apache Hadoop MapReduce Shuffle .................... SUCCESS [  7.498 s]\n[INFO] Apache Hadoop MapReduce App ........................ SUCCESS [ 10.849 s]\n[INFO] Apache Hadoop MapReduce HistoryServer .............. SUCCESS [  8.433 s]\n[INFO] Apache Hadoop MapReduce JobClient .................. SUCCESS [  8.381 s]\n[INFO] Apache Hadoop MapReduce HistoryServer Plugins ...... SUCCESS [  4.548 s]\n[INFO] Apache Hadoop MapReduce NativeTask ................. FAILURE [ 15.875 s]\n[INFO] Apache Hadoop MapReduce Examples ................... SKIPPED\n[INFO] Apache Hadoop MapReduce ............................ SKIPPED\n[INFO] Apache Hadoop MapReduce Streaming .................. SKIPPED\n[INFO] Apache Hadoop Distributed Copy ..................... SKIPPED\n[INFO] Apache Hadoop Archives ............................. SKIPPED\n[INFO] Apache Hadoop Archive Logs ......................... SKIPPED\n[INFO] Apache Hadoop Rumen ................................ SKIPPED\n[INFO] Apache Hadoop Gridmix .............................. SKIPPED\n[INFO] Apache Hadoop Data Join ............................ SKIPPED\n[INFO] Apache Hadoop Extras ............................... SKIPPED\n[INFO] Apache Hadoop Pipes ................................ SKIPPED\n[INFO] Apache Hadoop OpenStack support .................... SKIPPED\n[INFO] Apache Hadoop Amazon Web Services support .......... SKIPPED\n[INFO] Apache Hadoop Kafka Library support ................ SKIPPED\n[INFO] Apache Hadoop Azure support ........................ SKIPPED\n[INFO] Apache Hadoop Aliyun OSS support ................... SKIPPED\n[INFO] Apache Hadoop Client Aggregator .................... SKIPPED\n[INFO] Apache Hadoop Mini-Cluster ......................... SKIPPED\n[INFO] Apache Hadoop Scheduler Load Simulator ............. SKIPPED\n[INFO] Apache Hadoop Resource Estimator Service ........... SKIPPED\n[INFO] Apache Hadoop Azure Data Lake support .............. SKIPPED\n[INFO] Apache Hadoop Tools Dist ........................... SKIPPED\n[INFO] Apache Hadoop Tools ................................ SKIPPED\n[INFO] Apache Hadoop Client API ........................... SKIPPED\n[INFO] Apache Hadoop Client Runtime ....................... SKIPPED\n[INFO] Apache Hadoop Client Packaging Invariants .......... SKIPPED\n[INFO] Apache Hadoop Client Test Minicluster .............. SKIPPED\n[INFO] Apache Hadoop Client Packaging Invariants for Test . SKIPPED\n[INFO] Apache Hadoop Client Packaging Integration Tests ... SKIPPED\n[INFO] Apache Hadoop Distribution ......................... SKIPPED\n[INFO] Apache Hadoop Client Modules ....................... SKIPPED\n[INFO] Apache Hadoop Cloud Storage ........................ SKIPPED\n[INFO] Apache Hadoop Cloud Storage Project ................ SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 09:13 min\n[INFO] Finished at: 2018-03-07T09:33:16+08:00\n[INFO] Final Memory: 278M/800M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.hadoop:hadoop-maven-plugins:3.0.0:cmake-compile (cmake-compile) on project hadoop-mapreduce-client-nativetask: make failed with error code 2 -&gt; [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n[ERROR] \n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn &lt;goals&gt; -rf :hadoop-mapreduce-client-nativetask\nerror: Bad exit status from /var/tmp/rpm-tmp.JQgxkQ (%build)\n</code></pre><h2 id=\"h2-u95EEu9898u5206u6790u53CAu89E3u51B3\"><a name=\"问题分析及解决\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问题分析及解决</h2><h4 id=\"h4--x86-c-ppc64le-primitives-h-\"><a name=\"此版本代码在x86架构上编译是没问题的，而且出错部分是C++代码，所以极有可能是代码中缺少ppc64le架构的代码逻辑，在代码中发现  primitives.h 文件有以下相关逻辑：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>此版本代码在x86架构上编译是没问题的，而且出错部分是C++代码，所以极有可能是代码中缺少ppc64le架构的代码逻辑，在代码中发现<a href=\"https://github.com/apache/hadoop/blob/release-3.0.0-beta1-RC0/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/primitives.h\">primitives.h</a>文件有以下相关逻辑：</h4><pre><code>/**\n * little-endian to big-endian or vice versa\n */\ninline uint32_t bswap(uint32_t val) {\n#ifdef __aarch64__\n  __asm__(&quot;rev %w[dst], %w[src]&quot; : [dst]&quot;=r&quot;(val) : [src]&quot;r&quot;(val));\n#else\n  __asm__(&quot;bswap %0&quot; : &quot;=r&quot; (val) : &quot;0&quot; (val));\n#endif\n  return val;\n}\n\ninline uint64_t bswap64(uint64_t val) {\n#ifdef __aarch64__\n  __asm__(&quot;rev %[dst], %[src]&quot; : [dst]&quot;=r&quot;(val) : [src]&quot;r&quot;(val));\n#else\n#ifdef __X64\n  __asm__(&quot;bswapq %0&quot; : &quot;=r&quot; (val) : &quot;0&quot; (val));\n#else\n\n  uint64_t lower = val &amp; 0xffffffffU;\n  uint32_t higher = (val &gt;&gt; 32) &amp; 0xffffffffU;\n\n  lower = bswap(lower);\n  higher = bswap(higher);\n\n  return (lower &lt;&lt; 32) + higher;\n\n#endif\n#endif\n  return val;\n}\n</code></pre><h4 id=\"h4--ppc64le-bswap-c-\"><a name=\"可以看出，由于这里没有关于ppc64le架构的bswap返回值，所以编译出错，但这块涉及到C++和汇编语言，非本人所擅长，于是搜索社区，惊喜发现已有人提供解决方法\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>可以看出，由于这里没有关于ppc64le架构的bswap返回值，所以编译出错，但这块涉及到C++和汇编语言，非本人所擅长，于是搜索社区，惊喜发现已有人提供解决方法</h4><h4 id=\"h4--hadoop-14922\"><a name=\"问题解决方法，请参考  HADOOP-14922\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问题解决方法，请参考<a href=\"https://issues.apache.org/jira/browse/HADOOP-14922\">HADOOP-14922</a></h4>');
INSERT INTO `tbl_archive` VALUES ('34', '0', 'HDFS的异构存储测试', '23', '2018-03-07 15:27:10', '异构存储', null, '0', '589', null, null, '2018-03-07 15:27:10', '2018-03-07 15:57:22', null, null, '0', '0', '0', '0', '##存储类型\n根据存储的介质不同，存储类型按照存储的速度快慢排序依次为：RAM_DISK,SSD,DISK, ARCHIVE.\n- memory存储，数据放在内存中，读写速度快，数据可暂时存储\n- SSD：又称固态硬盘，读写速度仅次于memory，数据可以永久存放\n- DISK：普通机械硬盘。在hdfs中如果没有特意指定，数据默认都存在DISK中。\n- ARCHIV：具有较高的存储密度，读写速度差，用于归档存储。\n\n## 存储策略\n在hdfs中存储策略分为以下几种：\n- HOT：用于存储热数据，默认情况，hdfs的数据都采用的是HOT策略，所有的副本都存储在DISK中。\n- COLD：用于存储冷数据，所有的数据副本存储在ARCHIV中。\n- Warm：有些数据存在DISK中，有些做归档处理 。\n- All_SSD：所有的数据副本都存储在SSD中。\n- One_SSD：将数据的一个副本存储在SSD中，其余的副本存储在磁盘中。\n- Lazy_Persist：用于在内存中写入单个副本的块。该副本首先在RAM_DISK中写入，后续持久化到DISK中。\n\n通常一个存储策略有以下几个部分组成：Policy ID，Policy name，Block存储类型列表，文件创建时的备用存储类型列表，用于副本的备用存储类型列表。如下表所示：\n![](/upload/images/20180307//c9a075f9-8545-49f3-bf03-91845c294fa5.png)\n## 配置异构存储\n1.在hdfs-site.xml 文件中配置dfs.storage.policy.enabled属性，值为true（默认）\n\n2.dfs.datanode.data.dir值的配置：在每个datanode上，应该将逗号分隔的存储位置标记为它们的存储类型。这允许存储策略根据策略将块放在不同的存储类型上。例如：\nDataNode数据存储位置为：/data/hadoop/ssd 应该配置为[SSD]/data/hadoop/disk\n3.当对数据的存储策略做出改变是，需要使用mover命令对相关文件目录进行扫描，进行数据块的迁移。\n`hdfs mover [-p <files/dirs> | -f <local file name>]`\n-p: 指定要迁移的HDFS文件列表。\n-f：指定被迁移的HDFS文件对应的本地文件系统路径\n注：当忽略-p和-f选项时，默认路径是根目录。\n4.相关的命令：\n列出目前现有的存储策略\n`hdfs storagepolicies -listPolicies` \n对目标文件/目录设置存储策略\n`hdfs storagepolicies -setStoragePolicy -path <path> -policy <policy>`\n获取指定路径的存储策略\n`hdfs -getStoragePolicy -path <path>`\n\n##异构存储实战\n1.环境准备\n三台服务器：crh-1,crh-2,crh-3\n磁盘挂载情况相同，都有一个ssd盘，三个机械硬盘，如下所示\ncrh-1\n![](/upload/images/20180307//40a309de-7acb-4743-86f5-1aeaac2fe459.png)\ncrh-2\n![](/upload/images/20180307//a99df0ea-f017-47a8-8c02-976cf8fe24d1.png)\ncrh-3\n![](/upload/images/20180307//b45542dc-0e03-4481-947f-5f31781b447f.png)\n2.hadoop版本2.7.5，集群节点分布如下：\n![](/upload/images/20180307//32135dfb-fdd5-4bc2-a89a-725c7090ed30.png)\n3.在用ambari安装hadoop时填写dfs.datanode.data.dir时，根据自己的实际情况填写，如下：\n    /data/hdd1/hadoop/hdfs/data,/data/hdd2/hadoop/hdfs/data,/data/hdd3/hadoop/hdfs/data,[SSD]/data/ssd/hadoop/hdfs/data\n\n![](/upload/images/20180307//ce55d596-41ac-445f-8e1e-e191ec1857ab.png)\n4.命令实战\n切换到hdfs用户，查看当前有哪些存储策略可以用\n    hdfs storagepolicies –listPolicies\n	\n    [hdfs@crh-3 ~]$ hdfs storagepolicies -listPolicies\n    Block Storage Policies:\n    	BlockStoragePolicy{COLD:2, storageTypes=[ARCHIVE], creationFallbacks=[], replicationFallbacks=[]}\n    	BlockStoragePolicy{WARM:5, storageTypes=[DISK, ARCHIVE], creationFallbacks=[DISK, ARCHIVE], replicationFallbacks=[DISK, ARCHIVE]}\n    	BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n    	BlockStoragePolicy{ONE_SSD:10, storageTypes=[SSD, DISK], creationFallbacks=[SSD, DISK], replicationFallbacks=[SSD, DISK]}\n    	BlockStoragePolicy{ALL_SSD:12, storageTypes=[SSD], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n    	BlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n    \n\n2.获取指定路径的存储策略\nhdfs storagepolicies -getStoragePolicy -path /user\n\n    [hdfs@crh-3 ~]$ hdfs dfs -ls / \n    Found 8 items\n    drwxrwxrwx   - yarn   hadoop          0 2018-03-06 14:52 /app-logs\n    drwxr-xr-x   - yarn   hadoop          0 2018-03-06 14:37 /ats\n    drwxr-xr-x   - hdfs   hdfs            0 2018-03-06 15:39 /benchmarks\n    drwxr-xr-x   - hdfs   hdfs            0 2018-03-06 14:37 /crh\n    drwxr-xr-x   - mapred hdfs            0 2018-03-06 14:37 /mapred\n    drwxrwxrwx   - mapred hadoop          0 2018-03-06 14:37 /mr-history\n    drwxrwxrwx   - hdfs   hdfs            0 2018-03-06 14:38 /tmp\n    drwxr-xr-x   - hdfs   hdfs            0 2018-03-06 14:52 /user\n    [hdfs@crh-3 ~]$ hdfs storagepolicies -getStoragePolicy -path /user\n    The storage policy of /user is unspecified\n创建一个新的目录和文件，指定其存储策略\n\n    [hdfs@crh-3 ~]$ hdfs dfs -mkdir -p /test/data/\n    [hdfs@crh-3 ~]$ hdfs dfs -put /opt/test.txt /test/data/\n    [hdfs@crh-3 ~]$ hdfs dfs -ls /test/data/\n    Found 1 items\n    -rw-r--r--   3 hdfs hdfs     179714984449 2018-03-07 09:34 /test/data/test.txt\n    [hdfs@crh-3 ~]$ hdfs storagepolicies -setStoragePolicy -path /test/data/test.txt -policy ALL_SSD\n    Set storage policy ALL_SSD on /test/data/test.txt\n    \n执行hdfs mover 命令，进行数据块的迁移\n\n    hdfs mover -p /test/data/test.txt\n    [hdfs@crh-3 ~]$ hdfs mover -p /test/data/test.txt \n    18/03/07 09:49:54 INFO mover.Mover: namenodes = {hdfs://crh-1:8020=[/test/data/test.txt]}\n    18/03/07 09:49:55 INFO balancer.KeyManager: Block token params received from NN: update interval=10hrs, 0sec, token lifetime=10hrs, 0sec\n    18/03/07 09:49:55 INFO block.BlockTokenSecretManager: Setting block keys\n    18/03/07 09:49:55 INFO balancer.KeyManager: Update block keys every 2hrs, 30mins, 0sec\n    18/03/07 09:49:56 INFO block.BlockTokenSecretManager: Setting block keys\n    18/03/07 09:49:56 INFO net.NetworkTopology: Adding a new node: /default-rack/192.168.0.83:50010\n    18/03/07 09:49:56 INFO net.NetworkTopology: Adding a new node:\n	.............\n使用df -h 命令查看datanode的服务器上的ssd盘已经有数据了\ncrh-3\n![](/upload/images/20180307//ff2ce3cb-8f07-478b-8daa-c9f490180727.png)\ncrh-2\n![](/upload/images/20180307//b3397ec0-24f0-4b90-9c7a-88622c27e776.png)\n\n参考文档\n[http://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html](http://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html)', '0', '<h2 id=\"h2-u5B58u50A8u7C7Bu578B\"><a name=\"存储类型\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>存储类型</h2><p>根据存储的介质不同，存储类型按照存储的速度快慢排序依次为：RAM_DISK,SSD,DISK, ARCHIVE.</p>\n<ul>\n<li>memory存储，数据放在内存中，读写速度快，数据可暂时存储</li><li>SSD：又称固态硬盘，读写速度仅次于memory，数据可以永久存放</li><li>DISK：普通机械硬盘。在hdfs中如果没有特意指定，数据默认都存在DISK中。</li><li>ARCHIV：具有较高的存储密度，读写速度差，用于归档存储。</li></ul>\n<h2 id=\"h2-u5B58u50A8u7B56u7565\"><a name=\"存储策略\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>存储策略</h2><p>在hdfs中存储策略分为以下几种：</p>\n<ul>\n<li>HOT：用于存储热数据，默认情况，hdfs的数据都采用的是HOT策略，所有的副本都存储在DISK中。</li><li>COLD：用于存储冷数据，所有的数据副本存储在ARCHIV中。</li><li>Warm：有些数据存在DISK中，有些做归档处理 。</li><li>All_SSD：所有的数据副本都存储在SSD中。</li><li>One_SSD：将数据的一个副本存储在SSD中，其余的副本存储在磁盘中。</li><li>Lazy_Persist：用于在内存中写入单个副本的块。该副本首先在RAM_DISK中写入，后续持久化到DISK中。</li></ul>\n<p>通常一个存储策略有以下几个部分组成：Policy ID，Policy name，Block存储类型列表，文件创建时的备用存储类型列表，用于副本的备用存储类型列表。如下表所示：<br><img src=\"/upload/images/20180307//c9a075f9-8545-49f3-bf03-91845c294fa5.png\" alt=\"\"></p>\n<h2 id=\"h2-u914Du7F6Eu5F02u6784u5B58u50A8\"><a name=\"配置异构存储\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置异构存储</h2><p>1.在hdfs-site.xml 文件中配置dfs.storage.policy.enabled属性，值为true（默认）</p>\n<p>2.dfs.datanode.data.dir值的配置：在每个datanode上，应该将逗号分隔的存储位置标记为它们的存储类型。这允许存储策略根据策略将块放在不同的存储类型上。例如：<br>DataNode数据存储位置为：/data/hadoop/ssd 应该配置为[SSD]/data/hadoop/disk<br>3.当对数据的存储策略做出改变是，需要使用mover命令对相关文件目录进行扫描，进行数据块的迁移。<br><code>hdfs mover [-p &lt;files/dirs&gt; | -f &lt;local file name&gt;]</code><br>-p: 指定要迁移的HDFS文件列表。<br>-f：指定被迁移的HDFS文件对应的本地文件系统路径<br>注：当忽略-p和-f选项时，默认路径是根目录。<br>4.相关的命令：<br>列出目前现有的存储策略<br><code>hdfs storagepolicies -listPolicies</code><br>对目标文件/目录设置存储策略<br><code>hdfs storagepolicies -setStoragePolicy -path &lt;path&gt; -policy &lt;policy&gt;</code><br>获取指定路径的存储策略<br><code>hdfs -getStoragePolicy -path &lt;path&gt;</code></p>\n<h2 id=\"h2-u5F02u6784u5B58u50A8u5B9Eu6218\"><a name=\"异构存储实战\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>异构存储实战</h2><p>1.环境准备<br>三台服务器：crh-1,crh-2,crh-3<br>磁盘挂载情况相同，都有一个ssd盘，三个机械硬盘，如下所示<br>crh-1<br><img src=\"/upload/images/20180307//40a309de-7acb-4743-86f5-1aeaac2fe459.png\" alt=\"\"><br>crh-2<br><img src=\"/upload/images/20180307//a99df0ea-f017-47a8-8c02-976cf8fe24d1.png\" alt=\"\"><br>crh-3<br><img src=\"/upload/images/20180307//b45542dc-0e03-4481-947f-5f31781b447f.png\" alt=\"\"><br>2.hadoop版本2.7.5，集群节点分布如下：<br><img src=\"/upload/images/20180307//32135dfb-fdd5-4bc2-a89a-725c7090ed30.png\" alt=\"\"><br>3.在用ambari安装hadoop时填写dfs.datanode.data.dir时，根据自己的实际情况填写，如下：<br>    /data/hdd1/hadoop/hdfs/data,/data/hdd2/hadoop/hdfs/data,/data/hdd3/hadoop/hdfs/data,[SSD]/data/ssd/hadoop/hdfs/data</p>\n<p><img src=\"/upload/images/20180307//ce55d596-41ac-445f-8e1e-e191ec1857ab.png\" alt=\"\"><br>4.命令实战<br>切换到hdfs用户，查看当前有哪些存储策略可以用<br>    hdfs storagepolicies –listPolicies</p>\n<pre><code>[hdfs@crh-3 ~]$ hdfs storagepolicies -listPolicies\nBlock Storage Policies:\n    BlockStoragePolicy{COLD:2, storageTypes=[ARCHIVE], creationFallbacks=[], replicationFallbacks=[]}\n    BlockStoragePolicy{WARM:5, storageTypes=[DISK, ARCHIVE], creationFallbacks=[DISK, ARCHIVE], replicationFallbacks=[DISK, ARCHIVE]}\n    BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n    BlockStoragePolicy{ONE_SSD:10, storageTypes=[SSD, DISK], creationFallbacks=[SSD, DISK], replicationFallbacks=[SSD, DISK]}\n    BlockStoragePolicy{ALL_SSD:12, storageTypes=[SSD], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n    BlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n</code></pre><p>2.获取指定路径的存储策略<br>hdfs storagepolicies -getStoragePolicy -path /user</p>\n<pre><code>[hdfs@crh-3 ~]$ hdfs dfs -ls / \nFound 8 items\ndrwxrwxrwx   - yarn   hadoop          0 2018-03-06 14:52 /app-logs\ndrwxr-xr-x   - yarn   hadoop          0 2018-03-06 14:37 /ats\ndrwxr-xr-x   - hdfs   hdfs            0 2018-03-06 15:39 /benchmarks\ndrwxr-xr-x   - hdfs   hdfs            0 2018-03-06 14:37 /crh\ndrwxr-xr-x   - mapred hdfs            0 2018-03-06 14:37 /mapred\ndrwxrwxrwx   - mapred hadoop          0 2018-03-06 14:37 /mr-history\ndrwxrwxrwx   - hdfs   hdfs            0 2018-03-06 14:38 /tmp\ndrwxr-xr-x   - hdfs   hdfs            0 2018-03-06 14:52 /user\n[hdfs@crh-3 ~]$ hdfs storagepolicies -getStoragePolicy -path /user\nThe storage policy of /user is unspecified\n</code></pre><p>创建一个新的目录和文件，指定其存储策略</p>\n<pre><code>[hdfs@crh-3 ~]$ hdfs dfs -mkdir -p /test/data/\n[hdfs@crh-3 ~]$ hdfs dfs -put /opt/test.txt /test/data/\n[hdfs@crh-3 ~]$ hdfs dfs -ls /test/data/\nFound 1 items\n-rw-r--r--   3 hdfs hdfs     179714984449 2018-03-07 09:34 /test/data/test.txt\n[hdfs@crh-3 ~]$ hdfs storagepolicies -setStoragePolicy -path /test/data/test.txt -policy ALL_SSD\nSet storage policy ALL_SSD on /test/data/test.txt\n</code></pre><p>执行hdfs mover 命令，进行数据块的迁移</p>\n<pre><code>hdfs mover -p /test/data/test.txt\n[hdfs@crh-3 ~]$ hdfs mover -p /test/data/test.txt \n18/03/07 09:49:54 INFO mover.Mover: namenodes = {hdfs://crh-1:8020=[/test/data/test.txt]}\n18/03/07 09:49:55 INFO balancer.KeyManager: Block token params received from NN: update interval=10hrs, 0sec, token lifetime=10hrs, 0sec\n18/03/07 09:49:55 INFO block.BlockTokenSecretManager: Setting block keys\n18/03/07 09:49:55 INFO balancer.KeyManager: Update block keys every 2hrs, 30mins, 0sec\n18/03/07 09:49:56 INFO block.BlockTokenSecretManager: Setting block keys\n18/03/07 09:49:56 INFO net.NetworkTopology: Adding a new node: /default-rack/192.168.0.83:50010\n18/03/07 09:49:56 INFO net.NetworkTopology: Adding a new node:\n.............\n</code></pre><p>使用df -h 命令查看datanode的服务器上的ssd盘已经有数据了<br>crh-3<br><img src=\"/upload/images/20180307//ff2ce3cb-8f07-478b-8daa-c9f490180727.png\" alt=\"\"><br>crh-2<br><img src=\"/upload/images/20180307//b3397ec0-24f0-4b90-9c7a-88622c27e776.png\" alt=\"\"></p>\n<p>参考文档<br><a href=\"http://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html\">http://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('35', '0', 'hbase的基本sql使用', '14', '2018-03-08 09:16:30', '1.运用ambari安装phoenix,连接hbase,运用sql语句![这里写图片描述](http://img.blog.csdn.net/20180307154347597?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/diss', null, '0', '431', null, null, '2018-03-08 09:16:30', null, null, null, '0', '0', '0', '0', '1.	运用ambari安装phoenix,连接hbase,运用sql语句\n![这里写图片描述](http://img.blog.csdn.net/20180307154347597?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n \n2.	数据存储在HBase中，通过SQL进行CRUD操作\n创建test表\n\n```\ncreate table test(\npk VARCHAR primary key,\ncol1 VARCHAR null,\ncol2 VARCHAR null,\ncol3 VARCHAR null\n);\n```\n![这里写图片描述](http://img.blog.csdn.net/20180307154414858?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n \n创建SRC_TABLE表\n\n```\ncreate table SRC_TABLE (\npk VARCHAR primary key,\ncol1 VARCHAR null,\ncol2 VARCHAR null,\ncol3 VARCHAR null\n);\n```\n![这里写图片描述](http://img.blog.csdn.net/20180307154427459?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n \n往SRC_TABLE表中插入三条数据\n\n```\nupsert INTO SRC_TABLE (pk,col1, col2, col3) VALUES(\'2\',\'22\', \'22\', \'22\');\nupsert INTO SRC_TABLE (pk,col1, col2, col3) VALUES(\'3\',\'33\', \'33\', \'33\') ;\nupsert INTO SRC_TABLE (pk,col1, col2, col3) VALUES(\'4\',\'44\', \'44\', \'44\') ;\n```\n\n ![这里写图片描述](http://img.blog.csdn.net/2018030715450720?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\nSQL示例：\n向表test中插入一条数据\n```\nupsert INTO test(pk,col1, col2, col3) VALUES(\'1\',\'11\', \'22\', \'33\');\n```\n\n ![这里写图片描述](http://img.blog.csdn.net/20180307154533988?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n从SRC_TABLE表中查出数据插入到test表中\n```\nupsert INTO test select pk,col1,col2,col3 FROM SRC_TABLE;\n```\n![这里写图片描述](http://img.blog.csdn.net/2018030715455190?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n \n ![这里写图片描述](http://img.blog.csdn.net/20180307154608818?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n从SRC_TABLE表中查出一部分列数据插入到test表中\n```\nupsert INTO test(pk,col2, col1) select pk,col2, col1 FROM SRC_TABLE; \n```\n![这里写图片描述](http://img.blog.csdn.net/20180307154618725?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n \n修改test表中pk为1的列的值\n```\nupsert into test (pk,col1,col2) values (\'1\',\'value1\', \'value2\'); \n```\n![这里写图片描述](http://img.blog.csdn.net/20180307154647582?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n删除test表中pk为1的那一列\n```\ndelete from test where pk=\'1\';\n```\n![这里写图片描述](http://img.blog.csdn.net/20180307154714963?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n模糊查询删除所有的pk的列\n\n```\n  delete from test where pk like \'%\';\n```\n\n![这里写图片描述](http://img.blog.csdn.net/20180307154810659?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n 以上就是hbase phoneix的sql语句的基本用法。\n\n', '0', '<ol>\n<li><p>运用ambari安装phoenix,连接hbase,运用sql语句<br><img src=\"http://img.blog.csdn.net/20180307154347597?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n</li><li><p>数据存储在HBase中，通过SQL进行CRUD操作<br>创建test表</p>\n</li></ol>\n<pre><code>create table test(\npk VARCHAR primary key,\ncol1 VARCHAR null,\ncol2 VARCHAR null,\ncol3 VARCHAR null\n);\n</code></pre><p><img src=\"http://img.blog.csdn.net/20180307154414858?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n<p>创建SRC_TABLE表</p>\n<pre><code>create table SRC_TABLE (\npk VARCHAR primary key,\ncol1 VARCHAR null,\ncol2 VARCHAR null,\ncol3 VARCHAR null\n);\n</code></pre><p><img src=\"http://img.blog.csdn.net/20180307154427459?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n<p>往SRC_TABLE表中插入三条数据</p>\n<pre><code>upsert INTO SRC_TABLE (pk,col1, col2, col3) VALUES(&#39;2&#39;,&#39;22&#39;, &#39;22&#39;, &#39;22&#39;);\nupsert INTO SRC_TABLE (pk,col1, col2, col3) VALUES(&#39;3&#39;,&#39;33&#39;, &#39;33&#39;, &#39;33&#39;) ;\nupsert INTO SRC_TABLE (pk,col1, col2, col3) VALUES(&#39;4&#39;,&#39;44&#39;, &#39;44&#39;, &#39;44&#39;) ;\n</code></pre><p> <img src=\"http://img.blog.csdn.net/2018030715450720?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"><br>SQL示例：<br>向表test中插入一条数据</p>\n<pre><code>upsert INTO test(pk,col1, col2, col3) VALUES(&#39;1&#39;,&#39;11&#39;, &#39;22&#39;, &#39;33&#39;);\n</code></pre><p> <img src=\"http://img.blog.csdn.net/20180307154533988?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"><br>从SRC_TABLE表中查出数据插入到test表中</p>\n<pre><code>upsert INTO test select pk,col1,col2,col3 FROM SRC_TABLE;\n</code></pre><p><img src=\"http://img.blog.csdn.net/2018030715455190?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n<p> <img src=\"http://img.blog.csdn.net/20180307154608818?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"><br>从SRC_TABLE表中查出一部分列数据插入到test表中</p>\n<pre><code>upsert INTO test(pk,col2, col1) select pk,col2, col1 FROM SRC_TABLE;\n</code></pre><p><img src=\"http://img.blog.csdn.net/20180307154618725?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n<p>修改test表中pk为1的列的值</p>\n<pre><code>upsert into test (pk,col1,col2) values (&#39;1&#39;,&#39;value1&#39;, &#39;value2&#39;);\n</code></pre><p><img src=\"http://img.blog.csdn.net/20180307154647582?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n<p>删除test表中pk为1的那一列</p>\n<pre><code>delete from test where pk=&#39;1&#39;;\n</code></pre><p><img src=\"http://img.blog.csdn.net/20180307154714963?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"><br>模糊查询删除所有的pk的列</p>\n<pre><code>  delete from test where pk like &#39;%&#39;;\n</code></pre><p><img src=\"http://img.blog.csdn.net/20180307154810659?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzA0MDgxMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n<p> 以上就是hbase phoneix的sql语句的基本用法。</p>\n');
INSERT INTO `tbl_archive` VALUES ('36', '0', 'openstack-newton版自动化安装', '25', '2018-03-09 09:31:24', '简单配置，一键安装。', null, '0', '324', null, null, '2018-03-09 09:31:24', '2018-04-08 10:57:43', null, null, '0', '0', '0', '0', '# 基础环境准备\n#### 把自己的ip改成静态ip修改DNS添加网关让机器能上网\n```\n#cat /etc/sysconfig/network-scripts/ifcfg-eno16777736\nTYPE=\"Ethernet\"\nBOOTPROTO=\"static\"\nDEFROUTE=\"yes\"\nIPV4_FAILURE_FATAL=\"no\"\nIPV6INIT=\"yes\"\nIPV6_AUTOCONF=\"yes\"\nIPV6_DEFROUTE=\"yes\"\nIPV6_FAILURE_FATAL=\"no\"\nNAME=\"eno16780032\"\nUUID=\"d38bf87a-21fb-4d41-a44a-a1162e13583a\"\nDEVICE=\"eno16780032\"\nONBOOT=\"yes\"\nIPADDR=\"192.168.0.119\"\nPREFIX=\"24\"\nGATEWAY=\"192.168.0.1\"\nDNS1=\"114.114.114.114\"\nIPV6_PEERDNS=\"yes\"\nIPV6_PEERROUTES=\"yes\"\nIPV6_PRIVACY=\"no\"\n```\n#### 修改主机名\n```\n#cat /etc/hostname/\nopenstack-master\n```\n#### 查看系统版本号\n```\n# hostnamectl status\n   Static hostname: openstack-master\n         Icon name: computer-vm\n           Chassis: vm\n        Machine ID: fd369dbd8e7a44c39bb5882bd4a5ffbe\n           Boot ID: b998b48f0bab40a5bf793e8cb15b7a6a\n    Virtualization: vmware\n  Operating System: CentOS Linux 7 (Core)\n       CPE OS Name: cpe:/o:centos:centos:7\n            Kernel: Linux 3.10.0-327.el7.x86_64\n      Architecture: x86-64\n\n# cat /etc/redhat-release \nCentOS Linux release 7.2.1511 (Core)\n```\n### 关闭selinux和防火墙\n#### 关闭selinux\n```\n# sed -i \'s#SELINUX=enforcing#SELINUX=disabled#g\' /etc/selinux/config \n# setenforce 0\n# grep SELINUX=disabled /etc/selinux/config\n \n SELINUX=disabled\n\n```\n#### 关闭防火墙\n```\n#sudo systemctl status firewalld.service        \n#sudo systemctl stop firewalld.service \n#sudo systemctl disable firewalld.service \n#iptables -L -n\n```\n### 创建openstack用户\n```\n# useradd openstack \n# echo \"openstack123\"|passwd --stdin openstack \n# echo \'openstack ALL=(ALL) NOPASSWD: ALL\' >> /etc/sudoers\n```\n### 修改文件描述符\n```\n# echo \'* - nofile 65535\' >> /etc/security/limits.conf\n```\n### 配置ntp服务\n```\n# yum install ntpdate–y \n# systemctl start ntpdate\n# systemctl enable ntpdate \n```\n\n### 配置免秘钥登录和修改hosts文件 （IP映射）\n```\n# vim /etc/hosts/\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.119  openstack-master\n\n#ssh-keygen  -t rsa \n#ssh-copy-id openstack-master\n```\n## openstack-newton版 安装与配置\n> 必备条件：\n\n> Centos7、Redhat7   最小化安装系统。\n\n> openstack-N 版本\n\n> ssh 免密登录\n\n> Linux 基础优化/selinux关闭、关闭防火墙\n\n> cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core)\n \n> sestatus -v       \n SELinux status: disabled\n\n### 添加/etc/environment  如下面： \n```\nvim /etc/environment \nLANG=en_US.utf-8 \nLC_ALL=en_US.utf-8\n```\n### 安装openstack-newton\n> yum  search  openstack   /索取一下openstack\n\n> yum -y install centos-release-openstack-newton.noarch\n\n> sudo yum install -y openstack-packstack\n### 自动部署OPenstack\n> sudo packstack --allinone\n\n```\nDiscovering ip protocol version                      [ DONE ]\nSetting up ssh keys                                  [ DONE ]\n\nKeystone 验证信息\n[openstack@openstack-master ~]$ sudo cat /root/keystonerc_admin\nunset OS_SERVICE_TOKEN\nexport OS_USERNAME=admin\nexport OS_PASSWORD=ee24cdf7eda54a93\nexport OS_AUTH_URL=http://192.168.0.119:5000/v2.0\nexport PS1=\'[\\u@\\h \\W(keystone_admin)]\\$ \'\nexport OS_TENANT_NAME=admin\nexport OS_REGION_NAME=RegionOne\n\n[openstack@openstack-master ~]$ sudo cat /root/keystonerc_demo\nunset OS_SERVICE_TOKEN\nexport OS_USERNAME=demo\nexport OS_PASSWORD=436bdb9fac2b45b3\nexport PS1=\'[\\u@\\h \\W(keystone_demo)]\\$ \'\nexport OS_AUTH_URL=http://192.168.0.119:5000/v2.0\nexport OS_TENANT_NAME=demo\nexport OS_IDENTITY_API_VERSION=2.0\n```\n### 您还可以生成一个应答文件，并在其他系统上使用它\n\n```\n[openstack@openstack-controller ~]$ sudo su - root\nLast login: Tue Jun 14 00:05:28 CST 2016 on pts/0\n[root@openstack-controller ~]# ls\nanaconda-ks.cfg keystonerc_admin keystonerc_demo packstack-answers\n-20160613-231012.txt\n[root@openstack-controller ~]# packstack --gen-answer-file=answerfil\ne.txt\n[root@openstack-controller ~]# cat answerfile.txt |wc -l\n1307\n WebUI: http://192.168.2.110/dashboard\n Username/password: admin/ee24cdf7eda54a93\n[root@openstack-controller ~]# keystone user-list\n[root@openstack-controller ~]# keystone service-list\n[root@openstack-controller ~]# nova host-list\n\n```\n# 常见问题解答\n > https://www.rdoproject.org/testday/workarounds/\n \n> 看到后台都安装哪些rpm包：tailf /var/log/messages\n\n> [root@openstack-master  ~]# cat /var/log/yum.log |wc -l\n\n> 392\n \n > 服务器异常排查\n \n > [root@openstack-master ~]# openstack-status |grep neutron\n\n# 网络配置-后端\n\n> https://www.rdoproject.org/networking/neutron-with-existing-external-network/\n\n> 网络配置&可视化界面创建内外网信息做好路由转发！\n\n```\n          \n[root@openstack-master ~]# cat /etc/sysconfig/network-scripts/ifcfg-br-ex \nNAME=\"br-ex\"\nDEVICE=\"br-ex\"\nDEVICETYPE=ovs\nTYPE=OVSBridge\nONBOOT=yes\nIPV6INIT=no\nBOOTPROTO=none\nDNS1=114.114.114.114\nDOMAIN=openstack-master\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPADDR=192.168.0.119\nPREFIX=24\nGATEWAY=192.168.0.1\n```\n```\n[root@openstack-master ~]# cat /etc/sysconfig/network-scripts/ifcfg-eno16780032 \nNAME=\"eno16780032\"\nDEVICE=\"eno16780032\"\nONBOOT=\"yes\"\nIPV6INIT=no\nBOOTPROTO=none\nDEVICETYPE=ovs\nTYPE=OVSPort\nOVS_BRIDGE=br-ex\n```\n```\n[root@openstack-master~]# systemctl restart network.service\n\n[root@openstack-master ~]#  ovs-vsctl show\n98617d4a-0b4f-4a51-b78e-10efc80d67ab\n    Manager \"ptcp:6640:127.0.0.1\"\n        is_connected: true\n    Bridge br-ex\n        Port \"qg-14db6248-8f\"\n            Interface \"qg-14db6248-8f\"\n                type: internal\n        Port \"eno16780032\"\n            Interface \"eno16780032\"\n        Port br-ex\n            Interface br-ex\n                type: internal\n    Bridge br-int\n        Controller \"tcp:127.0.0.1:6633\"\n            is_connected: true\n        fail_mode: secure\n        Port br-int\n            Interface br-int\n                type: internal\n        Port \"tapc8836b55-50\"\n            tag: 1\n            Interface \"tapc8836b55-50\"\n                type: internal\n        Port \"qvo556e0b9c-65\"\n            tag: 2\n            Interface \"qvo556e0b9c-65\"\n        Port patch-tun\n            Interface patch-tun\n                type: patch\n                options: {peer=patch-int}\n        Port \"qr-e5b4826f-5a\"\n            tag: 2\n            Interface \"qr-e5b4826f-5a\"\n                type: internal\n        Port \"tap9fe5749b-c5\"\n            tag: 2\n            Interface \"tap9fe5749b-c5\"\n                type: internal\n    Bridge br-tun\n        Controller \"tcp:127.0.0.1:6633\"\n            is_connected: true\n        fail_mode: secure\n        Port patch-int\n            Interface patch-int\n                type: patch\n                options: {peer=patch-tun}\n        Port br-tun\n            Interface br-tun\n                type: internal\n    ovs_version: \"2.6.1\"\n\n```\n\n# 可视化配置网络-前端\n\n### 首先要先建立一个openstack用户，作为另外一个租户创建一个单独私有网段。\n\n![](/upload/images/20180309//0c8a5f1d-9412-469f-a65f-cd5c442ae81c.png)\n\n\n> 创建组\n\n![](/upload/images/20180309//f7b747b1-1b02-45d2-8b81-0af1cc14ae36.png)\n\n> 创建项目\n\n![](/upload/images/20180309//512134e0-53e7-490d-9d57-2cba0d0bc32b.png)\n\n> 创建用户\n\n![](/upload/images/20180309//506fba3e-d53f-4e45-b107-0432a50e2dcc.png)\n\n> 将openstack-cloud用户加入组\n\n![](/upload/images/20180309//1de1837c-24bb-4c8b-bf4e-a8494ed6b88d.png)\n\n![](/upload/images/20180309//b16f9003-8315-49ea-be13-0d2554140a0a.png)\n\n## openstack网络配置\n \n### 网络-公共网络\n\n> 首先通过admin登陆，找到管理员->系统，删除\"路由\",网络中的所有内容\n\n> 第一步\n\n![](/upload/images/20180309//2bc50ddb-a95e-49b9-94c4-8022214d6ab2.png)\n\n> 点击public网络，进去添加子网。点击下一步，最后点击创建\n\n> 第二步\n\n![](/upload/images/20180309//30a8acf4-2858-4580-b3d9-b1dde4072ce3.png)\n\n> 第三步\n\n![](/upload/images/20180309//3646afff-6649-4015-8d48-5008897eed23.png)\n\n> 第四步\n\n> 查看子网\n![](/upload/images/20180309//d27cc72f-5ddf-4772-9dfc-8480f905ca88.png)\n\n### 网络-私有网络 \n> 切换用户 用“openstack-cloud登陆”\n\n> 在项目-网络-网络，创建私有网络\n\n> 第一步\n![](/upload/images/20180309//aa65da73-8fd0-4868-a646-abd47f1b3249.png)\n\n> 第二步\n\n![](/upload/images/20180309//b6b97b79-4870-4260-92b9-8ffc63a00d39.png)\n\n> 第三步\n\n![](/upload/images/20180309//e8c07d19-94dc-43db-96c1-cd1d099e2bc4.png)\n\n> 完成创建\n\n> 查看网络\n\n![](/upload/images/20180309//cd686bcc-7521-4806-adf9-b74a06137556.png)\n\n### 创建路由\n\n> 在项目-网络-路由里面创建\n\n> 第一步 新建路由\n\n![](/upload/images/20180309//2f982277-b5c4-4851-b6f6-ecf717261b6e.png)\n\n> 第二步\n点击新建的路由，设置公网+私网通信，点击如下“增加接口”\n\n![](/upload/images/20180309//5c8ab3d4-cab5-4103-9bdf-e12395ecb1b9.png)\n\n![](/upload/images/20180309//3b4fbccf-bb3d-4bf2-b419-b678340924b0.png)\n\n### 项目-网络-网络拓扑\n\n> 出现以下拓扑图说明网络就可以了\n![](/upload/images/20180309//a8eb20c5-f422-4e42-b0b4-be4ca5748124.png)\n\n### 项目-计算-访问&安全\n\n> 安全组设置\n\n![](/upload/images/20180309//0eb7ab9c-4607-4615-8f0e-0063adf72a13.png)\n\n> 删除入口规则\n\n![](/upload/images/20180309//95eeb2f9-3cbb-4af2-b254-a98bd9b02de8.png)\n\n> 选择“添加规则”\n\n![](/upload/images/20180309//329dbabf-687f-4220-9c14-d1438516b60b.png)\n\n![](/upload/images/20180309//a88534e2-9739-4069-9fe6-7d354be9bd76.png)\n\n> 完成\n\n![](/upload/images/20180309//11efec65-378e-485a-ae98-2e1dd82396e0.png)\n\n### 访问&安全-密钥对\n\n> 去终端切换openstack用户执行以下命令\n\n> [openstack@openstack-master ~]$ssh-keygen	-t	rsa	-f	cloud.key\n\n> 导入密钥对\n\n![](/upload/images/20180309//12ca0aab-726e-4a2c-958d-19ad0682c1fb.png)\n\n# 添加多个compute节点\n\n> https://www.rdoproject.org/install/adding-a-compute-node/\n\n```\nNOTE: by default $youranswerfile is called packstack-answer-$date-$time.txt\n```\n```\n[root@openstack-master	 ~]#	 ls	 packstack-answers-20160517-215941.txt\npackstack-answers-20160517-215941.txt\nChange IP addresses\nChange the value for CONFIG_COMPUTE_HOSTS from the value of your first host IP address\nto the value of your second host IP address. Ensure that the\nkeyCONFIG_NETWORK_HOSTS exists and is set to the IP address of your first host.\nSkip installing on an already existing servers\nIn case you do not want to run the installation over again on the already configured\nservers, add the following parameter to the answerfile:\nEXCLUDE_SERVERS=<serverIP>,<serverIP>,...\n\n案例：\n[root@openstack-master	 ~]#	 egrep	 \"CONFIG_COMPUTE_HOSTS|CONFIG_NETW\nORK_HOSTS|EXCLUDE_SERVERS\"	 packstack-answers-20160613-231012.txt\nEXCLUDE_SERVERS=192.168.2.110\nCONFIG_COMPUTE_HOSTS=192.168.2.110,192.168.2.111,192.168.2.112,192.168.2.1\n13\nCONFIG_NETWORK_HOSTS=192.168.2.110\nRe-run	packstack	with	the	new	values	\nRun packstack again, specifying your modified answer file:\nNOTE: by default $youranswerfile is called packstack-answer-$date-$time.txt\n[root@openstack-master	 ~]#	 cp	 packstack-answers-20160613-231012.txt	 /hom\ne/openstack/\n[root@openstack-master	 ~]#	 exit\nlogout\n[root@openstack-master	 ~]#	 sudo	 packstack	 --answer-file=packstack-answers-2\n0160613-231012.txt\n```\n> 查看云主机列表\n\n![](/upload/images/20180309//871f41fa-383d-4f83-a273-8b7e343bfb17.png)\n\n\n```\n[root@openstack-master	 ~]#	 nova list	 --all\n#查看云硬盘信息\n[root@openstack-master	 ~]#	 cinder	 list\n#查看主机几点角色信息\n\n```\n# 上传镜像\n\n> 从公网上传一个镜像文件   http://cloud.centos.org/centos/7/images/\n\n> 先将镜像下载到本地上传上去\n\n![](/upload/images/20180309//c1aeaa25-8bc0-4542-bc4a-aea2e758568e.png)\n\n![](/upload/images/20180309//84e8ac5d-e6a1-4207-bb08-4b0fe45d5743.png)', '0', '<h1 id=\"h1-u57FAu7840u73AFu5883u51C6u5907\"><a name=\"基础环境准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>基础环境准备</h1><h4 id=\"h4--ip-ip-dns-\"><a name=\"把自己的ip改成静态ip修改DNS添加网关让机器能上网\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>把自己的ip改成静态ip修改DNS添加网关让机器能上网</h4><pre><code>#cat /etc/sysconfig/network-scripts/ifcfg-eno16777736\nTYPE=&quot;Ethernet&quot;\nBOOTPROTO=&quot;static&quot;\nDEFROUTE=&quot;yes&quot;\nIPV4_FAILURE_FATAL=&quot;no&quot;\nIPV6INIT=&quot;yes&quot;\nIPV6_AUTOCONF=&quot;yes&quot;\nIPV6_DEFROUTE=&quot;yes&quot;\nIPV6_FAILURE_FATAL=&quot;no&quot;\nNAME=&quot;eno16780032&quot;\nUUID=&quot;d38bf87a-21fb-4d41-a44a-a1162e13583a&quot;\nDEVICE=&quot;eno16780032&quot;\nONBOOT=&quot;yes&quot;\nIPADDR=&quot;192.168.0.119&quot;\nPREFIX=&quot;24&quot;\nGATEWAY=&quot;192.168.0.1&quot;\nDNS1=&quot;114.114.114.114&quot;\nIPV6_PEERDNS=&quot;yes&quot;\nIPV6_PEERROUTES=&quot;yes&quot;\nIPV6_PRIVACY=&quot;no&quot;\n</code></pre><h4 id=\"h4-u4FEEu6539u4E3Bu673Au540D\"><a name=\"修改主机名\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改主机名</h4><pre><code>#cat /etc/hostname/\nopenstack-master\n</code></pre><h4 id=\"h4-u67E5u770Bu7CFBu7EDFu7248u672Cu53F7\"><a name=\"查看系统版本号\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>查看系统版本号</h4><pre><code># hostnamectl status\n   Static hostname: openstack-master\n         Icon name: computer-vm\n           Chassis: vm\n        Machine ID: fd369dbd8e7a44c39bb5882bd4a5ffbe\n           Boot ID: b998b48f0bab40a5bf793e8cb15b7a6a\n    Virtualization: vmware\n  Operating System: CentOS Linux 7 (Core)\n       CPE OS Name: cpe:/o:centos:centos:7\n            Kernel: Linux 3.10.0-327.el7.x86_64\n      Architecture: x86-64\n\n# cat /etc/redhat-release \nCentOS Linux release 7.2.1511 (Core)\n</code></pre><h3 id=\"h3--selinux-\"><a name=\"关闭selinux和防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭selinux和防火墙</h3><h4 id=\"h4--selinux\"><a name=\"关闭selinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭selinux</h4><pre><code># sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/selinux/config \n# setenforce 0\n# grep SELINUX=disabled /etc/selinux/config\n\n SELINUX=disabled\n</code></pre><h4 id=\"h4-u5173u95EDu9632u706Bu5899\"><a name=\"关闭防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭防火墙</h4><pre><code>#sudo systemctl status firewalld.service        \n#sudo systemctl stop firewalld.service \n#sudo systemctl disable firewalld.service \n#iptables -L -n\n</code></pre><h3 id=\"h3--openstack-\"><a name=\"创建openstack用户\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建openstack用户</h3><pre><code># useradd openstack \n# echo &quot;openstack123&quot;|passwd --stdin openstack \n# echo &#39;openstack ALL=(ALL) NOPASSWD: ALL&#39; &gt;&gt; /etc/sudoers\n</code></pre><h3 id=\"h3-u4FEEu6539u6587u4EF6u63CFu8FF0u7B26\"><a name=\"修改文件描述符\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改文件描述符</h3><pre><code># echo &#39;* - nofile 65535&#39; &gt;&gt; /etc/security/limits.conf\n</code></pre><h3 id=\"h3--ntp-\"><a name=\"配置ntp服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置ntp服务</h3><pre><code># yum install ntpdate–y \n# systemctl start ntpdate\n# systemctl enable ntpdate\n</code></pre><h3 id=\"h3--hosts-ip-\"><a name=\"配置免秘钥登录和修改hosts文件 （IP映射）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置免秘钥登录和修改hosts文件 （IP映射）</h3><pre><code># vim /etc/hosts/\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.119  openstack-master\n\n#ssh-keygen  -t rsa \n#ssh-copy-id openstack-master\n</code></pre><h2 id=\"h2-openstack-newton-\"><a name=\"openstack-newton版 安装与配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>openstack-newton版 安装与配置</h2><blockquote>\n<p>必备条件：</p>\n<p>Centos7、Redhat7   最小化安装系统。</p>\n<p>openstack-N 版本</p>\n<p>ssh 免密登录</p>\n<p>Linux 基础优化/selinux关闭、关闭防火墙</p>\n<p>cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core)</p>\n<p>sestatus -v<br> SELinux status: disabled</p>\n</blockquote>\n<h3 id=\"h3--etc-environment-\"><a name=\"添加/etc/environment  如下面：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>添加/etc/environment  如下面：</h3><pre><code>vim /etc/environment \nLANG=en_US.utf-8 \nLC_ALL=en_US.utf-8\n</code></pre><h3 id=\"h3--openstack-newton\"><a name=\"安装openstack-newton\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装openstack-newton</h3><blockquote>\n<p>yum  search  openstack   /索取一下openstack</p>\n<p>yum -y install centos-release-openstack-newton.noarch</p>\n<p>sudo yum install -y openstack-packstack</p>\n<h3 id=\"h3--openstack\"><a name=\"自动部署OPenstack\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>自动部署OPenstack</h3><p>sudo packstack —allinone</p>\n</blockquote>\n<pre><code>Discovering ip protocol version                      [ DONE ]\nSetting up ssh keys                                  [ DONE ]\n\nKeystone 验证信息\n[openstack@openstack-master ~]$ sudo cat /root/keystonerc_admin\nunset OS_SERVICE_TOKEN\nexport OS_USERNAME=admin\nexport OS_PASSWORD=ee24cdf7eda54a93\nexport OS_AUTH_URL=http://192.168.0.119:5000/v2.0\nexport PS1=&#39;[\\u@\\h \\W(keystone_admin)]\\$ &#39;\nexport OS_TENANT_NAME=admin\nexport OS_REGION_NAME=RegionOne\n\n[openstack@openstack-master ~]$ sudo cat /root/keystonerc_demo\nunset OS_SERVICE_TOKEN\nexport OS_USERNAME=demo\nexport OS_PASSWORD=436bdb9fac2b45b3\nexport PS1=&#39;[\\u@\\h \\W(keystone_demo)]\\$ &#39;\nexport OS_AUTH_URL=http://192.168.0.119:5000/v2.0\nexport OS_TENANT_NAME=demo\nexport OS_IDENTITY_API_VERSION=2.0\n</code></pre><h3 id=\"h3--\"><a name=\"您还可以生成一个应答文件，并在其他系统上使用它\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>您还可以生成一个应答文件，并在其他系统上使用它</h3><pre><code>[openstack@openstack-controller ~]$ sudo su - root\nLast login: Tue Jun 14 00:05:28 CST 2016 on pts/0\n[root@openstack-controller ~]# ls\nanaconda-ks.cfg keystonerc_admin keystonerc_demo packstack-answers\n-20160613-231012.txt\n[root@openstack-controller ~]# packstack --gen-answer-file=answerfil\ne.txt\n[root@openstack-controller ~]# cat answerfile.txt |wc -l\n1307\n WebUI: http://192.168.2.110/dashboard\n Username/password: admin/ee24cdf7eda54a93\n[root@openstack-controller ~]# keystone user-list\n[root@openstack-controller ~]# keystone service-list\n[root@openstack-controller ~]# nova host-list\n</code></pre><h1 id=\"h1-u5E38u89C1u95EEu9898u89E3u7B54\"><a name=\"常见问题解答\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>常见问题解答</h1><blockquote>\n<p><a href=\"https://www.rdoproject.org/testday/workarounds/\">https://www.rdoproject.org/testday/workarounds/</a></p>\n<p>看到后台都安装哪些rpm包：tailf /var/log/messages</p>\n<p>[root<a href=\"https://github.com/openstack\" title=\"&#64;openstack\" class=\"at-link\">@openstack</a>-master  ~]# cat /var/log/yum.log |wc -l</p>\n<p>392</p>\n<p>服务器异常排查</p>\n<p>[root<a href=\"https://github.com/openstack\" title=\"&#64;openstack\" class=\"at-link\">@openstack</a>-master ~]# openstack-status |grep neutron</p>\n</blockquote>\n<h1 id=\"h1--\"><a name=\"网络配置-后端\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>网络配置-后端</h1><blockquote>\n<p><a href=\"https://www.rdoproject.org/networking/neutron-with-existing-external-network/\">https://www.rdoproject.org/networking/neutron-with-existing-external-network/</a></p>\n<p>网络配置&amp;可视化界面创建内外网信息做好路由转发！</p>\n</blockquote>\n<pre><code>\n[root@openstack-master ~]# cat /etc/sysconfig/network-scripts/ifcfg-br-ex \nNAME=&quot;br-ex&quot;\nDEVICE=&quot;br-ex&quot;\nDEVICETYPE=ovs\nTYPE=OVSBridge\nONBOOT=yes\nIPV6INIT=no\nBOOTPROTO=none\nDNS1=114.114.114.114\nDOMAIN=openstack-master\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPADDR=192.168.0.119\nPREFIX=24\nGATEWAY=192.168.0.1\n</code></pre><pre><code>[root@openstack-master ~]# cat /etc/sysconfig/network-scripts/ifcfg-eno16780032 \nNAME=&quot;eno16780032&quot;\nDEVICE=&quot;eno16780032&quot;\nONBOOT=&quot;yes&quot;\nIPV6INIT=no\nBOOTPROTO=none\nDEVICETYPE=ovs\nTYPE=OVSPort\nOVS_BRIDGE=br-ex\n</code></pre><pre><code>[root@openstack-master~]# systemctl restart network.service\n\n[root@openstack-master ~]#  ovs-vsctl show\n98617d4a-0b4f-4a51-b78e-10efc80d67ab\n    Manager &quot;ptcp:6640:127.0.0.1&quot;\n        is_connected: true\n    Bridge br-ex\n        Port &quot;qg-14db6248-8f&quot;\n            Interface &quot;qg-14db6248-8f&quot;\n                type: internal\n        Port &quot;eno16780032&quot;\n            Interface &quot;eno16780032&quot;\n        Port br-ex\n            Interface br-ex\n                type: internal\n    Bridge br-int\n        Controller &quot;tcp:127.0.0.1:6633&quot;\n            is_connected: true\n        fail_mode: secure\n        Port br-int\n            Interface br-int\n                type: internal\n        Port &quot;tapc8836b55-50&quot;\n            tag: 1\n            Interface &quot;tapc8836b55-50&quot;\n                type: internal\n        Port &quot;qvo556e0b9c-65&quot;\n            tag: 2\n            Interface &quot;qvo556e0b9c-65&quot;\n        Port patch-tun\n            Interface patch-tun\n                type: patch\n                options: {peer=patch-int}\n        Port &quot;qr-e5b4826f-5a&quot;\n            tag: 2\n            Interface &quot;qr-e5b4826f-5a&quot;\n                type: internal\n        Port &quot;tap9fe5749b-c5&quot;\n            tag: 2\n            Interface &quot;tap9fe5749b-c5&quot;\n                type: internal\n    Bridge br-tun\n        Controller &quot;tcp:127.0.0.1:6633&quot;\n            is_connected: true\n        fail_mode: secure\n        Port patch-int\n            Interface patch-int\n                type: patch\n                options: {peer=patch-tun}\n        Port br-tun\n            Interface br-tun\n                type: internal\n    ovs_version: &quot;2.6.1&quot;\n</code></pre><h1 id=\"h1--\"><a name=\"可视化配置网络-前端\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>可视化配置网络-前端</h1><h3 id=\"h3--openstack-\"><a name=\"首先要先建立一个openstack用户，作为另外一个租户创建一个单独私有网段。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>首先要先建立一个openstack用户，作为另外一个租户创建一个单独私有网段。</h3><p><img src=\"/upload/images/20180309//0c8a5f1d-9412-469f-a65f-cd5c442ae81c.png\" alt=\"\"></p>\n<blockquote>\n<p>创建组</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//f7b747b1-1b02-45d2-8b81-0af1cc14ae36.png\" alt=\"\"></p>\n<blockquote>\n<p>创建项目</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//512134e0-53e7-490d-9d57-2cba0d0bc32b.png\" alt=\"\"></p>\n<blockquote>\n<p>创建用户</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//506fba3e-d53f-4e45-b107-0432a50e2dcc.png\" alt=\"\"></p>\n<blockquote>\n<p>将openstack-cloud用户加入组</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//1de1837c-24bb-4c8b-bf4e-a8494ed6b88d.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180309//b16f9003-8315-49ea-be13-0d2554140a0a.png\" alt=\"\"></p>\n<h2 id=\"h2-openstack-\"><a name=\"openstack网络配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>openstack网络配置</h2><h3 id=\"h3--\"><a name=\"网络-公共网络\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>网络-公共网络</h3><blockquote>\n<p>首先通过admin登陆，找到管理员-&gt;系统，删除”路由”,网络中的所有内容</p>\n<p>第一步</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//2bc50ddb-a95e-49b9-94c4-8022214d6ab2.png\" alt=\"\"></p>\n<blockquote>\n<p>点击public网络，进去添加子网。点击下一步，最后点击创建</p>\n<p>第二步</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//30a8acf4-2858-4580-b3d9-b1dde4072ce3.png\" alt=\"\"></p>\n<blockquote>\n<p>第三步</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//3646afff-6649-4015-8d48-5008897eed23.png\" alt=\"\"></p>\n<blockquote>\n<p>第四步</p>\n<p>查看子网<br><img src=\"/upload/images/20180309//d27cc72f-5ddf-4772-9dfc-8480f905ca88.png\" alt=\"\"></p>\n</blockquote>\n<h3 id=\"h3--\"><a name=\"网络-私有网络\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>网络-私有网络</h3><blockquote>\n<p>切换用户 用“openstack-cloud登陆”</p>\n<p>在项目-网络-网络，创建私有网络</p>\n<p>第一步<br><img src=\"/upload/images/20180309//aa65da73-8fd0-4868-a646-abd47f1b3249.png\" alt=\"\"></p>\n<p>第二步</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//b6b97b79-4870-4260-92b9-8ffc63a00d39.png\" alt=\"\"></p>\n<blockquote>\n<p>第三步</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//e8c07d19-94dc-43db-96c1-cd1d099e2bc4.png\" alt=\"\"></p>\n<blockquote>\n<p>完成创建</p>\n<p>查看网络</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//cd686bcc-7521-4806-adf9-b74a06137556.png\" alt=\"\"></p>\n<h3 id=\"h3-u521Bu5EFAu8DEFu7531\"><a name=\"创建路由\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建路由</h3><blockquote>\n<p>在项目-网络-路由里面创建</p>\n<p>第一步 新建路由</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//2f982277-b5c4-4851-b6f6-ecf717261b6e.png\" alt=\"\"></p>\n<blockquote>\n<p>第二步<br>点击新建的路由，设置公网+私网通信，点击如下“增加接口”</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//5c8ab3d4-cab5-4103-9bdf-e12395ecb1b9.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180309//3b4fbccf-bb3d-4bf2-b419-b678340924b0.png\" alt=\"\"></p>\n<h3 id=\"h3--\"><a name=\"项目-网络-网络拓扑\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>项目-网络-网络拓扑</h3><blockquote>\n<p>出现以下拓扑图说明网络就可以了<br><img src=\"/upload/images/20180309//a8eb20c5-f422-4e42-b0b4-be4ca5748124.png\" alt=\"\"></p>\n</blockquote>\n<h3 id=\"h3--amp-\"><a name=\"项目-计算-访问&amp;安全\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>项目-计算-访问&amp;安全</h3><blockquote>\n<p>安全组设置</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//0eb7ab9c-4607-4615-8f0e-0063adf72a13.png\" alt=\"\"></p>\n<blockquote>\n<p>删除入口规则</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//95eeb2f9-3cbb-4af2-b254-a98bd9b02de8.png\" alt=\"\"></p>\n<blockquote>\n<p>选择“添加规则”</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//329dbabf-687f-4220-9c14-d1438516b60b.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180309//a88534e2-9739-4069-9fe6-7d354be9bd76.png\" alt=\"\"></p>\n<blockquote>\n<p>完成</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//11efec65-378e-485a-ae98-2e1dd82396e0.png\" alt=\"\"></p>\n<h3 id=\"h3--amp-\"><a name=\"访问&amp;安全-密钥对\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>访问&amp;安全-密钥对</h3><blockquote>\n<p>去终端切换openstack用户执行以下命令</p>\n<p>[openstack<a href=\"https://github.com/openstack\" title=\"&#64;openstack\" class=\"at-link\">@openstack</a>-master ~]$ssh-keygen    -t    rsa    -f    cloud.key</p>\n<p>导入密钥对</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//12ca0aab-726e-4a2c-958d-19ad0682c1fb.png\" alt=\"\"></p>\n<h1 id=\"h1--compute-\"><a name=\"添加多个compute节点\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>添加多个compute节点</h1><blockquote>\n<p><a href=\"https://www.rdoproject.org/install/adding-a-compute-node/\">https://www.rdoproject.org/install/adding-a-compute-node/</a></p>\n</blockquote>\n<pre><code>NOTE: by default $youranswerfile is called packstack-answer-$date-$time.txt\n</code></pre><pre><code>[root@openstack-master     ~]#     ls     packstack-answers-20160517-215941.txt\npackstack-answers-20160517-215941.txt\nChange IP addresses\nChange the value for CONFIG_COMPUTE_HOSTS from the value of your first host IP address\nto the value of your second host IP address. Ensure that the\nkeyCONFIG_NETWORK_HOSTS exists and is set to the IP address of your first host.\nSkip installing on an already existing servers\nIn case you do not want to run the installation over again on the already configured\nservers, add the following parameter to the answerfile:\nEXCLUDE_SERVERS=&lt;serverIP&gt;,&lt;serverIP&gt;,...\n\n案例：\n[root@openstack-master     ~]#     egrep     &quot;CONFIG_COMPUTE_HOSTS|CONFIG_NETW\nORK_HOSTS|EXCLUDE_SERVERS&quot;     packstack-answers-20160613-231012.txt\nEXCLUDE_SERVERS=192.168.2.110\nCONFIG_COMPUTE_HOSTS=192.168.2.110,192.168.2.111,192.168.2.112,192.168.2.1\n13\nCONFIG_NETWORK_HOSTS=192.168.2.110\nRe-run    packstack    with    the    new    values    \nRun packstack again, specifying your modified answer file:\nNOTE: by default $youranswerfile is called packstack-answer-$date-$time.txt\n[root@openstack-master     ~]#     cp     packstack-answers-20160613-231012.txt     /hom\ne/openstack/\n[root@openstack-master     ~]#     exit\nlogout\n[root@openstack-master     ~]#     sudo     packstack     --answer-file=packstack-answers-2\n0160613-231012.txt\n</code></pre><blockquote>\n<p>查看云主机列表</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//871f41fa-383d-4f83-a273-8b7e343bfb17.png\" alt=\"\"></p>\n<pre><code>[root@openstack-master     ~]#     nova list     --all\n#查看云硬盘信息\n[root@openstack-master     ~]#     cinder     list\n#查看主机几点角色信息\n</code></pre><h1 id=\"h1-u4E0Au4F20u955Cu50CF\"><a name=\"上传镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>上传镜像</h1><blockquote>\n<p>从公网上传一个镜像文件   <a href=\"http://cloud.centos.org/centos/7/images/\">http://cloud.centos.org/centos/7/images/</a></p>\n<p>先将镜像下载到本地上传上去</p>\n</blockquote>\n<p><img src=\"/upload/images/20180309//c1aeaa25-8bc0-4542-bc4a-aea2e758568e.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180309//84e8ac5d-e6a1-4207-bb08-4b0fe45d5743.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('37', '0', '利用tensorflow在mnist上训练和测试LeNet模型', '24', '2018-03-09 15:27:31', '#1.MNIST数据集的下载及其介绍MNIST数据集分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）。每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。训练数据集的图片是mnist.train.images，训练数据集的标签是mnist.train.labels。每一张图片包含28X28个像素点。把这个数组', null, '0', '535', null, null, '2018-03-09 15:27:31', '2018-03-16 10:39:49', null, null, '0', '0', '0', '0', '# 1. MNIST 数据集的下载及其介绍\nMNIST数据集分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）。每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。训练数据集的图片是 mnist.train.images ，训练数据集的标签是 mnist.train.labels。每一张图片包含28X28个像素点。把这个数组展开成一个向量，长度是 28x28 = 784。因此，在MNIST训练数据集中，mnist.train.images 是一个形状为 [60000, 784] 的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。在此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0和1之间。相对应的MNIST数据集的标签是介于0到9的数字，用来描述给定图片里表示的数字。此处使用的标签数据是\"one-hot vectors\"。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成([1,0,0,0,0,0,0,0,0,0,0])。因此， mnist.train.labels 是一个 [60000, 10] 的数字矩阵。\n# 2. 实现过程\n## 2.1 tensorflow 环境\n若集群未事先装有tensorflow模块，可利用cacheArchive参数特性进行配置，方法如下：\n- 打包TensorFlow的库，它依赖的那些库可以先在环境安装，也可以将所有依赖的一起打包。如：tar -zcvf tensorflow.tgz ./*\n- 上传该压缩包至hdfs，如放置在hdfs的/tmp/tensorflow.tgz\n- xlearning提交脚本中，添加cacheArchive参数，如： --cacheArchive /tmp/tensorflow.tgz#tensorflow\n- 在launch-cmd中所执行的脚本中，添加环境变量设置：export PYTHONPATH=./:$PYTHONPATH\n\ntensorflow依赖库安装\n```shell\nyum install numpy python-devel python-wheel\n```\n## 2.2 训练模型\n进入目录\n```shell\ncd /var/lib/ambari-server/resources/stacks/CRH/5.1/services/XLEARNING/xlearning-1.2/examples/tfmnist\nexport XLEARNING_HOME=/var/lib/ambari-server/resources/stacks/CRH/5.1/services/XLEARNING/xlearning-1.2\n```\n运行脚本run.sh\n```shell\n#!/bin/sh\n$XLEARNING_HOME/bin/xl-submit \\\n   --app-type \"tensorflow\" \\\n   --app-name \"tf-mnist\" \\\n   --input /tmp/data/tfmnist/MNIST_data#data \\\n   --output /tmp/tfmnist_model#model \\\n   --files demo.py,input_data.py,demo.sh \\\n   --cacheArchive /tmp/tensorflow.tgz#tensorflow \\\n   --launch-cmd \"sh demo.sh\" \\\n   --worker-memory 2G \\\n   --worker-num 2 \\\n   --worker-cores 3 \\\n   --ps-memory 2G \\\n   --ps-num 1 \\\n   --ps-cores 2 \\\n   --queue default \\\n```\ndemo.sh脚本\n```shell\nexport PYTHONPATH=./:$PYTHONPATH\npython demo.py --data_path=./data --save_path=./model --log_dir=./eventLog  --training_epochs=2\n```\ndemo.py代码\n```python\nimport argparse\nimport sys\nimport os\nimport json\nimport numpy as np\nimport time\n\nsys.path.append(os.getcwd())\nimport input_data\nmnist = input_data.read_data_sets(\'MNIST_data\', one_hot=True)\n\n\nimport tensorflow as tf\n\nFLAGS = None\n\n\ndef main(_):\n    # cluster specification\n    FLAGS.task_index = int(os.environ[\"TF_INDEX\"])\n    FLAGS.job_name = os.environ[\"TF_ROLE\"]\n    cluster_def = json.loads(os.environ[\"TF_CLUSTER_DEF\"])\n    cluster = tf.train.ClusterSpec(cluster_def)\n    sess = tf.InteractiveSession()\n\n    print(\"ClusterSpec:\", cluster_def)\n    print(\"current task id:\", FLAGS.task_index, \" role:\", FLAGS.job_name)\n\n    gpu_options = tf.GPUOptions(allow_growth=True)\n    server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index,\n                             config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True))\n\n    if FLAGS.job_name == \"ps\":\n        server.join()\n    elif FLAGS.job_name == \"worker\":\n        # set the train parameters\n        training_epochs = FLAGS.training_epochs\n        with tf.device(tf.train.replica_device_setter(worker_device=(\"/job:worker/task:%d\" % (FLAGS.task_index)),\n                                                      cluster=cluster)):\n            global_step = tf.get_variable(\'global_step\', [], initializer=tf.constant_initializer(0), trainable=False)\n            x = tf.placeholder(tf.float32, shape=[None, 784])\n            y_ = tf.placeholder(tf.float32, shape=[None, 10])\n            W = tf.Variable(tf.zeros([784, 10]))\n            b = tf.Variable(tf.zeros([10]))\n\n\n            y = tf.matmul(x, W) + b  \n            cross_entropy = tf.reduce_mean(\n                tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\n            train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n            def weight_variable(shape):\n                initial = tf.truncated_normal(shape, stddev=0.1)\n                return tf.Variable(initial)\n\n            def bias_variable(shape):\n                initial = tf.constant(0.1, shape=shape)\n                return tf.Variable(initial)\n\n            def conv2d(x, W):\n                return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\'SAME\')\n\n            def max_pool_2x2(x):\n                return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                                      strides=[1, 2, 2, 1], padding=\'SAME\')\n\n            W_conv1 = weight_variable([5, 5, 1, 32])\n            b_conv1 = bias_variable([32])\n            x_image = tf.reshape(x, [-1, 28, 28, 1])\n            h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n            h_pool1 = max_pool_2x2(h_conv1)\n\n            W_conv2 = weight_variable([5, 5, 32, 64])\n            b_conv2 = bias_variable([64])\n            h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n            h_pool2 = max_pool_2x2(h_conv2)\n\n            W_fc1 = weight_variable([7 * 7 * 64, 1024])\n            b_fc1 = bias_variable([1024])\n\n            h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n            keep_prob = tf.placeholder(tf.float32)\n            h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n            W_fc2 = weight_variable([1024, 10])\n            b_fc2 = bias_variable([10])\n            \n            y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n            cross_entropy = tf.reduce_mean(\n                tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n            train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n            correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n            init_op = tf.global_variables_initializer()\n            saver = tf.train.Saver()  # defaults to saving all variables\n            print(\"Variables initialized ...\")\n        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0), global_step=global_step, init_op=init_op)\n        with sv.prepare_or_wait_for_session(server.target,\n                                            config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True,\n                                                                  log_device_placement=True)) as sess:\n            # perform training cycles\n            start_time = time.time()\n            if (FLAGS.task_index == 0):\n                train_writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)\n\n            sess.run(init_op)\n            for epoch in range(training_epochs):\n                # number of batches in one epoch\n                sys.stderr.write(\"reporter progress:%0.4f\\n\" % (float(epoch) / (training_epochs)))\n                totalStep = 3000\n                for i in range(totalStep):\n                    batch = mnist.train.next_batch(50)\n                    elapsed_time = time.time() - start_time\n                    start_time = time.time()\n                    if i % 100 == 0:\n                        train_accuracy = accuracy.eval(feed_dict={\n                            x: batch[0], y_: batch[1], keep_prob: 1.0})\n                        print(\"step %d,epoch %2d, training accuracy %g, Time: %3.2fms\" % (\n                        i, epoch, train_accuracy, float(elapsed_time * 1000)))\n                    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n                sys.stderr.write(\"reporter progress:%0.4f\\n\"%(float(epoch+1)/(training_epochs)))\n            print(\"Train Completed.\")\n            if (FLAGS.task_index == 0):\n                train_writer.close()\n                print(\"saving model...\")\n                saver.save(sess, FLAGS.save_path + \"/model.ckpt\")\n                #print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n                #    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\n        print(\"done\")\n\nif __name__ == \"__main__\":\n  parser = argparse.ArgumentParser()\n  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n  # Flags for defining the tf.train.ClusterSpec\n  parser.add_argument(\n    \"--job_name\",\n    type=str,\n    default=\"\",\n    help=\"One of \'ps\', \'worker\'\"\n  )\n  # Flags for defining the tf.train.Server\n  parser.add_argument(\n    \"--task_index\",\n    type=int,\n    default=0,\n    help=\"Index of task within the job\"\n  )\n  # Flags for defining the parameter of data path\n  parser.add_argument(\n    \"--data_path\",\n    type=str,\n    default=\"\",\n    help=\"The path for train file\"\n  )\n  parser.add_argument(\n    \"--save_path\",\n    type=str,\n    default=\"\",\n    help=\"The save path for model\"\n  )\n  parser.add_argument(\n    \"--log_dir\",\n    type=str,\n    default=\"\",\n    help=\"The log path for model\"\n  )\n  parser.add_argument(\n      \"--training_epochs\",\n      type=int,\n      default=5,\n      help=\"the epoch of the train\"\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main)\n\n```\n注：saver部分将训练的权重和偏置保存下来，在评价程序中可以再次使用。\n## 2.3 准备测试图片，用Opencv进行预处理\n训练好了网络，下一步就要测试它了。准备一张图片，然后用Opencv预处理一下再放到评价程序里，看看能不能准确识别。\n使用的是Opencv对图像进行预处理，缩小它的大小为28*28像素，并转变为灰度图，进行二值化处理。\n(1) stdafx.h文件\n添加opencv相关的头文件\n```cpp\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/opencv.hpp> \n#include <opencv2/gpu/gpu.hpp>\n#include <opencv2/core/core.hpp>\n#include <opencv/cv.h>\n#include <opencv/cxcore.h>\n#include <opencv/highgui.h>\n```\n(2)TF_ImgPreProcess.cpp文件\n```cpp\n#include \"stdafx.h\"\n\n#include <opencv2/core/core.hpp>\n#include <opencv2/core/opengl_interop.hpp>\n#include <opencv2/gpu/gpu.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/contrib/contrib.hpp>\nusing namespace std;\nusing namespace cv;\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n   IplImage* img = cvLoadImage(\"E:\\\\png\\\\5.png\",1);\n   IplImage* copyImg=cvCreateImage(cvGetSize(img),IPL_DEPTH_8U,3);\n   cvCopyImage(img,copyImg);\n   IplImage* ResImg=cvCreateImage(cvSize(28,28),IPL_DEPTH_8U,1);\n   IplImage* TmpImg=cvCreateImage(cvGetSize(ResImg),IPL_DEPTH_8U,3);\n\n   cvResize(copyImg,TmpImg,CV_INTER_LINEAR); \n   cvCvtColor(TmpImg,ResImg,CV_RGB2GRAY);\n   cvThreshold(ResImg,ResImg,100,255,CV_THRESH_BINARY_INV);\n\n   cvSaveImage(\"E:\\\\png\\\\result\\\\1.png\",ResImg);\n   cvWaitKey(0);\n\n    return 0;\n}\n```\n## 2.4 将图片输入网络进行识别\n若未安装TensorFlow，要先安装TensorFlow环境。\n在环境中安装opencv包\n```shell\n yum install opencv-python -y\n```\n这里编写了一个前向传播的程序，最后softmax层分类的结果就是最后的识别结果。\n程序如下:\n ```python\nfrom PIL import Image, ImageFilter\nimport tensorflow as tf\nimport cv2\n\ndef imageprepare():\n    \"\"\"\n    This function returns the pixel values.\n    The imput is a png file location.\n    \"\"\"\n    file_name=\'/data/sxl/MNIST_recognize/p_num2.png\'#导入自己的图片地址\n    #in terminal \'mogrify -format png *.jpg\' convert jpg to png\n    im = Image.open(file_name).convert(\'L\')\n\n\n    im.save(\"/data/sxl/MNIST_recognize/sample.png\")\n    tv = list(im.getdata()) #get pixel values\n\n    #normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n    tva = [ (255-x)*1.0/255.0 for x in tv] \n    #print(tva)\n    return tva\n\n\n\n    \"\"\"\n    This function returns the predicted integer.\n    The imput is the pixel values from the imageprepare() function.\n    \"\"\"\n\n    # Define the model (same as when creating the model file)\nresult=imageprepare()\nx = tf.placeholder(tf.float32, [None, 784])\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\ndef weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\ndef bias_variable(shape):\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)\n\ndef conv2d(x, W):\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\'SAME\')\n\ndef max_pool_2x2(x):\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')   \n\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\n\nx_image = tf.reshape(x, [-1,28,28,1])\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\n\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)\n\nW_fc1 = weight_variable([7 * 7 * 64, 1024])\nb_fc1 = bias_variable([1024])\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\n\ny_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\n#init_op = tf.initialize_all_variables()\ninit_op = tf.global_variables_initializer()\n\n\n\"\"\"\nLoad the model2.ckpt file\nfile is stored in the same directory as this python script is started\nUse the model to predict the integer. Integer is returend as list.\n\nBased on the documentatoin at\nhttps://www.tensorflow.org/versions/master/how_tos/variables/index.html\n\"\"\"\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    sess.run(init_op)\n    saver.restore(sess, \"/data/sxl/MNIST_recognize/form/model2.ckpt\")#这里使用了之前保存的模型参数\n    #print (\"Model restored.\")\n\n    prediction=tf.argmax(y_conv,1)\n    predint=prediction.\n    print(h_conv2)\n\n    print(\'recognize result:\')\nprint(predint[0])\n```\n输入图片为：\n![](/upload/images/20180309//f8c775df-a50b-4278-a2aa-ef51653938a1.png)\n运行结果为：\n![](/upload/images/20180309//be8605a5-d009-4156-b1d7-d423d35797de.png)\n说明：\ntensorflow模型保存为:\n```python\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    init_op = tf.global_variables_initializer()\nsaver.save(sess,\"checkpoint/model.ckpt\",global_step=1)\n```\n运行后,保存模型保存,得到三个文件,分别为.data,.meta,.index,\nmodel.ckpt.data-00000-of-00001\nmodel.ckpt.index\nmodel.ckpt.meta\nmeta file保存了graph结构,包括 GraphDef, SaverDef等.\nindex file为一个 string-string table,table的key值为tensor名,value为BundleEntryProto, BundleEntryProto.\ndata file保存了模型的所有变量的值.\n模型加载为:\n```python\nwith tf.Session() as sess:\n  saver.restore(sess, \"/checkpoint/model.ckpt\")\n```\n', '0', '<h1 id=\"h1-1-mnist-\"><a name=\"1. MNIST 数据集的下载及其介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. MNIST 数据集的下载及其介绍</h1><p>MNIST数据集分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）。每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。训练数据集的图片是 mnist.train.images ，训练数据集的标签是 mnist.train.labels。每一张图片包含28X28个像素点。把这个数组展开成一个向量，长度是 28x28 = 784。因此，在MNIST训练数据集中，mnist.train.images 是一个形状为 [60000, 784] 的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。在此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0和1之间。相对应的MNIST数据集的标签是介于0到9的数字，用来描述给定图片里表示的数字。此处使用的标签数据是”one-hot vectors”。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成([1,0,0,0,0,0,0,0,0,0,0])。因此， mnist.train.labels 是一个 [60000, 10] 的数字矩阵。</p>\n<h1 id=\"h1-2-\"><a name=\"2. 实现过程\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2. 实现过程</h1><h2 id=\"h2-2-1-tensorflow-\"><a name=\"2.1 tensorflow 环境\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1 tensorflow 环境</h2><p>若集群未事先装有tensorflow模块，可利用cacheArchive参数特性进行配置，方法如下：</p>\n<ul>\n<li>打包TensorFlow的库，它依赖的那些库可以先在环境安装，也可以将所有依赖的一起打包。如：tar -zcvf tensorflow.tgz ./*</li><li>上传该压缩包至hdfs，如放置在hdfs的/tmp/tensorflow.tgz</li><li>xlearning提交脚本中，添加cacheArchive参数，如： —cacheArchive /tmp/tensorflow.tgz#tensorflow</li><li>在launch-cmd中所执行的脚本中，添加环境变量设置：export PYTHONPATH=./:$PYTHONPATH</li></ul>\n<p>tensorflow依赖库安装</p>\n<pre><code class=\"lang-shell\">yum install numpy python-devel python-wheel\n</code></pre>\n<h2 id=\"h2-2-2-\"><a name=\"2.2 训练模型\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2 训练模型</h2><p>进入目录</p>\n<pre><code class=\"lang-shell\">cd /var/lib/ambari-server/resources/stacks/CRH/5.1/services/XLEARNING/xlearning-1.2/examples/tfmnist\nexport XLEARNING_HOME=/var/lib/ambari-server/resources/stacks/CRH/5.1/services/XLEARNING/xlearning-1.2\n</code></pre>\n<p>运行脚本run.sh</p>\n<pre><code class=\"lang-shell\">#!/bin/sh\n$XLEARNING_HOME/bin/xl-submit \\\n   --app-type &quot;tensorflow&quot; \\\n   --app-name &quot;tf-mnist&quot; \\\n   --input /tmp/data/tfmnist/MNIST_data#data \\\n   --output /tmp/tfmnist_model#model \\\n   --files demo.py,input_data.py,demo.sh \\\n   --cacheArchive /tmp/tensorflow.tgz#tensorflow \\\n   --launch-cmd &quot;sh demo.sh&quot; \\\n   --worker-memory 2G \\\n   --worker-num 2 \\\n   --worker-cores 3 \\\n   --ps-memory 2G \\\n   --ps-num 1 \\\n   --ps-cores 2 \\\n   --queue default \\\n</code></pre>\n<p>demo.sh脚本</p>\n<pre><code class=\"lang-shell\">export PYTHONPATH=./:$PYTHONPATH\npython demo.py --data_path=./data --save_path=./model --log_dir=./eventLog  --training_epochs=2\n</code></pre>\n<p>demo.py代码</p>\n<pre><code class=\"lang-python\">import argparse\nimport sys\nimport os\nimport json\nimport numpy as np\nimport time\n\nsys.path.append(os.getcwd())\nimport input_data\nmnist = input_data.read_data_sets(&#39;MNIST_data&#39;, one_hot=True)\n\n\nimport tensorflow as tf\n\nFLAGS = None\n\n\ndef main(_):\n    # cluster specification\n    FLAGS.task_index = int(os.environ[&quot;TF_INDEX&quot;])\n    FLAGS.job_name = os.environ[&quot;TF_ROLE&quot;]\n    cluster_def = json.loads(os.environ[&quot;TF_CLUSTER_DEF&quot;])\n    cluster = tf.train.ClusterSpec(cluster_def)\n    sess = tf.InteractiveSession()\n\n    print(&quot;ClusterSpec:&quot;, cluster_def)\n    print(&quot;current task id:&quot;, FLAGS.task_index, &quot; role:&quot;, FLAGS.job_name)\n\n    gpu_options = tf.GPUOptions(allow_growth=True)\n    server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index,\n                             config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True))\n\n    if FLAGS.job_name == &quot;ps&quot;:\n        server.join()\n    elif FLAGS.job_name == &quot;worker&quot;:\n        # set the train parameters\n        training_epochs = FLAGS.training_epochs\n        with tf.device(tf.train.replica_device_setter(worker_device=(&quot;/job:worker/task:%d&quot; % (FLAGS.task_index)),\n                                                      cluster=cluster)):\n            global_step = tf.get_variable(&#39;global_step&#39;, [], initializer=tf.constant_initializer(0), trainable=False)\n            x = tf.placeholder(tf.float32, shape=[None, 784])\n            y_ = tf.placeholder(tf.float32, shape=[None, 10])\n            W = tf.Variable(tf.zeros([784, 10]))\n            b = tf.Variable(tf.zeros([10]))\n\n\n            y = tf.matmul(x, W) + b  \n            cross_entropy = tf.reduce_mean(\n                tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\n            train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n            def weight_variable(shape):\n                initial = tf.truncated_normal(shape, stddev=0.1)\n                return tf.Variable(initial)\n\n            def bias_variable(shape):\n                initial = tf.constant(0.1, shape=shape)\n                return tf.Variable(initial)\n\n            def conv2d(x, W):\n                return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;)\n\n            def max_pool_2x2(x):\n                return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                                      strides=[1, 2, 2, 1], padding=&#39;SAME&#39;)\n\n            W_conv1 = weight_variable([5, 5, 1, 32])\n            b_conv1 = bias_variable([32])\n            x_image = tf.reshape(x, [-1, 28, 28, 1])\n            h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n            h_pool1 = max_pool_2x2(h_conv1)\n\n            W_conv2 = weight_variable([5, 5, 32, 64])\n            b_conv2 = bias_variable([64])\n            h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n            h_pool2 = max_pool_2x2(h_conv2)\n\n            W_fc1 = weight_variable([7 * 7 * 64, 1024])\n            b_fc1 = bias_variable([1024])\n\n            h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n            keep_prob = tf.placeholder(tf.float32)\n            h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n            W_fc2 = weight_variable([1024, 10])\n            b_fc2 = bias_variable([10])\n\n            y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n            cross_entropy = tf.reduce_mean(\n                tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n            train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n            correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n            init_op = tf.global_variables_initializer()\n            saver = tf.train.Saver()  # defaults to saving all variables\n            print(&quot;Variables initialized ...&quot;)\n        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0), global_step=global_step, init_op=init_op)\n        with sv.prepare_or_wait_for_session(server.target,\n                                            config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True,\n                                                                  log_device_placement=True)) as sess:\n            # perform training cycles\n            start_time = time.time()\n            if (FLAGS.task_index == 0):\n                train_writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)\n\n            sess.run(init_op)\n            for epoch in range(training_epochs):\n                # number of batches in one epoch\n                sys.stderr.write(&quot;reporter progress:%0.4f\\n&quot; % (float(epoch) / (training_epochs)))\n                totalStep = 3000\n                for i in range(totalStep):\n                    batch = mnist.train.next_batch(50)\n                    elapsed_time = time.time() - start_time\n                    start_time = time.time()\n                    if i % 100 == 0:\n                        train_accuracy = accuracy.eval(feed_dict={\n                            x: batch[0], y_: batch[1], keep_prob: 1.0})\n                        print(&quot;step %d,epoch %2d, training accuracy %g, Time: %3.2fms&quot; % (\n                        i, epoch, train_accuracy, float(elapsed_time * 1000)))\n                    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n                sys.stderr.write(&quot;reporter progress:%0.4f\\n&quot;%(float(epoch+1)/(training_epochs)))\n            print(&quot;Train Completed.&quot;)\n            if (FLAGS.task_index == 0):\n                train_writer.close()\n                print(&quot;saving model...&quot;)\n                saver.save(sess, FLAGS.save_path + &quot;/model.ckpt&quot;)\n                #print(&quot;test accuracy %g&quot; % accuracy.eval(feed_dict={\n                #    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\n        print(&quot;done&quot;)\n\nif __name__ == &quot;__main__&quot;:\n  parser = argparse.ArgumentParser()\n  parser.register(&quot;type&quot;, &quot;bool&quot;, lambda v: v.lower() == &quot;true&quot;)\n  # Flags for defining the tf.train.ClusterSpec\n  parser.add_argument(\n    &quot;--job_name&quot;,\n    type=str,\n    default=&quot;&quot;,\n    help=&quot;One of &#39;ps&#39;, &#39;worker&#39;&quot;\n  )\n  # Flags for defining the tf.train.Server\n  parser.add_argument(\n    &quot;--task_index&quot;,\n    type=int,\n    default=0,\n    help=&quot;Index of task within the job&quot;\n  )\n  # Flags for defining the parameter of data path\n  parser.add_argument(\n    &quot;--data_path&quot;,\n    type=str,\n    default=&quot;&quot;,\n    help=&quot;The path for train file&quot;\n  )\n  parser.add_argument(\n    &quot;--save_path&quot;,\n    type=str,\n    default=&quot;&quot;,\n    help=&quot;The save path for model&quot;\n  )\n  parser.add_argument(\n    &quot;--log_dir&quot;,\n    type=str,\n    default=&quot;&quot;,\n    help=&quot;The log path for model&quot;\n  )\n  parser.add_argument(\n      &quot;--training_epochs&quot;,\n      type=int,\n      default=5,\n      help=&quot;the epoch of the train&quot;\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main)\n</code></pre>\n<p>注：saver部分将训练的权重和偏置保存下来，在评价程序中可以再次使用。</p>\n<h2 id=\"h2-2-3-opencv-\"><a name=\"2.3 准备测试图片，用Opencv进行预处理\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3 准备测试图片，用Opencv进行预处理</h2><p>训练好了网络，下一步就要测试它了。准备一张图片，然后用Opencv预处理一下再放到评价程序里，看看能不能准确识别。<br>使用的是Opencv对图像进行预处理，缩小它的大小为28*28像素，并转变为灰度图，进行二值化处理。<br>(1) stdafx.h文件<br>添加opencv相关的头文件</p>\n<pre><code class=\"lang-cpp\">#include &lt;opencv2/highgui/highgui.hpp&gt;\n#include &lt;opencv2/opencv.hpp&gt; \n#include &lt;opencv2/gpu/gpu.hpp&gt;\n#include &lt;opencv2/core/core.hpp&gt;\n#include &lt;opencv/cv.h&gt;\n#include &lt;opencv/cxcore.h&gt;\n#include &lt;opencv/highgui.h&gt;\n</code></pre>\n<p>(2)TF_ImgPreProcess.cpp文件</p>\n<pre><code class=\"lang-cpp\">#include &quot;stdafx.h&quot;\n\n#include &lt;opencv2/core/core.hpp&gt;\n#include &lt;opencv2/core/opengl_interop.hpp&gt;\n#include &lt;opencv2/gpu/gpu.hpp&gt;\n#include &lt;opencv2/highgui/highgui.hpp&gt;\n#include &lt;opencv2/contrib/contrib.hpp&gt;\nusing namespace std;\nusing namespace cv;\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n   IplImage* img = cvLoadImage(&quot;E:\\\\png\\\\5.png&quot;,1);\n   IplImage* copyImg=cvCreateImage(cvGetSize(img),IPL_DEPTH_8U,3);\n   cvCopyImage(img,copyImg);\n   IplImage* ResImg=cvCreateImage(cvSize(28,28),IPL_DEPTH_8U,1);\n   IplImage* TmpImg=cvCreateImage(cvGetSize(ResImg),IPL_DEPTH_8U,3);\n\n   cvResize(copyImg,TmpImg,CV_INTER_LINEAR); \n   cvCvtColor(TmpImg,ResImg,CV_RGB2GRAY);\n   cvThreshold(ResImg,ResImg,100,255,CV_THRESH_BINARY_INV);\n\n   cvSaveImage(&quot;E:\\\\png\\\\result\\\\1.png&quot;,ResImg);\n   cvWaitKey(0);\n\n    return 0;\n}\n</code></pre>\n<h2 id=\"h2-2-4-\"><a name=\"2.4 将图片输入网络进行识别\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4 将图片输入网络进行识别</h2><p>若未安装TensorFlow，要先安装TensorFlow环境。<br>在环境中安装opencv包</p>\n<pre><code class=\"lang-shell\"> yum install opencv-python -y\n</code></pre>\n<p>这里编写了一个前向传播的程序，最后softmax层分类的结果就是最后的识别结果。<br>程序如下:</p>\n<pre><code class=\"lang-python\">from PIL import Image, ImageFilter\nimport tensorflow as tf\nimport cv2\n\ndef imageprepare():\n    &quot;&quot;&quot;\n    This function returns the pixel values.\n    The imput is a png file location.\n    &quot;&quot;&quot;\n    file_name=&#39;/data/sxl/MNIST_recognize/p_num2.png&#39;#导入自己的图片地址\n    #in terminal &#39;mogrify -format png *.jpg&#39; convert jpg to png\n    im = Image.open(file_name).convert(&#39;L&#39;)\n\n\n    im.save(&quot;/data/sxl/MNIST_recognize/sample.png&quot;)\n    tv = list(im.getdata()) #get pixel values\n\n    #normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n    tva = [ (255-x)*1.0/255.0 for x in tv] \n    #print(tva)\n    return tva\n\n\n\n    &quot;&quot;&quot;\n    This function returns the predicted integer.\n    The imput is the pixel values from the imageprepare() function.\n    &quot;&quot;&quot;\n\n    # Define the model (same as when creating the model file)\nresult=imageprepare()\nx = tf.placeholder(tf.float32, [None, 784])\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\ndef weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\ndef bias_variable(shape):\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)\n\ndef conv2d(x, W):\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;)\n\ndef max_pool_2x2(x):\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;)   \n\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\n\nx_image = tf.reshape(x, [-1,28,28,1])\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\n\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)\n\nW_fc1 = weight_variable([7 * 7 * 64, 1024])\nb_fc1 = bias_variable([1024])\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\n\ny_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\n#init_op = tf.initialize_all_variables()\ninit_op = tf.global_variables_initializer()\n\n\n&quot;&quot;&quot;\nLoad the model2.ckpt file\nfile is stored in the same directory as this python script is started\nUse the model to predict the integer. Integer is returend as list.\n\nBased on the documentatoin at\nhttps://www.tensorflow.org/versions/master/how_tos/variables/index.html\n&quot;&quot;&quot;\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    sess.run(init_op)\n    saver.restore(sess, &quot;/data/sxl/MNIST_recognize/form/model2.ckpt&quot;)#这里使用了之前保存的模型参数\n    #print (&quot;Model restored.&quot;)\n\n    prediction=tf.argmax(y_conv,1)\n    predint=prediction.\n    print(h_conv2)\n\n    print(&#39;recognize result:&#39;)\nprint(predint[0])\n</code></pre>\n<p>输入图片为：<br><img src=\"/upload/images/20180309//f8c775df-a50b-4278-a2aa-ef51653938a1.png\" alt=\"\"><br>运行结果为：<br><img src=\"/upload/images/20180309//be8605a5-d009-4156-b1d7-d423d35797de.png\" alt=\"\"><br>说明：<br>tensorflow模型保存为:</p>\n<pre><code class=\"lang-python\">saver = tf.train.Saver()\nwith tf.Session() as sess:\n    init_op = tf.global_variables_initializer()\nsaver.save(sess,&quot;checkpoint/model.ckpt&quot;,global_step=1)\n</code></pre>\n<p>运行后,保存模型保存,得到三个文件,分别为.data,.meta,.index,<br>model.ckpt.data-00000-of-00001<br>model.ckpt.index<br>model.ckpt.meta<br>meta file保存了graph结构,包括 GraphDef, SaverDef等.<br>index file为一个 string-string table,table的key值为tensor名,value为BundleEntryProto, BundleEntryProto.<br>data file保存了模型的所有变量的值.<br>模型加载为:</p>\n<pre><code class=\"lang-python\">with tf.Session() as sess:\n  saver.restore(sess, &quot;/checkpoint/model.ckpt&quot;)\n</code></pre>\n');
INSERT INTO `tbl_archive` VALUES ('38', '0', '浅析高光谱遥感图像处理流程', '31', '2018-03-14 17:06:13', '利用图像的光谱特征，可以快速的对物体进行识别，避免了深度学习中繁杂的样本训练和参数调整等内容。本文简要介绍了使用一些开源的软件或者组件来实现从数据获取到数据可视化的处理流程。', null, '0', '470', null, null, '2018-03-14 17:06:13', '2018-03-14 17:26:06', null, null, '0', '0', '0', '0', '# 1 高光谱介绍  \n#### 人们日常生活中所见的光，是由多种颜色构成的复色光，通过棱镜等分光后显现的是单色光。这些单色光按不同波长（或频率）大小依次排列形成的图案，就是光谱。光谱分析是人类借助光认知世界的重要方式，地球上不同的元素及其化合物都有自己独特的光谱特征，光谱因此被视为辨别物质的“指纹”。如果说肉眼光学成像能看到物质的形状、尺寸等信息，光谱分析则能获取物质的成分信息。\n#### 要获取更丰富、精细的物质成分信息，除了提升分光系统性能外，还可以改进分光方法、呈现方式等——高光谱遥感就是这样一种思路。高光谱遥感的特点是能在可见光到短波红外的光谱区间连续成像，传统的彩色相机只能记录红绿蓝三个通道的影像，且每个通道的带宽很宽，而高光谱成像所记录的通道数量可以达到数百个，且光谱通道很窄，分辨率很高，其光谱探测范围远远超过了人类肉眼的感知范围，能够探测人眼无法看到的大量信息，提高人们对自然和物质的认识。\n#### 因为能在非常窄的光谱波段内获取丰富的信息，利用高光谱技术获取的信息分辨率很高，甚至能分辨出观测物质的分子和原子结构，这是普通的光学遥感所达不到的。\n#### 高光谱遥感成像的原理：高光谱仪器扫描字画表面，获取图像上每个点的光谱数据；因为高光谱连续成像的特征，能够获得目标数百张不同波长的图像，这些图像叠加起来，在三维空间上就能形成一个图像立方体，将每个像素对应的数百张数字图像的数值连接起来，就成为一条光谱曲线。\n# 2 高光谱数据处理栈\n- ####**数据源**\n##### EO-1、[矿物光谱](https://crustal.usgs.gov/speclab/QueryAll07a.php \"矿物光谱\")\n- ####**处理**\n##### Hadoop、[Spectral Python](http://www.spectralpython.net \"spectral python\")\n- ####**存储**\n##### Postgresql\n- ####**可视化**\n##### GeoServer、PostGis、OpenStreetMap、OpenLayers\n\n# 3 EO-1 卫星简介\n#### 地球观测卫星-1（[EO-1](http://blog.sina.com.cn/s/blog_764b1e9d0102x2y2.html \"EO-1\")）是NASA新千年计划（NMP）的第一颗对地观测卫星，也是面向21世纪为接替Landsat7而研制的新型地球观测卫星，目的是对卫星本体和新型遥感器技术进行验证。该卫星于2000年11月21日成功发射。\n####  EO-1上搭载了3 种传感器，即：\n- #### 高光谱成像光谱仪Hyperion\n- #### 高级陆地成像仪ALI(Advanced Land Imager)\n- #### 大气校正仪AC(Atmospheric Corrector)\n\n#### 高光谱数据的获取：\n- ##### 网站一：http://edcsns17.cr.usgs.gov/NewEarthExplorer/ 首先根据一步步的提示注册账号，然后就可以在网页的Data Sets上设置你要下载的EO-1数据，然后输入你要下载的范围，有两种：一种是通过输入四个角点的经纬度坐标；另一种是通过输入序列号，输入所需要影像时间段范围。\n- ##### 网站二：http://datamirror.csdb.cn/admin/dataEO1Main.jsp 这个网站是中国科学院建立的国际科学数据服务平台，首先也需要注册，点击数据检索——EO-1数据检索。可以框选，也可以通过经纬度来选择，但是数据有限。\n\n# 4 分析工具\n#### 分析卫星图像需要Python强大的工具库的支持，由于环境配置的复杂性，建议使用Anaconda作为分析工具，另外可以根据需要添加[Gdal](http://www.osgeo.cn/page/python_opengis \"Gdal\")，Wxpython库。\n\n\n', '0', '<h1 id=\"h1-1-\"><a name=\"1 高光谱介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1 高光谱介绍</h1><h4 id=\"h4--\"><a name=\"人们日常生活中所见的光，是由多种颜色构成的复色光，通过棱镜等分光后显现的是单色光。这些单色光按不同波长（或频率）大小依次排列形成的图案，就是光谱。光谱分析是人类借助光认知世界的重要方式，地球上不同的元素及其化合物都有自己独特的光谱特征，光谱因此被视为辨别物质的“指纹”。如果说肉眼光学成像能看到物质的形状、尺寸等信息，光谱分析则能获取物质的成分信息。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>人们日常生活中所见的光，是由多种颜色构成的复色光，通过棱镜等分光后显现的是单色光。这些单色光按不同波长（或频率）大小依次排列形成的图案，就是光谱。光谱分析是人类借助光认知世界的重要方式，地球上不同的元素及其化合物都有自己独特的光谱特征，光谱因此被视为辨别物质的“指纹”。如果说肉眼光学成像能看到物质的形状、尺寸等信息，光谱分析则能获取物质的成分信息。</h4><h4 id=\"h4--\"><a name=\"要获取更丰富、精细的物质成分信息，除了提升分光系统性能外，还可以改进分光方法、呈现方式等——高光谱遥感就是这样一种思路。高光谱遥感的特点是能在可见光到短波红外的光谱区间连续成像，传统的彩色相机只能记录红绿蓝三个通道的影像，且每个通道的带宽很宽，而高光谱成像所记录的通道数量可以达到数百个，且光谱通道很窄，分辨率很高，其光谱探测范围远远超过了人类肉眼的感知范围，能够探测人眼无法看到的大量信息，提高人们对自然和物质的认识。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>要获取更丰富、精细的物质成分信息，除了提升分光系统性能外，还可以改进分光方法、呈现方式等——高光谱遥感就是这样一种思路。高光谱遥感的特点是能在可见光到短波红外的光谱区间连续成像，传统的彩色相机只能记录红绿蓝三个通道的影像，且每个通道的带宽很宽，而高光谱成像所记录的通道数量可以达到数百个，且光谱通道很窄，分辨率很高，其光谱探测范围远远超过了人类肉眼的感知范围，能够探测人眼无法看到的大量信息，提高人们对自然和物质的认识。</h4><h4 id=\"h4--\"><a name=\"因为能在非常窄的光谱波段内获取丰富的信息，利用高光谱技术获取的信息分辨率很高，甚至能分辨出观测物质的分子和原子结构，这是普通的光学遥感所达不到的。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>因为能在非常窄的光谱波段内获取丰富的信息，利用高光谱技术获取的信息分辨率很高，甚至能分辨出观测物质的分子和原子结构，这是普通的光学遥感所达不到的。</h4><h4 id=\"h4--\"><a name=\"高光谱遥感成像的原理：高光谱仪器扫描字画表面，获取图像上每个点的光谱数据；因为高光谱连续成像的特征，能够获得目标数百张不同波长的图像，这些图像叠加起来，在三维空间上就能形成一个图像立方体，将每个像素对应的数百张数字图像的数值连接起来，就成为一条光谱曲线。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>高光谱遥感成像的原理：高光谱仪器扫描字画表面，获取图像上每个点的光谱数据；因为高光谱连续成像的特征，能够获得目标数百张不同波长的图像，这些图像叠加起来，在三维空间上就能形成一个图像立方体，将每个像素对应的数百张数字图像的数值连接起来，就成为一条光谱曲线。</h4><h1 id=\"h1-2-\"><a name=\"2 高光谱数据处理栈\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2 高光谱数据处理栈</h1><ul>\n<li><h4 id=\"h4--strong-strong-\"><a name=\"<strong>数据源</strong>\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><strong>数据源</strong></h4><h5 id=\"h5-eo-1-\"><a name=\"EO-1、  矿物光谱\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>EO-1、<a href=\"https://crustal.usgs.gov/speclab/QueryAll07a.php\" title=\"矿物光谱\">矿物光谱</a></h5></li><li><h4 id=\"h4--strong-strong-\"><a name=\"<strong>处理</strong>\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><strong>处理</strong></h4><h5 id=\"h5-hadoop-spectral-python\"><a name=\"Hadoop、  Spectral Python\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Hadoop、<a href=\"http://www.spectralpython.net\" title=\"spectral python\">Spectral Python</a></h5></li><li><h4 id=\"h4--strong-strong-\"><a name=\"<strong>存储</strong>\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><strong>存储</strong></h4><h5 id=\"h5-postgresql\"><a name=\"Postgresql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Postgresql</h5></li><li><h4 id=\"h4--strong-strong-\"><a name=\"<strong>可视化</strong>\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><strong>可视化</strong></h4><h5 id=\"h5-geoserver-postgis-openstreetmap-openlayers\"><a name=\"GeoServer、PostGis、OpenStreetMap、OpenLayers\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>GeoServer、PostGis、OpenStreetMap、OpenLayers</h5></li></ul>\n<h1 id=\"h1-3-eo-1-\"><a name=\"3 EO-1 卫星简介\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3 EO-1 卫星简介</h1><h4 id=\"h4--1-eo-1-nasa-nmp-21-landsat7-2000-11-21-\"><a name=\"地球观测卫星-1（  EO-1 ）是NASA新千年计划（NMP）的第一颗对地观测卫星，也是面向21世纪为接替Landsat7而研制的新型地球观测卫星，目的是对卫星本体和新型遥感器技术进行验证。该卫星于2000年11月21日成功发射。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>地球观测卫星-1（<a href=\"http://blog.sina.com.cn/s/blog_764b1e9d0102x2y2.html\" title=\"EO-1\">EO-1</a>）是NASA新千年计划（NMP）的第一颗对地观测卫星，也是面向21世纪为接替Landsat7而研制的新型地球观测卫星，目的是对卫星本体和新型遥感器技术进行验证。该卫星于2000年11月21日成功发射。</h4><h4 id=\"h4-eo-1-3-\"><a name=\"EO-1上搭载了3 种传感器，即：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>EO-1上搭载了3 种传感器，即：</h4><ul>\n<li><h4 id=\"h4--hyperion\"><a name=\"高光谱成像光谱仪Hyperion\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>高光谱成像光谱仪Hyperion</h4></li><li><h4 id=\"h4--ali-advanced-land-imager-\"><a name=\"高级陆地成像仪ALI(Advanced Land Imager)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>高级陆地成像仪ALI(Advanced Land Imager)</h4></li><li><h4 id=\"h4--ac-atmospheric-corrector-\"><a name=\"大气校正仪AC(Atmospheric Corrector)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>大气校正仪AC(Atmospheric Corrector)</h4></li></ul>\n<h4 id=\"h4--\"><a name=\"高光谱数据的获取：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>高光谱数据的获取：</h4><ul>\n<li><h5 id=\"h5--http-edcsns17-cr-usgs-gov-newearthexplorer-data-sets-eo-1-\"><a name=\"网站一：  http://edcsns17.cr.usgs.gov/NewEarthExplorer/  首先根据一步步的提示注册账号，然后就可以在网页的Data Sets上设置你要下载的EO-1数据，然后输入你要下载的范围，有两种：一种是通过输入四个角点的经纬度坐标；另一种是通过输入序列号，输入所需要影像时间段范围。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>网站一：<a href=\"http://edcsns17.cr.usgs.gov/NewEarthExplorer/\">http://edcsns17.cr.usgs.gov/NewEarthExplorer/</a> 首先根据一步步的提示注册账号，然后就可以在网页的Data Sets上设置你要下载的EO-1数据，然后输入你要下载的范围，有两种：一种是通过输入四个角点的经纬度坐标；另一种是通过输入序列号，输入所需要影像时间段范围。</h5></li><li><h5 id=\"h5--http-datamirror-csdb-cn-admin-dataeo1main-jsp-eo-1-\"><a name=\"网站二：  http://datamirror.csdb.cn/admin/dataEO1Main.jsp  这个网站是中国科学院建立的国际科学数据服务平台，首先也需要注册，点击数据检索——EO-1数据检索。可以框选，也可以通过经纬度来选择，但是数据有限。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>网站二：<a href=\"http://datamirror.csdb.cn/admin/dataEO1Main.jsp\">http://datamirror.csdb.cn/admin/dataEO1Main.jsp</a> 这个网站是中国科学院建立的国际科学数据服务平台，首先也需要注册，点击数据检索——EO-1数据检索。可以框选，也可以通过经纬度来选择，但是数据有限。</h5></li></ul>\n<h1 id=\"h1-4-\"><a name=\"4 分析工具\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4 分析工具</h1><h4 id=\"h4--python-anaconda-gdal-wxpython-\"><a name=\"分析卫星图像需要Python强大的工具库的支持，由于环境配置的复杂性，建议使用Anaconda作为分析工具，另外可以根据需要添加  Gdal ，Wxpython库。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>分析卫星图像需要Python强大的工具库的支持，由于环境配置的复杂性，建议使用Anaconda作为分析工具，另外可以根据需要添加<a href=\"http://www.osgeo.cn/page/python_opengis\" title=\"Gdal\">Gdal</a>，Wxpython库。</h4>');
INSERT INTO `tbl_archive` VALUES ('39', '0', 'Grafana +MySQL Data Source', '11', '2018-03-21 19:11:26', '汽车工厂焊枪数据使用Grafanau展现数据', null, '0', '488', '', '', '2018-03-21 19:11:26', '2018-04-09 11:35:35', null, null, '0', '0', '0', '0', '###### 汽车工厂焊枪集控系统数据使用Grafana 展现、分析、预警\n### 1. grafana 、mysql安装\n -   grafana 安装\n>>[Grafana Linux版本安装地址](https://grafana.com/grafana/download \"Grafana Linux版本安装地址\")\n\n\n##### mysql 安装\n###### 这里选 mariadb\n- 安装\n\n```\n yum -y install mariadb mariadb-server\n```\n- 启动MariaDB,设置开机自启动\n\n```\nsystemctl start mariadb\n\nsystemctl enable mariadb\n```\n- mariadb初始化\n\n```\n[root@cloud01 ~]# mysql_secure_installation\n\nNOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB\n      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!\n\nIn order to log into MariaDB to secure it, we\'ll need the current\npassword for the root user.  If you\'ve just installed MariaDB, and\nyou haven\'t set the root password yet, the password will be blank,\nso you should just press enter here.\n\nEnter current password for root (enter for none): \nOK, successfully used password, moving on...\n\nSetting the root password ensures that nobody can log into the MariaDB\nroot user without the proper authorisation.\n\nSet root password? [Y/n] \nNew password: \nRe-enter new password: \nPassword updated successfully!\nReloading privilege tables..\n ... Success!\n\n\nBy default, a MariaDB installation has an anonymous user, allowing anyone\nto log into MariaDB without having to have a user account created for\nthem.  This is intended only for testing, and to make the installation\ngo a bit smoother.  You should remove them before moving into a\nproduction environment.\n\nRemove anonymous users? [Y/n] \n ... Success!\n\nNormally, root should only be allowed to connect from \'localhost\'.  This\nensures that someone cannot guess at the root password from the network.\n\nDisallow root login remotely? [Y/n] \n ... Success!\n\nBy default, MariaDB comes with a database named \'test\' that anyone can\naccess.  This is also intended only for testing, and should be removed\nbefore moving into a production environment.\n\nRemove test database and access to it? [Y/n] \n - Dropping test database...\n ... Success!\n - Removing privileges on test database...\n ... Success!\n\nReloading the privilege tables will ensure that all changes made so far\nwill take effect immediately.\n\nReload privilege tables now? [Y/n] \n ... Success!\n\nCleaning up...\n\nAll done!  If you\'ve completed all of the above steps, your MariaDB\ninstallation should now be secure.\n\nThanks for using MariaDB!\n[root@cloud01 ~]# \n\n```\n- 测试登入mariadb,创建表grafana，修改连接权限\n\n```\n[root@cloud01 ~]# mysql -uroot -p \nEnter password: \nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 14\nServer version: 5.5.56-MariaDB MariaDB Server医用\n\nCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.\n\nType \'help;\' or \'\\h\' for help. Type \'\\c\' to clear the current input statement.\n\nMariaDB [(none)]> \nMariaDB [mysql]> CREATE DATABASE grafana;\nQuery OK, 1 row affected (0.00 sec)\n\nMariaDB [mysql]> \nMariaDB [mysql]> select user,host from user;\n+------+-----------+\n| user | host      |\n+------+-----------+\n| root | 127.0.0.1 |\n| root | ::1       |\n| root | localhost |\n+------+-----------+\n3 rows in set (0.00 sec)\n\nMariaDB [mysql]> update user set host = \'%\' where user = \'root\'; \nERROR 1062 (23000): Duplicate entry \'%-root\' for key \'PRIMARY\'\nMariaDB [mysql]> select user,host from user;\n+------+-----------+\n| user | host      |\n+------+-----------+\n| root | %         |\n| root | 127.0.0.1 |\n| root | ::1       |\n+------+-----------+\n3 rows in set (0.00 sec)\n\nMariaDB [mysql]> FLUSH PRIVILEGES;\nQuery OK, 0 rows affected (0.00 sec)\n\nMariaDB [mysql]> \n\n```\n### 2.数据导入mariadb\n- 前期测试直接把测试数据（excle表）导入mariadb中。\n\n### 3.Grafana+MariaDB Data Source\n\n**- 添加数据源**\n![添加数据源](/upload/images/20180321//0b65f215-c00d-4fb1-8ec6-548babb082ef.png \"添加数据源\")\n**- 配置数据源**\n![编辑配置](/upload/images/20180321//c78a5287-57eb-41e9-9c6f-a046974de9bc.png)\n**- 创建模板**\n![创建模板](/upload/images/20180321//77832ac7-bb8e-4b49-a0e5-e4200127e82b.png)\n**- 选grafana**\n![选grafana](/upload/images/20180321//e2debe15-0c58-4df1-a884-5fadd440527f.png)\n**- 编辑配置**\n![](/upload/images/20180321//a5b024ed-8414-4582-b4a2-b1936aa51e33.png)\n**- 选着添加好的数据源**\n![](/upload/images/20180321//21248404-7a5b-4a51-bc81-3df7cd8254e0.png)\n**- Add Query**\n```\nSELECT\n  UNIX_TIMESTAMP(Date_Time) as time_sec,\n  Total_Current as value,\n  Timer_Id as metric\nFROM workinfo\nWHERE $__timeFilter(Date_Time)\nORDER BY Date_Time ASC\n```\n**- 指标上下限设置**\n![](/upload/images/20180321//6c05f500-f5e9-4c3e-a794-4bd1813bedab.png)\n', '1', '<h6 id=\"h6--grafana-\"><a name=\"汽车工厂焊枪集控系统数据使用Grafana 展现、分析、预警\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>汽车工厂焊枪集控系统数据使用Grafana 展现、分析、预警</h6><h3 id=\"h3-1-grafana-mysql-\"><a name=\"1. grafana 、mysql安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. grafana 、mysql安装</h3><ul>\n<li>grafana 安装<blockquote>\n<blockquote>\n<p><a href=\"https://grafana.com/grafana/download\" title=\"Grafana Linux版本安装地址\">Grafana Linux版本安装地址</a></p>\n</blockquote>\n</blockquote>\n</li></ul>\n<h5 id=\"h5-mysql-\"><a name=\"mysql 安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>mysql 安装</h5><h6 id=\"h6--mariadb\"><a name=\"这里选 mariadb\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>这里选 mariadb</h6><ul>\n<li>安装</li></ul>\n<pre><code> yum -y install mariadb mariadb-server\n</code></pre><ul>\n<li>启动MariaDB,设置开机自启动</li></ul>\n<pre><code>systemctl start mariadb\n\nsystemctl enable mariadb\n</code></pre><ul>\n<li>mariadb初始化</li></ul>\n<pre><code>[root@cloud01 ~]# mysql_secure_installation\n\nNOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB\n      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!\n\nIn order to log into MariaDB to secure it, we&#39;ll need the current\npassword for the root user.  If you&#39;ve just installed MariaDB, and\nyou haven&#39;t set the root password yet, the password will be blank,\nso you should just press enter here.\n\nEnter current password for root (enter for none): \nOK, successfully used password, moving on...\n\nSetting the root password ensures that nobody can log into the MariaDB\nroot user without the proper authorisation.\n\nSet root password? [Y/n] \nNew password: \nRe-enter new password: \nPassword updated successfully!\nReloading privilege tables..\n ... Success!\n\n\nBy default, a MariaDB installation has an anonymous user, allowing anyone\nto log into MariaDB without having to have a user account created for\nthem.  This is intended only for testing, and to make the installation\ngo a bit smoother.  You should remove them before moving into a\nproduction environment.\n\nRemove anonymous users? [Y/n] \n ... Success!\n\nNormally, root should only be allowed to connect from &#39;localhost&#39;.  This\nensures that someone cannot guess at the root password from the network.\n\nDisallow root login remotely? [Y/n] \n ... Success!\n\nBy default, MariaDB comes with a database named &#39;test&#39; that anyone can\naccess.  This is also intended only for testing, and should be removed\nbefore moving into a production environment.\n\nRemove test database and access to it? [Y/n] \n - Dropping test database...\n ... Success!\n - Removing privileges on test database...\n ... Success!\n\nReloading the privilege tables will ensure that all changes made so far\nwill take effect immediately.\n\nReload privilege tables now? [Y/n] \n ... Success!\n\nCleaning up...\n\nAll done!  If you&#39;ve completed all of the above steps, your MariaDB\ninstallation should now be secure.\n\nThanks for using MariaDB!\n[root@cloud01 ~]#\n</code></pre><ul>\n<li>测试登入mariadb,创建表grafana，修改连接权限</li></ul>\n<pre><code>[root@cloud01 ~]# mysql -uroot -p \nEnter password: \nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 14\nServer version: 5.5.56-MariaDB MariaDB Server医用\n\nCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.\n\nType &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.\n\nMariaDB [(none)]&gt; \nMariaDB [mysql]&gt; CREATE DATABASE grafana;\nQuery OK, 1 row affected (0.00 sec)\n\nMariaDB [mysql]&gt; \nMariaDB [mysql]&gt; select user,host from user;\n+------+-----------+\n| user | host      |\n+------+-----------+\n| root | 127.0.0.1 |\n| root | ::1       |\n| root | localhost |\n+------+-----------+\n3 rows in set (0.00 sec)\n\nMariaDB [mysql]&gt; update user set host = &#39;%&#39; where user = &#39;root&#39;; \nERROR 1062 (23000): Duplicate entry &#39;%-root&#39; for key &#39;PRIMARY&#39;\nMariaDB [mysql]&gt; select user,host from user;\n+------+-----------+\n| user | host      |\n+------+-----------+\n| root | %         |\n| root | 127.0.0.1 |\n| root | ::1       |\n+------+-----------+\n3 rows in set (0.00 sec)\n\nMariaDB [mysql]&gt; FLUSH PRIVILEGES;\nQuery OK, 0 rows affected (0.00 sec)\n\nMariaDB [mysql]&gt;\n</code></pre><h3 id=\"h3-2-mariadb\"><a name=\"2.数据导入mariadb\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.数据导入mariadb</h3><ul>\n<li>前期测试直接把测试数据（excle表）导入mariadb中。</li></ul>\n<h3 id=\"h3-3-grafana-mariadb-data-source\"><a name=\"3.Grafana+MariaDB Data Source\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.Grafana+MariaDB Data Source</h3><p><strong>- 添加数据源</strong><br><img src=\"/upload/images/20180321//0b65f215-c00d-4fb1-8ec6-548babb082ef.png\" alt=\"添加数据源\" title=\"添加数据源\"><br><strong>- 配置数据源</strong><br><img src=\"/upload/images/20180321//c78a5287-57eb-41e9-9c6f-a046974de9bc.png\" alt=\"编辑配置\"><br><strong>- 创建模板</strong><br><img src=\"/upload/images/20180321//77832ac7-bb8e-4b49-a0e5-e4200127e82b.png\" alt=\"创建模板\"><br><strong>- 选grafana</strong><br><img src=\"/upload/images/20180321//e2debe15-0c58-4df1-a884-5fadd440527f.png\" alt=\"选grafana\"><br><strong>- 编辑配置</strong><br><img src=\"/upload/images/20180321//a5b024ed-8414-4582-b4a2-b1936aa51e33.png\" alt=\"\"><br><strong>- 选着添加好的数据源</strong><br><img src=\"/upload/images/20180321//21248404-7a5b-4a51-bc81-3df7cd8254e0.png\" alt=\"\"><br><strong>- Add Query</strong></p>\n<pre><code>SELECT\n  UNIX_TIMESTAMP(Date_Time) as time_sec,\n  Total_Current as value,\n  Timer_Id as metric\nFROM workinfo\nWHERE $__timeFilter(Date_Time)\nORDER BY Date_Time ASC\n</code></pre><p><strong>- 指标上下限设置</strong><br><img src=\"/upload/images/20180321//6c05f500-f5e9-4c3e-a794-4bd1813bedab.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('40', '0', 'centos-6.5 制作openstack镜像', '25', '2018-03-22 16:23:59', 'centos-6.5 制作openstack镜像', null, '0', '267', null, null, '2018-03-22 16:23:59', '2018-04-08 10:57:23', null, null, '0', '0', '0', '0', '# 准备工作\n> 首先你需要有一台CentOS的机器，作为制作镜像的机器。比如自己的虚拟机。我的环境是用一台R410上面装CentOS6.5的系统来做的。\n\n##注意事项\n> 注意：kvm安装的虚拟机，不确定是那一台，在后台就是一个进程，每增加一台端口号+1，第一次创建的为5900！\n\n## 安装基础工具包 \n\n\n```\n[root@node1 ~]#yum -y install wget vim lsof \n```\n\n### 关闭防火墙和selinux\n```\n[root@node1 ~]#/etc/init.d/iptables stop \n\n[root@node1 ~]# sed -i \'s#SELINUX=enforcing#SELINUX=disabled#g\' /etc/selinux/config \n[root@node1 ~]#setenforce 0\n[root@node1 ~]# grep SELINUX=disabled /etc/selinux/config\n\nSELINUX=disabled\n\n```\n### 安装底层支持包\n\n```\n[root@node1 ~]#yum install libvirt libguestfs-tools qemu-kvm qemu-img\n[root@node1 ~]#yum groupinstall Virtualization \"Virtualization Client\" -y\n[root@node1 ~]#yum install tigervnc tigervnc-server tigervnc-server-module\n```\n\n### 下载或从本地上传进去一个完整的系统镜像\n```\n[root@node1 ~]#cd /opt/\n[root@node1 ~]#wget  http://ftp.sjtu.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-1708.iso (可自行从网上下载)\n```\n### 启动服务\n```\n[root@node1 ~]#yum install avahi\n修改配置文件：\n[root@node1 ~]#/etc/libvirt/qemu.conf(199行)\n打开user=“root”和group=“root”的注释\n \n[root@node1 ~]#/etc/init.d/libvirtd start\n```\n### 桥接网络 \n> （目标为了能让新建出来的虚拟机能够和宿主机在同一网段通过xshell连上）\n\n```\nKVM修改NAT模式为桥接[案例]\n在开始案例之前，需要知道的必要信息，宿主机IP是192.168.1.249，操作系统版本Centos-6.5-x86_64。\n\n启动虚拟网卡\n\n[root@node1 ~]#ifup eth0\n这里网卡是NAT模式，可以上网，ping通其他机器，但是其他机器无法登陆！\n\n宿主机查看网卡信息\n[root@node1 ~]#brctl show\n\n[root@node1 ~]#ifconfig virbr0\n\n[root@node1 ~]#ifconfig vnet0\n实现网桥，在kvm宿主机完成\n\n步骤1，创建一个网桥，新建网桥连接到eth0,删除eth0,让新的网桥拥有eth0的ip\n[root@node1 ~]#brctl addbr br0  #创建一个网桥\n\n[root@node1 ~]#brctl show       #显示网桥信息\n\n[root@node1 ~]#brctl addif br0 eth0 && ip addr del dev eth0 192.168.1.249/24 && ifconfig br0 192.168.1.249/24 up\n\n[root@node1 ~]#brctl show      #查看结果\n[root@node1 ~]#ifconfig br0    #验证br0是否成功取代了eth0的IP\n```\n\n# 制作镜像\n### 建立镜像文件\n```\n[root@node1 ~]#qemu-img create -f qcow2 CentOS-7.2-redoop.qcow2 80G\n```\n\n### 通过virt-install来创建一个新的虚拟机\n```\n#非桥接网卡\n[root@node1 ~]# virt-install \\\n--virt-type qemu \\\n--name centos \\\n--ram 10240 \\     （内存，可自行配置）\n--disk CentOS-7.2-redoop.qcow2,format=qcow2 \\\n--network network=default \\\n--graphics vnc,listen=0.0.0.0 --noautoconsole \\\n--os-type=linux --os-variant=rhel7 \\\n--location=/opt/CentOS-7-x86_64-DVD-1708.iso\n\n#桥接网卡\n[root@node1 ~]# virt-install \\\n  --virt-type qemu \\\n  --name centos \\\n  --ram 10240\\           （内存，可自行配置）\n  --disk CentOS-7.2-redoop.qcow2,format=qcow2 \\\n  --network bridge=br0 \\  (此处=后面是要桥接网卡的名字)\n  --graphics vnc,listen=0.0.0.0 --noautoconsole \\\n  --os-type=linux --os-variant=rhel7 \\\n  --location=/opt/CentOS-7-x86_64-DVD-1708.iso\n\n#检测5900端口\n[root@node1 ~]#lsof -i :5900\n\n[root@node1 ~]#virsh list --all (查看所有创建虚拟机)\n\n[root@node1 ~]#virsh start name  （启动虚拟机）\n\n\n\n  ```\n \n \n  \n### 用VNC连接创建出来的虚拟机\n\n> 我用到的是windows版VNC以下是下载地址\n\n> http://www.tightvnc.com\n\n![](/upload/images/20180322//74a11d03-f893-4fbb-9cab-caf9d7944043.png)\n\n### 安装操作系统\n```\n操作系统的安装和正常的安装几乎一样,你需要什么样的包,就安装什么样的包,有两点需要注意的:\n注意一：分区，分区的时候只给\"/\" 根目录分一个区即可，其他都不要。 \n注意二：网络设置方面，确保你的网卡eth0是DHCP状态的，而且请务必勾上\"auto connect\"的对勾\n```\n\n![](/upload/images/20180322//d4185886-6707-4b21-b304-8539d88f570c.png)\n\n> 选择英文语言，下一步\n\n\n![](/upload/images/20180322//e0f13e91-01d8-4bfc-a202-b3cd135b2aff.png)\n\n> #选择时区：亚洲上海\n\n![](/upload/images/20180322//ddbce07a-c8bc-44e4-a405-7d8e374c6b1f.png)\n\n> 选择最小化安装包组\n\n![](/upload/images/20180322//d5988954-3e20-4c9d-9d35-47537e285349.png)\n\n> 自定义磁盘分区\n\n![](/upload/images/20180322//69134dac-96d7-4f19-ac75-6140fa8951f3.png)\n\n> 不使用LVM，单机 \"+\" 添加分区\n\n![](/upload/images/20180322//e4bef3d9-d9ca-44e8-994e-0a15a3a10885.png)\n\n> 只分配一个 “/” 分区，不创建 swap分区，本身就是虚拟机，更影响性能。\n\n![](/upload/images/20180322//9840a7ea-999e-4df0-95fa-458c099deaab.png)\n\n> 创建完，单机左上角“done”\n\n![](/upload/images/20180322//33c93157-58d8-4c1b-87be-c63193692ace.png)\n\n> #开始安装系统\n\n![](/upload/images/20180322//a61de527-4e6f-4516-9005-f47fa5b8ae75.png)\n\n> 给root用户创建密码\n\n## 通过xshell连接虚拟机并优化 \n```\n[root@localhost  ~]# yum install -y  net-tools  wget git vim  lsof tcpdump\n\n```\n\n### 修改网卡信息（只保留以下内容）\n\n```\n[root@localhost  ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0\n3 TYPE=Ethernet\n4 BOOTPROTO=dhcp\n5 NAME=eth0\n6 DEVICE=eth0\n7 ONBOOT=yes\n```\n### 修改yum源 \n```\n[root@localhost mple ~]# rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm\n```\n### 关闭Networkemanager和防火墙\n```\n1 [root@localhost  ~]# systemctl disable firewalld\n2 [root@localhost  ~]# systemctl stop firewalld   \n3 [root@localhost ~]# systemctl stop NetworkManager\n```\n### 关闭selinux(两种方式，自行选择)\n```\n1.\n#修改selinux配置文件\n[root@localhosmple ~]# vim /etc/sysconfig/selinux\nSELINUX=enforcing 改为 SELINUX=disabled\n#重启后，检查结果如下\n[root@localhost ~]# getsebool\ngetsebool:  SELinux is disabled\n\n2.\n[root@localhost ~]# sed –i \'s/SELINUX=enforcing/SELINUX=disabled/g\' /etc/selinux/config\n\n```\n### 配置\n> 删除已生成的网络设备规则(最后再删除，这样可以继续上网)\n```\n[root@localhost ~]#rm -rf /etc/udev/rules.d/70-persistent-net.rules\n```\n```\n增加一行到/etc/sysconfig/network\nNOZEROCONF=yes（必须的\n```\n```\n修改分区加载表（/etc/fstab），注释或删除以前的，加上 UUID=cec-rootfs 一行：\n[root@localhost ~]# vim /etc/fstab\n#UUID=47a90bea-2d88-4c82-a335-09c1533b1538 / ext4 defaults 1 1\nUUID=cec-rootfs                           / ext4 defaults 0 0\n#其余的不用变\n```\n\n### ssh免密登录配置\n\n```\n vi /etc/ssh/sshd_config\n...\nRSAAuthentication yes\nPubkeyAuthentication yes\nPermitRootLogin without-password\nChallengeResponseAuthentication no\nPasswordAuthentication no\nUsePAM no\n、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、\n#       $OpenBSD: sshd_config,v 1.80 2008/07/02 02:24:18 djm Exp $\n \n# This is the sshd server system-wide configuration file.  See\n# sshd_config(5) for more information.\n \n# This sshd was compiled with PATH=/usr/local/bin:/bin:/usr/bin\n \n# The strategy used for options in the default sshd_config shipped with\n# OpenSSH is to specify options with their default value where\n# possible, but leave them commented.  Uncommented options change a\n# default value.\n \n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n \n# Disable legacy (protocol version 1) support in the server for new\n# installations. In future the default will change to require explicit\n# activation of protocol 1\nProtocol 2\n \n# HostKey for protocol version 1\n#HostKey /etc/ssh/ssh_host_key\n# HostKeys for protocol version 2\n#HostKey /etc/ssh/ssh_host_rsa_key\n#HostKey /etc/ssh/ssh_host_dsa_key\n \n# Lifetime and size of ephemeral version 1 server key\n#KeyRegenerationInterval 1h\n#ServerKeyBits 1024\n \n# Logging\n# obsoletes QuietMode and FascistLogging\n#SyslogFacility AUTH\nSyslogFacility AUTHPRIV\n#LogLevel INFO\n \n# Authentication:\n \n#LoginGraceTime 2m\nPermitRootLogin yes\n#StrictModes yes\n#MaxAuthTries 6\n#MaxSessions 10\n \nRSAAuthentication yes\nPubkeyAuthentication yes\n#AuthorizedKeysFile     .ssh/authorized_keys\n#AuthorizedKeysCommand none\n#AuthorizedKeysCommandRunAs nobody\n \n# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts\n#RhostsRSAAuthentication no\n# similar for protocol version 2\n#HostbasedAuthentication no\n# Change to yes if you don\'t trust ~/.ssh/known_hosts for\n# RhostsRSAAuthentication and HostbasedAuthentication\n#IgnoreUserKnownHosts no\n# Don\'t read the user\'s ~/.rhosts and ~/.shosts files\n#IgnoreRhosts yes\n \n# To disable tunneled clear text passwords, change to no here!\nPasswordAuthentication yes\n#PermitEmptyPasswords no\nPasswordAuthentication yes\n \n# Change to no to disable s/key passwords\n#ChallengeResponseAuthentication yes\nChallengeResponseAuthentication no\n \n# Kerberos options\n#KerberosAuthentication no\n#KerberosOrLocalPasswd yes\n#KerberosTicketCleanup yes\n#KerberosGetAFSToken no\n#KerberosUseKuserok yes\n \n# GSSAPI options\n#GSSAPIAuthentication no\nGSSAPIAuthentication yes\n#GSSAPICleanupCredentials yes\nGSSAPICleanupCredentials yes\n#GSSAPIStrictAcceptorCheck yes\n#GSSAPIKeyExchange no\n \n# Set this to \'yes\' to enable PAM authentication, account processing,\n# and session processing. If this is enabled, PAM authentication will\n# be allowed through the ChallengeResponseAuthentication and\n# PasswordAuthentication.  Depending on your PAM configuration,\n# PAM authentication via ChallengeResponseAuthentication may bypass\n# the setting of \"PermitRootLogin without-password\".\n# If you just want the PAM account and session checks to run without\n# PAM authentication, then enable this but set PasswordAuthentication\n# and ChallengeResponseAuthentication to \'no\'.\n#UsePAM no\nUsePAM yes\n \n# Accept locale-related environment variables\nAcceptEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES\nAcceptEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT\nAcceptEnv LC_IDENTIFICATION LC_ALL LANGUAGE\nAcceptEnv XMODIFIERS\n \n#AllowAgentForwarding yes\n#AllowTcpForwarding yes\n#GatewayPorts no\n#X11Forwarding no\nX11Forwarding yes\n#X11DisplayOffset 10\n#X11UseLocalhost yes\n#PrintMotd yes\n#PrintLastLog yes\n#TCPKeepAlive yes\n#UseLogin no\n#UsePrivilegeSeparation yes\n#PermitUserEnvironment no\n#Compression delayed\n#ClientAliveInterval 0\n#ClientAliveCountMax 3\n#ShowPatchLevel no\n#UseDNS yes\n#PidFile /var/run/sshd.pid\n#MaxStartups 10:30:100\n#PermitTunnel no\n#ChrootDirectory none\n \n# no default banner path\n#Banner none\n \n# override default of no subsystems\nSubsystem       sftp    /usr/libexec/openssh/sftp-server\n \n# Example of overriding settings on a per-user basis\n#Match User anoncvs\n#       X11Forwarding no\n#       AllowTcpForwarding no\n#       ForceCommand cvs server\n\n```\n\n#### （可选）设置系统能自动获取openstack指定的hostname和ssh-key\n```\n使用vim编辑/etc/rc.local文件\n然后将以下内容输入进去，放在\"touch /var/lock/subsys/local\"之前\n if [ ! -d /root/.ssh ]; then   \n  mkdir -p /root/.ssh   \n  chmod 700 /root/.ssh   \nfi   \n   \n   \n# Fetch public key using HTTP   \nATTEMPTS=30   \nFAILED=0   \nwhile [ ! -f /root/.ssh/authorized_keys ]; do   \n    curl -f http://169.254.169.254/latest/meta-data/public-keys/0/openssh-key > /tmp/metadata-key 2>/dev/null   \n    if [ $? -eq 0 ]; then   \n        cat /tmp/metadata-key >> /root/.ssh/authorized_keys   \n        chmod 0600 /root/.ssh/authorized_keys   \n        restorecon /root/.ssh/authorized_keys   \n        rm -f /tmp/metadata-key   \n        echo \"Successfully retrieved public key from instance metadata\"   \n        echo \"*****************\"   \n        echo \"AUTHORIZED KEYS\"   \n        echo \"*****************\"   \n        cat /root/.ssh/authorized_keys   \n        echo \"*****************\"   \n   \n        curl -f http://169.254.169.254/latest/meta-data/hostname > /tmp/metadata-hostname 2>/dev/null   \n        if [ $? -eq 0 ]; then   \n            TEMP_HOST=`cat /tmp/metadata-hostname`   \n            sed -i \"s/^HOSTNAME=.*$/HOSTNAME=$TEMP_HOST/g\" /etc/sysconfig/network   \n            /bin/hostname $TEMP_HOST   \n            echo \"Successfully retrieved hostname from instance metadata\"   \n            echo \"*****************\"   \n            echo \"HOSTNAME CONFIG\"   \n            echo \"*****************\"   \n            cat /etc/sysconfig/network   \n            echo \"*****************\"   \n   \n        else   \n            echo \"Failed to retrieve hostname from instance metadata. This is a soft error so we\'ll continue\"   \n        fi   \n        rm -f /tmp/metadata-hostname   \n    else   \n        FAILED=$(($FAILED + 1))   \n        if [ $FAILED -ge $ATTEMPTS ]; then   \n            echo \"Failed to retrieve public key from instance metadata after $FAILED attempts, quitting\"   \n            break   \n        fi   \n        echo \"Could not retrieve public key from instance metadata (attempt #$FAILED/$ATTEMPTS), retrying in 5 seconds...\"   \n        sleep 5   \n  fi   \ndone \n```\n### 关机\n> [root@localhost ~]# poweroff\n### 以下操作去宿主机上\n> 清除网络相关硬件生成信息 \n\n> [root@node1 ~]#virt-sysprep -d centos\n\n\n### 压缩镜像 \n```\n[root@node1 ~]#virt-sparsify --compress CentOS-7.2-redoop.qcow2 centos-7.2cloud.qcow2\n```\n镜像制作到此结束', '0', '<h1 id=\"h1-u51C6u5907u5DE5u4F5C\"><a name=\"准备工作\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>准备工作</h1><blockquote>\n<p>首先你需要有一台CentOS的机器，作为制作镜像的机器。比如自己的虚拟机。我的环境是用一台R410上面装CentOS6.5的系统来做的。</p>\n</blockquote>\n<h2 id=\"h2-u6CE8u610Fu4E8Bu9879\"><a name=\"注意事项\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>注意事项</h2><blockquote>\n<p>注意：kvm安装的虚拟机，不确定是那一台，在后台就是一个进程，每增加一台端口号+1，第一次创建的为5900！</p>\n</blockquote>\n<h2 id=\"h2-u5B89u88C5u57FAu7840u5DE5u5177u5305\"><a name=\"安装基础工具包\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装基础工具包</h2><pre><code>[root@node1 ~]#yum -y install wget vim lsof\n</code></pre><h3 id=\"h3--selinux\"><a name=\"关闭防火墙和selinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭防火墙和selinux</h3><pre><code>[root@node1 ~]#/etc/init.d/iptables stop \n\n[root@node1 ~]# sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/selinux/config \n[root@node1 ~]#setenforce 0\n[root@node1 ~]# grep SELINUX=disabled /etc/selinux/config\n\nSELINUX=disabled\n</code></pre><h3 id=\"h3-u5B89u88C5u5E95u5C42u652Fu6301u5305\"><a name=\"安装底层支持包\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装底层支持包</h3><pre><code>[root@node1 ~]#yum install libvirt libguestfs-tools qemu-kvm qemu-img\n[root@node1 ~]#yum groupinstall Virtualization &quot;Virtualization Client&quot; -y\n[root@node1 ~]#yum install tigervnc tigervnc-server tigervnc-server-module\n</code></pre><h3 id=\"h3-u4E0Bu8F7Du6216u4ECEu672Cu5730u4E0Au4F20u8FDBu53BBu4E00u4E2Au5B8Cu6574u7684u7CFBu7EDFu955Cu50CF\"><a name=\"下载或从本地上传进去一个完整的系统镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>下载或从本地上传进去一个完整的系统镜像</h3><pre><code>[root@node1 ~]#cd /opt/\n[root@node1 ~]#wget  http://ftp.sjtu.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-1708.iso (可自行从网上下载)\n</code></pre><h3 id=\"h3-u542Fu52A8u670Du52A1\"><a name=\"启动服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>启动服务</h3><pre><code>[root@node1 ~]#yum install avahi\n修改配置文件：\n[root@node1 ~]#/etc/libvirt/qemu.conf(199行)\n打开user=“root”和group=“root”的注释\n\n[root@node1 ~]#/etc/init.d/libvirtd start\n</code></pre><h3 id=\"h3-u6865u63A5u7F51u7EDC\"><a name=\"桥接网络\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>桥接网络</h3><blockquote>\n<p>（目标为了能让新建出来的虚拟机能够和宿主机在同一网段通过xshell连上）</p>\n</blockquote>\n<pre><code>KVM修改NAT模式为桥接[案例]\n在开始案例之前，需要知道的必要信息，宿主机IP是192.168.1.249，操作系统版本Centos-6.5-x86_64。\n\n启动虚拟网卡\n\n[root@node1 ~]#ifup eth0\n这里网卡是NAT模式，可以上网，ping通其他机器，但是其他机器无法登陆！\n\n宿主机查看网卡信息\n[root@node1 ~]#brctl show\n\n[root@node1 ~]#ifconfig virbr0\n\n[root@node1 ~]#ifconfig vnet0\n实现网桥，在kvm宿主机完成\n\n步骤1，创建一个网桥，新建网桥连接到eth0,删除eth0,让新的网桥拥有eth0的ip\n[root@node1 ~]#brctl addbr br0  #创建一个网桥\n\n[root@node1 ~]#brctl show       #显示网桥信息\n\n[root@node1 ~]#brctl addif br0 eth0 &amp;&amp; ip addr del dev eth0 192.168.1.249/24 &amp;&amp; ifconfig br0 192.168.1.249/24 up\n\n[root@node1 ~]#brctl show      #查看结果\n[root@node1 ~]#ifconfig br0    #验证br0是否成功取代了eth0的IP\n</code></pre><h1 id=\"h1-u5236u4F5Cu955Cu50CF\"><a name=\"制作镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>制作镜像</h1><h3 id=\"h3-u5EFAu7ACBu955Cu50CFu6587u4EF6\"><a name=\"建立镜像文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>建立镜像文件</h3><pre><code>[root@node1 ~]#qemu-img create -f qcow2 CentOS-7.2-redoop.qcow2 80G\n</code></pre><h3 id=\"h3--virt-install-\"><a name=\"通过virt-install来创建一个新的虚拟机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>通过virt-install来创建一个新的虚拟机</h3><pre><code>#非桥接网卡\n[root@node1 ~]# virt-install \\\n--virt-type qemu \\\n--name centos \\\n--ram 10240 \\     （内存，可自行配置）\n--disk CentOS-7.2-redoop.qcow2,format=qcow2 \\\n--network network=default \\\n--graphics vnc,listen=0.0.0.0 --noautoconsole \\\n--os-type=linux --os-variant=rhel7 \\\n--location=/opt/CentOS-7-x86_64-DVD-1708.iso\n\n#桥接网卡\n[root@node1 ~]# virt-install \\\n  --virt-type qemu \\\n  --name centos \\\n  --ram 10240\\           （内存，可自行配置）\n  --disk CentOS-7.2-redoop.qcow2,format=qcow2 \\\n  --network bridge=br0 \\  (此处=后面是要桥接网卡的名字)\n  --graphics vnc,listen=0.0.0.0 --noautoconsole \\\n  --os-type=linux --os-variant=rhel7 \\\n  --location=/opt/CentOS-7-x86_64-DVD-1708.iso\n\n#检测5900端口\n[root@node1 ~]#lsof -i :5900\n\n[root@node1 ~]#virsh list --all (查看所有创建虚拟机)\n\n[root@node1 ~]#virsh start name  （启动虚拟机）\n</code></pre><h3 id=\"h3--vnc-\"><a name=\"用VNC连接创建出来的虚拟机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>用VNC连接创建出来的虚拟机</h3><blockquote>\n<p>我用到的是windows版VNC以下是下载地址</p>\n<p><a href=\"http://www.tightvnc.com\">http://www.tightvnc.com</a></p>\n</blockquote>\n<p><img src=\"/upload/images/20180322//74a11d03-f893-4fbb-9cab-caf9d7944043.png\" alt=\"\"></p>\n<h3 id=\"h3-u5B89u88C5u64CDu4F5Cu7CFBu7EDF\"><a name=\"安装操作系统\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装操作系统</h3><pre><code>操作系统的安装和正常的安装几乎一样,你需要什么样的包,就安装什么样的包,有两点需要注意的:\n注意一：分区，分区的时候只给&quot;/&quot; 根目录分一个区即可，其他都不要。 \n注意二：网络设置方面，确保你的网卡eth0是DHCP状态的，而且请务必勾上&quot;auto connect&quot;的对勾\n</code></pre><p><img src=\"/upload/images/20180322//d4185886-6707-4b21-b304-8539d88f570c.png\" alt=\"\"></p>\n<blockquote>\n<p>选择英文语言，下一步</p>\n</blockquote>\n<p><img src=\"/upload/images/20180322//e0f13e91-01d8-4bfc-a202-b3cd135b2aff.png\" alt=\"\"></p>\n<blockquote>\n<h1 id=\"h1--\"><a name=\"选择时区：亚洲上海\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>选择时区：亚洲上海</h1></blockquote>\n<p><img src=\"/upload/images/20180322//ddbce07a-c8bc-44e4-a405-7d8e374c6b1f.png\" alt=\"\"></p>\n<blockquote>\n<p>选择最小化安装包组</p>\n</blockquote>\n<p><img src=\"/upload/images/20180322//d5988954-3e20-4c9d-9d35-47537e285349.png\" alt=\"\"></p>\n<blockquote>\n<p>自定义磁盘分区</p>\n</blockquote>\n<p><img src=\"/upload/images/20180322//69134dac-96d7-4f19-ac75-6140fa8951f3.png\" alt=\"\"></p>\n<blockquote>\n<p>不使用LVM，单机 “+” 添加分区</p>\n</blockquote>\n<p><img src=\"/upload/images/20180322//e4bef3d9-d9ca-44e8-994e-0a15a3a10885.png\" alt=\"\"></p>\n<blockquote>\n<p>只分配一个 “/” 分区，不创建 swap分区，本身就是虚拟机，更影响性能。</p>\n</blockquote>\n<p><img src=\"/upload/images/20180322//9840a7ea-999e-4df0-95fa-458c099deaab.png\" alt=\"\"></p>\n<blockquote>\n<p>创建完，单机左上角“done”</p>\n</blockquote>\n<p><img src=\"/upload/images/20180322//33c93157-58d8-4c1b-87be-c63193692ace.png\" alt=\"\"></p>\n<blockquote>\n<h1 id=\"h1-u5F00u59CBu5B89u88C5u7CFBu7EDF\"><a name=\"开始安装系统\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>开始安装系统</h1></blockquote>\n<p><img src=\"/upload/images/20180322//a61de527-4e6f-4516-9005-f47fa5b8ae75.png\" alt=\"\"></p>\n<blockquote>\n<p>给root用户创建密码</p>\n</blockquote>\n<h2 id=\"h2--xshell-\"><a name=\"通过xshell连接虚拟机并优化\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>通过xshell连接虚拟机并优化</h2><pre><code>[root@localhost  ~]# yum install -y  net-tools  wget git vim  lsof tcpdump\n</code></pre><h3 id=\"h3--\"><a name=\"修改网卡信息（只保留以下内容）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改网卡信息（只保留以下内容）</h3><pre><code>[root@localhost  ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0\n3 TYPE=Ethernet\n4 BOOTPROTO=dhcp\n5 NAME=eth0\n6 DEVICE=eth0\n7 ONBOOT=yes\n</code></pre><h3 id=\"h3--yum-\"><a name=\"修改yum源\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改yum源</h3><pre><code>[root@localhost mple ~]# rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm\n</code></pre><h3 id=\"h3--networkemanager-\"><a name=\"关闭Networkemanager和防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭Networkemanager和防火墙</h3><pre><code>1 [root@localhost  ~]# systemctl disable firewalld\n2 [root@localhost  ~]# systemctl stop firewalld   \n3 [root@localhost ~]# systemctl stop NetworkManager\n</code></pre><h3 id=\"h3--selinux-\"><a name=\"关闭selinux(两种方式，自行选择)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭selinux(两种方式，自行选择)</h3><pre><code>1.\n#修改selinux配置文件\n[root@localhosmple ~]# vim /etc/sysconfig/selinux\nSELINUX=enforcing 改为 SELINUX=disabled\n#重启后，检查结果如下\n[root@localhost ~]# getsebool\ngetsebool:  SELinux is disabled\n\n2.\n[root@localhost ~]# sed –i &#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config\n</code></pre><h3 id=\"h3-u914Du7F6E\"><a name=\"配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置</h3><blockquote>\n<p>删除已生成的网络设备规则(最后再删除，这样可以继续上网)</p>\n<pre><code>[root@localhost ~]#rm -rf /etc/udev/rules.d/70-persistent-net.rules\n</code></pre><pre><code>增加一行到/etc/sysconfig/network\nNOZEROCONF=yes（必须的\n</code></pre><pre><code>修改分区加载表（/etc/fstab），注释或删除以前的，加上 UUID=cec-rootfs 一行：\n[root@localhost ~]# vim /etc/fstab\n#UUID=47a90bea-2d88-4c82-a335-09c1533b1538 / ext4 defaults 1 1\nUUID=cec-rootfs                           / ext4 defaults 0 0\n#其余的不用变\n</code></pre></blockquote>\n<h3 id=\"h3-ssh-\"><a name=\"ssh免密登录配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>ssh免密登录配置</h3><pre><code> vi /etc/ssh/sshd_config\n...\nRSAAuthentication yes\nPubkeyAuthentication yes\nPermitRootLogin without-password\nChallengeResponseAuthentication no\nPasswordAuthentication no\nUsePAM no\n、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、\n#       $OpenBSD: sshd_config,v 1.80 2008/07/02 02:24:18 djm Exp $\n\n# This is the sshd server system-wide configuration file.  See\n# sshd_config(5) for more information.\n\n# This sshd was compiled with PATH=/usr/local/bin:/bin:/usr/bin\n\n# The strategy used for options in the default sshd_config shipped with\n# OpenSSH is to specify options with their default value where\n# possible, but leave them commented.  Uncommented options change a\n# default value.\n\n#Port 22\n#AddressFamily any\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n\n# Disable legacy (protocol version 1) support in the server for new\n# installations. In future the default will change to require explicit\n# activation of protocol 1\nProtocol 2\n\n# HostKey for protocol version 1\n#HostKey /etc/ssh/ssh_host_key\n# HostKeys for protocol version 2\n#HostKey /etc/ssh/ssh_host_rsa_key\n#HostKey /etc/ssh/ssh_host_dsa_key\n\n# Lifetime and size of ephemeral version 1 server key\n#KeyRegenerationInterval 1h\n#ServerKeyBits 1024\n\n# Logging\n# obsoletes QuietMode and FascistLogging\n#SyslogFacility AUTH\nSyslogFacility AUTHPRIV\n#LogLevel INFO\n\n# Authentication:\n\n#LoginGraceTime 2m\nPermitRootLogin yes\n#StrictModes yes\n#MaxAuthTries 6\n#MaxSessions 10\n\nRSAAuthentication yes\nPubkeyAuthentication yes\n#AuthorizedKeysFile     .ssh/authorized_keys\n#AuthorizedKeysCommand none\n#AuthorizedKeysCommandRunAs nobody\n\n# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts\n#RhostsRSAAuthentication no\n# similar for protocol version 2\n#HostbasedAuthentication no\n# Change to yes if you don&#39;t trust ~/.ssh/known_hosts for\n# RhostsRSAAuthentication and HostbasedAuthentication\n#IgnoreUserKnownHosts no\n# Don&#39;t read the user&#39;s ~/.rhosts and ~/.shosts files\n#IgnoreRhosts yes\n\n# To disable tunneled clear text passwords, change to no here!\nPasswordAuthentication yes\n#PermitEmptyPasswords no\nPasswordAuthentication yes\n\n# Change to no to disable s/key passwords\n#ChallengeResponseAuthentication yes\nChallengeResponseAuthentication no\n\n# Kerberos options\n#KerberosAuthentication no\n#KerberosOrLocalPasswd yes\n#KerberosTicketCleanup yes\n#KerberosGetAFSToken no\n#KerberosUseKuserok yes\n\n# GSSAPI options\n#GSSAPIAuthentication no\nGSSAPIAuthentication yes\n#GSSAPICleanupCredentials yes\nGSSAPICleanupCredentials yes\n#GSSAPIStrictAcceptorCheck yes\n#GSSAPIKeyExchange no\n\n# Set this to &#39;yes&#39; to enable PAM authentication, account processing,\n# and session processing. If this is enabled, PAM authentication will\n# be allowed through the ChallengeResponseAuthentication and\n# PasswordAuthentication.  Depending on your PAM configuration,\n# PAM authentication via ChallengeResponseAuthentication may bypass\n# the setting of &quot;PermitRootLogin without-password&quot;.\n# If you just want the PAM account and session checks to run without\n# PAM authentication, then enable this but set PasswordAuthentication\n# and ChallengeResponseAuthentication to &#39;no&#39;.\n#UsePAM no\nUsePAM yes\n\n# Accept locale-related environment variables\nAcceptEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES\nAcceptEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT\nAcceptEnv LC_IDENTIFICATION LC_ALL LANGUAGE\nAcceptEnv XMODIFIERS\n\n#AllowAgentForwarding yes\n#AllowTcpForwarding yes\n#GatewayPorts no\n#X11Forwarding no\nX11Forwarding yes\n#X11DisplayOffset 10\n#X11UseLocalhost yes\n#PrintMotd yes\n#PrintLastLog yes\n#TCPKeepAlive yes\n#UseLogin no\n#UsePrivilegeSeparation yes\n#PermitUserEnvironment no\n#Compression delayed\n#ClientAliveInterval 0\n#ClientAliveCountMax 3\n#ShowPatchLevel no\n#UseDNS yes\n#PidFile /var/run/sshd.pid\n#MaxStartups 10:30:100\n#PermitTunnel no\n#ChrootDirectory none\n\n# no default banner path\n#Banner none\n\n# override default of no subsystems\nSubsystem       sftp    /usr/libexec/openssh/sftp-server\n\n# Example of overriding settings on a per-user basis\n#Match User anoncvs\n#       X11Forwarding no\n#       AllowTcpForwarding no\n#       ForceCommand cvs server\n</code></pre><h4 id=\"h4--openstack-hostname-ssh-key\"><a name=\"（可选）设置系统能自动获取openstack指定的hostname和ssh-key\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>（可选）设置系统能自动获取openstack指定的hostname和ssh-key</h4><pre><code>使用vim编辑/etc/rc.local文件\n然后将以下内容输入进去，放在&quot;touch /var/lock/subsys/local&quot;之前\n if [ ! -d /root/.ssh ]; then   \n  mkdir -p /root/.ssh   \n  chmod 700 /root/.ssh   \nfi   \n\n\n# Fetch public key using HTTP   \nATTEMPTS=30   \nFAILED=0   \nwhile [ ! -f /root/.ssh/authorized_keys ]; do   \n    curl -f http://169.254.169.254/latest/meta-data/public-keys/0/openssh-key &gt; /tmp/metadata-key 2&gt;/dev/null   \n    if [ $? -eq 0 ]; then   \n        cat /tmp/metadata-key &gt;&gt; /root/.ssh/authorized_keys   \n        chmod 0600 /root/.ssh/authorized_keys   \n        restorecon /root/.ssh/authorized_keys   \n        rm -f /tmp/metadata-key   \n        echo &quot;Successfully retrieved public key from instance metadata&quot;   \n        echo &quot;*****************&quot;   \n        echo &quot;AUTHORIZED KEYS&quot;   \n        echo &quot;*****************&quot;   \n        cat /root/.ssh/authorized_keys   \n        echo &quot;*****************&quot;   \n\n        curl -f http://169.254.169.254/latest/meta-data/hostname &gt; /tmp/metadata-hostname 2&gt;/dev/null   \n        if [ $? -eq 0 ]; then   \n            TEMP_HOST=`cat /tmp/metadata-hostname`   \n            sed -i &quot;s/^HOSTNAME=.*$/HOSTNAME=$TEMP_HOST/g&quot; /etc/sysconfig/network   \n            /bin/hostname $TEMP_HOST   \n            echo &quot;Successfully retrieved hostname from instance metadata&quot;   \n            echo &quot;*****************&quot;   \n            echo &quot;HOSTNAME CONFIG&quot;   \n            echo &quot;*****************&quot;   \n            cat /etc/sysconfig/network   \n            echo &quot;*****************&quot;   \n\n        else   \n            echo &quot;Failed to retrieve hostname from instance metadata. This is a soft error so we&#39;ll continue&quot;   \n        fi   \n        rm -f /tmp/metadata-hostname   \n    else   \n        FAILED=$(($FAILED + 1))   \n        if [ $FAILED -ge $ATTEMPTS ]; then   \n            echo &quot;Failed to retrieve public key from instance metadata after $FAILED attempts, quitting&quot;   \n            break   \n        fi   \n        echo &quot;Could not retrieve public key from instance metadata (attempt #$FAILED/$ATTEMPTS), retrying in 5 seconds...&quot;   \n        sleep 5   \n  fi   \ndone\n</code></pre><h3 id=\"h3-u5173u673A\"><a name=\"关机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关机</h3><blockquote>\n<p>[root<a href=\"https://github.com/localhost\" title=\"&#64;localhost\" class=\"at-link\">@localhost</a> ~]# poweroff</p>\n<h3 id=\"h3-u4EE5u4E0Bu64CDu4F5Cu53BBu5BBFu4E3Bu673Au4E0A\"><a name=\"以下操作去宿主机上\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>以下操作去宿主机上</h3><p>清除网络相关硬件生成信息 </p>\n<p>[root<a href=\"https://github.com/node1\" title=\"&#64;node1\" class=\"at-link\">@node1</a> ~]#virt-sysprep -d centos</p>\n</blockquote>\n<h3 id=\"h3-u538Bu7F29u955Cu50CF\"><a name=\"压缩镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>压缩镜像</h3><pre><code>[root@node1 ~]#virt-sparsify --compress CentOS-7.2-redoop.qcow2 centos-7.2cloud.qcow2\n</code></pre><p>镜像制作到此结束</p>\n');
INSERT INTO `tbl_archive` VALUES ('41', '0', 'Storm的编译问题', '18', '2018-03-23 08:39:34', '#Storm的编译问题##在power机器上编译Storm的时候遇到以下问题：```gpg:nodefaultsecretkey:Badpassphrasegpg:signingfailed:Badpassphrase[INFO]------------------------------------------------------------------------[INFO]BUILDFA', null, '0', '269', null, null, '2018-03-23 08:39:34', null, null, null, '0', '0', '0', '0', '# Storm的编译问题\n## 在power机器上编译Storm的时候遇到以下问题：\n\n```\ngpg: no default secret key: Bad passphrase\ngpg: signing failed: Bad passphrase\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 19.752 s\n[INFO] Finished at: 2018-03-21T15:36:48+08:00\n[INFO] Final Memory: 17M/320M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-gpg-plugin:1.6:sign (default) on project apache-storm-bin: Exit code: 2 -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\nerror: Bad exit status from /var/tmp/rpm-tmp.o8C8Ug (%build)\n\n```\n## 经过观察错误信息发现是由于再编译Storm的时候需要使用到gpg加密，解决方法如下：\n\n```\n[root@power bigtop]# gpg --gen-key\ngpg (GnuPG) 2.0.22; Copyright (C) 2013 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nPlease select what kind of key you want:\n   (1) RSA and RSA (default)\n   (2) DSA and Elgamal\n   (3) DSA (sign only)\n   (4) RSA (sign only)\nYour selection? \nRSA keys may be between 1024 and 4096 bits long.\nWhat keysize do you want? (2048) \nRequested keysize is 2048 bits\nPlease specify how long the key should be valid.\n         0 = key does not expire\n      <n>  = key expires in n days\n      <n>w = key expires in n weeks\n      <n>m = key expires in n months\n      <n>y = key expires in n years\nKey is valid for? (0) \nKey does not expire at all\nIs this correct? (y/N) y\n\nGnuPG needs to construct a user ID to identify your key.\n\nReal name: zhaoshuai\nEmail address: zhaoshuai@redoop.com\nComment: gpg\nYou selected this USER-ID:\n    \"zhaoshuai (gpg) <zhaoshuai@redoop.com>\"\n\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o\nYou need a Passphrase to protect your secret key.\n  lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk\n                                            x Enter passphrase                                    x\n                                            x                                                     x\n                                            x                                                     x\n                                            x Passphrase 输入密码 ________________________________________ x\n                                            x                                                     x\n                                            x       <OK>                             <Cancel>     x\n                                            mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\nWe need to generate a lot of random bytes. It is a good idea to perform\nsome other action (type on the keyboard, move the mouse, utilize the\ndisks) during the prime generation; this gives the random number\ngenerator a better chance to gain enough entropy.\nWe need to generate a lot of random bytes. It is a good idea to perform\nsome other action (type on the keyboard, move the mouse, utilize the\ndisks) during the prime generation; this gives the random number\ngenerator a better chance to gain enough entropy.\ngpg: key C3B7C89E marked as ultimately trusted\npublic and secret key created and signed.\n\ngpg: checking the trustdb\ngpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model\ngpg: depth: 0  valid:   3  signed:   0  trust: 0-, 0q, 0n, 0m, 0f, 3u\npub   2048R/C3B7C89E 2018-03-21\n      Key fingerprint = 7941 2EAF 88F7 D72F 10A5  0765 611A 7414 C3B7 C89E\nuid                  zhaoshuai (gpg) <zhaoshuai@redoop.com>\nsub   2048R/90B99D38 2018-03-21\n\n```\n## 执行完上述操作后在bigtop/bigtop-packages/src/common/storm修改do-component-build文件\n\n```\nset -e\n\necho \"-------------- Storm-do-component-build-started -----------\"\n\nbase_path=`pwd`\nbuild_support_dir=`echo ${base_path%bigtop*}`\n\n\n. `dirname $0`/bigtop.bom\n\nmvn clean install -DskipTests \"$@\"\n\ncd ${base_path}\ncd storm-dist/binary/\nmvn package -Dgpg.passphrase=您的密码 \"$@\"\n\ncd ${base_path}\ncd storm-dist/source/\nmvn package -Dgpg.passphrase=您的密码 \"$@\"\n\n```\n\n', '0', '<h1 id=\"h1-storm-\"><a name=\"Storm的编译问题\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Storm的编译问题</h1><h2 id=\"h2--power-storm-\"><a name=\"在power机器上编译Storm的时候遇到以下问题：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在power机器上编译Storm的时候遇到以下问题：</h2><pre><code>gpg: no default secret key: Bad passphrase\ngpg: signing failed: Bad passphrase\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 19.752 s\n[INFO] Finished at: 2018-03-21T15:36:48+08:00\n[INFO] Final Memory: 17M/320M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-gpg-plugin:1.6:sign (default) on project apache-storm-bin: Exit code: 2 -&gt; [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\nerror: Bad exit status from /var/tmp/rpm-tmp.o8C8Ug (%build)\n</code></pre><h2 id=\"h2--storm-gpg-\"><a name=\"经过观察错误信息发现是由于再编译Storm的时候需要使用到gpg加密，解决方法如下：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>经过观察错误信息发现是由于再编译Storm的时候需要使用到gpg加密，解决方法如下：</h2><pre><code>[root@power bigtop]# gpg --gen-key\ngpg (GnuPG) 2.0.22; Copyright (C) 2013 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nPlease select what kind of key you want:\n   (1) RSA and RSA (default)\n   (2) DSA and Elgamal\n   (3) DSA (sign only)\n   (4) RSA (sign only)\nYour selection? \nRSA keys may be between 1024 and 4096 bits long.\nWhat keysize do you want? (2048) \nRequested keysize is 2048 bits\nPlease specify how long the key should be valid.\n         0 = key does not expire\n      &lt;n&gt;  = key expires in n days\n      &lt;n&gt;w = key expires in n weeks\n      &lt;n&gt;m = key expires in n months\n      &lt;n&gt;y = key expires in n years\nKey is valid for? (0) \nKey does not expire at all\nIs this correct? (y/N) y\n\nGnuPG needs to construct a user ID to identify your key.\n\nReal name: zhaoshuai\nEmail address: zhaoshuai@redoop.com\nComment: gpg\nYou selected this USER-ID:\n    &quot;zhaoshuai (gpg) &lt;zhaoshuai@redoop.com&gt;&quot;\n\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o\nYou need a Passphrase to protect your secret key.\n  lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk\n                                            x Enter passphrase                                    x\n                                            x                                                     x\n                                            x                                                     x\n                                            x Passphrase 输入密码 ________________________________________ x\n                                            x                                                     x\n                                            x       &lt;OK&gt;                             &lt;Cancel&gt;     x\n                                            mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\nWe need to generate a lot of random bytes. It is a good idea to perform\nsome other action (type on the keyboard, move the mouse, utilize the\ndisks) during the prime generation; this gives the random number\ngenerator a better chance to gain enough entropy.\nWe need to generate a lot of random bytes. It is a good idea to perform\nsome other action (type on the keyboard, move the mouse, utilize the\ndisks) during the prime generation; this gives the random number\ngenerator a better chance to gain enough entropy.\ngpg: key C3B7C89E marked as ultimately trusted\npublic and secret key created and signed.\n\ngpg: checking the trustdb\ngpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model\ngpg: depth: 0  valid:   3  signed:   0  trust: 0-, 0q, 0n, 0m, 0f, 3u\npub   2048R/C3B7C89E 2018-03-21\n      Key fingerprint = 7941 2EAF 88F7 D72F 10A5  0765 611A 7414 C3B7 C89E\nuid                  zhaoshuai (gpg) &lt;zhaoshuai@redoop.com&gt;\nsub   2048R/90B99D38 2018-03-21\n</code></pre><h2 id=\"h2--bigtop-bigtop-packages-src-common-storm-do-component-build-\"><a name=\"执行完上述操作后在bigtop/bigtop-packages/src/common/storm修改do-component-build文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>执行完上述操作后在bigtop/bigtop-packages/src/common/storm修改do-component-build文件</h2><pre><code>set -e\n\necho &quot;-------------- Storm-do-component-build-started -----------&quot;\n\nbase_path=`pwd`\nbuild_support_dir=`echo ${base_path%bigtop*}`\n\n\n. `dirname $0`/bigtop.bom\n\nmvn clean install -DskipTests &quot;$@&quot;\n\ncd ${base_path}\ncd storm-dist/binary/\nmvn package -Dgpg.passphrase=您的密码 &quot;$@&quot;\n\ncd ${base_path}\ncd storm-dist/source/\nmvn package -Dgpg.passphrase=您的密码 &quot;$@&quot;\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('42', '0', 'CRH5.1_x64_CentOS7集群上搭建ntp服务器实现时间同步', '11', '2018-03-26 18:48:23', '安装CRH组件HBase需要满足所有机器系统时间同步。', null, '0', '247', null, null, '2018-03-26 18:48:23', '2018-03-26 18:58:03', null, null, '0', '0', '0', '0', '### 分有外网和无外网情况。\n\n-  注意配置ip映射\n\n#### 1. 有外网\n\n- 每台机器直接安装使用ntp服务，让时间与网络时间同步。\n\n```\n安装\n[root@redoop01 ~]#  for ip in $(cat hosts);do  ssh ${ip} yum install -y ntp; done\n启动\n[root@redoop01 ~]#  for ip in $(cat hosts);do  ssh ${ip} systemcntl start ntpd ; done\n开机自启动\n[root@redoop01 ~]#  for ip in $(cat hosts);do  ssh ${ip} systemcntl enable ntpd ; done\n```\n\n\n\n#### 2. 无外网，选一台机器做ntp server,其他机器做 ntp client\n\n- 集群所有机器安装 ntp\n\n```\n[root@redoop01 ~]#  for ip in $(cat hosts);do  ssh ${ip} yum install -y ntp; done\n```\n- 启动ntp server节点 ntp服务\n\n```\nsystemctl start ntpd\n\nsystemctl enable ntpd\n```\n- 在server节点上设置其ntp服务器为其自身，同时设置可以接受连接服务的客户端，通过更改/etc/ntp.conf文件来实现，其中server设置127.127.1.0为其自身，新增加一个restrict段为可以接受服务的网段 \n\n```\n# For more information about this file, see the man pages\n# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).\n\ndriftfile /var/lib/ntp/drift\n\n# Permit time synchronization with our time source, but do not\n# permit the source to query or modify the service on this system.\nrestrict default nomodify notrap nopeer noquery\n\n# Permit all access over the loopback interface.  This could\n# be tightened as well, but to do so would effect some of\n# the administrative functions.\nrestrict 127.0.0.1\nrestrict ::1\nrestrict 192.168.0.0 mask 255.255.0.0\n# Hosts on local network are less restricted.\n#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver  127.127.1.0\n#server 0.centos.pool.ntp.org iburst\n#server 1.centos.pool.ntp.org iburst\n#server 2.centos.pool.ntp.org iburst\n#server 3.centos.pool.ntp.org iburst\n### \n```\n- 重启ntp server 节点的 ntp 服务\n\n```\nsystemctl restart ntpd\n```\n- 在client节点上设置ntp server机器为 授时服务器 \n\n```\n# For more information about this file, see the man pages\n# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).\n\ndriftfile /var/lib/ntp/drift\n\n# Permit time synchronization with our time source, but do not\n# permit the source to query or modify the service on this system.\nrestrict default nomodify notrap nopeer noquery\n\n# Permit all access over the loopback interface.  This could\n# be tightened as well, but to do so would effect some of\n# the administrative functions.\nrestrict 127.0.0.1\nrestrict ::1\n\n\n# Hosts on local network are less restricted.\n#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver redoop03\n#server 0.centos.pool.ntp.org iburst\n#server 1.centos.pool.ntp.org iburst\n#server 2.centos.pool.ntp.org iburst\n\n```\n\n\n\n\n- 在client节点上同步server的时间 \n\n```\nntpdate redoop03\n```\n- client节点启动ntpd服务\n\n```\nsystemctl start ntpd\nsystemctl enable ntpd\n```\n- 所有节点启动时间同步\n\n```\ntimedatectl set-ntp yes\n```\n- 查看同步效果\n\n```\n[root@redoop01 ~]# for ip in $(cat hosts);do ssh ${ip} date -R;done\nMon, 26 Mar 2018 16:03:08 +0800\nMon, 26 Mar 2018 16:03:08 +0800\nMon, 26 Mar 2018 16:03:09 +0800\n[root@redoop01 ~]# \n\n```\n\n\n\n\n', '0', '<h3 id=\"h3--\"><a name=\"分有外网和无外网情况。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>分有外网和无外网情况。</h3><ul>\n<li>注意配置ip映射</li></ul>\n<h4 id=\"h4-1-\"><a name=\"1. 有外网\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. 有外网</h4><ul>\n<li>每台机器直接安装使用ntp服务，让时间与网络时间同步。</li></ul>\n<pre><code>安装\n[root@redoop01 ~]#  for ip in $(cat hosts);do  ssh ${ip} yum install -y ntp; done\n启动\n[root@redoop01 ~]#  for ip in $(cat hosts);do  ssh ${ip} systemcntl start ntpd ; done\n开机自启动\n[root@redoop01 ~]#  for ip in $(cat hosts);do  ssh ${ip} systemcntl enable ntpd ; done\n</code></pre><h4 id=\"h4-2-ntp-server-ntp-client\"><a name=\"2. 无外网，选一台机器做ntp server,其他机器做 ntp client\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2. 无外网，选一台机器做ntp server,其他机器做 ntp client</h4><ul>\n<li>集群所有机器安装 ntp</li></ul>\n<pre><code>[root@redoop01 ~]#  for ip in $(cat hosts);do  ssh ${ip} yum install -y ntp; done\n</code></pre><ul>\n<li>启动ntp server节点 ntp服务</li></ul>\n<pre><code>systemctl start ntpd\n\nsystemctl enable ntpd\n</code></pre><ul>\n<li>在server节点上设置其ntp服务器为其自身，同时设置可以接受连接服务的客户端，通过更改/etc/ntp.conf文件来实现，其中server设置127.127.1.0为其自身，新增加一个restrict段为可以接受服务的网段 </li></ul>\n<pre><code># For more information about this file, see the man pages\n# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).\n\ndriftfile /var/lib/ntp/drift\n\n# Permit time synchronization with our time source, but do not\n# permit the source to query or modify the service on this system.\nrestrict default nomodify notrap nopeer noquery\n\n# Permit all access over the loopback interface.  This could\n# be tightened as well, but to do so would effect some of\n# the administrative functions.\nrestrict 127.0.0.1\nrestrict ::1\nrestrict 192.168.0.0 mask 255.255.0.0\n# Hosts on local network are less restricted.\n#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver  127.127.1.0\n#server 0.centos.pool.ntp.org iburst\n#server 1.centos.pool.ntp.org iburst\n#server 2.centos.pool.ntp.org iburst\n#server 3.centos.pool.ntp.org iburst\n###\n</code></pre><ul>\n<li>重启ntp server 节点的 ntp 服务</li></ul>\n<pre><code>systemctl restart ntpd\n</code></pre><ul>\n<li>在client节点上设置ntp server机器为 授时服务器 </li></ul>\n<pre><code># For more information about this file, see the man pages\n# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).\n\ndriftfile /var/lib/ntp/drift\n\n# Permit time synchronization with our time source, but do not\n# permit the source to query or modify the service on this system.\nrestrict default nomodify notrap nopeer noquery\n\n# Permit all access over the loopback interface.  This could\n# be tightened as well, but to do so would effect some of\n# the administrative functions.\nrestrict 127.0.0.1\nrestrict ::1\n\n\n# Hosts on local network are less restricted.\n#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver redoop03\n#server 0.centos.pool.ntp.org iburst\n#server 1.centos.pool.ntp.org iburst\n#server 2.centos.pool.ntp.org iburst\n</code></pre><ul>\n<li>在client节点上同步server的时间 </li></ul>\n<pre><code>ntpdate redoop03\n</code></pre><ul>\n<li>client节点启动ntpd服务</li></ul>\n<pre><code>systemctl start ntpd\nsystemctl enable ntpd\n</code></pre><ul>\n<li>所有节点启动时间同步</li></ul>\n<pre><code>timedatectl set-ntp yes\n</code></pre><ul>\n<li>查看同步效果</li></ul>\n<pre><code>[root@redoop01 ~]# for ip in $(cat hosts);do ssh ${ip} date -R;done\nMon, 26 Mar 2018 16:03:08 +0800\nMon, 26 Mar 2018 16:03:08 +0800\nMon, 26 Mar 2018 16:03:09 +0800\n[root@redoop01 ~]#\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('43', '0', 'Tez编译问题', '19', '2018-03-27 10:05:08', 'protobuf缺失：解决办法：安装protobufprotobuf安装步骤：1.下载protobuf安装包2.解压文件，进入压缩目录，执行如下命令：```./configure--prefix=/usr/local/protobufmakemakecheckmakeinstall```3.配置protobuf.sh文件```vim/etc/profile/protobuf.sh添加如下内容exp', null, '0', '215', null, null, '2018-03-27 10:05:08', '2018-03-28 09:40:41', null, null, '0', '0', '0', '0', 'protobuf缺失：\n解决办法：安装protobuf\nprotobuf安装步骤：\n1.下载protobuf安装包\n2.解压文件，进入压缩目录，执行如下命令：\n``` \n ./configure --prefix=/usr/local/protobuf\n make \n make check \n make install\n```\n3.配置protobuf.sh文件\n```\n vim /etc/profile/protobuf.sh添加如下内容\n export PATH=$PATH:/usr/local/protobuf/bin\n export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/protobuf/lib\n```\n4.执行\n```\n> source /etc/profile\n```\n\n\nbower缺失：\n1.执行命令\n```\n> npm install -g bower\n```\n2.解压apache-tez-0.7.0-src.tar.gz文件修改tez-ui中的配置文件，如下（添加--allow-root）\n```\n </executable>\n   <arguments>\n    <argument>node_modules/bower/bin/bower</argument>\n    <argument>install</argument>\n    <argument>--remove-unnecessary-resolutions=false</argument>\n    <argument>--allow-root</argument>\n   </arguments>\n </configuration>\n```\n3.把修改之后的文件夹压缩成原来的格式\n```\n tar -czf apache-tez-0.7.0-src.tar.gz apache-tez-0.7.0-src\n```\n', '0', '<p>protobuf缺失：<br>解决办法：安装protobuf<br>protobuf安装步骤：<br>1.下载protobuf安装包<br>2.解压文件，进入压缩目录，执行如下命令：</p>\n<pre><code> ./configure --prefix=/usr/local/protobuf\n make \n make check \n make install\n</code></pre><p>3.配置protobuf.sh文件</p>\n<pre><code> vim /etc/profile/protobuf.sh添加如下内容\n export PATH=$PATH:/usr/local/protobuf/bin\n export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/protobuf/lib\n</code></pre><p>4.执行</p>\n<pre><code>&gt; source /etc/profile\n</code></pre><p>bower缺失：<br>1.执行命令</p>\n<pre><code>&gt; npm install -g bower\n</code></pre><p>2.解压apache-tez-0.7.0-src.tar.gz文件修改tez-ui中的配置文件，如下（添加—allow-root）</p>\n<pre><code> &lt;/executable&gt;\n   &lt;arguments&gt;\n    &lt;argument&gt;node_modules/bower/bin/bower&lt;/argument&gt;\n    &lt;argument&gt;install&lt;/argument&gt;\n    &lt;argument&gt;--remove-unnecessary-resolutions=false&lt;/argument&gt;\n    &lt;argument&gt;--allow-root&lt;/argument&gt;\n   &lt;/arguments&gt;\n &lt;/configuration&gt;\n</code></pre><p>3.把修改之后的文件夹压缩成原来的格式</p>\n<pre><code> tar -czf apache-tez-0.7.0-src.tar.gz apache-tez-0.7.0-src\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('44', '0', 'Centos系统中进行深度学习后本地显示效果图片', '26', '2018-03-29 10:54:51', '在Centos系统中进行深度学习，尤其进行图像分割时，python脚本中matplotlib作图命令最终效果往往需要将图片保存下来再进行查看，现将在本地显示图片的方法分享出来。', null, '0', '293', null, null, '2018-03-29 10:54:51', '2018-03-29 10:59:51', null, null, '0', '0', '0', '0', '首先在Xshell中连接上远程服务器，然后点击文件，选择属性，在连接/SSH/隧道中勾选X11转移，转发X11连接到(X):，选择Xmanager(M)。![](/upload/images/20180329//60717171-e9d6-4d8e-b541-a5f6c1e58f6a.png)\n设置后新打开一个连接窗口，如果出现提示：\n![](/upload/images/20180329//200cdbfc-cbe5-4cf0-b50f-8608c5ebeb8a.png)\n说明目前X11连接不可用，通过查阅资料，发现是缺少一个依赖包：\nyum -y install xorg-x11-xauth\n重新打开，发现WARNING不再出现。\n\n接下来在本地安装Xmanager\n![](/upload/images/20180329//e939e64a-fd45-46f5-af02-e89ba233d6fe.png)\n本地安装后，桌面出现Xmanager文件夹，打开包含5个快捷方式\n![](/upload/images/20180329//05c19425-b153-4156-be69-a2103a519797.png)\n运行Xstart，运行界面如下。\n![](/upload/images/20180329//3c5bb8d5-a79b-4b7b-95fc-b438b694a1dc.png)\n在界面中进行以下配置：\n在会话栏点击新建，输入名称；\n主机中输入服务器IP；\n协议中选择SSH；\n用户名和身份验证输入主机用户名和密钥。\n设置完成后点击右上角运行，出现运行界面说明Xmanager运行成功。\n![](/upload/images/20180329//74616371-f7ef-469e-88a2-deb38e85e9ec.png)\n在Xmanager中双击运行Xmanager-Passive\n\n至此，所需的环境都已经准备好，运行图像分割的python脚本，图像分割后的效果图会直接以弹窗的形式在本地显示。效果如下：\n![](/upload/images/20180329//895fa5dd-aa74-47fc-b78e-196eb99af73c.png)\n', '0', '<p>首先在Xshell中连接上远程服务器，然后点击文件，选择属性，在连接/SSH/隧道中勾选X11转移，转发X11连接到(X):，选择Xmanager(M)。<img src=\"/upload/images/20180329//60717171-e9d6-4d8e-b541-a5f6c1e58f6a.png\" alt=\"\"><br>设置后新打开一个连接窗口，如果出现提示：<br><img src=\"/upload/images/20180329//200cdbfc-cbe5-4cf0-b50f-8608c5ebeb8a.png\" alt=\"\"><br>说明目前X11连接不可用，通过查阅资料，发现是缺少一个依赖包：<br>yum -y install xorg-x11-xauth<br>重新打开，发现WARNING不再出现。</p>\n<p>接下来在本地安装Xmanager<br><img src=\"/upload/images/20180329//e939e64a-fd45-46f5-af02-e89ba233d6fe.png\" alt=\"\"><br>本地安装后，桌面出现Xmanager文件夹，打开包含5个快捷方式<br><img src=\"/upload/images/20180329//05c19425-b153-4156-be69-a2103a519797.png\" alt=\"\"><br>运行Xstart，运行界面如下。<br><img src=\"/upload/images/20180329//3c5bb8d5-a79b-4b7b-95fc-b438b694a1dc.png\" alt=\"\"><br>在界面中进行以下配置：<br>在会话栏点击新建，输入名称；<br>主机中输入服务器IP；<br>协议中选择SSH；<br>用户名和身份验证输入主机用户名和密钥。<br>设置完成后点击右上角运行，出现运行界面说明Xmanager运行成功。<br><img src=\"/upload/images/20180329//74616371-f7ef-469e-88a2-deb38e85e9ec.png\" alt=\"\"><br>在Xmanager中双击运行Xmanager-Passive</p>\n<p>至此，所需的环境都已经准备好，运行图像分割的python脚本，图像分割后的效果图会直接以弹窗的形式在本地显示。效果如下：<br><img src=\"/upload/images/20180329//895fa5dd-aa74-47fc-b78e-196eb99af73c.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('45', '0', '在XLearning中添加ffmpeg压缩视频的运行示例', '24', '2018-03-29 11:32:14', '类似于caffe，tensorflow等深度学习框架的集成，在XLearning中增加了基于HadoopYarn上的FFmpeg的调度。##1.安装ffmpeg##install-ffmpeg.sh脚本代码：```#安装EPELRelease，因为安装需要使用其他的repo源，所以需要EPEL支持yuminstall-yepel-release#导入一个Codesudorpm--importhtt', null, '0', '448', null, null, '2018-03-29 11:32:14', '2018-03-29 15:02:46', null, null, '0', '0', '0', '0', '类似于caffe，tensorflow等深度学习框架的集成，在XLearning中增加了基于Hadoop Yarn上的FFmpeg的调度。\r\n## 1. 安装ffmpeg ##\r\ninstall-ffmpeg.sh脚本代码：\r\n```\r\n#安装EPEL Release，因为安装需要使用其他的repo源，所以需要EPEL支持\r\nyum install -y epel-release \r\n#导入一个Code\r\nsudo rpm --import http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro \r\n#安装nux-dextop源\r\nsudo rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-1.el7.nux.noarch.rpm\r\n#查看repo源是否安装成功\r\nyum repolist \r\n#yum安装ffmpeg\r\nyum install -y ffmpeg\r\n#安装完成后检查ffmpeg 版本\r\nffmpeg -version\r\n```\r\n![](/upload/images/20180329//6c1220d2-49e5-4bb5-8dce-5a4d3c5155fe.png)\r\n## 2.ffmpeg转压视频命令 ##\r\n\r\n```\r\nffmpeg -i H00C1T20171120230303C77.sdv -vcodec libx264 -preset fast -crf 20 -y -vf \"scale=1920:-1\" -acodec libmp3lame -ab 128k b.mp4\r\n```\r\n\r\n参数简单解释如下:\r\n-vcodec： libx264 强制指定视频编码模式,使用codec编解码\r\n-preset：指定编码的配置。x264提供了一些预设值，而这些预设值可以通过preset指定。这些预设值包括：ultrafast，superfast，veryfast，faster，fast，medium，slow，slower，veryslow和placebo。ultrafast编码速度最快，但压缩率低，生成的文件更大，placebo则正好相反。x264所取的默认值为medium。需要说明的是，preset主要是影响编码的速度，并不会很大的影响编码出来的结果的质量。压缩高清电影时，一般用slow或者slower，当你的机器性能很好时也可以使用veryslow，不过一般并不会带来很大的好处。\r\n-crf：这是最重要的一个选项，用于指定输出视频的质量，取值范围是0-51，默认值为23，数字越小输出视频的质量越高。这个选项会直接影响到输出视频的码率。\r\n-vf ：video filters 设置视频过滤器\r\n-acodec：audio codec，强制指定音频处理模式,使用codec编解码\r\n-ab ：audio bitrate 设置音频码率 64k/128k\r\n-y：覆盖输出文件\r\n## 3.运行脚本 ##\r\nrun.sh脚本代码：\r\n\r\n```\r\n#/bin/sh\r\n$XLEARNING_HOME/bin/xl-submit \\\r\n   --app-type \"ffmpeg\" \\\r\n   --app-name \"ffmpeg_demo\" \\\r\n   --input /tmp/data/ffmpeg#data \\\r\n   --output /tmp/ffmpeg_output#video \\\r\n   --files demo.sh,ffmpeg.py \\\r\n   --launch-cmd \"sh demo.sh\" \\\r\n   --worker-memory 2G \\\r\n   --worker-cores 2 \\\r\n   --queue default \\\r\n```\r\ndemo.sh脚本代码：\r\n用于传递ffmpeg命令参数\r\n```\r\npython ffmpeg.py -i ./data/H00C1T20171120230303C77.sdv -preset fast -crf 20 -ab 128k -y ./video/b.mp4\r\n```\r\nffmpeg.py代码：\r\n\r\n```\r\nimport argparse\r\nimport sys\r\nimport os\r\nimport json\r\nimport subprocess\r\n\r\nsys.path.append(os.getcwd())\r\n\r\nFLAGS = None\r\n\r\ndef test():\r\n    print(\"start test!\")\r\n    input_file = FLAGS.i\r\n    video_codec = FLAGS.vcodec\r\n    pre_set = FLAGS.preset\r\n    crf = FLAGS.crf\r\n    video_filters = FLAGS.vf\r\n    audio_codec = FLAGS.acodec\r\n    audio_bitrate = FLAGS.ab\r\n    output_file = FLAGS.y\r\n    print(\"test finished!\")\r\n\r\nif __name__ == \"__main__\":\r\n  parser = argparse.ArgumentParser()\r\n  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\r\n  # Flags for defining the tf.train.ClusterSpec\r\n  parser.add_argument(\r\n    \"-i\",\r\n    type=str,\r\n    default=\"\",\r\n    help=\"input of video file\"\r\n  )\r\n\r\n  parser.add_argument(\r\n      \"-vcodec\",\r\n      type=str,\r\n      default=\"libx264\",\r\n      help=\"Coercive use of video codec codec\"\r\n  )\r\n\r\n  parser.add_argument(\r\n      \"-preset\",\r\n      type=str,\r\n      default=\"medium\",\r\n      help=\"Coded configuration,included ultrafast,superfast,veryfast,faster,fast,medium,slow,slower,veryslow and placebo\"\r\n  )\r\n\r\n  parser.add_argument(\r\n      \"-crf\",\r\n      type=int,\r\n      default=23,\r\n      help=\"Quality of output video,the range of value is 0-51\"\r\n  )\r\n\r\n  parser.add_argument(\r\n      \"-vf\",\r\n      type=str,\r\n      default=\"scale=1920:-1\",\r\n      help=\"set video filters  \"\r\n  )\r\n\r\n  parser.add_argument(\r\n      \"-acodec\",\r\n      type=str,\r\n      default=\"libmp3lame\",\r\n      help=\"use of audio codec codec\"\r\n  )\r\n\r\n  parser.add_argument(\r\n      \"-ab\",\r\n      type=str,\r\n      default=\"\",\r\n      help=\"Setting the audio bitrate\"\r\n  )\r\n\r\n  parser.add_argument(\r\n      \"-y\",\r\n      type=str,\r\n      default=\"\",\r\n      help=\"Overlay output file\"\r\n  )\r\n\r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  test()\r\n```\r\n## 4. 运行结果 ##\r\n![](/upload/images/20180329//43ca4c71-927a-4be0-a6dc-7287d4cf61ef.png)\r\n![](/upload/images/20180329//9f60ed88-d74a-4a35-9496-bd9a1caa9b8c.png)\r\n![](/upload/images/20180329//1d12c42c-f1fa-4ad4-9f8a-d681372f3af5.png)\r\n...\r\n![](/upload/images/20180329//43d4f65e-7d8f-48a8-aebb-6dce60596ec3.png)\r\n...\r\n![](/upload/images/20180329//ce5823c9-5d79-43e7-865e-45b92c1c2146.png)\r\n', '0', '<p>类似于caffe，tensorflow等深度学习框架的集成，在XLearning中增加了基于Hadoop Yarn上的FFmpeg的调度。</p>\r\n<h2 id=\"h2-1-ffmpeg\"><a name=\"1. 安装ffmpeg\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. 安装ffmpeg</h2><p>install-ffmpeg.sh脚本代码：</p>\r\n<pre><code>#安装EPEL Release，因为安装需要使用其他的repo源，所以需要EPEL支持\r\nyum install -y epel-release \r\n#导入一个Code\r\nsudo rpm --import http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro \r\n#安装nux-dextop源\r\nsudo rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-1.el7.nux.noarch.rpm\r\n#查看repo源是否安装成功\r\nyum repolist \r\n#yum安装ffmpeg\r\nyum install -y ffmpeg\r\n#安装完成后检查ffmpeg 版本\r\nffmpeg -version\r\n</code></pre><p><img src=\"/upload/images/20180329//6c1220d2-49e5-4bb5-8dce-5a4d3c5155fe.png\" alt=\"\"></p>\r\n<h2 id=\"h2-2-ffmpeg-\"><a name=\"2.ffmpeg转压视频命令\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.ffmpeg转压视频命令</h2><pre><code>ffmpeg -i H00C1T20171120230303C77.sdv -vcodec libx264 -preset fast -crf 20 -y -vf &quot;scale=1920:-1&quot; -acodec libmp3lame -ab 128k b.mp4\r\n</code></pre><p>参数简单解释如下:<br>-vcodec： libx264 强制指定视频编码模式,使用codec编解码<br>-preset：指定编码的配置。x264提供了一些预设值，而这些预设值可以通过preset指定。这些预设值包括：ultrafast，superfast，veryfast，faster，fast，medium，slow，slower，veryslow和placebo。ultrafast编码速度最快，但压缩率低，生成的文件更大，placebo则正好相反。x264所取的默认值为medium。需要说明的是，preset主要是影响编码的速度，并不会很大的影响编码出来的结果的质量。压缩高清电影时，一般用slow或者slower，当你的机器性能很好时也可以使用veryslow，不过一般并不会带来很大的好处。<br>-crf：这是最重要的一个选项，用于指定输出视频的质量，取值范围是0-51，默认值为23，数字越小输出视频的质量越高。这个选项会直接影响到输出视频的码率。<br>-vf ：video filters 设置视频过滤器<br>-acodec：audio codec，强制指定音频处理模式,使用codec编解码<br>-ab ：audio bitrate 设置音频码率 64k/128k<br>-y：覆盖输出文件</p>\r\n<h2 id=\"h2-3-\"><a name=\"3.运行脚本\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.运行脚本</h2><p>run.sh脚本代码：</p>\r\n<pre><code>#/bin/sh\r\n$XLEARNING_HOME/bin/xl-submit \\\r\n   --app-type &quot;ffmpeg&quot; \\\r\n   --app-name &quot;ffmpeg_demo&quot; \\\r\n   --input /tmp/data/ffmpeg#data \\\r\n   --output /tmp/ffmpeg_output#video \\\r\n   --files demo.sh,ffmpeg.py \\\r\n   --launch-cmd &quot;sh demo.sh&quot; \\\r\n   --worker-memory 2G \\\r\n   --worker-cores 2 \\\r\n   --queue default \\\r\n</code></pre><p>demo.sh脚本代码：<br>用于传递ffmpeg命令参数</p>\r\n<pre><code>python ffmpeg.py -i ./data/H00C1T20171120230303C77.sdv -preset fast -crf 20 -ab 128k -y ./video/b.mp4\r\n</code></pre><p>ffmpeg.py代码：</p>\r\n<pre><code>import argparse\r\nimport sys\r\nimport os\r\nimport json\r\nimport subprocess\r\n\r\nsys.path.append(os.getcwd())\r\n\r\nFLAGS = None\r\n\r\ndef test():\r\n    print(&quot;start test!&quot;)\r\n    input_file = FLAGS.i\r\n    video_codec = FLAGS.vcodec\r\n    pre_set = FLAGS.preset\r\n    crf = FLAGS.crf\r\n    video_filters = FLAGS.vf\r\n    audio_codec = FLAGS.acodec\r\n    audio_bitrate = FLAGS.ab\r\n    output_file = FLAGS.y\r\n    print(&quot;test finished!&quot;)\r\n\r\nif __name__ == &quot;__main__&quot;:\r\n  parser = argparse.ArgumentParser()\r\n  parser.register(&quot;type&quot;, &quot;bool&quot;, lambda v: v.lower() == &quot;true&quot;)\r\n  # Flags for defining the tf.train.ClusterSpec\r\n  parser.add_argument(\r\n    &quot;-i&quot;,\r\n    type=str,\r\n    default=&quot;&quot;,\r\n    help=&quot;input of video file&quot;\r\n  )\r\n\r\n  parser.add_argument(\r\n      &quot;-vcodec&quot;,\r\n      type=str,\r\n      default=&quot;libx264&quot;,\r\n      help=&quot;Coercive use of video codec codec&quot;\r\n  )\r\n\r\n  parser.add_argument(\r\n      &quot;-preset&quot;,\r\n      type=str,\r\n      default=&quot;medium&quot;,\r\n      help=&quot;Coded configuration,included ultrafast,superfast,veryfast,faster,fast,medium,slow,slower,veryslow and placebo&quot;\r\n  )\r\n\r\n  parser.add_argument(\r\n      &quot;-crf&quot;,\r\n      type=int,\r\n      default=23,\r\n      help=&quot;Quality of output video,the range of value is 0-51&quot;\r\n  )\r\n\r\n  parser.add_argument(\r\n      &quot;-vf&quot;,\r\n      type=str,\r\n      default=&quot;scale=1920:-1&quot;,\r\n      help=&quot;set video filters  &quot;\r\n  )\r\n\r\n  parser.add_argument(\r\n      &quot;-acodec&quot;,\r\n      type=str,\r\n      default=&quot;libmp3lame&quot;,\r\n      help=&quot;use of audio codec codec&quot;\r\n  )\r\n\r\n  parser.add_argument(\r\n      &quot;-ab&quot;,\r\n      type=str,\r\n      default=&quot;&quot;,\r\n      help=&quot;Setting the audio bitrate&quot;\r\n  )\r\n\r\n  parser.add_argument(\r\n      &quot;-y&quot;,\r\n      type=str,\r\n      default=&quot;&quot;,\r\n      help=&quot;Overlay output file&quot;\r\n  )\r\n\r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  test()\r\n</code></pre><h2 id=\"h2-4-\"><a name=\"4. 运行结果\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4. 运行结果</h2><p><img src=\"/upload/images/20180329//43ca4c71-927a-4be0-a6dc-7287d4cf61ef.png\" alt=\"\"><br><img src=\"/upload/images/20180329//9f60ed88-d74a-4a35-9496-bd9a1caa9b8c.png\" alt=\"\"><br><img src=\"/upload/images/20180329//1d12c42c-f1fa-4ad4-9f8a-d681372f3af5.png\" alt=\"\"><br>…<br><img src=\"/upload/images/20180329//43d4f65e-7d8f-48a8-aebb-6dce60596ec3.png\" alt=\"\"><br>…<br><img src=\"/upload/images/20180329//ce5823c9-5d79-43e7-865e-45b92c1c2146.png\" alt=\"\"></p>\r\n');
INSERT INTO `tbl_archive` VALUES ('46', '0', 'mysql CDC', '16', '2018-03-30 16:00:22', '使用Apache NiFi中的CaptureChangeMySQL，EnforceOrder和PutDatabaseRecord处理器使用MySQL事件日志复制数据库', null, '0', '437', '', '', '2018-03-30 16:00:22', '2018-04-11 10:35:54', null, null, '0', '0', '0', '0', '## mysqlCDC\n### 简介\n  使用Apache NiFi中的CaptureChangeMySQL，EnforceOrder和PutDatabaseRecord处理器使用MySQL事件日志复制数据库。\n### 环境要求\n    MySQL 5.7\n	Nifi 1.2或以上版本\n### 基本配置\n在my.cnf加入以下配置开启binary logging\n\n    server_id = 1\n    log_bin = delta\n    binlog_format = row\n    binlog_do_db = source\n\n创建数据库和表\n\n    create database source;\n    create database copy;\n    use source;\n    \n    CREATE TABLE `users` ( \n    `id` mediumint(9) NOT NULL AUTO_INCREMENT PRIMARY KEY, \n    `title` text, \n    `first` text, \n    `last` text, \n    `street` text, \n    `city` text, \n    `state` text, \n    `zip` text, \n    `gender` text, \n    `email` text, \n    `username` text, \n    `password` text, \n    `phone` text, \n    `cell` text, \n    `ssn` text, \n    `date_of_birth` timestamp NULL DEFAULT NULL, \n    `reg_date` timestamp NULL DEFAULT NULL, \n    `large` text, \n    `medium` text, \n    `thumbnail` text, \n    `version` text, \n    `nationality` text) \n    ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf-8;\n    \n为user表插入数据\n\n    INSERT INTO `users` (`id`, `title`, `first`, `last`, `street`, `city`, `state`, `zip`, `gender`, `email`, `username`, `password`, `phone`, `cell`, `ssn`, `date_of_birth`, `reg_date`, `large`, `medium`, `thumbnail`, `version`, `nationality`) \n    VALUES (1, \'miss\', \'marlene\', \'shaw\', \'3450 w belt line rd\', \'abilene\', \'florida\', \'31995\', \'F\', \'marlene.shaw75@example.com\', \'goldenpanda70\', \'naughty\', \'(176)-908-6931\', \'(711)-565-2194\', \'800-71-1872\', \'1991-10-07 00:22:53\', \'2004-01-29 16:19:10\', \'http://api.randomuser.me/portraits/women/67.jpg\', \'http://api.randomuser.me/portraits/med/women/67.jpg\', \'http://api.randomuser.me/portraits/thumb/women/67.jpg\', \'0.6\', \'US\'), \n    (2, \'ms\', \'letitia\', \'jordan\', \'2974 mockingbird hill\', \'irvine\', \'new jersey\', \'64361\', \'F\', \'letitia.jordan64@example.com\', \'lazytiger614\', \'aaaaa1\', \'(860)-602-3314\', \'(724)-685-3472\', \'548-93-7031\', \'1977-11-14 11:58:01\', \'2002-02-09 17:04:59\', \'http://api.randomuser.me/portraits/women/19.jpg\', \'http://api.randomuser.me/portraits/med/women/19.jpg\', \'http://api.randomuser.me/portraits/thumb/women/19.jpg\', \'0.6\', \'US\'), \n    (3, \'mr\', \'todd\', \'graham\', \'5760 spring hill rd\', \'garden grove\', \'north carolina\', \'81790\', \'M\', \'todd.graham39@example.com\', \'purplekoala484\', \'paintball\', \'(230)-874-6532\', \'(186)-529-4912\', \'362-31-5248\', \'2006-07-25 05:48:01\', \'2004-12-05 11:26:34\', \'http://api.randomuser.me/portraits/men/39.jpg\', \'http://api.randomuser.me/portraits/med/men/39.jpg\', \'http://api.randomuser.me/portraits/thumb/men/39.jpg\', \'0.6\', \'US\'), \n    (4, \'mr\', \'seth\', \'martinez\', \'4377 fincher rd\', \'chandler\', \'south carolina\', \'73651\', \'M\', \'seth.martinez82@example.com\', \'bigbutterfly149\', \'navy\', \'(122)-782-5822\', \'(720)-778-8541\', \'200-80-9087\', \'1981-02-28 08:22:49\', \'2009-08-31 12:42:57\', \'http://api.randomuser.me/portraits/men/96.jpg\', \'http://api.randomuser.me/portraits/med/men/96.jpg\', \'http://api.randomuser.me/portraits/thumb/men/96.jpg\', \'0.6\', \'US\'), \n    (5, \'mr\', \'guy\', \'mckinney\', \'4524 hogan st\', \'iowa park\', \'ohio\', \'24140\', \'M\', \'guy.mckinney53@example.com\', \'blueduck623\', \'office\', \'(309)-556-7859\', \'(856)-764-9146\', \'973-37-9077\', \'1983-11-03 22:02:12\', \'2003-10-20 07:23:06\', \'http://api.randomuser.me/portraits/men/24.jpg\', \'http://api.randomuser.me/portraits/med/men/24.jpg\', \'http://api.randomuser.me/portraits/thumb/men/24.jpg\', \'0.6\', \'US\'), \n    (6, \'ms\', \'anna\', \'smith\', \'5047 cackson st\', \'rancho cucamonga\', \'pennsylvania\', \'56486\', \'F\', \'anna.smith74@example.com\', \'goldenfish121\', \'albion\', \'(335)-388-7351\', \'(485)-150-6348\', \'680-20-6440\', \'1977-09-05 16:08:05\', \'2008-07-11 11:09:12\', \'http://api.randomuser.me/portraits/women/89.jpg\', \'http://api.randomuser.me/portraits/med/women/89.jpg\', \'http://api.randomuser.me/portraits/thumb/women/89.jpg\', \'0.6\', \'US\'), \n    (7, \'mr\', \'johnny\', \'johnson\', \'7250 bruce st\', \'gresham\', \'new mexico\', \'83973\', \'M\', \'johnny.johnson73@example.com\', \'crazyduck127\', \'toast\', \'(142)-971-3099\', \'(991)-131-1582\', \'683-26-4133\', \'1988-08-12 14:04:27\', \'2001-04-30 15:32:34\', \'http://api.randomuser.me/portraits/men/78.jpg\', \'http://api.randomuser.me/portraits/med/men/78.jpg\', \'http://api.randomuser.me/portraits/thumb/men/78.jpg\', \'0.6\', \'US\'), \n    (8, \'mrs\', \'robin\', \'white\', \'7882 northaven rd\', \'orlando\', \'connecticut\', \'40452\', \'F\', \'robin.white46@example.com\', \'whitetiger371\', \'elizabeth\', \'(311)-659-3812\', \'(689)-468-6420\', \'960-70-3399\', \'2003-07-05 13:09:41\', \'2014-10-01 02:54:46\', \'http://api.randomuser.me/portraits/women/82.jpg\', \'http://api.randomuser.me/portraits/med/women/82.jpg\', \'http://api.randomuser.me/portraits/thumb/women/82.jpg\', \'0.6\', \'US\'), \n    (9, \'miss\', \'allison\', \'williams\', \'7648 edwards rd\', \'edison\', \'louisiana\', \'52040\', \'F\', \'allison.williams82@example.com\', \'beautifulfish354\', \'sanfran\', \'(328)-592-3520\', \'(550)-172-4018\', \'164-78-8160\', \'1983-04-09 08:00:42\', \'2000-01-01 07:18:54\', \'http://api.randomuser.me/portraits/women/16.jpg\', \'http://api.randomuser.me/portraits/med/women/16.jpg\', \'http://api.randomuser.me/portraits/thumb/women/16.jpg\', \'0.6\', \'US\'), \n    (10, \'mrs\', \'erika\', \'king\', \'1171 depaul dr\', \'addison\', \'wisconsin\', \'50082\', \'F\', \'erika.king55@example.com\', \'goldenbutterfly498\', \'chill\', \'(635)-117-5424\', \'(662)-110-8448\', \'122-71-7145\', \'2003-09-19 07:26:17\', \'2002-12-31 00:08:43\', \'http://api.randomuser.me/portraits/women/52.jpg\', \'http://api.randomuser.me/portraits/med/women/52.jpg\', \'http://api.randomuser.me/portraits/thumb/women/52.jpg\', \'0.6\', \'US\');\n\n\n## 开始CDC流程\n### 流程概述\n以下是CDC流程的简要概述：\n\n    1. CaptureChangeMySQL读取bin日志以生成FlowFiles（JSON）\n    2. FlowFiles根据事件类型进行路由：\n        • 开始/提交事件：由JoltTransformJSON操纵的JSON\n        • DDL事件：添加架构（QUERY）和语句类型（SQL）属性\n        • 删除/插入/更新事件：添加表名，模式（USERS）和语句类型属性，操纵JSON\n    3. EnforceOrder确保所有更改事件按正确顺序处理\n    4. PutDatabaseRecord使用RecordReader从输入流文件输入多条记录。这些记录被转换为SQL语句并作为一个批处理执行。\n### 流程步骤\n#### 1.上传模板\n\n![](/upload/images/20180330//3a64c8e5-f294-4e70-a271-b9d029fd1a31.png)\n#### 2.使用模板\n![](/upload/images/20180330//f3454679-e6c1-495c-bc2f-cdb63a996d82.png)\n![](/upload/images/20180330//ed4fcdda-34be-46e4-96f1-ea3cd129c976.png)\n#### 3.流程配置\n##### a.选择流程中的第一个处理器CaptureChangeMySQL。右键单击并从菜单中选择“配置”。将数据库相关属性修改为刚创建的数据库地址，修改JDBC驱动程序为本机位置，并添加mysql用户密码。\n\n![](/upload/images/20180330//4a0de49c-2923-4cc4-950b-ea77830764a7.png)\n##### b.点击画布空白位子，然后选着配置按钮，进入服务配置管理页面。\n![](/upload/images/20180330//5f00469c-11d2-49fb-b7f3-db2bad3b3048.png)\n![](/upload/images/20180330//09eafd58-fd49-490f-9aa9-adb88d3a0c12.png)\n##### c. 单击“+”按钮并添加DistributedMapCacheServer控制器服务。不需要对默认属性做任何更改。\n![](/upload/images/20180330//442f3f0e-e310-4b10-8394-61a7a460bb40.png)\n##### d. 选择“MySQL CDC Backup”控制器服务并选择编辑按钮（铅笔图标）。修改数据库属性以指向MySQL实例的“复制”数据库。添加JDBC驱动程序的位置和用户密码。\n![](/upload/images/20180330//60b6daed-906a-4297-8de3-02c8c71f3ac2.png)\n\n***修改完成后点击apply进行保存。然后点击闪电标志启动5个服务。（注意：除非引用的控制器服务AvroSchemaRegistry先启用，否则无法启用JsonPathReader。）到目前画布上还有两个LogAttribute还是警告状态，它们仅作调试使用，现在先忽略它们。***\n##### e.启动执行CaptureChangeMySQL处理器，及其他处理器\n![](/upload/images/20180330//d86d1a36-65a1-486a-8fd3-d3c20f3d4643.png)', '0', '<h2 id=\"h2-mysqlcdc\"><a name=\"mysqlCDC\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>mysqlCDC</h2><h3 id=\"h3-u7B80u4ECB\"><a name=\"简介\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>简介</h3><p>  使用Apache NiFi中的CaptureChangeMySQL，EnforceOrder和PutDatabaseRecord处理器使用MySQL事件日志复制数据库。</p>\n<h3 id=\"h3-u73AFu5883u8981u6C42\"><a name=\"环境要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>环境要求</h3><pre><code>MySQL 5.7\nNifi 1.2或以上版本\n</code></pre><h3 id=\"h3-u57FAu672Cu914Du7F6E\"><a name=\"基本配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>基本配置</h3><p>在my.cnf加入以下配置开启binary logging</p>\n<pre><code>server_id = 1\nlog_bin = delta\nbinlog_format = row\nbinlog_do_db = source\n</code></pre><p>创建数据库和表</p>\n<pre><code>create database source;\ncreate database copy;\nuse source;\n\nCREATE TABLE `users` ( \n`id` mediumint(9) NOT NULL AUTO_INCREMENT PRIMARY KEY, \n`title` text, \n`first` text, \n`last` text, \n`street` text, \n`city` text, \n`state` text, \n`zip` text, \n`gender` text, \n`email` text, \n`username` text, \n`password` text, \n`phone` text, \n`cell` text, \n`ssn` text, \n`date_of_birth` timestamp NULL DEFAULT NULL, \n`reg_date` timestamp NULL DEFAULT NULL, \n`large` text, \n`medium` text, \n`thumbnail` text, \n`version` text, \n`nationality` text) \nENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf-8;\n</code></pre><p>为user表插入数据</p>\n<pre><code>INSERT INTO `users` (`id`, `title`, `first`, `last`, `street`, `city`, `state`, `zip`, `gender`, `email`, `username`, `password`, `phone`, `cell`, `ssn`, `date_of_birth`, `reg_date`, `large`, `medium`, `thumbnail`, `version`, `nationality`) \nVALUES (1, &#39;miss&#39;, &#39;marlene&#39;, &#39;shaw&#39;, &#39;3450 w belt line rd&#39;, &#39;abilene&#39;, &#39;florida&#39;, &#39;31995&#39;, &#39;F&#39;, &#39;marlene.shaw75@example.com&#39;, &#39;goldenpanda70&#39;, &#39;naughty&#39;, &#39;(176)-908-6931&#39;, &#39;(711)-565-2194&#39;, &#39;800-71-1872&#39;, &#39;1991-10-07 00:22:53&#39;, &#39;2004-01-29 16:19:10&#39;, &#39;http://api.randomuser.me/portraits/women/67.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/women/67.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/women/67.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(2, &#39;ms&#39;, &#39;letitia&#39;, &#39;jordan&#39;, &#39;2974 mockingbird hill&#39;, &#39;irvine&#39;, &#39;new jersey&#39;, &#39;64361&#39;, &#39;F&#39;, &#39;letitia.jordan64@example.com&#39;, &#39;lazytiger614&#39;, &#39;aaaaa1&#39;, &#39;(860)-602-3314&#39;, &#39;(724)-685-3472&#39;, &#39;548-93-7031&#39;, &#39;1977-11-14 11:58:01&#39;, &#39;2002-02-09 17:04:59&#39;, &#39;http://api.randomuser.me/portraits/women/19.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/women/19.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/women/19.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(3, &#39;mr&#39;, &#39;todd&#39;, &#39;graham&#39;, &#39;5760 spring hill rd&#39;, &#39;garden grove&#39;, &#39;north carolina&#39;, &#39;81790&#39;, &#39;M&#39;, &#39;todd.graham39@example.com&#39;, &#39;purplekoala484&#39;, &#39;paintball&#39;, &#39;(230)-874-6532&#39;, &#39;(186)-529-4912&#39;, &#39;362-31-5248&#39;, &#39;2006-07-25 05:48:01&#39;, &#39;2004-12-05 11:26:34&#39;, &#39;http://api.randomuser.me/portraits/men/39.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/men/39.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/men/39.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(4, &#39;mr&#39;, &#39;seth&#39;, &#39;martinez&#39;, &#39;4377 fincher rd&#39;, &#39;chandler&#39;, &#39;south carolina&#39;, &#39;73651&#39;, &#39;M&#39;, &#39;seth.martinez82@example.com&#39;, &#39;bigbutterfly149&#39;, &#39;navy&#39;, &#39;(122)-782-5822&#39;, &#39;(720)-778-8541&#39;, &#39;200-80-9087&#39;, &#39;1981-02-28 08:22:49&#39;, &#39;2009-08-31 12:42:57&#39;, &#39;http://api.randomuser.me/portraits/men/96.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/men/96.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/men/96.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(5, &#39;mr&#39;, &#39;guy&#39;, &#39;mckinney&#39;, &#39;4524 hogan st&#39;, &#39;iowa park&#39;, &#39;ohio&#39;, &#39;24140&#39;, &#39;M&#39;, &#39;guy.mckinney53@example.com&#39;, &#39;blueduck623&#39;, &#39;office&#39;, &#39;(309)-556-7859&#39;, &#39;(856)-764-9146&#39;, &#39;973-37-9077&#39;, &#39;1983-11-03 22:02:12&#39;, &#39;2003-10-20 07:23:06&#39;, &#39;http://api.randomuser.me/portraits/men/24.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/men/24.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/men/24.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(6, &#39;ms&#39;, &#39;anna&#39;, &#39;smith&#39;, &#39;5047 cackson st&#39;, &#39;rancho cucamonga&#39;, &#39;pennsylvania&#39;, &#39;56486&#39;, &#39;F&#39;, &#39;anna.smith74@example.com&#39;, &#39;goldenfish121&#39;, &#39;albion&#39;, &#39;(335)-388-7351&#39;, &#39;(485)-150-6348&#39;, &#39;680-20-6440&#39;, &#39;1977-09-05 16:08:05&#39;, &#39;2008-07-11 11:09:12&#39;, &#39;http://api.randomuser.me/portraits/women/89.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/women/89.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/women/89.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(7, &#39;mr&#39;, &#39;johnny&#39;, &#39;johnson&#39;, &#39;7250 bruce st&#39;, &#39;gresham&#39;, &#39;new mexico&#39;, &#39;83973&#39;, &#39;M&#39;, &#39;johnny.johnson73@example.com&#39;, &#39;crazyduck127&#39;, &#39;toast&#39;, &#39;(142)-971-3099&#39;, &#39;(991)-131-1582&#39;, &#39;683-26-4133&#39;, &#39;1988-08-12 14:04:27&#39;, &#39;2001-04-30 15:32:34&#39;, &#39;http://api.randomuser.me/portraits/men/78.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/men/78.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/men/78.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(8, &#39;mrs&#39;, &#39;robin&#39;, &#39;white&#39;, &#39;7882 northaven rd&#39;, &#39;orlando&#39;, &#39;connecticut&#39;, &#39;40452&#39;, &#39;F&#39;, &#39;robin.white46@example.com&#39;, &#39;whitetiger371&#39;, &#39;elizabeth&#39;, &#39;(311)-659-3812&#39;, &#39;(689)-468-6420&#39;, &#39;960-70-3399&#39;, &#39;2003-07-05 13:09:41&#39;, &#39;2014-10-01 02:54:46&#39;, &#39;http://api.randomuser.me/portraits/women/82.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/women/82.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/women/82.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(9, &#39;miss&#39;, &#39;allison&#39;, &#39;williams&#39;, &#39;7648 edwards rd&#39;, &#39;edison&#39;, &#39;louisiana&#39;, &#39;52040&#39;, &#39;F&#39;, &#39;allison.williams82@example.com&#39;, &#39;beautifulfish354&#39;, &#39;sanfran&#39;, &#39;(328)-592-3520&#39;, &#39;(550)-172-4018&#39;, &#39;164-78-8160&#39;, &#39;1983-04-09 08:00:42&#39;, &#39;2000-01-01 07:18:54&#39;, &#39;http://api.randomuser.me/portraits/women/16.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/women/16.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/women/16.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;), \n(10, &#39;mrs&#39;, &#39;erika&#39;, &#39;king&#39;, &#39;1171 depaul dr&#39;, &#39;addison&#39;, &#39;wisconsin&#39;, &#39;50082&#39;, &#39;F&#39;, &#39;erika.king55@example.com&#39;, &#39;goldenbutterfly498&#39;, &#39;chill&#39;, &#39;(635)-117-5424&#39;, &#39;(662)-110-8448&#39;, &#39;122-71-7145&#39;, &#39;2003-09-19 07:26:17&#39;, &#39;2002-12-31 00:08:43&#39;, &#39;http://api.randomuser.me/portraits/women/52.jpg&#39;, &#39;http://api.randomuser.me/portraits/med/women/52.jpg&#39;, &#39;http://api.randomuser.me/portraits/thumb/women/52.jpg&#39;, &#39;0.6&#39;, &#39;US&#39;);\n</code></pre><h2 id=\"h2--cdc-\"><a name=\"开始CDC流程\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>开始CDC流程</h2><h3 id=\"h3-u6D41u7A0Bu6982u8FF0\"><a name=\"流程概述\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>流程概述</h3><p>以下是CDC流程的简要概述：</p>\n<pre><code>1. CaptureChangeMySQL读取bin日志以生成FlowFiles（JSON）\n2. FlowFiles根据事件类型进行路由：\n    • 开始/提交事件：由JoltTransformJSON操纵的JSON\n    • DDL事件：添加架构（QUERY）和语句类型（SQL）属性\n    • 删除/插入/更新事件：添加表名，模式（USERS）和语句类型属性，操纵JSON\n3. EnforceOrder确保所有更改事件按正确顺序处理\n4. PutDatabaseRecord使用RecordReader从输入流文件输入多条记录。这些记录被转换为SQL语句并作为一个批处理执行。\n</code></pre><h3 id=\"h3-u6D41u7A0Bu6B65u9AA4\"><a name=\"流程步骤\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>流程步骤</h3><h4 id=\"h4-1-\"><a name=\"1.上传模板\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.上传模板</h4><p><img src=\"/upload/images/20180330//3a64c8e5-f294-4e70-a271-b9d029fd1a31.png\" alt=\"\"></p>\n<h4 id=\"h4-2-\"><a name=\"2.使用模板\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.使用模板</h4><p><img src=\"/upload/images/20180330//f3454679-e6c1-495c-bc2f-cdb63a996d82.png\" alt=\"\"><br><img src=\"/upload/images/20180330//ed4fcdda-34be-46e4-96f1-ea3cd129c976.png\" alt=\"\"></p>\n<h4 id=\"h4-3-\"><a name=\"3.流程配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.流程配置</h4><h5 id=\"h5-a-capturechangemysql-jdbc-mysql-\"><a name=\"a.选择流程中的第一个处理器CaptureChangeMySQL。右键单击并从菜单中选择“配置”。将数据库相关属性修改为刚创建的数据库地址，修改JDBC驱动程序为本机位置，并添加mysql用户密码。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>a.选择流程中的第一个处理器CaptureChangeMySQL。右键单击并从菜单中选择“配置”。将数据库相关属性修改为刚创建的数据库地址，修改JDBC驱动程序为本机位置，并添加mysql用户密码。</h5><p><img src=\"/upload/images/20180330//4a0de49c-2923-4cc4-950b-ea77830764a7.png\" alt=\"\"></p>\n<h5 id=\"h5-b-\"><a name=\"b.点击画布空白位子，然后选着配置按钮，进入服务配置管理页面。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>b.点击画布空白位子，然后选着配置按钮，进入服务配置管理页面。</h5><p><img src=\"/upload/images/20180330//5f00469c-11d2-49fb-b7f3-db2bad3b3048.png\" alt=\"\"><br><img src=\"/upload/images/20180330//09eafd58-fd49-490f-9aa9-adb88d3a0c12.png\" alt=\"\"></p>\n<h5 id=\"h5-c-distributedmapcacheserver-\"><a name=\"c. 单击“+”按钮并添加DistributedMapCacheServer控制器服务。不需要对默认属性做任何更改。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>c. 单击“+”按钮并添加DistributedMapCacheServer控制器服务。不需要对默认属性做任何更改。</h5><p><img src=\"/upload/images/20180330//442f3f0e-e310-4b10-8394-61a7a460bb40.png\" alt=\"\"></p>\n<h5 id=\"h5-d-mysql-cdc-backup-mysql-jdbc-\"><a name=\"d. 选择“MySQL CDC Backup”控制器服务并选择编辑按钮（铅笔图标）。修改数据库属性以指向MySQL实例的“复制”数据库。添加JDBC驱动程序的位置和用户密码。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>d. 选择“MySQL CDC Backup”控制器服务并选择编辑按钮（铅笔图标）。修改数据库属性以指向MySQL实例的“复制”数据库。添加JDBC驱动程序的位置和用户密码。</h5><p><img src=\"/upload/images/20180330//60b6daed-906a-4297-8de3-02c8c71f3ac2.png\" alt=\"\"></p>\n<p><strong><em>修改完成后点击apply进行保存。然后点击闪电标志启动5个服务。（注意：除非引用的控制器服务AvroSchemaRegistry先启用，否则无法启用JsonPathReader。）到目前画布上还有两个LogAttribute还是警告状态，它们仅作调试使用，现在先忽略它们。</em></strong></p>\n<h5 id=\"h5-e-capturechangemysql-\"><a name=\"e.启动执行CaptureChangeMySQL处理器，及其他处理器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>e.启动执行CaptureChangeMySQL处理器，及其他处理器</h5><p><img src=\"/upload/images/20180330//d86d1a36-65a1-486a-8fd3-d3c20f3d4643.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('47', '0', '医疗大数据平台AI，Azkaban，anaconda，Jupyter', '16', '2018-04-03 10:02:13', '医疗大数据平台AI实践，Azkaban调度实践，anaconda+Jupyter + hive、spark科学计算分析实践', null, '0', '200', null, null, '2018-04-03 10:02:13', '2018-04-03 17:02:10', null, null, '0', '0', '0', '0', '## 完成工作：\n1.	Azkaban调研，安装。\n完成了Azkaban对组件的调研开发以及对Azkaban组件在HDP集群下的单节点安装和分布式安装.\n\n2. Azkaban26项功能验证\n完成了Azkaban在集群安装完成之后的功能验证,主要包括(调度按照 任务->批次->作业 层级配置功能,Azkaban组件支持任务、批次、作业依赖功能,组件支持批量配置,增量配置,配置失败重做N次,按照时间点设置调度,不同调度频度配置(日、周、月、季、旬、年)，一个任务存在不同频度调度，但是不影响依赖,忽略节假日调度,任务循环调度,调度状态通知(邮件/短信/微信),调度程序应用(ShellHive/Spark/Sqoop/Kettle/ Datastage/Package/Java/Python),调度参数配置传入(增量调度时间),配置导入导出等功能)\n\n3. Azkaban安装使用文档编写\nAzkaban组件在集群安装配置测试完成之后,完成了包含Azkaban组件的安装使用,配置,使用调度的文档编写.\n\n4. ai功能安装验证\n主要完成了TensorFlow组件对于数据的执行与分析,验证了AI功能对于YARN,hdfs组件的支持实现,支持验证了使用TensorFlow深度学习框架在Yarn上分布式进行训练任务，TensorFlow 支持PS节点 和 多Works节点等模式\n\n5. 教对方人员使用xleaning，添加服务\n教授客户人员使用Xleaning组件,并且演示HDP集群添加XLEarning服务至HDP集群之中.\n\n6. anaconda调研，安装\n完成对anaconda组件的调研开发以及anaconda组件在HDP集群下的安装使用演示\n\n7. anaconda安装，基础使用文档编写\n验证anaconda组件的conda的使用验证,以及anaconda组件里集成的jupyter组件的配置使用.\n\n8. 沙盒环境准备，hdp集群安装\n多次准备HDP的沙盒环境,安装HDP集群,已完成组件的调研,开发,以及测试验证\n\n9. Azkaban与hdp平台环境调度测试\n测试Azkaban组件在HDP集群平台环境下的任务调度测试\n\n10.anaconda + Jupyter Notebook，python、R语言测试demo\n完成在anaconda组件的Jupyter Notebook平台下集成R语言,Python到Jupyter Notebook中,并完成Python,R语言的分布式数据分析,以及存取分布式数据的测试操作\n\n11.anaconda + Jupyter Notebook，python、R不同版本使用测试\n下集成不同版本Python,R语言环境到anaconda组件的Jupyter Notebook下,并进行功能测试.\n\n12.anaconda + Jupyter Notebook，与hive，spark连接测试\n完成在Jupyter Notebook组件下,不同版本的Python(Python2和Python3),R(R语言和spark R)对HDP集群环境hive,spark的链接测试.\n\n13.oozie研究学习\n完成对oozie组件的调研以及基本测试研究学习\n下面附上各个组件的测试用例,里面包括具体的组件功能测试.\n### AI功能测试\n\n测试项目  AI功能对HDFS、YARN的支持实现  用例编号\n用例类型  数据科学分析实现测试  测 试 人\n测试目的  验证AI任务是否可以基于HDFS、YARN实现数据训练和结果搜集。\n前置条件  HADOOP平台安装部署完毕。\n测试步骤	1、安装部署一定的数据训练集在HADOOP服务器上。\n2、打开数据训练功能，使用TensorFlow运行训练程序。\n3、观察TensorFlow任务运行状态。\n4、验证Model结果的准确性。\n预期结果	1、	支持TensorFlow 深度学习框架从HDFS中读取数据并生成数据到 HDFS 目录。\n2、	支持TensorFlow 深度学习框架的HDFS数据训练功能。\n3、	支持使用TensorFlow深度学习框架在Yarn上分布式进行训练任务，TensorFlow 支持PS节点 和 多Works节点等模式；\n4、TensorFlow的Model运行结果正确。\n测试结果	\n评测标准	1、不能支持HDFS，扣除50%。\n2、不能支持YARN，实现AI任务参数结果的正确搜集，扣除50%。\n评测得分	\n小    结	\nAzkaban组件功能测试用例\n测试项目	调度配置测试	用例编号	\n用例类型	调度测试	测 试 人	\n测试目的	1.	调度可按照 任务->批次->作业 层级配置。\n2.	支持任务、批次、作业依赖。\n3.	支持批量配置。\n4.	支持增量配置。\n5.	支持配置失败重做N次。\n6.	支持按照时间点设置调度。\n7.	支持不同调度频度配置(日、周、月、季、旬、年)，一个任务存在不同频度调度，但是不影响依赖。。\n8.	支持忽略节假日调度。\n9.	支持任务循环调度。\n10.	支持调度状态通知(邮件/短信/微信)。\n11.	支持调度程序应用(ShellHive/Spark/Sqoop/Kettle/ Datastage/Package/Java/Python)。\n12.	支持调度参数配置传入(增量调度时间)。\n13.	支持配置导入导出。\n前置条件	安装好调度平台\nHadoop集群平台可用\n测试步骤	1.	新增一个TASK_T1任务，在测试任务下新增批次BAT_1，在批次下新增JOB1和JOB2个作业。\n2.	新增一个TASK_T2任务，在测试任务下新增批次BAT_1，在批次下新增JOB3和JOB42个作业。\n3.	将Job配置覆盖测试点。\n4.	配置TASK_T2依赖TASK_T1和批次依赖。\n5.	将配置文件导出再导入。\n预期结果	支持13个测试点。\n\n测试结果	\n评测标准	按照支持的功能点进行评分\n评测得分	\n小    结	\n测试项目	调度权限测试	用例编号	\n用例类型	调度测试	测 试 人	\n测试目的	支持不同用户不同权限\n1.	管理用户(系统配置test1)\n2.	变更用户(调度配置test2)\n3.	运维用户(调度处理test3)\n4.	监控用户(调度监控test4)\n前置条件	安装好调度平台\nHadoop集群平台可用\n测试步骤	1.	新创建4个测试用户\n2.	管理用户登陆,支持整个平台管理。\n3.	变更用户登陆，支持任务部署。\n4.	运维用户登陆，支持调度操作。\n5.	监控用户登陆，支持调度可视监控。\n预期结果	1.	管理用户具有所有权限。\n2.	变更用户具有任务部署、调度操作、调度可视监控权限。\n3.	运维用户具有调度操作、调度可视监控权限。\n4.	监控用户具有监控调度可视监控。\n测试结果	\n评测标准	按照支持的功能点进行评分\n评测得分	\n小    结	\n测试项目	调度运维测试	用例编号	\n用例类型	调度测试	测 试 人	\n测试目的	测试调度平台的运维如下功能：\n1.	支持任务、批次、作业重做。\n2.	支持依赖忽略。\n3.	支持作业中断。\n4.	支持作业未跑设置成功。\n5.	支持作业挂起。\n6.	支持调度日志实时查看。\n7.	支持调度历史日志查看(支持导出)。\n8.	支持依赖拓扑图。\n前置条件	安装好调度平台\nHadoop集群平台可用\n测试步骤	1.	点击任务、批次、作业重做。\n2.	点击作业忽略依赖。\n3.	点击作业中断。\n4.	点击作业设置成功。\n5.	点击作业挂起。\n6.	点击查看调度日志。\n7.	点击导出调度历史日志查看\n8.	点击查看依赖拓扑图。\n预期结果	支持运维的8个需求点\n测试结果	\n评测标准	按照支持的功能点进行评分\n评测得分	\n小    结	\nAnaconda组件测试用例\n测试项目	Anaconda分析功能验证	用例编号	\n用例类型	数据科学分析实现测试	测 试 人	\n测试目的	验证Anaconda分析工具基于HADOOP平台上的分析功能。\n前置条件	HADOOP平台安装部署完毕。\nAnaconda工具安装运行正常。\n测试步骤	1、运行样例程序，使之通过Anaconda工具运行在HADOOP平台上。\n2、样例程序可以正常完成。\n预期结果	1、样例程序可以通过Anaconda工具运行在HADOOP平台上，且运行正常。\n测试结果	\n评测标准	1、不能调试样例程序运行在Anaconda和HADOOP集成环境中，扣除100%。\n评测得分	\n小    结	\nPython和R语言环境\n测试项目	Python功能验证	用例编号	\n用例类型	数据科学分析实现测试	测 试 人	\n测试目的	验证python基于HADOOP平台上的分析功能。\n前置条件	HADOOP平台安装部署完毕。\npython工具安装运行正常。\n测试步骤	执行脚本：\n# -*- coding: utf-8 -*-\nimport sys\n\ndef test():\n    args = sys.argv\n    if len(args)==1:\n        print(\'Hello, world!\')\n    elif len(args)==2:\n        print(\'Hello, %s!\' % args[1])\n    else:\n        print(\'Too many arguments!\')\n\nif __name__==\'__main__\':\n    test()\n预期结果	1. 不传入参数，结果为 hello,world\n2. 传入一个参数a，结果为hello,a\n3. 传入两个或者两个以上，结果为Too many arguments\n测试结果	\n评测标准	1.能正常执行结果得50分\n2.支持分布式得25分\n3.页面易用美观得25分\n评测得分	\n小    结	\n\n测试项目	R功能验证	用例编号	\n用例类型	数据科学分析实现测试	测 试 人	\n测试目的	验证R基于HADOOP平台去连接hive并查询出hive库表的数据量。\n前置条件	HADOOP平台安装部署完毕。\nAnaconda工具安装运行正常。\n测试步骤	执行下列样例，改变对应的参数\n\nlibrary(\"DBI\")\nlibrary(\"rJava\")\nlibrary(\"RJDBC\")\nhive.class.path = list.files(path=c(\"/opt/cloudera/parcels/CDH/lib/hive/lib\"),pattern=\"jar\", full.names=\nT);\ncp = c(hive.class.path)\n.jinit(classpath=cp,parameters=\"-Djavax.security.auth.useSubjectCredsOnly=false\")\ndrv <- JDBC(\"org.apache.hive.jdbc.HiveDriver\", \"/home/ec2-user/hive-test/hivedriver/HiveJDBC41.jar\",iden\ntifier.quote=\"`\")\nconn <- dbConnect(drv, \"jdbc:hive2://ip-172-31-21-45.ap-southeast-1.compute.internal:10000\")\nshow_databases <- dbGetQuery(conn, \"show databases\")\nshow_databases\ntableCount <- dbGetQuery(conn, \"select count(*) from tpcds_parquet.call_center\")\ntableCount\n预期结果	1、通过平台能正常hive库，并且能查出数据量。\n测试结果	\n评测标准	1.能正常执行结果得50分\n2.支持分布式得25分\n3.页面易用美观得25分\n评测得分	\n小    结	\n\n##不足总结：\n1.	对crh/hdp平台了解不够透彻，需要加深学习各个组件、及整体之间相关性能指标方案等。\n2.	公司可以出针对数据分析与平台互联的案例demo（如：python、R与spark、hive连接），在客户有需要时可直接安装部署执行，增加专业度。\n3.	针对crh各个组件有运行demo，演示验收时可直接运行。减少测试验收时间，增加测试实施效率，同时增加客户兴趣。\n4.	完善的测试项（如HA、权限、可用性），针对常规需求可直接按照文档测试输出。\n\n##成长总结：\n5.	知道了国际原厂是怎么进行工作。\n6.	对待客户有更好的心态。\n7.	对待突发事件的处理能力。\n8.	增加调度、数据处理、ai组件的理解。\n', '0', '<h2 id=\"h2--\"><a name=\"完成工作：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>完成工作：</h2><ol>\n<li><p>Azkaban调研，安装。<br>完成了Azkaban对组件的调研开发以及对Azkaban组件在HDP集群下的单节点安装和分布式安装.</p>\n</li><li><p>Azkaban26项功能验证<br>完成了Azkaban在集群安装完成之后的功能验证,主要包括(调度按照 任务-&gt;批次-&gt;作业 层级配置功能,Azkaban组件支持任务、批次、作业依赖功能,组件支持批量配置,增量配置,配置失败重做N次,按照时间点设置调度,不同调度频度配置(日、周、月、季、旬、年)，一个任务存在不同频度调度，但是不影响依赖,忽略节假日调度,任务循环调度,调度状态通知(邮件/短信/微信),调度程序应用(ShellHive/Spark/Sqoop/Kettle/ Datastage/Package/Java/Python),调度参数配置传入(增量调度时间),配置导入导出等功能)</p>\n</li><li><p>Azkaban安装使用文档编写<br>Azkaban组件在集群安装配置测试完成之后,完成了包含Azkaban组件的安装使用,配置,使用调度的文档编写.</p>\n</li><li><p>ai功能安装验证<br>主要完成了TensorFlow组件对于数据的执行与分析,验证了AI功能对于YARN,hdfs组件的支持实现,支持验证了使用TensorFlow深度学习框架在Yarn上分布式进行训练任务，TensorFlow 支持PS节点 和 多Works节点等模式</p>\n</li><li><p>教对方人员使用xleaning，添加服务<br>教授客户人员使用Xleaning组件,并且演示HDP集群添加XLEarning服务至HDP集群之中.</p>\n</li><li><p>anaconda调研，安装<br>完成对anaconda组件的调研开发以及anaconda组件在HDP集群下的安装使用演示</p>\n</li><li><p>anaconda安装，基础使用文档编写<br>验证anaconda组件的conda的使用验证,以及anaconda组件里集成的jupyter组件的配置使用.</p>\n</li><li><p>沙盒环境准备，hdp集群安装<br>多次准备HDP的沙盒环境,安装HDP集群,已完成组件的调研,开发,以及测试验证</p>\n</li><li><p>Azkaban与hdp平台环境调度测试<br>测试Azkaban组件在HDP集群平台环境下的任务调度测试</p>\n</li></ol>\n<p>10.anaconda + Jupyter Notebook，python、R语言测试demo<br>完成在anaconda组件的Jupyter Notebook平台下集成R语言,Python到Jupyter Notebook中,并完成Python,R语言的分布式数据分析,以及存取分布式数据的测试操作</p>\n<p>11.anaconda + Jupyter Notebook，python、R不同版本使用测试<br>下集成不同版本Python,R语言环境到anaconda组件的Jupyter Notebook下,并进行功能测试.</p>\n<p>12.anaconda + Jupyter Notebook，与hive，spark连接测试<br>完成在Jupyter Notebook组件下,不同版本的Python(Python2和Python3),R(R语言和spark R)对HDP集群环境hive,spark的链接测试.</p>\n<p>13.oozie研究学习<br>完成对oozie组件的调研以及基本测试研究学习<br>下面附上各个组件的测试用例,里面包括具体的组件功能测试.</p>\n<h3 id=\"h3-ai-\"><a name=\"AI功能测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>AI功能测试</h3><p>测试项目  AI功能对HDFS、YARN的支持实现  用例编号<br>用例类型  数据科学分析实现测试  测 试 人<br>测试目的  验证AI任务是否可以基于HDFS、YARN实现数据训练和结果搜集。<br>前置条件  HADOOP平台安装部署完毕。<br>测试步骤    1、安装部署一定的数据训练集在HADOOP服务器上。<br>2、打开数据训练功能，使用TensorFlow运行训练程序。<br>3、观察TensorFlow任务运行状态。<br>4、验证Model结果的准确性。<br>预期结果    1、    支持TensorFlow 深度学习框架从HDFS中读取数据并生成数据到 HDFS 目录。<br>2、    支持TensorFlow 深度学习框架的HDFS数据训练功能。<br>3、    支持使用TensorFlow深度学习框架在Yarn上分布式进行训练任务，TensorFlow 支持PS节点 和 多Works节点等模式；<br>4、TensorFlow的Model运行结果正确。<br>测试结果<br>评测标准    1、不能支持HDFS，扣除50%。<br>2、不能支持YARN，实现AI任务参数结果的正确搜集，扣除50%。<br>评测得分<br>小    结<br>Azkaban组件功能测试用例<br>测试项目    调度配置测试    用例编号<br>用例类型    调度测试    测 试 人<br>测试目的    1.    调度可按照 任务-&gt;批次-&gt;作业 层级配置。</p>\n<ol>\n<li>支持任务、批次、作业依赖。</li><li>支持批量配置。</li><li>支持增量配置。</li><li>支持配置失败重做N次。</li><li>支持按照时间点设置调度。</li><li>支持不同调度频度配置(日、周、月、季、旬、年)，一个任务存在不同频度调度，但是不影响依赖。。</li><li>支持忽略节假日调度。</li><li>支持任务循环调度。</li><li>支持调度状态通知(邮件/短信/微信)。</li><li>支持调度程序应用(ShellHive/Spark/Sqoop/Kettle/ Datastage/Package/Java/Python)。</li><li>支持调度参数配置传入(增量调度时间)。</li><li>支持配置导入导出。<br>前置条件    安装好调度平台<br>Hadoop集群平台可用<br>测试步骤    1.    新增一个TASK_T1任务，在测试任务下新增批次BAT_1，在批次下新增JOB1和JOB2个作业。</li><li>新增一个TASK_T2任务，在测试任务下新增批次BAT_1，在批次下新增JOB3和JOB42个作业。</li><li>将Job配置覆盖测试点。</li><li>配置TASK_T2依赖TASK_T1和批次依赖。</li><li>将配置文件导出再导入。<br>预期结果    支持13个测试点。</li></ol>\n<p>测试结果<br>评测标准    按照支持的功能点进行评分<br>评测得分<br>小    结<br>测试项目    调度权限测试    用例编号<br>用例类型    调度测试    测 试 人<br>测试目的    支持不同用户不同权限</p>\n<ol>\n<li>管理用户(系统配置test1)</li><li>变更用户(调度配置test2)</li><li>运维用户(调度处理test3)</li><li>监控用户(调度监控test4)<br>前置条件    安装好调度平台<br>Hadoop集群平台可用<br>测试步骤    1.    新创建4个测试用户</li><li>管理用户登陆,支持整个平台管理。</li><li>变更用户登陆，支持任务部署。</li><li>运维用户登陆，支持调度操作。</li><li>监控用户登陆，支持调度可视监控。<br>预期结果    1.    管理用户具有所有权限。</li><li>变更用户具有任务部署、调度操作、调度可视监控权限。</li><li>运维用户具有调度操作、调度可视监控权限。</li><li>监控用户具有监控调度可视监控。<br>测试结果<br>评测标准    按照支持的功能点进行评分<br>评测得分<br>小    结<br>测试项目    调度运维测试    用例编号<br>用例类型    调度测试    测 试 人<br>测试目的    测试调度平台的运维如下功能：</li><li>支持任务、批次、作业重做。</li><li>支持依赖忽略。</li><li>支持作业中断。</li><li>支持作业未跑设置成功。</li><li>支持作业挂起。</li><li>支持调度日志实时查看。</li><li>支持调度历史日志查看(支持导出)。</li><li>支持依赖拓扑图。<br>前置条件    安装好调度平台<br>Hadoop集群平台可用<br>测试步骤    1.    点击任务、批次、作业重做。</li><li>点击作业忽略依赖。</li><li>点击作业中断。</li><li>点击作业设置成功。</li><li>点击作业挂起。</li><li>点击查看调度日志。</li><li>点击导出调度历史日志查看</li><li>点击查看依赖拓扑图。<br>预期结果    支持运维的8个需求点<br>测试结果<br>评测标准    按照支持的功能点进行评分<br>评测得分<br>小    结<br>Anaconda组件测试用例<br>测试项目    Anaconda分析功能验证    用例编号<br>用例类型    数据科学分析实现测试    测 试 人<br>测试目的    验证Anaconda分析工具基于HADOOP平台上的分析功能。<br>前置条件    HADOOP平台安装部署完毕。<br>Anaconda工具安装运行正常。<br>测试步骤    1、运行样例程序，使之通过Anaconda工具运行在HADOOP平台上。<br>2、样例程序可以正常完成。<br>预期结果    1、样例程序可以通过Anaconda工具运行在HADOOP平台上，且运行正常。<br>测试结果<br>评测标准    1、不能调试样例程序运行在Anaconda和HADOOP集成环境中，扣除100%。<br>评测得分<br>小    结<br>Python和R语言环境<br>测试项目    Python功能验证    用例编号<br>用例类型    数据科学分析实现测试    测 试 人<br>测试目的    验证python基于HADOOP平台上的分析功能。<br>前置条件    HADOOP平台安装部署完毕。<br>python工具安装运行正常。<br>测试步骤    执行脚本：<h1 id=\"h1--em-coding-utf-8-em-\"><a name=\"-<em>- coding: utf-8 -</em>-\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>-<em>- coding: utf-8 -</em>-</h1>import sys</li></ol>\n<p>def test():<br>    args = sys.argv<br>    if len(args)==1:<br>        print(‘Hello, world!’)<br>    elif len(args)==2:<br>        print(‘Hello, %s!’ % args[1])<br>    else:<br>        print(‘Too many arguments!’)</p>\n<p>if <strong>name</strong>==’<strong>main</strong>‘:<br>    test()<br>预期结果    1. 不传入参数，结果为 hello,world</p>\n<ol>\n<li>传入一个参数a，结果为hello,a</li><li>传入两个或者两个以上，结果为Too many arguments<br>测试结果<br>评测标准    1.能正常执行结果得50分<br>2.支持分布式得25分<br>3.页面易用美观得25分<br>评测得分<br>小    结    </li></ol>\n<p>测试项目    R功能验证    用例编号<br>用例类型    数据科学分析实现测试    测 试 人<br>测试目的    验证R基于HADOOP平台去连接hive并查询出hive库表的数据量。<br>前置条件    HADOOP平台安装部署完毕。<br>Anaconda工具安装运行正常。<br>测试步骤    执行下列样例，改变对应的参数</p>\n<p>library(“DBI”)<br>library(“rJava”)<br>library(“RJDBC”)<br>hive.class.path = list.files(path=c(“/opt/cloudera/parcels/CDH/lib/hive/lib”),pattern=”jar”, full.names=<br>T);<br>cp = c(hive.class.path)<br>.jinit(classpath=cp,parameters=”-Djavax.security.auth.useSubjectCredsOnly=false”)<br>drv &lt;- JDBC(“org.apache.hive.jdbc.HiveDriver”, “/home/ec2-user/hive-test/hivedriver/HiveJDBC41.jar”,iden<br>tifier.quote=”`”)<br>conn &lt;- dbConnect(drv, “jdbc<img src=\"../plugins/emoji-dialog/emoji/hive2.png\" class=\"emoji\" title=\"&#58;hive2&#58;\" alt=\"&#58;hive2&#58;\" />//ip-172-31-21-45.ap-southeast-1.compute.internal:10000”)<br>show_databases &lt;- dbGetQuery(conn, “show databases”)<br>show_databases<br>tableCount &lt;- dbGetQuery(conn, “select count(*) from tpcds_parquet.call_center”)<br>tableCount<br>预期结果    1、通过平台能正常hive库，并且能查出数据量。<br>测试结果<br>评测标准    1.能正常执行结果得50分<br>2.支持分布式得25分<br>3.页面易用美观得25分<br>评测得分<br>小    结    </p>\n<h2 id=\"h2--\"><a name=\"不足总结：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>不足总结：</h2><ol>\n<li>对crh/hdp平台了解不够透彻，需要加深学习各个组件、及整体之间相关性能指标方案等。</li><li>公司可以出针对数据分析与平台互联的案例demo（如：python、R与spark、hive连接），在客户有需要时可直接安装部署执行，增加专业度。</li><li>针对crh各个组件有运行demo，演示验收时可直接运行。减少测试验收时间，增加测试实施效率，同时增加客户兴趣。</li><li>完善的测试项（如HA、权限、可用性），针对常规需求可直接按照文档测试输出。</li></ol>\n<h2 id=\"h2--\"><a name=\"成长总结：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>成长总结：</h2><ol>\n<li>知道了国际原厂是怎么进行工作。</li><li>对待客户有更好的心态。</li><li>对待突发事件的处理能力。</li><li>增加调度、数据处理、ai组件的理解。</li></ol>\n');
INSERT INTO `tbl_archive` VALUES ('50', '0', 'Openstack+redcloud集成CRH5.1', '25', '2018-04-16 14:45:24', 'Openstack+redcloud集成CRH5.1', null, '0', '357', null, null, '2018-04-16 14:45:24', '2018-04-18 16:10:04', null, null, '0', '0', '0', '0', '# Openstack+redcloud集成CRH5.1\n\n##Openstack和RedCloud对接\n###环境要求：\n要有一个Openstack-newton集群（能正常使用）\n安装文档地址http://www.redoop.net/group/topic/36\n要有一个自己制作好的CRH5.1镜像（以便于后面创建CRH集群）\n制作镜像地址http://www.redoop.net/group/topic/40\n### 查看镜像和主机独立存储\n修改镜像存储路径和挂载点，同时权限分配也要正确。\n###验证网络的可用性\n由于连接openstack使用的是admin账户，所以其他账户下创建的网络都要删掉，重新创建自己的网络。\n![](/upload/images/20180416//2a31bf9c-af11-4cc3-b316-04cb69c3b094.png)\n![](/upload/images/20180416//4f9fc23b-9023-4d37-9a78-f29ef4ec2525.png)\n在路由详情的接口里面加入创建的子网\n![](/upload/images/20180416//061955c5-bdb6-4fe1-9b6b-d801a251fb70.png)\n整体的网络拓扑如下所示：\n![](/upload/images/20180416//7acd496b-11c2-4a2b-aea0-c135a0933369.png)\n\n###安全组管理规则\n![](/upload/images/20180416//3c477685-b143-47ea-802f-4441ad395203.png)\n![](/upload/images/20180416//77b0b004-a82e-4294-b514-fcc44e1515b2.png)\n注意开放icmp端口，这样主机就可以ping通，开放tcp的所有端口，强调22和3306端口。\n#上传镜像\n##上传空机器的镜像\n登陆到openstack主页，选择左侧菜单的“镜像”，选择“创建镜像”，如下图所示:\n![](/upload/images/20180416//231ad59c-c47a-4898-a432-727716b37106.png)\n填写相关的参数，选择创建：\n\n等待一段时间，镜像上传完毕，效果如图所示：\n![](/upload/images/20180416//8ee00811-1d6c-4f4a-9d53-8331655ac86f.png)\n\n##上传集群的镜像\n依次添加5个镜像到系统中，过程与上传单个镜像一样\n![](/upload/images/20180416//744a16f5-46ef-4857-91f9-80ac4b75d9e2.png)\n#制作模板\n##申请5台新机器\n![](/upload/images/20180416//5d0e0784-e9ba-4d64-9e08-d76c1deecf09.png)\n点击启动云主机，批量申请5个\n![](/upload/images/20180416//a9df7b1e-091d-40db-9d6e-0fe17cc20d8a.png)\n选择一个密匙对\n![](/upload/images/20180416//36d3c006-c388-47b3-bc6e-72839b0cf86c.png)\n选择一个网络：\n![](/upload/images/20180416//a0d6a6a1-8f83-4ac3-88fc-6516bfd90891.png)\n![](/upload/images/20180416//1bb2cdb7-5967-4d13-8b6c-cbcacfce0930.png)\n## 绑定一个浮动ip\n![](/upload/images/20180416//96f0c3c1-ac56-4b95-8b28-83069e55f891.png)\n## 安装databank\n注：模板1部署databank，并且databank必须部署在namenode上。\n###安装mysql，修改mysql密码为RedHadoop-123\nyum install -y mysql*\n![](/upload/images/20180416//efde5e42-b938-46a2-bc3d-21429a8eecfa.png)\n查看mysql状态\nsystemctl status mysqld\n![](/upload/images/20180416//05322736-dd45-49e4-b335-10492913ba2d.png)\n启动mysql服务\nsystemctl start mysqld\n![](/upload/images/20180416//857757df-4f76-49c3-b47f-0cc265cd69c2.png)\n从mysql的日志文件中找到mysql的root用户的初始密码\nvi /var/log/mysqld.log\n![](/upload/images/20180416//10556d4a-8ea9-47a4-9478-8a4c3602fe48.png)\n使用用户名和密码登录mysql\nmysql -uroot -p\n![](/upload/images/20180416//c66f26ee-42f5-46e3-82cf-2b71c05f3483.png)\n修改root用户的密码：\nset password for root@localhost=password(\"RedHadoop-123\")\n![](/upload/images/20180416//53a02177-caf3-4aee-899b-a88293c0fa67.png)\n修改权限，让连接mysql的工具有权限访问到mysql\nGRANT ALL PRIVILEGES ON *.* TO root@\'%\' IDENTIFIED BY \'RedHadoop-123\';\n![](/upload/images/20180416//0f838f89-ba4b-4bf1-aa23-0fa5e174432a.png)\n###配置java的环境变量。\n安装java环境\nyum install -y java\nyum install -y java-1.8.0-openjdk-devel\n设置java环境变量，在/etc/profile.d/目录下创建java.sh，内容如下：\nvim /etc/profile.d/java.sh\nexport JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.65-3.b17.axs7.ppc64le\nexport JRE_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.65-3.b17.axs7.ppc64le/jre\nexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin\n![](/upload/images/20180416//4d8f37be-c239-4b53-a669-8bb0b2627245.png)\n执行source /etc/profile 命令，让java环境变量生效\n###创建相关目录。\n在opt下创建redcloud和temp目录，在temp目录下创建jars和data两个目录。\n在tmp下创建redcloud目录。\n###安装tomcat，修改tomcat的端口为9999\n![](/upload/images/20180416//e2132a43-f539-4194-b875-fc09c0215ce7.png)\n### 部署databank.war，启动tomcat。\n![](/upload/images/20180416//67f1de2d-626a-4b53-a2fa-d28ad0e4b0a8.png)\n#配置应用\n##云主机的配置\n第一步：配置java环境变量，使用$JAVA_HOME可以看到结果。\n第二步：安装mysql，配置远程可连接（这两步同3.4）不同的是：\n需要在etc/my.cnf文件中追加：[mysqld]  lower_case_table_names=1\n大小写不敏感\n第三步：安装tomcat，修改server.xml，配置端口为80。\n![](/upload/images/20180416//b7952e28-62c7-4381-8ff6-33bc2c662ee1.png)\n修改conf目录下的Catalina.properties，在“tomcat.util.scan.DefaultJarScanner.jarsToSkip=\\”后面追加“,*”\n在tomcat目录的bin下，修改Catalina，文件后面追加如下配置：\n![](/upload/images/20180416//3939b119-030d-4afb-9a2d-95d113390e64.png)\n这样项目启动的时候不会报内存溢出的错误了。\n第四步：导入脚本，修改数据库表的配置，如网络，集群，镜像等。\n连接到数据库，创建数据库itcast，导入脚本itcast.sql，然后对几张表进行手动配置。\n### 修改表信息：tb_apiinfo  \n配置openstack的终端，提供商，区域id，区域名信息\n![](/upload/images/20180416//63f68e01-c0ab-49d0-9f06-2c67e4dbab16.png)\nCredential是openstack的登陆密码，endpoint的端口和后面的v2.0不需要改动，在地址变化时只用修改ip地址。Identity、provider、regionName不需要改变，regionID 可能是RegionOne、regionOne、regionone，具体是哪个，可以通过一个测试文件获取。\n![](/upload/images/20180416//1879101e-c3da-434a-a2e0-da17f4a10844.png)\n### 修改表tb_flavourinfo\n配置机器的cpu硬盘等信息\n![](/upload/images/20180416//8f590766-b017-4e13-bc08-f3dc28258d5a.png)\n与openstack管理中的云主机类型选项的内容一致：\n![](/upload/images/20180416//aba187d8-d755-4333-bed8-b0706bd1aae1.png)\nDisk为硬盘容量，name和类型名称保持一致，ram是内存，resourceID是资源ID，vcpus是核数，rank是等级，从tiny到xlarge依次是1,2,3,4,5\n### 修改表 tb_imageinfo\n配置的主机镜像信息\n![](/upload/images/20180416//22e90c35-e8a6-43b1-b83a-4c81316bc30c.png)\nName为主机镜像名称，resourceID为资源id，minFlavourRand为主机所处的等级，与tb_flavourinfo中的rank对应。\n![](/upload/images/20180416//24d3a271-1f08-4f7a-84d4-db530a63c651.png)\n![](/upload/images/20180416//17d5392e-d0b9-4180-9ec3-29dee2fe4d62.png)\n\n### 修改表 tb_keypairs\n配置键值对\n![](/upload/images/20180416//8da0e04e-ed11-4709-ac58-7c1c2da5742a.png)\n\n![](/upload/images/20180416//90766706-4241-450c-ab96-bb0761088727.png)\n![](/upload/images/20180416//30fc46ff-f061-4079-885e-3b048cb52a03.png)\n\nFingerpring为指纹信息，name为键值对的名称，public_key信息在新版的openstack管理界面中可以查看。其余选项不需要修改。\n### 修改表 tb_networkinfo（配置的是内网的信息）\n配置网络信息\n![](/upload/images/20180416//f68c1992-758b-4887-a7bc-f06c79266af8.png)\n点击public，即可看到子网详细信息\n![](/upload/images/20180416//ca11e903-1fee-4662-ae64-5de34defb435.png)\n![](/upload/images/20180416//451c51ba-a314-459f-afc2-d01dbecceb44.png)\n只要name，networkid，resourceId三项修改，与网络详情中的配置保持一致。注意好对应关系。Networkid是网络的自身id，resourceID是网络所属项目的项目id。subnet一项不用填写。\n### 修改表tb_subnetinfo（配置内网的子网）\n配置子网信息\n![](/upload/images/20180416//7893f2a8-9fa2-442d-815d-223d9f5ae0c8.png)\n![](/upload/images/20180416//2a598688-fecf-42fd-895f-48899919096c.png)\n![](/upload/images/20180416//651feda8-aad0-443d-a804-016bbbaaf851.png)\n\n要配置动态ip段的分配，修改cidr；gateway_ip配置网关信息，name为子网名称，network_id为自身的ID，subnetid为父网的网络id。\n\n### 修改表  tb_snapshotinfo\n这张表里面存储的是5个模板的信息，5个模板的相关信息如下：\n![](/upload/images/20180416//380d1dd2-a049-45d3-8295-6ecc8c77a42b.png)\n关键字段为instanceInfoResourceId，resourceID和originalIP，\n![](/upload/images/20180416//214d562f-bc4b-4ed7-b3c9-d8b6bde4827b.png)\n其中instanceInfoResourceId为instance_uuid，resourceID为镜像自身id，originalIP为在制作模板的时候原来主机的ip，这个字段是为了恢复集群时进行ip替换。\n### 修改表 tb_ clustersnapshot\n这张表是集群、主机、镜像的关联表，核心字段是namenode，是为了在恢复集群时确定那个节点是主节点，数值为tb_snapshotinfo的id字段。\n![](/upload/images/20180416//b9268f21-5509-4602-aa9b-3026fb73483d.png)\n### 修改表 tb_ipwhitelist\nIp地址白名单，这张表是为了某些ip地址在openstack占用，但是不希望被用户所申请而设计。Ip里面的地址是外网地址。\n![](/upload/images/20180416//f616dcf9-f8f9-44b4-98b0-96bd14dff860.png)\n\n### 修改系统配置\n删掉 /root/.ssh/known_hosts\n修改etc/ssh/ssh_config，文件末尾追加StrictHostKeyChecking no和UserKnownHostsFile /dev/null\n第六步：配置主机到集群5台主机ssh无密码登陆。\n#验证redcloud功能\n##申请集群\n####注册用户，登录\n![](/upload/images/20180416//d4dd0e64-6d54-4fbf-a20d-b1e7447c944b.png)\n####登陆账号后：\n![](/upload/images/20180416//bbc455d0-73fd-440a-9d73-54ec3ffd909e.png)\n####创建集群\n![](/upload/images/20180416//f98154a9-4aa0-478b-9f94-80f671fcae36.png)\n####点击创建镜像\n![](/upload/images/20180416//e77c5fa7-e5f7-442e-8969-b3ecbccf5915.png)\n####新注册用户需要创建SSH\n点击创建SSH\n![](/upload/images/20180416//2d24cdf7-f485-4c38-bd7e-de2d20781e57.png)\n点击创建密钥对\n![](/upload/images/20180416//3957c1f0-7cfc-47d2-bae6-3b0517db94db.png)\n在输入框中输入要创建密钥的名字\n![](/upload/images/20180416//70b8beb9-fee0-4666-b83b-180f19f004f0.png)\n点击创建/创建成功\n![](/upload/images/20180416//4d5c89e4-d0a9-48b7-8d5a-e57677ed8907.png)\n####点击左侧栏（镜像），创建云集群\n在SSH栏中选择刚刚创建的SSH\n![](/upload/images/20180416//937d6f77-25d0-4aae-be30-efa92a8da4a4.png)\n####点击创建集群，创建成功（这里只创建两个节点）\n![](/upload/images/20180416//66fd4f16-fe2e-4076-a70c-e48b64bacb5d.png)\n####申请公网IP\n![](/upload/images/20180416//7a6f5b6f-c3e5-45f8-91fd-65ec99b37db3.png)\n![](/upload/images/20180416//f85ccbfe-406d-4b0f-a21a-21e5efe98d84.png)\n申请IP成功页面\n![](/upload/images/20180416//7b86ffd8-100a-4d75-abd7-d622076d1b2a.png)\n\n####绑定集群\n![](/upload/images/20180416//71a37643-24f9-44ef-95cb-364da880eba4.png)\n选择要绑定的云主机并关联\n![](/upload/images/20180416//dcc85fef-d80a-44b0-b1fb-b402bb2f72f2.png)\n####查看集群状态，公网IP申请成功，并记住申请的公网IP（223.223.176.30）\n![](/upload/images/20180416//eeb75079-f8f3-4bf7-9999-b21fc8520339.png)\n####进行VNC登陆启动集群\n![](/upload/images/20180416//a4e82755-aa64-47ae-a0e0-6f9f2dd924bf.png)\nVNC登陆\n![](/upload/images/20180416//8dfcb076-2239-44cd-9984-e3a1bacc1c3c.png)\n启动ambari服务\nambari-server start	           \n![](/upload/images/20180416//42a287c1-ea71-4ddd-afa7-2f743cf1a049.png)\n\n#Aambari页面，操作CRH集群\n##登陆ambari页面：223.223.176.30:8080（http://公网IP:8080）   \n####账号：admin 密码：admin\n![](/upload/images/20180416//978760f3-7760-4b97-ab8c-e17a4abecb50.png)\n####启动服务\n![](/upload/images/20180416//13da6c9a-67bb-49d0-acf2-b31197e48c97.png)\n####启动成功\n![](/upload/images/20180416//85356149-f219-47b8-a8c9-d2913883959b.png)\n![](/upload/images/20180416//555afc63-e678-4893-ace4-7b4aa9ffdae5.png)\n', '0', '<h1 id=\"h1-openstack-redcloud-crh5-1\"><a name=\"Openstack+redcloud集成CRH5.1\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Openstack+redcloud集成CRH5.1</h1><h2 id=\"h2-openstack-redcloud-\"><a name=\"Openstack和RedCloud对接\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Openstack和RedCloud对接</h2><h3 id=\"h3--\"><a name=\"环境要求：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>环境要求：</h3><p>要有一个Openstack-newton集群（能正常使用）<br>安装文档地址<a href=\"http://www.redoop.net/group/topic/36\">http://www.redoop.net/group/topic/36</a><br>要有一个自己制作好的CRH5.1镜像（以便于后面创建CRH集群）<br>制作镜像地址<a href=\"http://www.redoop.net/group/topic/40\">http://www.redoop.net/group/topic/40</a></p>\n<h3 id=\"h3-u67E5u770Bu955Cu50CFu548Cu4E3Bu673Au72ECu7ACBu5B58u50A8\"><a name=\"查看镜像和主机独立存储\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>查看镜像和主机独立存储</h3><p>修改镜像存储路径和挂载点，同时权限分配也要正确。</p>\n<h3 id=\"h3-u9A8Cu8BC1u7F51u7EDCu7684u53EFu7528u6027\"><a name=\"验证网络的可用性\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>验证网络的可用性</h3><p>由于连接openstack使用的是admin账户，所以其他账户下创建的网络都要删掉，重新创建自己的网络。<br><img src=\"/upload/images/20180416//2a31bf9c-af11-4cc3-b316-04cb69c3b094.png\" alt=\"\"><br><img src=\"/upload/images/20180416//4f9fc23b-9023-4d37-9a78-f29ef4ec2525.png\" alt=\"\"><br>在路由详情的接口里面加入创建的子网<br><img src=\"/upload/images/20180416//061955c5-bdb6-4fe1-9b6b-d801a251fb70.png\" alt=\"\"><br>整体的网络拓扑如下所示：<br><img src=\"/upload/images/20180416//7acd496b-11c2-4a2b-aea0-c135a0933369.png\" alt=\"\"></p>\n<h3 id=\"h3-u5B89u5168u7EC4u7BA1u7406u89C4u5219\"><a name=\"安全组管理规则\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安全组管理规则</h3><p><img src=\"/upload/images/20180416//3c477685-b143-47ea-802f-4441ad395203.png\" alt=\"\"><br><img src=\"/upload/images/20180416//77b0b004-a82e-4294-b514-fcc44e1515b2.png\" alt=\"\"><br>注意开放icmp端口，这样主机就可以ping通，开放tcp的所有端口，强调22和3306端口。</p>\n<h1 id=\"h1-u4E0Au4F20u955Cu50CF\"><a name=\"上传镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>上传镜像</h1><h2 id=\"h2-u4E0Au4F20u7A7Au673Au5668u7684u955Cu50CF\"><a name=\"上传空机器的镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>上传空机器的镜像</h2><p>登陆到openstack主页，选择左侧菜单的“镜像”，选择“创建镜像”，如下图所示:<br><img src=\"/upload/images/20180416//231ad59c-c47a-4898-a432-727716b37106.png\" alt=\"\"><br>填写相关的参数，选择创建：</p>\n<p>等待一段时间，镜像上传完毕，效果如图所示：<br><img src=\"/upload/images/20180416//8ee00811-1d6c-4f4a-9d53-8331655ac86f.png\" alt=\"\"></p>\n<h2 id=\"h2-u4E0Au4F20u96C6u7FA4u7684u955Cu50CF\"><a name=\"上传集群的镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>上传集群的镜像</h2><p>依次添加5个镜像到系统中，过程与上传单个镜像一样<br><img src=\"/upload/images/20180416//744a16f5-46ef-4857-91f9-80ac4b75d9e2.png\" alt=\"\"></p>\n<h1 id=\"h1-u5236u4F5Cu6A21u677F\"><a name=\"制作模板\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>制作模板</h1><h2 id=\"h2--5-\"><a name=\"申请5台新机器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>申请5台新机器</h2><p><img src=\"/upload/images/20180416//5d0e0784-e9ba-4d64-9e08-d76c1deecf09.png\" alt=\"\"><br>点击启动云主机，批量申请5个<br><img src=\"/upload/images/20180416//a9df7b1e-091d-40db-9d6e-0fe17cc20d8a.png\" alt=\"\"><br>选择一个密匙对<br><img src=\"/upload/images/20180416//36d3c006-c388-47b3-bc6e-72839b0cf86c.png\" alt=\"\"><br>选择一个网络：<br><img src=\"/upload/images/20180416//a0d6a6a1-8f83-4ac3-88fc-6516bfd90891.png\" alt=\"\"><br><img src=\"/upload/images/20180416//1bb2cdb7-5967-4d13-8b6c-cbcacfce0930.png\" alt=\"\"></p>\n<h2 id=\"h2--ip\"><a name=\"绑定一个浮动ip\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>绑定一个浮动ip</h2><p><img src=\"/upload/images/20180416//96f0c3c1-ac56-4b95-8b28-83069e55f891.png\" alt=\"\"></p>\n<h2 id=\"h2--databank\"><a name=\"安装databank\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装databank</h2><p>注：模板1部署databank，并且databank必须部署在namenode上。</p>\n<h3 id=\"h3--mysql-mysql-redhadoop-123\"><a name=\"安装mysql，修改mysql密码为RedHadoop-123\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装mysql，修改mysql密码为RedHadoop-123</h3><p>yum install -y mysql<em><br><img src=\"/upload/images/20180416//efde5e42-b938-46a2-bc3d-21429a8eecfa.png\" alt=\"\"><br>查看mysql状态<br>systemctl status mysqld<br><img src=\"/upload/images/20180416//05322736-dd45-49e4-b335-10492913ba2d.png\" alt=\"\"><br>启动mysql服务<br>systemctl start mysqld<br><img src=\"/upload/images/20180416//857757df-4f76-49c3-b47f-0cc265cd69c2.png\" alt=\"\"><br>从mysql的日志文件中找到mysql的root用户的初始密码<br>vi /var/log/mysqld.log<br><img src=\"/upload/images/20180416//10556d4a-8ea9-47a4-9478-8a4c3602fe48.png\" alt=\"\"><br>使用用户名和密码登录mysql<br>mysql -uroot -p<br><img src=\"/upload/images/20180416//c66f26ee-42f5-46e3-82cf-2b71c05f3483.png\" alt=\"\"><br>修改root用户的密码：<br>set password for root<a href=\"https://github.com/localhost\" title=\"&#64;localhost\" class=\"at-link\">@localhost</a>=password(“RedHadoop-123”)<br><img src=\"/upload/images/20180416//53a02177-caf3-4aee-899b-a88293c0fa67.png\" alt=\"\"><br>修改权限，让连接mysql的工具有权限访问到mysql<br>GRANT ALL PRIVILEGES ON </em>.* TO root@’%’ IDENTIFIED BY ‘RedHadoop-123’;<br><img src=\"/upload/images/20180416//0f838f89-ba4b-4bf1-aa23-0fa5e174432a.png\" alt=\"\"></p>\n<h3 id=\"h3--java-\"><a name=\"配置java的环境变量。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置java的环境变量。</h3><p>安装java环境<br>yum install -y java<br>yum install -y java-1.8.0-openjdk-devel<br>设置java环境变量，在/etc/profile.d/目录下创建java.sh，内容如下：<br>vim /etc/profile.d/java.sh<br>export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.65-3.b17.axs7.ppc64le<br>export JRE_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.65-3.b17.axs7.ppc64le/jre<br>export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin<br><img src=\"/upload/images/20180416//4d8f37be-c239-4b53-a669-8bb0b2627245.png\" alt=\"\"><br>执行source /etc/profile 命令，让java环境变量生效</p>\n<h3 id=\"h3--\"><a name=\"创建相关目录。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建相关目录。</h3><p>在opt下创建redcloud和temp目录，在temp目录下创建jars和data两个目录。<br>在tmp下创建redcloud目录。</p>\n<h3 id=\"h3--tomcat-tomcat-9999\"><a name=\"安装tomcat，修改tomcat的端口为9999\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装tomcat，修改tomcat的端口为9999</h3><p><img src=\"/upload/images/20180416//e2132a43-f539-4194-b875-fc09c0215ce7.png\" alt=\"\"></p>\n<h3 id=\"h3--databank-war-tomcat-\"><a name=\"部署databank.war，启动tomcat。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>部署databank.war，启动tomcat。</h3><p><img src=\"/upload/images/20180416//67f1de2d-626a-4b53-a2fa-d28ad0e4b0a8.png\" alt=\"\"></p>\n<h1 id=\"h1-u914Du7F6Eu5E94u7528\"><a name=\"配置应用\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置应用</h1><h2 id=\"h2-u4E91u4E3Bu673Au7684u914Du7F6E\"><a name=\"云主机的配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>云主机的配置</h2><p>第一步：配置java环境变量，使用$JAVA_HOME可以看到结果。<br>第二步：安装mysql，配置远程可连接（这两步同3.4）不同的是：<br>需要在etc/my.cnf文件中追加：[mysqld]  lower_case_table_names=1<br>大小写不敏感<br>第三步：安装tomcat，修改server.xml，配置端口为80。<br><img src=\"/upload/images/20180416//b7952e28-62c7-4381-8ff6-33bc2c662ee1.png\" alt=\"\"><br>修改conf目录下的Catalina.properties，在“tomcat.util.scan.DefaultJarScanner.jarsToSkip=\\”后面追加“,*”<br>在tomcat目录的bin下，修改Catalina，文件后面追加如下配置：<br><img src=\"/upload/images/20180416//3939b119-030d-4afb-9a2d-95d113390e64.png\" alt=\"\"><br>这样项目启动的时候不会报内存溢出的错误了。<br>第四步：导入脚本，修改数据库表的配置，如网络，集群，镜像等。<br>连接到数据库，创建数据库itcast，导入脚本itcast.sql，然后对几张表进行手动配置。</p>\n<h3 id=\"h3--tb_apiinfo\"><a name=\"修改表信息：tb_apiinfo\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表信息：tb_apiinfo</h3><p>配置openstack的终端，提供商，区域id，区域名信息<br><img src=\"/upload/images/20180416//63f68e01-c0ab-49d0-9f06-2c67e4dbab16.png\" alt=\"\"><br>Credential是openstack的登陆密码，endpoint的端口和后面的v2.0不需要改动，在地址变化时只用修改ip地址。Identity、provider、regionName不需要改变，regionID 可能是RegionOne、regionOne、regionone，具体是哪个，可以通过一个测试文件获取。<br><img src=\"/upload/images/20180416//1879101e-c3da-434a-a2e0-da17f4a10844.png\" alt=\"\"></p>\n<h3 id=\"h3--tb_flavourinfo\"><a name=\"修改表tb_flavourinfo\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表tb_flavourinfo</h3><p>配置机器的cpu硬盘等信息<br><img src=\"/upload/images/20180416//8f590766-b017-4e13-bc08-f3dc28258d5a.png\" alt=\"\"><br>与openstack管理中的云主机类型选项的内容一致：<br><img src=\"/upload/images/20180416//aba187d8-d755-4333-bed8-b0706bd1aae1.png\" alt=\"\"><br>Disk为硬盘容量，name和类型名称保持一致，ram是内存，resourceID是资源ID，vcpus是核数，rank是等级，从tiny到xlarge依次是1,2,3,4,5</p>\n<h3 id=\"h3--tb_imageinfo\"><a name=\"修改表 tb_imageinfo\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表 tb_imageinfo</h3><p>配置的主机镜像信息<br><img src=\"/upload/images/20180416//22e90c35-e8a6-43b1-b83a-4c81316bc30c.png\" alt=\"\"><br>Name为主机镜像名称，resourceID为资源id，minFlavourRand为主机所处的等级，与tb_flavourinfo中的rank对应。<br><img src=\"/upload/images/20180416//24d3a271-1f08-4f7a-84d4-db530a63c651.png\" alt=\"\"><br><img src=\"/upload/images/20180416//17d5392e-d0b9-4180-9ec3-29dee2fe4d62.png\" alt=\"\"></p>\n<h3 id=\"h3--tb_keypairs\"><a name=\"修改表 tb_keypairs\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表 tb_keypairs</h3><p>配置键值对<br><img src=\"/upload/images/20180416//8da0e04e-ed11-4709-ac58-7c1c2da5742a.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180416//90766706-4241-450c-ab96-bb0761088727.png\" alt=\"\"><br><img src=\"/upload/images/20180416//30fc46ff-f061-4079-885e-3b048cb52a03.png\" alt=\"\"></p>\n<p>Fingerpring为指纹信息，name为键值对的名称，public_key信息在新版的openstack管理界面中可以查看。其余选项不需要修改。</p>\n<h3 id=\"h3--tb_networkinfo-\"><a name=\"修改表 tb_networkinfo（配置的是内网的信息）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表 tb_networkinfo（配置的是内网的信息）</h3><p>配置网络信息<br><img src=\"/upload/images/20180416//f68c1992-758b-4887-a7bc-f06c79266af8.png\" alt=\"\"><br>点击public，即可看到子网详细信息<br><img src=\"/upload/images/20180416//ca11e903-1fee-4662-ae64-5de34defb435.png\" alt=\"\"><br><img src=\"/upload/images/20180416//451c51ba-a314-459f-afc2-d01dbecceb44.png\" alt=\"\"><br>只要name，networkid，resourceId三项修改，与网络详情中的配置保持一致。注意好对应关系。Networkid是网络的自身id，resourceID是网络所属项目的项目id。subnet一项不用填写。</p>\n<h3 id=\"h3--tb_subnetinfo-\"><a name=\"修改表tb_subnetinfo（配置内网的子网）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表tb_subnetinfo（配置内网的子网）</h3><p>配置子网信息<br><img src=\"/upload/images/20180416//7893f2a8-9fa2-442d-815d-223d9f5ae0c8.png\" alt=\"\"><br><img src=\"/upload/images/20180416//2a598688-fecf-42fd-895f-48899919096c.png\" alt=\"\"><br><img src=\"/upload/images/20180416//651feda8-aad0-443d-a804-016bbbaaf851.png\" alt=\"\"></p>\n<p>要配置动态ip段的分配，修改cidr；gateway_ip配置网关信息，name为子网名称，network_id为自身的ID，subnetid为父网的网络id。</p>\n<h3 id=\"h3--tb_snapshotinfo\"><a name=\"修改表  tb_snapshotinfo\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表  tb_snapshotinfo</h3><p>这张表里面存储的是5个模板的信息，5个模板的相关信息如下：<br><img src=\"/upload/images/20180416//380d1dd2-a049-45d3-8295-6ecc8c77a42b.png\" alt=\"\"><br>关键字段为instanceInfoResourceId，resourceID和originalIP，<br><img src=\"/upload/images/20180416//214d562f-bc4b-4ed7-b3c9-d8b6bde4827b.png\" alt=\"\"><br>其中instanceInfoResourceId为instance_uuid，resourceID为镜像自身id，originalIP为在制作模板的时候原来主机的ip，这个字段是为了恢复集群时进行ip替换。</p>\n<h3 id=\"h3--tb_-clustersnapshot\"><a name=\"修改表 tb_ clustersnapshot\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表 tb_ clustersnapshot</h3><p>这张表是集群、主机、镜像的关联表，核心字段是namenode，是为了在恢复集群时确定那个节点是主节点，数值为tb_snapshotinfo的id字段。<br><img src=\"/upload/images/20180416//b9268f21-5509-4602-aa9b-3026fb73483d.png\" alt=\"\"></p>\n<h3 id=\"h3--tb_ipwhitelist\"><a name=\"修改表 tb_ipwhitelist\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改表 tb_ipwhitelist</h3><p>Ip地址白名单，这张表是为了某些ip地址在openstack占用，但是不希望被用户所申请而设计。Ip里面的地址是外网地址。<br><img src=\"/upload/images/20180416//f616dcf9-f8f9-44b4-98b0-96bd14dff860.png\" alt=\"\"></p>\n<h3 id=\"h3-u4FEEu6539u7CFBu7EDFu914Du7F6E\"><a name=\"修改系统配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改系统配置</h3><p>删掉 /root/.ssh/known_hosts<br>修改etc/ssh/ssh_config，文件末尾追加StrictHostKeyChecking no和UserKnownHostsFile /dev/null<br>第六步：配置主机到集群5台主机ssh无密码登陆。</p>\n<h1 id=\"h1--redcloud-\"><a name=\"验证redcloud功能\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>验证redcloud功能</h1><h2 id=\"h2-u7533u8BF7u96C6u7FA4\"><a name=\"申请集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>申请集群</h2><h4 id=\"h4--\"><a name=\"注册用户，登录\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>注册用户，登录</h4><p><img src=\"/upload/images/20180416//d4dd0e64-6d54-4fbf-a20d-b1e7447c944b.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"登陆账号后：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>登陆账号后：</h4><p><img src=\"/upload/images/20180416//bbc455d0-73fd-440a-9d73-54ec3ffd909e.png\" alt=\"\"></p>\n<h4 id=\"h4-u521Bu5EFAu96C6u7FA4\"><a name=\"创建集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建集群</h4><p><img src=\"/upload/images/20180416//f98154a9-4aa0-478b-9f94-80f671fcae36.png\" alt=\"\"></p>\n<h4 id=\"h4-u70B9u51FBu521Bu5EFAu955Cu50CF\"><a name=\"点击创建镜像\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击创建镜像</h4><p><img src=\"/upload/images/20180416//e77c5fa7-e5f7-442e-8969-b3ecbccf5915.png\" alt=\"\"></p>\n<h4 id=\"h4--ssh\"><a name=\"新注册用户需要创建SSH\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>新注册用户需要创建SSH</h4><p>点击创建SSH<br><img src=\"/upload/images/20180416//2d24cdf7-f485-4c38-bd7e-de2d20781e57.png\" alt=\"\"><br>点击创建密钥对<br><img src=\"/upload/images/20180416//3957c1f0-7cfc-47d2-bae6-3b0517db94db.png\" alt=\"\"><br>在输入框中输入要创建密钥的名字<br><img src=\"/upload/images/20180416//70b8beb9-fee0-4666-b83b-180f19f004f0.png\" alt=\"\"><br>点击创建/创建成功<br><img src=\"/upload/images/20180416//4d5c89e4-d0a9-48b7-8d5a-e57677ed8907.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"点击左侧栏（镜像），创建云集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击左侧栏（镜像），创建云集群</h4><p>在SSH栏中选择刚刚创建的SSH<br><img src=\"/upload/images/20180416//937d6f77-25d0-4aae-be30-efa92a8da4a4.png\" alt=\"\"></p>\n<h4 id=\"h4--\"><a name=\"点击创建集群，创建成功（这里只创建两个节点）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>点击创建集群，创建成功（这里只创建两个节点）</h4><p><img src=\"/upload/images/20180416//66fd4f16-fe2e-4076-a70c-e48b64bacb5d.png\" alt=\"\"></p>\n<h4 id=\"h4--ip\"><a name=\"申请公网IP\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>申请公网IP</h4><p><img src=\"/upload/images/20180416//7a6f5b6f-c3e5-45f8-91fd-65ec99b37db3.png\" alt=\"\"><br><img src=\"/upload/images/20180416//f85ccbfe-406d-4b0f-a21a-21e5efe98d84.png\" alt=\"\"><br>申请IP成功页面<br><img src=\"/upload/images/20180416//7b86ffd8-100a-4d75-abd7-d622076d1b2a.png\" alt=\"\"></p>\n<h4 id=\"h4-u7ED1u5B9Au96C6u7FA4\"><a name=\"绑定集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>绑定集群</h4><p><img src=\"/upload/images/20180416//71a37643-24f9-44ef-95cb-364da880eba4.png\" alt=\"\"><br>选择要绑定的云主机并关联<br><img src=\"/upload/images/20180416//dcc85fef-d80a-44b0-b1fb-b402bb2f72f2.png\" alt=\"\"></p>\n<h4 id=\"h4--ip-ip-223-223-176-30-\"><a name=\"查看集群状态，公网IP申请成功，并记住申请的公网IP（223.223.176.30）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>查看集群状态，公网IP申请成功，并记住申请的公网IP（223.223.176.30）</h4><p><img src=\"/upload/images/20180416//eeb75079-f8f3-4bf7-9999-b21fc8520339.png\" alt=\"\"></p>\n<h4 id=\"h4--vnc-\"><a name=\"进行VNC登陆启动集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>进行VNC登陆启动集群</h4><p><img src=\"/upload/images/20180416//a4e82755-aa64-47ae-a0e0-6f9f2dd924bf.png\" alt=\"\"><br>VNC登陆<br><img src=\"/upload/images/20180416//8dfcb076-2239-44cd-9984-e3a1bacc1c3c.png\" alt=\"\"><br>启动ambari服务<br>ambari-server start<br><img src=\"/upload/images/20180416//42a287c1-ea71-4ddd-afa7-2f743cf1a049.png\" alt=\"\"></p>\n<h1 id=\"h1-aambari-crh-\"><a name=\"Aambari页面，操作CRH集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Aambari页面，操作CRH集群</h1><h2 id=\"h2--ambari-223-223-176-30-8080-http-ip-8080-\"><a name=\"登陆ambari页面：223.223.176.30:8080（  http://公网IP:8080）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>登陆ambari页面：223.223.176.30:8080（<a href=\"http://公网IP:8080）\">http://公网IP:8080）</a></h2><h4 id=\"h4--admin-admin\"><a name=\"账号：admin 密码：admin\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>账号：admin 密码：admin</h4><p><img src=\"/upload/images/20180416//978760f3-7760-4b97-ab8c-e17a4abecb50.png\" alt=\"\"></p>\n<h4 id=\"h4-u542Fu52A8u670Du52A1\"><a name=\"启动服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>启动服务</h4><p><img src=\"/upload/images/20180416//13da6c9a-67bb-49d0-acf2-b31197e48c97.png\" alt=\"\"></p>\n<h4 id=\"h4-u542Fu52A8u6210u529F\"><a name=\"启动成功\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>启动成功</h4><p><img src=\"/upload/images/20180416//85356149-f219-47b8-a8c9-d2913883959b.png\" alt=\"\"><br><img src=\"/upload/images/20180416//555afc63-e678-4893-ace4-7b4aa9ffdae5.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('51', '0', 'Centos7上安装ftp服务', '25', '2018-04-24 11:33:46', 'Centos7上安装ftp服务', null, '0', '234', null, null, '2018-04-24 11:33:46', null, null, null, '0', '0', '0', '0', '# 安装Vsftpd服务端\r\n```\r\n[root@localhost ~]#systemctl stop firewalld  \r\n[root@localhost ~]# setenforce 0\r\n[root@localhost ~]# yum -y  install vsftpd\r\n[root@localhost ~]# cd /etc/vsftpd/\r\n[root@localhost vsftpd]# mv vsftpd.conf vsftpd.conf.bak\r\n[root@localhost vsftpd]# grep -v -E \"^#|^$\" vsftpd.conf.bak  > vsftpd.conf\r\n\r\n[root@localhost vsftpd]# chown ftp /var/ftp/pub/\r\n[root@localhost vsftpd]# ls -ld /var/ftp/pub/\r\ndrwxr-xr-x 2 ftp root 4096 Aug  4  2014 /var/ftp/pub/\r\n\r\n[root@localhost vsftpd]# vim vsftpd.conf\r\nanonymous_enable=YES                  设置是否允许匿名用户登录FTP服务器。默认为YES\r\nanon_umask=022                          \r\nanon_upload_enable=YES                是否允许匿名用户上传文件。只有在write_enable设置为YES时，该配置项才有效。而且匿名用户对相应的目录必须有写权限。默认为NO。\r\nanon_mkdir_write_enable=YES           是否允许匿名用户创建目录。只有在write_enable设置为    YES时有效。且匿名用户对上层目录有写入的权限。默认为NO。\r\nanon_other_write_enable=NO            若设置为YES，则匿名用户会被允许拥有多于\r\nanon_world_readable_only=YES          匿名用户是否允许下载可阅读的文档，默认为YES。\r\nno_anon_password=YES                  匿名用户登录时是否询问口令。设置为YES，则不询问。默 \r\nlocal_enable=YES                      是否允许本地用户登录FTP服务器。默认为NO\r\nwrite_enable=YES                      是否对登录用户开启写权限。属全局性设置。默认NO\r\nlocal_umask=022                       设置本地用户新增文档的umask，默认为022，对应的权限为755。\r\ndirmessage_enable=YES                 设置是否显示目录消息。若设置为YES，则当用户进入特定目录（比如/var/ftp/linux）时，将显示该目录中的由message_file配置项指定的文件（.message）中的内容\r\nxferlog_enable=YES                    是否启用上传/下载日志记录。默认为NO\r\nconnect_from_port_20=YES              默认值为YES，指定FTP数据传输连接使用20端口。若设置为NO，则进行数据连接时，所使用的端口由ftp_data_port指定\r\nxferlog_std_format=YES                日志文件是否使用标准的xferlog日志文件格式（与wu-ftpd使用的格式相同） 。默认为NO\r\nlisten=YES                            是否监听端口\r\npam_service_name=vsftpd               设置在PAM所使用的名称，默认值为vsftpd。\r\nuserlist_enable=YES                   决定/etc/vsftpd/user_list文件是否启用生效。YES则生效，NO不生效。\r\ntcp_wrappers=YES                      \r\n\r\n[root@localhost vsftpd]# systemctl restart  vsftpd\r\n[root@localhost vsftpd]# lsof -i :21\r\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\r\nvsftpd  1390 root    3u  IPv4  18333      0t0  TCP *:ftp (LISTEN)\r\n```\r\n安装完成后可以在windows上面访问 ftp://ip（如下图）\r\n![](/upload/images/20180424//462cfc82-1dcd-45d6-88a4-503319967d4c.png)\r\n\r\n## 安装客户端ftp   \r\n ```\r\n[root@localhost ~]# yum -y install ftp\r\nConnected to 192.168.200.101 (192.168.200.101).\r\n220 (vsFTPd 2.2.2)\r\nName (192.168.200.101:root): ftp\r\n331 Please specify the password.\r\nPassword:\r\n230 Login successful.\r\nRemote system type is UNIX.\r\nUsing binary mode to transfer files.\r\nftp> ls\r\n227 Entering Passive Mode (192,168,200,101,162,145).\r\n150 Here comes the directory listing.\r\ndrwxr-xr-x    3 14       0            4096 Mar 25 01:12 pub\r\n226 Directory send OK.\r\nftp> cd pub\r\n250 Directory successfully changed.\r\nftp> ls\r\n227 Entering Passive Mode (192,168,200,101,135,230).\r\n150 Here comes the directory listing.\r\ndrwxr-xr-x    2 14       50           4096 Mar 25 01:11 123\r\n226 Directory send OK.\r\nftp> quit\r\n221 Goodbye.\r\n=================================================================\r\nget 下载\r\nput 上传\r\n=================================================================   \r\n[root@localhost ~]# useradd u1\r\n[root@localhost ~]# useradd u2\r\n[root@localhost ~]# useradd u3\r\n[root@localhost ~]# echo \"123\" | passwd --stdin u1\r\nChanging password for user u1.\r\npasswd: all authentication tokens updated successfully.\r\n[root@localhost ~]# echo \"123\" | passwd --stdin u2\r\nChanging password for user u2.\r\npasswd: all authentication tokens updated successfully.\r\n[root@localhost ~]# echo \"123\" | passwd --stdin u3\r\nChanging password for user u3.\r\npasswd: all authentication tokens updated successfully.\r\n\r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\nlocal_enable=YES\r\nwrite_enable=YES\r\nlocal_umask=077\r\nchroot_local_user=YES\r\n\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]\r\n \r\n客户端所有用户登录测试。 \r\n   \r\n[root@localhost ~]# vim /etc/vsftpd/ftpusers \r\nu3   \r\n客户端u3用户登录测试。    \r\n   \r\n   \r\n[root@localhost ~]# tail -2 /etc/vsftpd/user_list\r\nu1\r\nu2\r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\nuserlist_enable=YES\r\nuserlist_deny=NO\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]   \r\n   \r\n**************\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\nuserlist_enable=YES\r\nuserlist_deny=YES\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]    \r\n   \r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf   \r\nlisten=YES\r\nlisten_address=192.168.200.101\r\nlisten_port=21\r\n\r\npasv_enable=YES\r\npasv_min_port=25000\r\npasv_max_port=26000\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]  \r\n\r\n\r\n\r\n\r\n\r\n\r\n==============================================================\r\n[root@localhost ~]# cd /etc/vsftpd/\r\n[root@localhost vsftpd]# vim vusers.txt \r\nmike\r\n123\r\njohn\r\n456\r\n\r\n[root@localhost vsftpd]# rpm -q db4-utils\r\ndb4-utils-4.7.25-18.el6_4.x86_64\r\n[root@localhost vsftpd]# \r\n[root@localhost vsftpd]# db_load -T -t hash -f vusers.txt vu.db\r\n[root@localhost vsftpd]# chmod 600 vusers.txt vu.db\r\n[root@localhost vsftpd]# ls -l vusers.txt vu.db\r\n-rw------- 1 root root 12288 Mar 25 11:26 vu.db\r\n-rw------- 1 root root    18 Mar 25 11:25 vusers.txt\r\n\r\n[root@localhost vsftpd]# useradd -d /var/ftproot -s /sbin/nologin virtual\r\n[root@localhost vsftpd]# chmod 755 /var/ftproot\r\n\r\n[root@localhost vsftpd]# vim /etc/pam.d/vsftpd.vu\r\n#%PAM-1.0\r\nauth       required     pam_userdb.so db=/etc/vsftpd/vu\r\naccount    required     pam_userdb.so db=/etc/vsftpd/vu\r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\nguest_enable=YES\r\nguest_username=virtual\r\npam_service_name=vsftpd.vu\r\nuser_config_dir=/etc/vsftpd/vusers_dir\r\n\r\nanonymous_enable=NO\r\n\r\n[root@localhost vsftpd]# mkdir /etc/vsftpd/vusers_dir\r\n[root@localhost vsftpd]# touch /etc/vsftpd/vusers_dir/mike\r\n[root@localhost vsftpd]# vim /etc/vsftpd/vusers_dir/john \r\nanon_upload_enable=YES\r\nanon_mkdir_write_enable=YES\r\n\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]  \r\n\r\n注意：在主配置文件中删除如下3行：\r\nanon_upload_enable=YES\r\nanon_mkdir_write_enable=YES\r\nanon_other_write_enable=YES\r\n\r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\ndirmessage_enable=YES\r\n\r\n[root@localhost vsftpd]# echo \"---------hello,user---------\" > /var/ftproot/.message\r\n\r\nC:\\Users\\Crushlinux>ftp 192.168.200.101\r\n连接到 192.168.200.101。\r\n220 (vsFTPd 2.2.2)\r\n用户(192.168.200.101:(none)): mike\r\n331 Please specify the password.\r\n密码:\r\n230----------hello,user---------\r\n230 Login successful.\r\n```', '0', '<h1 id=\"h1--vsftpd-\"><a name=\"安装Vsftpd服务端\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装Vsftpd服务端</h1><pre><code>[root@localhost ~]#systemctl stop firewalld  \r\n[root@localhost ~]# setenforce 0\r\n[root@localhost ~]# yum -y  install vsftpd\r\n[root@localhost ~]# cd /etc/vsftpd/\r\n[root@localhost vsftpd]# mv vsftpd.conf vsftpd.conf.bak\r\n[root@localhost vsftpd]# grep -v -E &quot;^#|^$&quot; vsftpd.conf.bak  &gt; vsftpd.conf\r\n\r\n[root@localhost vsftpd]# chown ftp /var/ftp/pub/\r\n[root@localhost vsftpd]# ls -ld /var/ftp/pub/\r\ndrwxr-xr-x 2 ftp root 4096 Aug  4  2014 /var/ftp/pub/\r\n\r\n[root@localhost vsftpd]# vim vsftpd.conf\r\nanonymous_enable=YES                  设置是否允许匿名用户登录FTP服务器。默认为YES\r\nanon_umask=022                          \r\nanon_upload_enable=YES                是否允许匿名用户上传文件。只有在write_enable设置为YES时，该配置项才有效。而且匿名用户对相应的目录必须有写权限。默认为NO。\r\nanon_mkdir_write_enable=YES           是否允许匿名用户创建目录。只有在write_enable设置为    YES时有效。且匿名用户对上层目录有写入的权限。默认为NO。\r\nanon_other_write_enable=NO            若设置为YES，则匿名用户会被允许拥有多于\r\nanon_world_readable_only=YES          匿名用户是否允许下载可阅读的文档，默认为YES。\r\nno_anon_password=YES                  匿名用户登录时是否询问口令。设置为YES，则不询问。默 \r\nlocal_enable=YES                      是否允许本地用户登录FTP服务器。默认为NO\r\nwrite_enable=YES                      是否对登录用户开启写权限。属全局性设置。默认NO\r\nlocal_umask=022                       设置本地用户新增文档的umask，默认为022，对应的权限为755。\r\ndirmessage_enable=YES                 设置是否显示目录消息。若设置为YES，则当用户进入特定目录（比如/var/ftp/linux）时，将显示该目录中的由message_file配置项指定的文件（.message）中的内容\r\nxferlog_enable=YES                    是否启用上传/下载日志记录。默认为NO\r\nconnect_from_port_20=YES              默认值为YES，指定FTP数据传输连接使用20端口。若设置为NO，则进行数据连接时，所使用的端口由ftp_data_port指定\r\nxferlog_std_format=YES                日志文件是否使用标准的xferlog日志文件格式（与wu-ftpd使用的格式相同） 。默认为NO\r\nlisten=YES                            是否监听端口\r\npam_service_name=vsftpd               设置在PAM所使用的名称，默认值为vsftpd。\r\nuserlist_enable=YES                   决定/etc/vsftpd/user_list文件是否启用生效。YES则生效，NO不生效。\r\ntcp_wrappers=YES                      \r\n\r\n[root@localhost vsftpd]# systemctl restart  vsftpd\r\n[root@localhost vsftpd]# lsof -i :21\r\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\r\nvsftpd  1390 root    3u  IPv4  18333      0t0  TCP *:ftp (LISTEN)\r\n</code></pre><p>安装完成后可以在windows上面访问 ftp://ip（如下图）<br><img src=\"/upload/images/20180424//462cfc82-1dcd-45d6-88a4-503319967d4c.png\" alt=\"\"></p>\r\n<h2 id=\"h2--ftp\"><a name=\"安装客户端ftp\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装客户端ftp</h2><pre><code>[root@localhost ~]# yum -y install ftp\r\nConnected to 192.168.200.101 (192.168.200.101).\r\n220 (vsFTPd 2.2.2)\r\nName (192.168.200.101:root): ftp\r\n331 Please specify the password.\r\nPassword:\r\n230 Login successful.\r\nRemote system type is UNIX.\r\nUsing binary mode to transfer files.\r\nftp&gt; ls\r\n227 Entering Passive Mode (192,168,200,101,162,145).\r\n150 Here comes the directory listing.\r\ndrwxr-xr-x    3 14       0            4096 Mar 25 01:12 pub\r\n226 Directory send OK.\r\nftp&gt; cd pub\r\n250 Directory successfully changed.\r\nftp&gt; ls\r\n227 Entering Passive Mode (192,168,200,101,135,230).\r\n150 Here comes the directory listing.\r\ndrwxr-xr-x    2 14       50           4096 Mar 25 01:11 123\r\n226 Directory send OK.\r\nftp&gt; quit\r\n221 Goodbye.\r\n=================================================================\r\nget 下载\r\nput 上传\r\n=================================================================   \r\n[root@localhost ~]# useradd u1\r\n[root@localhost ~]# useradd u2\r\n[root@localhost ~]# useradd u3\r\n[root@localhost ~]# echo &quot;123&quot; | passwd --stdin u1\r\nChanging password for user u1.\r\npasswd: all authentication tokens updated successfully.\r\n[root@localhost ~]# echo &quot;123&quot; | passwd --stdin u2\r\nChanging password for user u2.\r\npasswd: all authentication tokens updated successfully.\r\n[root@localhost ~]# echo &quot;123&quot; | passwd --stdin u3\r\nChanging password for user u3.\r\npasswd: all authentication tokens updated successfully.\r\n\r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\nlocal_enable=YES\r\nwrite_enable=YES\r\nlocal_umask=077\r\nchroot_local_user=YES\r\n\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]\r\n\r\n客户端所有用户登录测试。 \r\n\r\n[root@localhost ~]# vim /etc/vsftpd/ftpusers \r\nu3   \r\n客户端u3用户登录测试。    \r\n\r\n\r\n[root@localhost ~]# tail -2 /etc/vsftpd/user_list\r\nu1\r\nu2\r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\nuserlist_enable=YES\r\nuserlist_deny=NO\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]   \r\n\r\n**************\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\nuserlist_enable=YES\r\nuserlist_deny=YES\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]    \r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf   \r\nlisten=YES\r\nlisten_address=192.168.200.101\r\nlisten_port=21\r\n\r\npasv_enable=YES\r\npasv_min_port=25000\r\npasv_max_port=26000\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]  \r\n\r\n\r\n\r\n\r\n\r\n\r\n==============================================================\r\n[root@localhost ~]# cd /etc/vsftpd/\r\n[root@localhost vsftpd]# vim vusers.txt \r\nmike\r\n123\r\njohn\r\n456\r\n\r\n[root@localhost vsftpd]# rpm -q db4-utils\r\ndb4-utils-4.7.25-18.el6_4.x86_64\r\n[root@localhost vsftpd]# \r\n[root@localhost vsftpd]# db_load -T -t hash -f vusers.txt vu.db\r\n[root@localhost vsftpd]# chmod 600 vusers.txt vu.db\r\n[root@localhost vsftpd]# ls -l vusers.txt vu.db\r\n-rw------- 1 root root 12288 Mar 25 11:26 vu.db\r\n-rw------- 1 root root    18 Mar 25 11:25 vusers.txt\r\n\r\n[root@localhost vsftpd]# useradd -d /var/ftproot -s /sbin/nologin virtual\r\n[root@localhost vsftpd]# chmod 755 /var/ftproot\r\n\r\n[root@localhost vsftpd]# vim /etc/pam.d/vsftpd.vu\r\n#%PAM-1.0\r\nauth       required     pam_userdb.so db=/etc/vsftpd/vu\r\naccount    required     pam_userdb.so db=/etc/vsftpd/vu\r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\nguest_enable=YES\r\nguest_username=virtual\r\npam_service_name=vsftpd.vu\r\nuser_config_dir=/etc/vsftpd/vusers_dir\r\n\r\nanonymous_enable=NO\r\n\r\n[root@localhost vsftpd]# mkdir /etc/vsftpd/vusers_dir\r\n[root@localhost vsftpd]# touch /etc/vsftpd/vusers_dir/mike\r\n[root@localhost vsftpd]# vim /etc/vsftpd/vusers_dir/john \r\nanon_upload_enable=YES\r\nanon_mkdir_write_enable=YES\r\n\r\n[root@localhost ~]# service vsftpd restart\r\nShutting down vsftpd:                                      [  OK  ]\r\nStarting vsftpd for vsftpd:                                [  OK  ]  \r\n\r\n注意：在主配置文件中删除如下3行：\r\nanon_upload_enable=YES\r\nanon_mkdir_write_enable=YES\r\nanon_other_write_enable=YES\r\n\r\n\r\n[root@localhost ~]# vim /etc/vsftpd/vsftpd.conf\r\ndirmessage_enable=YES\r\n\r\n[root@localhost vsftpd]# echo &quot;---------hello,user---------&quot; &gt; /var/ftproot/.message\r\n\r\nC:\\Users\\Crushlinux&gt;ftp 192.168.200.101\r\n连接到 192.168.200.101。\r\n220 (vsFTPd 2.2.2)\r\n用户(192.168.200.101:(none)): mike\r\n331 Please specify the password.\r\n密码:\r\n230----------hello,user---------\r\n230 Login successful.\r\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('52', '0', 'CRH6.0.1 Hadoop3 for Power 说明及安装简述', '13', '2018-04-24 13:16:00', '##说明CRH6.0.1是CRH6的先行版，专为Hadoop3和Power而制作，此版本仅供预览和体验，不提供任何技术支持，切勿将其应用到生产环境中，否则后果自负。CRH6的第一个版本CRH6.1将在近期发布，敬请期待。##操作系统CRH6.0.1适用于RHEL7(Centos7)ppc64le操作系统，请准备好相应的系统环境。##安装CRH6.0.1####安装ambari并setup-请参照R', null, '0', '313', null, null, '2018-04-24 13:16:00', null, null, null, '0', '0', '0', '0', '## 说明\nCRH6.0.1是CRH6的先行版，专为Hadoop3和Power而制作，此版本仅供预览和体验，不提供任何技术支持，切勿将其应用到生产环境中，否则后果自负。\nCRH6的第一个版本CRH6.1将在近期发布，敬请期待。\n\n## 操作系统\nCRH6.0.1适用于RHEL7(Centos7) ppc64le 操作系统，请准备好相应的系统环境。\n\n## 安装CRH6.0.1\n#### 安装ambari并setup\n- 请参照Redoop官网文档进行ambari安装环境准备\n- 安装ambari-server并setup\n\n#### 安装Hadoop3\n- 安装CRH6.0.1\n\n```\nyum install ambari-mpacks_6_0_1_3_0_925-crh-hadoop3\n```\n- 进入ambari web界面\n- 在选择版本界面进行版本选择，选择CRH-6.0.1\n- 系统类型选择 redhat-ppc7，添加源的URL地址\n- 继续按照ambari安装文档进行安装\n', '0', '<h2 id=\"h2-u8BF4u660E\"><a name=\"说明\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>说明</h2><p>CRH6.0.1是CRH6的先行版，专为Hadoop3和Power而制作，此版本仅供预览和体验，不提供任何技术支持，切勿将其应用到生产环境中，否则后果自负。<br>CRH6的第一个版本CRH6.1将在近期发布，敬请期待。</p>\n<h2 id=\"h2-u64CDu4F5Cu7CFBu7EDF\"><a name=\"操作系统\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>操作系统</h2><p>CRH6.0.1适用于RHEL7(Centos7) ppc64le 操作系统，请准备好相应的系统环境。</p>\n<h2 id=\"h2--crh6-0-1\"><a name=\"安装CRH6.0.1\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装CRH6.0.1</h2><h4 id=\"h4--ambari-setup\"><a name=\"安装ambari并setup\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装ambari并setup</h4><ul>\n<li>请参照Redoop官网文档进行ambari安装环境准备</li><li>安装ambari-server并setup</li></ul>\n<h4 id=\"h4--hadoop3\"><a name=\"安装Hadoop3\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装Hadoop3</h4><ul>\n<li>安装CRH6.0.1</li></ul>\n<pre><code>yum install ambari-mpacks_6_0_1_3_0_925-crh-hadoop3\n</code></pre><ul>\n<li>进入ambari web界面</li><li>在选择版本界面进行版本选择，选择CRH-6.0.1</li><li>系统类型选择 redhat-ppc7，添加源的URL地址</li><li>继续按照ambari安装文档进行安装</li></ul>\n');
INSERT INTO `tbl_archive` VALUES ('53', '0', 'CRF平台进行Superset连接mysql视图展现', '25', '2018-04-25 13:56:03', 'CRF平台进行Superse连接mysql视图展现', null, '0', '478', null, null, '2018-04-25 13:56:03', '2018-06-01 09:37:55', null, null, '0', '0', '0', '0', '# CRF平台进行Superset连接mysql视图展现\n系统版本：CentOS7.2\n## 登录Superset客户端\n>IP地址:9088(端口根据业务需求进行更改)\n用户名和密码填写创建组件时的用户和密码\n![](/upload/images/20180425//b3acce89-c8c0-46aa-8f58-0058f0cdbec8.png)\n\n> 登录之后，进入主页面\n![](/upload/images/20180425//6cccf8e6-007f-4bc4-9c7c-ec103bfd2a01.png)\n\n> 选择source，进行创建数据库连接\n![](/upload/images/20180425//cbfcf50f-9490-4289-8501-34af5c690908.png)\n![](/upload/images/20180425//a4915514-6a6b-4365-b920-c4f75ca67bd9.png)\n\n> 点击右上角＋号创建新的连接\n\n![](/upload/images/20180425//2531ffad-8933-4c6f-b65d-05291b15a5a0.png)\n![](/upload/images/20180425//2750281c-084a-42cc-a128-8bf2eb67cdbb.png)\n> Database：输入数据库名称（postgres）\n> SQLAlchemy URI：连接地址(mysql://用户名:密码@localhost:3306/test)\n> 输入之后点击test connection进行连接测试\n![](/upload/images/20180425//4315c5b2-cf5c-40da-b8f1-ab8fec70d964.png)\n\n> 成功后，提示Seems OK \n![](/upload/images/20180425//8d2a9788-9f6b-4729-a7fb-836b3c0acf28.png)\n\n> 测试成功之后下方会出现你要查询数据库的所有信息表\n![](/upload/images/20180425//7b92fdb1-b4f9-4889-bb75-a48e675b2b77.png)\n\n> 点击保存，返回页面\n![](/upload/images/20180425//ac18a8a1-21c2-4aef-bf5d-1cc94fca47c0.png)\n\n##  数据展现\n> 点击sources下的Tables，创建查询表\n![](/upload/images/20180425//980e12fe-d2fe-4cdd-985d-786ea7160a65.png)\n![](/upload/images/20180425//1131ef64-901e-4c9f-971e-5be2e86d4381.png)\n\n> 在database下拉选择框中选择刚刚连接的数据库\n![](/upload/images/20180425//1f05a9a3-38f6-4b2a-8878-124136ca7d58.png)\n\n> Schema默认就行\nTable Name 填写连接库的其中一张表的名称\n![](/upload/images/20180425//073d0f50-3987-4969-b0c7-92c5809b1a44.png)\n\n> 保存\n![](/upload/images/20180425//7f42943f-40e7-4640-9d6f-de2e09448a05.png)\n\n> 点击ceshi，进入视图展现页面\n![](/upload/images/20180425//ace7c1be-2fdb-43d0-82b2-392006688a1a.png)\n> 左侧栏为设置属性。右侧则是展现效果图示界面\n> TableView：选择要展示的图示类型\n> Time：时间选择\n> Query：查询展示字段\n> Chart Options：图表选项\n> SQL:查询条件 where语句\n![](/upload/images/20180425//00330164-e426-4d66-9431-c052a1463510.png)\n\n\n\n> 配置要展示的信息设置\n![](/upload/images/20180425//21ba813c-e4c2-4775-ae8f-b84e67518716.png)\n\n> 点击RunQuery进行图示展示（这里用的是饼状图）\n![](/upload/images/20180425//76228fee-9fc0-4392-988a-6389436559b2.png)\n\n> 柱形图\n![](/upload/images/20180425//a1cd0029-732a-43ea-b8e8-9382b7769ae7.png)\n\n> 折线图\n![](/upload/images/20180425//181af77c-d30f-42bd-86d9-a0e39a1c509f.png)', '0', '<h1 id=\"h1-crf-superset-mysql-\"><a name=\"CRF平台进行Superset连接mysql视图展现\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>CRF平台进行Superset连接mysql视图展现</h1><p>系统版本：CentOS7.2</p>\n<h2 id=\"h2--superset-\"><a name=\"登录Superset客户端\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>登录Superset客户端</h2><blockquote>\n<p>IP地址:9088(端口根据业务需求进行更改)<br>用户名和密码填写创建组件时的用户和密码<br><img src=\"/upload/images/20180425//b3acce89-c8c0-46aa-8f58-0058f0cdbec8.png\" alt=\"\"></p>\n<p>登录之后，进入主页面<br><img src=\"/upload/images/20180425//6cccf8e6-007f-4bc4-9c7c-ec103bfd2a01.png\" alt=\"\"></p>\n<p>选择source，进行创建数据库连接<br><img src=\"/upload/images/20180425//cbfcf50f-9490-4289-8501-34af5c690908.png\" alt=\"\"><br><img src=\"/upload/images/20180425//a4915514-6a6b-4365-b920-c4f75ca67bd9.png\" alt=\"\"></p>\n<p>点击右上角＋号创建新的连接</p>\n</blockquote>\n<p><img src=\"/upload/images/20180425//2531ffad-8933-4c6f-b65d-05291b15a5a0.png\" alt=\"\"><br><img src=\"/upload/images/20180425//2750281c-084a-42cc-a128-8bf2eb67cdbb.png\" alt=\"\"></p>\n<blockquote>\n<p>Database：输入数据库名称（postgres）<br>SQLAlchemy URI：连接地址(mysql://用户名:密码<a href=\"https://github.com/localhost\" title=\"&#64;localhost\" class=\"at-link\">@localhost</a>:3306/test)<br>输入之后点击test connection进行连接测试<br><img src=\"/upload/images/20180425//4315c5b2-cf5c-40da-b8f1-ab8fec70d964.png\" alt=\"\"></p>\n<p>成功后，提示Seems OK<br><img src=\"/upload/images/20180425//8d2a9788-9f6b-4729-a7fb-836b3c0acf28.png\" alt=\"\"></p>\n<p>测试成功之后下方会出现你要查询数据库的所有信息表<br><img src=\"/upload/images/20180425//7b92fdb1-b4f9-4889-bb75-a48e675b2b77.png\" alt=\"\"></p>\n<p>点击保存，返回页面<br><img src=\"/upload/images/20180425//ac18a8a1-21c2-4aef-bf5d-1cc94fca47c0.png\" alt=\"\"></p>\n</blockquote>\n<h2 id=\"h2-u6570u636Eu5C55u73B0\"><a name=\"数据展现\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>数据展现</h2><blockquote>\n<p>点击sources下的Tables，创建查询表<br><img src=\"/upload/images/20180425//980e12fe-d2fe-4cdd-985d-786ea7160a65.png\" alt=\"\"><br><img src=\"/upload/images/20180425//1131ef64-901e-4c9f-971e-5be2e86d4381.png\" alt=\"\"></p>\n<p>在database下拉选择框中选择刚刚连接的数据库<br><img src=\"/upload/images/20180425//1f05a9a3-38f6-4b2a-8878-124136ca7d58.png\" alt=\"\"></p>\n<p>Schema默认就行<br>Table Name 填写连接库的其中一张表的名称<br><img src=\"/upload/images/20180425//073d0f50-3987-4969-b0c7-92c5809b1a44.png\" alt=\"\"></p>\n<p>保存<br><img src=\"/upload/images/20180425//7f42943f-40e7-4640-9d6f-de2e09448a05.png\" alt=\"\"></p>\n<p>点击ceshi，进入视图展现页面<br><img src=\"/upload/images/20180425//ace7c1be-2fdb-43d0-82b2-392006688a1a.png\" alt=\"\"><br>左侧栏为设置属性。右侧则是展现效果图示界面<br>TableView：选择要展示的图示类型<br>Time：时间选择<br>Query：查询展示字段<br>Chart Options：图表选项<br>SQL:查询条件 where语句<br><img src=\"/upload/images/20180425//00330164-e426-4d66-9431-c052a1463510.png\" alt=\"\"></p>\n<p>配置要展示的信息设置<br><img src=\"/upload/images/20180425//21ba813c-e4c2-4775-ae8f-b84e67518716.png\" alt=\"\"></p>\n<p>点击RunQuery进行图示展示（这里用的是饼状图）<br><img src=\"/upload/images/20180425//76228fee-9fc0-4392-988a-6389436559b2.png\" alt=\"\"></p>\n<p>柱形图<br><img src=\"/upload/images/20180425//a1cd0029-732a-43ea-b8e8-9382b7769ae7.png\" alt=\"\"></p>\n<p>折线图<br><img src=\"/upload/images/20180425//181af77c-d30f-42bd-86d9-a0e39a1c509f.png\" alt=\"\"></p>\n</blockquote>\n');
INSERT INTO `tbl_archive` VALUES ('56', '1', 'CRF3.0部署手册', '25', '2018-04-27 15:50:29', 'CRF是一款数据流接入，展现，可以能够为大家快速接入数据，快速数据分析，以及展现。', null, '0', '215', null, null, '2018-04-27 15:50:29', '2018-04-28 10:48:13', null, null, '0', '0', '0', '0', '# CRF3.0部署手册\n\n\n\n\n\n\n# 安装环境推荐\n\n## 1.1 硬件环境要求\n|   推荐 |小规模硬件推荐：4-10个节点 |  中等规模硬件配置推荐：20+个节点 | 大规模硬件配置推荐：100节点以上 | \n| --------  | :----:  |  :----: |  :----:  \n| 处理器cpu    | 2路 8核心XeonE5处理器(3.8GHz)| 2路 10核心XeonE5处理器(3.8GHz)   |  2路 10核心 XeonE7处理器(3.8GHz)\n| 内存        |   64G或者以上内存，DDR3L，RRECC   |   128G或者以上内存，DDR3L,RRECC  | 128G或者以上内存，DDR3L,RRECC\n| 系统盘        |    2*500G SSD  |  2*500G SSD  |2*500G SSD\n|  磁盘接口   |   SAS 6GB/s  |  SAS 6GB/s  |SAS 6GB/s\n|     磁盘    |     12个2T或者6T 7200RPM SATA硬盘  |  12个4T或者6T 7200RPM  |12个6T  7200RPM SATA\n|硬盘     |  SATA硬盘  | SATA硬盘 |SATA硬盘\n| Raid卡  |   1G缓存支持RAIDO,1,5  |  1G缓存支持RAIDO,1,5  |1G缓存支持RAIDO,1,5\n| 网络       |   10Gb以太网和千兆以太网    |  10Gb以太网和千兆以太网  |10Gb以太网和千兆以太网\n|电源     |   1+1冗余电源   |  1+1冗余电源  |1+1冗余电源\n\n\n## 1.2 操作系统要求\n\n|   系统版本 |  CentOS release 7 \n| --------  | :----:  |  :----: |  :----:  \n|内核版本   |    3.10.0-327.13.1.el7.x86_64\n## 1.3 Java环境要求\n如果您的集群的机器上还没有安装JDK，请自主下载安装JDK 1.8（Oracle版本）。\n\n```\n[root@crf1 jvm]# java  -version \njava version \"1.8.0_144\"\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n```\n## 1.4 支持的浏览器\n   | 浏览器                   |    版本\n | --------         |  :----:  |  :----: |   :----:  \n| Internet Explorer |          8.0 以上\n| Chrome|   23.0 以上\n\n\n\n# 安装基础环境准备\n### 2.1 修改主机名\n>主机名即计算机的名字（计算机名），主机名有时称为域名。主机名映射到 IP 地址，但是主机名和 IP 地址之间没有一对一关系。对于用户来说，主机名比数字 IP 地址更方便。所以会选择其主机名，用户能很容易地记住这些主机名。\n\n本次测试建立于三台服务器的基础上演示\n\n192.168.0.245  crf1\n\n192.168.0.246   crf2\n\n192.168.0.247   crf3\n\n修改每台主机的主机名\n```\n\n[root@crf1 ~]# vi /etc/hostname\ncrf1\n\n[root@crf2 ~]# vi /etc/hostname\ncrf2\n\n[root@crf3 ~]# vi /etc/hostname\ncrf3\n```\n## 2.2 主机与IP映射\n> hosts文件是Linux系统中一个负责IP地址与域名快速解析的文件，一般会保存在“/etc”目录下，文件名为“hosts”（不同的linux版本，这个配置文件也可能不同）。hosts文件是一个用于存储计算机网络中节点信息的文件，它可以将主机名映射到相应的IP地址，在没有域名服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的IP地址，否则就需要使用DNS服务程序来解决。通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。\n\n三台服务器均配置hosts文件\n```\ncrf1\n[root@crf1 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n-----------------------------------------------------------------------------\ncrf3\n[root@crf3 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n```\n## 2.3 安全设置\n\n### 2.3.1 关闭SElinux\n```\ncrf1\n[root@crf1 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf2\n[root@crf2 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf3\n[root@crf3 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n```\n### 2.3.2 关闭防火墙\n> 防火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。\n\n```\ncrf1\n[root@crf1 ~]# systemctl stop firewalld\n\ncrf2\n[root@nx-2 ~]# systemctl stop firewalld\n\ncrf3\n[root@nx-3 ~]# systemctl stop firewalld\n```\n## 2.4 免密码登录\n> 为了方便用户使用，一般会设置免密码登录，当Linux设置免密码登录后，节点跳转时SSH不会询问密码。\n\n### 2.4.1 生成私钥和公钥\n```\ncrf1\n[root@crf1 ~]# ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n01:f7:8d:da:63:cc:cc:26:6a:ee:82:6c:1e:bd:21:5c root@crf1\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|      . .        |\n|       o . o     |\n|        . o .    |\n|         O       |\n|    E   S X      |\n| . o   . + .     |\n| .+.o o          |\n|  +o.=           |\n| o. .oo          |\n+-----------------+\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n4d:16:c2:15:99:31:f6:87:57:83:12:52:ff:e9:2c:92 root@crf2\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|       ..oOB. ...|\n|        .o+=.o ..|\n|          o +.o  |\n|         +   o. .|\n|        S .    o |\n|            . o  |\n|           E . o |\n|            . .  |\n|                 |\n+-----------------+\n---------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd5:fb:e3:fe:11:a9:6c:0a:69:15:46:e1:79:5d:e7:2c root@crf3\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|           o.   o|\n|          o.. .oo|\n|          .=..E.o|\n|         .. o. ..|\n|        S  ..  o |\n|          o ... .|\n|         +   +o. |\n|        . . o. ..|\n|           . .o..|\n+-----------------+\n```\n### 2.4.2 将公钥复制到远程主机\n在服务器中的每一台服务器建立服务器之间的ssh免密码登陆。在系统询问Are you sure you want to continue connecting (yes/no)?时输入yes并按回车，在系统询问root@crf1\'s password:时输入密码（注意：密码输入时，密码不显示）。\n```\ncrf1\n[root@crf1 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf1 ~]# ssh-copy-id crf2\nThe authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf1 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf2\n2The authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n-------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf3 ~]# ssh-copy-id crf2\nThe authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf3 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n```\n### 2.5 配置源\nrepo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用！\n```\n[root@crf1 ~]# cd /etc/yum.repos.d\n\n[root@crf1 yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/ambari/ambari.repo\n\n[root@crf1 yum.repos.d]# cat ambari.repo \n[redoop-crf3.0]\nName=Redoop’s Distribution for crf, Version 3.0.0\nBaseurl= http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/ambari\ngpgcheck=0\nenabaled=1\n\n[root@crf1 yum.repos.d]# yum clean all\n\nLoaded plugins: fastestmirror\nLoaded plugins: fastestmirror\nCleaning repos: ambari-2.5.1.0 base extras updates\nCleaning up everything\nCleaning up list of fastest mirrors\n```\n#  安装ambari和mysql\nAmbari的Server程序，主要管理部署在每个节点上的管理监控程序\n## 3.1 安装ambari-server\n```\ncrf1\n[root@crf1 ~]# yum install -y ambari-server\n\nLoaded plugins: fastestmirror\nambari-2.5.1.0                                                       | 2.9 kB  00:00:00\nbase                                                                 | 3.6 kB  00:00:00\nextras                                                               | 3.4 kB  00:00:00\nupdates                                                              | 3.4 kB  00:00:00\n(1/5): ambari-2.5.1.0/primary_db                                     | 8.7 kB  00:00:00\n(2/5): base/7/x86_64/group_gz                                        | 156 kB  00:00:00\n(3/5): extras/7/x86_64/primary_db                                    | 166 kB  00:00:00\n(4/5): base/7/x86_64/primary_db                                      | 5.7 MB  00:00:07\n(5/5): updates/7/x86_64/primary_db                                   | 6.0 MB  00:00:23\nDetermining fastest mirrors\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies........\nInstalled:\n  ambari-server.x86_64 0:2.5.1.0-159\nDependency Installed:\n  postgresql.x86_64 0:9.2.23-3.el7_4            postgresql-libs.x86_64 0:9.2.23-3.el7_4\n  postgresql-server.x86_64 0:9.2.23-3.el7_4\nComplete!   \n```\n## 3.2 安装mysql将ambari关联mysql数据库\n```\n[root@crf1 ~]# yum install mysql-connector-java* -y\n\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies\n--> Running transaction check\n    ..................................\n\nDependency Updated:\n  chkconfig.x86_64 0:1.7.4-1.el7                  nspr.x86_64 0:4.13.1-1.0.el7_3\n  nss.x86_64 0:3.28.4-15.el7_4                    nss-softokn.x86_64 0:3.28.3-8.el7_4\n  nss-softokn-freebl.x86_64 0:3.28.3-8.el7_4      nss-sysinit.x86_64 0:3.28.4-15.el7_4\n  nss-tools.x86_64 0:3.28.4-15.el7_4              nss-util.x86_64 0:3.28.4-3.el7\n\nComplete!\n\n[root@crf1~]#sudo ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n\n[root@crf1~]# cd /etc/yum.repos.d/\n[root@crf1~yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/utils/mysql/mysql_57.repo\n\n[root@crf1 yum.repos.d]# ls                    \nambari.repo            CentOS-Media.repo\nCentOS-Base.repo       CentOS-Sources.repo\nCentOS-CR.repo         CentOS-Vault.repo\nCentOS-Debuginfo.repo  mysql_57.repo\nCentOS-fasttrack.repo\n \n [root@crf1yum.repos.d]# yum clean all\nLoaded plugins: fastestmirror\nCleaning repos: base extras mysql-5.7\n              : redoop-crf3.0 updates\nCleaning up everything\nCleaning up list of fastest mirrors\n\n\n[root@crf1 yum.repos.d]# yum install mysql-community-server –y\n\nWarning: RPMDB altered outside of yum.\n  Installing : mysql-community-common-5.7.21-1.el7.x86_64                               1/7\n      ..............................\n\nInstalled:\n  mysql-community-libs.x86_64 0:5.7.21-1.el7\n  mysql-community-libs-compat.x86_64 0:5.7.21-1.el7\n  mysql-community-server.x86_64 0:5.7.21-1.el7\nDependency Installed:\n  \n  mysql-community-client.x86_64 0:5.7.21-1.el7 mysql-community-common.x86_64 0:5.7.21-1.el7\n  net-tools.x86_64 0:2.0-0.22.20131004git.el7\n\nReplaced:\n  mariadb-libs.x86_64 1:5.5.44-2.el7.centos\n\nComplete!\n```\n## 3.3启动mysql\n```\n[root@crf1 ~]# systemctl  start   mysqld.service\n[root@crf1 ~]# systemctl  enable   mysqld.service\n```\n## 3.4给mysql用户更改密码和配置mysql\n```\n[root@crf1 yum.repos.d]# grep \'A temporary password is generated for root@localhost\' /var/log/mysqld.log |tail -1\n\n2018-02-02T06:01:02.850616Z 1 [Note] A temporary password is generated for root@localhost: `Jl-l.%hNl4Po`  //红色部分为初始密码\n\n[root@crf1 ~]# # mysqladmin -u root -p password \"Redoop123$%^\"\nEnter password: Jl-l.%hNl4Po  // 红色为新更改密码\n\n[root@crf1 yum.repos.d]# mysql -u root -p\nEnter password: Redoop123$%^\n\nelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 14\nServer version: 5.7.21\n\nmysql> create database registry;\n\nmysql> create database streamline;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE USER \'registry\'@\'%\' IDENTIFIED BY \'R12$%34qw\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE USER \'streamline\'@\'%\' IDENTIFIED BY \'R12$%34qw\';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> GRANT ALL PRIVILEGES ON registry.* TO \'registry\'@\'%\' WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON streamline.* TO \'streamline\'@\'%\' WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> commit;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE DATABASE druid DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE DATABASE superset DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE USER \'druid\'@\'%\' IDENTIFIED BY \'9oNio)ex1ndL\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE USER \'superset\'@\'%\' IDENTIFIED BY \'9oNio)ex1ndL\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON *.* TO \'druid\'@\'%\' WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON *.* TO \'superset\'@\'%\' WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> commit;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> exit;\nBye\n```\n## 3.5安装CRF版mpack\n```\n[root@crf1~]#cd /opt/\n\n[root@crf1 opt~]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/mpack/crf-ambari-mpack-3.0.0.0-512.tar.gz\n\n--2018-02-0214:22:37-- http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/mpack/crf-ambari-mpack-3.0.0.tar.gz\nConnecting to 192.168.0.220:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 56231837 (54M) [application/x-gzip]\nSaving to: ‘CRF-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz’\n100%[==================================================>] 56,231,837   118MB/s   in 0.5s\n2018-02-02 14:22:37 (118 MB/s) - ‘CRF-ambari-mpack-3.0.0.tar.gz’ saved [56231837/56231837]\n\n[root@crf1 opt]# ls\ncrf-ambari-mpack-3.0.0.tar.gz\n\n[root@crf1opt]#ambari-server install-mpack --mpack=/opt/CRF-ambari-mpack-3.0.0.tar.gz --purge --verbose\n\nUsing python  /usr/bin/python\nInstalling management pack\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Installing management pack /opt/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Download management pack to temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Expand management pack at temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512/\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nLooking for available JDKs at /usr/jdk64\nFound: []\nCAUTION: You have specified the --purge option with --purge-list=[\'stack-definitions\', \'mpacks\']. This will replace all existing stack definitions, management packs currently installed.\nAre you absolutely sure you want to perform the purge [yes/no]? (no)\"yes\"\n . ......\nINFO: Management pack crf-ambari-mpack-0.1.0.0.3.0.0-512 successfully installed! Please restart ambari-server.\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nAmbari Server \'install-mpack\' completed successfully.\n```\n## 3.6 初始化ambari\n下载JDK\n\n待安装完成后，便需要对 Ambari Server 做一个简单的配置。执行下面的命令。\n```\n[root@crf1 opt]# cd /var/lib/ambari-server/resources/\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jce_policy-8.zip\n\nSaving to: ‘jce_policy-8.zip’\n100%[==================================================>] 8,409       --.-K/s   in 0s\n2018-02-03 00:18:44 (32.0 MB/s) - ‘jce_policy-8.zip’ saved [8409/8409]\n\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jdk-8u112-linux-x64.tar.gz\n\nSaving to: ‘jdk-8u112-linux-x64.tar.gz’\n100%[==================================================>] 183,212,596 11.1MB/s   in 16s\n2018-02-03 00:19:11 (11.1 MB/s) - ‘jdk-8u112-linux-x64.tar.gz’ saved [183212596/183212596]\n\n[root@crf1 ~]# ambari-server setup\n\n\nUsing python  /usr/bin/python\nSetup ambari-server\nChecking SELinux...\nSELinux status is \'disabled\'\nCustomize user account for ambari-server daemon [y/n] （点击回车键）\nAdjusting ambari-server permissions and ownership...\nChecking firewall status...\nChecking JDK...\n[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8\n[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7\n[3] Custom JDK\n==============================================================================\nEnter choice (1): \"点击回车键\"\nJDK already exists, using /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz\nInstalling JDK to /usr/jdk64/\nSuccessfully installed JDK to /usr/jdk64/\nJCE Policy archive already exists, using /var/lib/ambari-server/resources/jce_policy-8.zip\nInstalling JCE policy...\nCompleting setup...\nConfiguring database...\nEnter advanced database configuration [y/n] (点击回车键)\nConfiguring database...\nChecking PostgreSQL...\nRunning initdb: This may take up to a minute.\nInitializing database ... OK\n...........\nAdjusting ambari-server permissions and ownership...\nAmbari Server \'setup\' completed successfully.\n```\n## 3.6启动ambari\n```\n[root@crf1 ~]# ambari-server start\n\nUsing python  /usr/bin/python\nStarting ambari-server\nAmbari Server running with administrator privileges.\nOrganizing resource files at /var/lib/ambari-server/resources...\nAmbari database consistency check started...\nServer PID at: /var/run/ambari-server/ambari-server.pid\nServer out at: /var/log/ambari-server/ambari-server.out\nServer log at: /var/log/ambari-server/ambari-server.log\nWaiting for server start........................\nServer started listening on 8080\n\n```\n## 3.7检测ambari-server端口\n> 注意：要没有lsof服务记得安装，yum -y install lsof \n```\n[root@crf1 ~]#  lsof -i :8080\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\njava    3921 root 1435u  IPv6  24888      0t0  TCP *:webcache (LISTEN)\n```\n# 安装部署集群	\n## 4.1 配置集群\n打开客户端浏览器（推荐使用Google 浏览器），输入安装好的管理节点IP或DNS地址，比如http:// 192.168.0.245:8080/(192.168.0.245是管理节点的IP地址)。访问这个地址，您会看到下面的集群登录页面。以admin的身份登录，密码也是admin。\n\n> 注意事项：以下组件依赖于mysql  \nregistry  streamline  druid   superset\n\n\n![](/upload/images/20180203//5de26234-9333-49ae-8716-6795471b9100.png)\n\n\n\n## 4.2 安装crf组件\n第一次进入的时候需要我们自己创建一个集群，点击Launch Install Wizard进行创建进入集群创建向导。\n\n![](/upload/images/20180203//43297fe9-e20a-4392-b5f0-e8c63800b9c6.png)\n\n集群安装向导：开始\n为集群取一名字：CRF，输入集群名字后点击“下一步”进入选择安装包\n\n![](/upload/images/20180203//6ff15a22-ef96-465b-bebd-4ebbb32ee417.png)\n\n集群安装向导：选择软件包\n选择系统默认的软件包crf3.0，选择OS为redhat7，\n路径为：http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/\n\n![](/upload/images/20180203//384143a6-f2d1-4b0a-86ff-18f9e01a75eb.png)\n\n特别注意源的选择，需要把地址链接复制进去\n\n![](/upload/images/20180203//d2bff5b3-e2a2-4208-9832-1603346a2fbd.png)\n\n\n点击下一步\n填入主机名，复制主机秘钥，到输入框，注册主机\n如下图：\n\n![](/upload/images/20180203//df13d12f-b950-40c9-b85a-3d2706c1b3af.png)\n\n点击“注册并确认”\n\n![](/upload/images/20180203//1c26e646-4a0e-4284-8c94-70cd5f50bcc6.png)\n\n点击“OK”\n\n\n![](/upload/images/20180203//0016ab0d-24c3-4b17-a707-1becb189bfc0.png)\n\n主机安装成功，点击“下一步”\n\n集群安装向导：选择服务\n\n选择需要安装的服务，选择服务时会根据服务\n分配Master角色\n![](/upload/images/20180203//59f5541e-c137-4ca9-a790-02519aafa781.png)\n\n点击“下一步”继续安装\n\n特别注意：\"NIFI 和 superset 不能装在同一台机器上\"\n\n集群安装向导:分配Slaves和Clients,点击下一步\n\n![](/upload/images/20180203//8c69a365-8e86-4112-9537-f37d09e0d456.png)\n\n集群安装向导：定制服务\n\n![](/upload/images/20180203//d6736459-3f0e-4699-b5b8-e483c2530c9c.png)\n\n\n\nAmbari-Metrics組件密码列：123456/ 这样形式来填写\n\n![](/upload/images/20180203//e6b04dd1-6220-4c27-8976-3fd7b2e6d977.png)\n\nLogsearch組件密码列：123456/ 这样形式来填写\n\n![](/upload/images/20180203//d0cca700-5de7-418b-82f0-6b1624da3c14.png)\n\n![](/upload/images/20180203//d0c4e363-134d-4eff-8fc7-7973e7572ad7.png)\n![](/upload/images/20180203//5992cba8-9128-4a40-840e-d20d438d0324.png)\n\nNifi组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//fcad373f-5393-493b-b1a8-df6d757cacd2.png)\n\n\nRegistry 这个密码比较特殊，这个密码是给mysql用户授权的密码 \n密码：R12$%34qw\n\n\n![](/upload/images/20180203//b26bdf66-4069-4021-a725-ecdec4b9e33f.png)\n![](/upload/images/20180322//a332c704-c2cd-4aaf-adb1-8e5104ba2e9f.png)\n![](/upload/images/20180203//68ad30d1-99bb-47a0-9221-a352ce421ada.png)\n\nStreamline组件 和Registry组件 一样 都是需要mysql 给用户授权的那个密码\n密码R12$%34qw\n\n![](/upload/images/20180203//6687fc57-42b0-4ea8-a6f1-a5c4d157ee6c.png)\n![](/upload/images/20180322//2bbf28a0-e519-4685-a613-b20915d53167.png)\n\n![](/upload/images/20180203//314d4443-a8d6-4083-a0f0-9e6cf66b7ecc.png)\nSuperset组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//b5a67a6a-249d-4e41-81dd-fa11201a4353.png)\n![](/upload/images/20180424//f0171731-37f4-40a0-bae5-a448851eae67.png)\nSuperset组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//3beb7fe2-683e-4e44-9376-c92437b8428b.png)\n注意：单节点安装Superset和NiFi 要更改Superset端口号，否则会和NiFi端口冲突（如下图更改端口号）\n![](/upload/images/20180413//4617cb9c-ce6f-44b5-886e-20428315aca2.png)\n点击“继续执行”\n![](/upload/images/20180203//7b234518-5ec2-450a-9837-f77cfc6e8f99.png)\n\n检查安装配置\n\n![](/upload/images/20180203//9d5567c6-a1cc-47a3-a86b-3faae0f97dcb.png)\n\n点击“部署”，开始部署组件\n\n![](/upload/images/20180203//2baa3f8b-2c23-41a0-a44f-f9f1a64c9cb0.png)\n\n集群安装向导：安装、启动并测试\n\n\n![](/upload/images/20180203//78ccdb62-86c9-4a91-814b-68d4397d5c34.png)\n\n等待安装完成 \n\n![](/upload/images/20180203//614fdf35-b532-4bef-a5fe-cdc6d8bb5568.png)\n\n点击下一步\n![](/upload/images/20180203//c676a7e1-8884-4fcc-944a-ab59ea296b51.png)\n\n查看服务概要\n\n![](/upload/images/20180203//374ca460-6a2e-4143-b3a7-1f6b8919e31e.png)\n\n点击“完成”\n\n安装成功，查看界面\n\n![](/upload/images/20180203//30c4ffaa-ea15-4c35-b620-ed95c21035d1.png)# CRF3.0部署手册\n\n\n\n\n\n\n# 安装环境推荐\n\n## 1.1 硬件环境要求\n|   推荐 |小规模硬件推荐：4-10个节点 |  中等规模硬件配置推荐：20+个节点 | 大规模硬件配置推荐：100节点以上 | \n| --------  | :----:  |  :----: |  :----:  \n| 处理器cpu    | 2路 8核心XeonE5处理器(3.8GHz)| 2路 10核心XeonE5处理器(3.8GHz)   |  2路 10核心 XeonE7处理器(3.8GHz)\n| 内存        |   64G或者以上内存，DDR3L，RRECC   |   128G或者以上内存，DDR3L,RRECC  | 128G或者以上内存，DDR3L,RRECC\n| 系统盘        |    2*500G SSD  |  2*500G SSD  |2*500G SSD\n|  磁盘接口   |   SAS 6GB/s  |  SAS 6GB/s  |SAS 6GB/s\n|     磁盘    |     12个2T或者6T 7200RPM SATA硬盘  |  12个4T或者6T 7200RPM  |12个6T  7200RPM SATA\n|硬盘     |  SATA硬盘  | SATA硬盘 |SATA硬盘\n| Raid卡  |   1G缓存支持RAIDO,1,5  |  1G缓存支持RAIDO,1,5  |1G缓存支持RAIDO,1,5\n| 网络       |   10Gb以太网和千兆以太网    |  10Gb以太网和千兆以太网  |10Gb以太网和千兆以太网\n|电源     |   1+1冗余电源   |  1+1冗余电源  |1+1冗余电源\n\n\n## 1.2 操作系统要求\n\n|   系统版本 |  CentOS release 7 \n| --------  | :----:  |  :----: |  :----:  \n|内核版本   |    3.10.0-327.13.1.el7.x86_64\n## 1.3 Java环境要求\n如果您的集群的机器上还没有安装JDK，请自主下载安装JDK 1.8（Oracle版本）。\n\n```\n[root@crf1 jvm]# java  -version \njava version \"1.8.0_144\"\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n```\n## 1.4 支持的浏览器\n   | 浏览器                   |    版本\n | --------         |  :----:  |  :----: |   :----:  \n| Internet Explorer |          8.0 以上\n| Chrome|   23.0 以上\n\n\n\n# 安装基础环境准备\n### 2.1 修改主机名\n>主机名即计算机的名字（计算机名），主机名有时称为域名。主机名映射到 IP 地址，但是主机名和 IP 地址之间没有一对一关系。对于用户来说，主机名比数字 IP 地址更方便。所以会选择其主机名，用户能很容易地记住这些主机名。\n\n本次测试建立于三台服务器的基础上演示\n\n192.168.0.245  crf1\n\n192.168.0.246   crf2\n\n192.168.0.247   crf3\n\n修改每台主机的主机名\n```\n\n[root@crf1 ~]# vi /etc/hostname\ncrf1\n\n[root@crf2 ~]# vi /etc/hostname\ncrf2\n\n[root@crf3 ~]# vi /etc/hostname\ncrf3\n```\n## 2.2 主机与IP映射\n> hosts文件是Linux系统中一个负责IP地址与域名快速解析的文件，一般会保存在“/etc”目录下，文件名为“hosts”（不同的linux版本，这个配置文件也可能不同）。hosts文件是一个用于存储计算机网络中节点信息的文件，它可以将主机名映射到相应的IP地址，在没有域名服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的IP地址，否则就需要使用DNS服务程序来解决。通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。\n\n三台服务器均配置hosts文件\n```\ncrf1\n[root@crf1 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n-----------------------------------------------------------------------------\ncrf3\n[root@crf3 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n```\n## 2.3 安全设置\n\n### 2.3.1 关闭SElinux\n```\ncrf1\n[root@crf1 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf2\n[root@crf2 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf3\n[root@crf3 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n```\n### 2.3.2 关闭防火墙\n> 防火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。\n\n```\ncrf1\n[root@crf1 ~]# systemctl stop firewalld\n\ncrf2\n[root@nx-2 ~]# systemctl stop firewalld\n\ncrf3\n[root@nx-3 ~]# systemctl stop firewalld\n```\n## 2.4 免密码登录\n> 为了方便用户使用，一般会设置免密码登录，当Linux设置免密码登录后，节点跳转时SSH不会询问密码。\n\n### 2.4.1 生成私钥和公钥\n```\ncrf1\n[root@crf1 ~]# ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n01:f7:8d:da:63:cc:cc:26:6a:ee:82:6c:1e:bd:21:5c root@crf1\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|      . .        |\n|       o . o     |\n|        . o .    |\n|         O       |\n|    E   S X      |\n| . o   . + .     |\n| .+.o o          |\n|  +o.=           |\n| o. .oo          |\n+-----------------+\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n4d:16:c2:15:99:31:f6:87:57:83:12:52:ff:e9:2c:92 root@crf2\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|       ..oOB. ...|\n|        .o+=.o ..|\n|          o +.o  |\n|         +   o. .|\n|        S .    o |\n|            . o  |\n|           E . o |\n|            . .  |\n|                 |\n+-----------------+\n---------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd5:fb:e3:fe:11:a9:6c:0a:69:15:46:e1:79:5d:e7:2c root@crf3\nThe key\'s randomart image is:\n+--[ RSA 2048]----+\n|           o.   o|\n|          o.. .oo|\n|          .=..E.o|\n|         .. o. ..|\n|        S  ..  o |\n|          o ... .|\n|         +   +o. |\n|        . . o. ..|\n|           . .o..|\n+-----------------+\n```\n### 2.4.2 将公钥复制到远程主机\n在服务器中的每一台服务器建立服务器之间的ssh免密码登陆。在系统询问Are you sure you want to continue connecting (yes/no)?时输入yes并按回车，在系统询问root@crf1\'s password:时输入密码（注意：密码输入时，密码不显示）。\n```\ncrf1\n[root@crf1 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf1 ~]# ssh-copy-id crf2\nThe authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf1 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf2\n2The authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n-------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-copy-id crf1\nThe authenticity of host \'crf1 (192.168.0.245)\' can\'t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type \'yes\' or \'no\': yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1\'s password: \nPermission denied, please try again.\nroot@crf1\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf1\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf3 ~]# ssh-copy-id crf2\nThe authenticity of host \'crf2 (192.168.0.246)\' can\'t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf2\'\"\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf3 ~]# ssh-copy-id crf3\nThe authenticity of host \'crf3 (192.168.0.247)\' can\'t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3\'s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   \"ssh \'crf3\'\"\nand check to make sure that only the key(s) you wanted were added.\n```\n### 2.5 配置源\nrepo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用！\n```\n[root@crf1 ~]# cd /etc/yum.repos.d\n\n[root@crf1 yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/ambari/ambari.repo\n\n[root@crf1 yum.repos.d]# cat ambari.repo \n[redoop-crf3.0]\nName=Redoop’s Distribution for crf, Version 3.0.0\nBaseurl= http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/ambari\ngpgcheck=0\nenabaled=1\n\n[root@crf1 yum.repos.d]# yum clean all\n\nLoaded plugins: fastestmirror\nLoaded plugins: fastestmirror\nCleaning repos: ambari-2.5.1.0 base extras updates\nCleaning up everything\nCleaning up list of fastest mirrors\n```\n#  安装ambari和mysql\nAmbari的Server程序，主要管理部署在每个节点上的管理监控程序\n## 3.1 安装ambari-server\n```\ncrf1\n[root@crf1 ~]# yum install -y ambari-server\n\nLoaded plugins: fastestmirror\nambari-2.5.1.0                                                       | 2.9 kB  00:00:00\nbase                                                                 | 3.6 kB  00:00:00\nextras                                                               | 3.4 kB  00:00:00\nupdates                                                              | 3.4 kB  00:00:00\n(1/5): ambari-2.5.1.0/primary_db                                     | 8.7 kB  00:00:00\n(2/5): base/7/x86_64/group_gz                                        | 156 kB  00:00:00\n(3/5): extras/7/x86_64/primary_db                                    | 166 kB  00:00:00\n(4/5): base/7/x86_64/primary_db                                      | 5.7 MB  00:00:07\n(5/5): updates/7/x86_64/primary_db                                   | 6.0 MB  00:00:23\nDetermining fastest mirrors\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies........\nInstalled:\n  ambari-server.x86_64 0:2.5.1.0-159\nDependency Installed:\n  postgresql.x86_64 0:9.2.23-3.el7_4            postgresql-libs.x86_64 0:9.2.23-3.el7_4\n  postgresql-server.x86_64 0:9.2.23-3.el7_4\nComplete!   \n```\n## 3.2 安装mysql将ambari关联mysql数据库\n```\n[root@crf1 ~]# yum install mysql-connector-java* -y\n\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies\n--> Running transaction check\n    ..................................\n\nDependency Updated:\n  chkconfig.x86_64 0:1.7.4-1.el7                  nspr.x86_64 0:4.13.1-1.0.el7_3\n  nss.x86_64 0:3.28.4-15.el7_4                    nss-softokn.x86_64 0:3.28.3-8.el7_4\n  nss-softokn-freebl.x86_64 0:3.28.3-8.el7_4      nss-sysinit.x86_64 0:3.28.4-15.el7_4\n  nss-tools.x86_64 0:3.28.4-15.el7_4              nss-util.x86_64 0:3.28.4-3.el7\n\nComplete!\n\n[root@crf1~]#sudo ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n\n[root@crf1~]# cd /etc/yum.repos.d/\n[root@crf1~yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/utils/mysql/mysql_57.repo\n\n[root@crf1 yum.repos.d]# ls                    \nambari.repo            CentOS-Media.repo\nCentOS-Base.repo       CentOS-Sources.repo\nCentOS-CR.repo         CentOS-Vault.repo\nCentOS-Debuginfo.repo  mysql_57.repo\nCentOS-fasttrack.repo\n \n [root@crf1yum.repos.d]# yum clean all\nLoaded plugins: fastestmirror\nCleaning repos: base extras mysql-5.7\n              : redoop-crf3.0 updates\nCleaning up everything\nCleaning up list of fastest mirrors\n\n\n[root@crf1 yum.repos.d]# yum install mysql-community-server –y\n\nWarning: RPMDB altered outside of yum.\n  Installing : mysql-community-common-5.7.21-1.el7.x86_64                               1/7\n      ..............................\n\nInstalled:\n  mysql-community-libs.x86_64 0:5.7.21-1.el7\n  mysql-community-libs-compat.x86_64 0:5.7.21-1.el7\n  mysql-community-server.x86_64 0:5.7.21-1.el7\nDependency Installed:\n  \n  mysql-community-client.x86_64 0:5.7.21-1.el7 mysql-community-common.x86_64 0:5.7.21-1.el7\n  net-tools.x86_64 0:2.0-0.22.20131004git.el7\n\nReplaced:\n  mariadb-libs.x86_64 1:5.5.44-2.el7.centos\n\nComplete!\n```\n## 3.3启动mysql\n```\n[root@crf1 ~]# systemctl  start   mysqld.service\n[root@crf1 ~]# systemctl  enable   mysqld.service\n```\n## 3.4给mysql用户更改密码和配置mysql\n```\n[root@crf1 yum.repos.d]# grep \'A temporary password is generated for root@localhost\' /var/log/mysqld.log |tail -1\n\n2018-02-02T06:01:02.850616Z 1 [Note] A temporary password is generated for root@localhost: `Jl-l.%hNl4Po`  //红色部分为初始密码\n\n[root@crf1 ~]# # mysqladmin -u root -p password \"Redoop123$%^\"\nEnter password: Jl-l.%hNl4Po  // 红色为新更改密码\n\n[root@crf1 yum.repos.d]# mysql -u root -p\nEnter password: Redoop123$%^\n\nelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 14\nServer version: 5.7.21\n\nmysql> create database registry;\n\nmysql> create database streamline;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE USER \'registry\'@\'%\' IDENTIFIED BY \'R12$%34qw\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE USER \'streamline\'@\'%\' IDENTIFIED BY \'R12$%34qw\';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> GRANT ALL PRIVILEGES ON registry.* TO \'registry\'@\'%\' WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON streamline.* TO \'streamline\'@\'%\' WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> commit;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE DATABASE druid DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE DATABASE superset DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> CREATE USER \'druid\'@\'%\' IDENTIFIED BY \'9oNio)ex1ndL\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE USER \'superset\'@\'%\' IDENTIFIED BY \'9oNio)ex1ndL\';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON *.* TO \'druid\'@\'%\' WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> GRANT ALL PRIVILEGES ON *.* TO \'superset\'@\'%\' WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> commit;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> exit;\nBye\n```\n## 3.5安装CRF版mpack\n```\n[root@crf1~]#cd /opt/\n\n[root@crf1 opt~]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/mpack/crf-ambari-mpack-3.0.0.0-512.tar.gz\n\n--2018-02-0214:22:37-- http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/mpack/crf-ambari-mpack-3.0.0.tar.gz\nConnecting to 192.168.0.220:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 56231837 (54M) [application/x-gzip]\nSaving to: ‘CRF-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz’\n100%[==================================================>] 56,231,837   118MB/s   in 0.5s\n2018-02-02 14:22:37 (118 MB/s) - ‘CRF-ambari-mpack-3.0.0.tar.gz’ saved [56231837/56231837]\n\n[root@crf1 opt]# ls\ncrf-ambari-mpack-3.0.0.tar.gz\n\n[root@crf1opt]# ambari-server install-mpack --mpack=/opt/crf-ambari-mpack-3.0.0.0-512.tar.gz --purge --verbose\n\nUsing python  /usr/bin/python\nInstalling management pack\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Installing management pack /opt/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Download management pack to temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Expand management pack at temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512/\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nLooking for available JDKs at /usr/jdk64\nFound: []\nCAUTION: You have specified the --purge option with --purge-list=[\'stack-definitions\', \'mpacks\']. This will replace all existing stack definitions, management packs currently installed.\nAre you absolutely sure you want to perform the purge [yes/no]? (no)\"yes\"\n . ......\nINFO: Management pack crf-ambari-mpack-0.1.0.0.3.0.0-512 successfully installed! Please restart ambari-server.\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nAmbari Server \'install-mpack\' completed successfully.\n```\n## 3.6 初始化ambari\n下载JDK\n\n待安装完成后，便需要对 Ambari Server 做一个简单的配置。执行下面的命令。\n```\n[root@crf1 opt]# cd /var/lib/ambari-server/resources/\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jce_policy-8.zip\n\nSaving to: ‘jce_policy-8.zip’\n100%[==================================================>] 8,409       --.-K/s   in 0s\n2018-02-03 00:18:44 (32.0 MB/s) - ‘jce_policy-8.zip’ saved [8409/8409]\n\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jdk-8u112-linux-x64.tar.gz\n\nSaving to: ‘jdk-8u112-linux-x64.tar.gz’\n100%[==================================================>] 183,212,596 11.1MB/s   in 16s\n2018-02-03 00:19:11 (11.1 MB/s) - ‘jdk-8u112-linux-x64.tar.gz’ saved [183212596/183212596]\n\n[root@crf1 ~]# ambari-server setup\n\n\nUsing python  /usr/bin/python\nSetup ambari-server\nChecking SELinux...\nSELinux status is \'disabled\'\nCustomize user account for ambari-server daemon [y/n] （点击回车键）\nAdjusting ambari-server permissions and ownership...\nChecking firewall status...\nChecking JDK...\n[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8\n[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7\n[3] Custom JDK\n==============================================================================\nEnter choice (1): \"点击回车键\"\nJDK already exists, using /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz\nInstalling JDK to /usr/jdk64/\nSuccessfully installed JDK to /usr/jdk64/\nJCE Policy archive already exists, using /var/lib/ambari-server/resources/jce_policy-8.zip\nInstalling JCE policy...\nCompleting setup...\nConfiguring database...\nEnter advanced database configuration [y/n] (点击回车键)\nConfiguring database...\nChecking PostgreSQL...\nRunning initdb: This may take up to a minute.\nInitializing database ... OK\n...........\nAdjusting ambari-server permissions and ownership...\nAmbari Server \'setup\' completed successfully.\n```\n## 3.6启动ambari\n```\n[root@crf1 ~]# ambari-server start\n\nUsing python  /usr/bin/python\nStarting ambari-server\nAmbari Server running with administrator privileges.\nOrganizing resource files at /var/lib/ambari-server/resources...\nAmbari database consistency check started...\nServer PID at: /var/run/ambari-server/ambari-server.pid\nServer out at: /var/log/ambari-server/ambari-server.out\nServer log at: /var/log/ambari-server/ambari-server.log\nWaiting for server start........................\nServer started listening on 8080\n\n```\n## 3.7检测ambari-server端口\n> 注意：要没有lsof服务记得安装，yum -y install lsof \n```\n[root@crf1 ~]#  lsof -i :8080\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\njava    3921 root 1435u  IPv6  24888      0t0  TCP *:webcache (LISTEN)\n```\n# 安装部署集群	\n## 4.1 配置集群\n打开客户端浏览器（推荐使用Google 浏览器），输入安装好的管理节点IP或DNS地址，比如http:// 192.168.0.245:8080/(192.168.0.245是管理节点的IP地址)。访问这个地址，您会看到下面的集群登录页面。以admin的身份登录，密码也是admin。\n\n> 注意事项：以下组件依赖于mysql  \nregistry  streamline  druid   superset\n\n\n![](/upload/images/20180203//5de26234-9333-49ae-8716-6795471b9100.png)\n\n\n\n## 4.2 安装crf组件\n第一次进入的时候需要我们自己创建一个集群，点击Launch Install Wizard进行创建进入集群创建向导。\n\n![](/upload/images/20180203//43297fe9-e20a-4392-b5f0-e8c63800b9c6.png)\n\n集群安装向导：开始\n为集群取一名字：CRF，输入集群名字后点击“下一步”进入选择安装包\n\n![](/upload/images/20180203//6ff15a22-ef96-465b-bebd-4ebbb32ee417.png)\n\n集群安装向导：选择软件包\n选择系统默认的软件包crf3.0，选择OS为redhat7，\n路径为：http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/\n\n![](/upload/images/20180203//384143a6-f2d1-4b0a-86ff-18f9e01a75eb.png)\n\n特别注意源的选择，需要把地址链接复制进去\n\n![](/upload/images/20180203//d2bff5b3-e2a2-4208-9832-1603346a2fbd.png)\n\n\n点击下一步\n填入主机名，复制主机秘钥，到输入框，注册主机\n如下图：\n\n![](/upload/images/20180203//df13d12f-b950-40c9-b85a-3d2706c1b3af.png)\n\n点击“注册并确认”\n\n![](/upload/images/20180203//1c26e646-4a0e-4284-8c94-70cd5f50bcc6.png)\n\n点击“OK”\n\n\n![](/upload/images/20180203//0016ab0d-24c3-4b17-a707-1becb189bfc0.png)\n\n主机安装成功，点击“下一步”\n\n集群安装向导：选择服务\n\n选择需要安装的服务，选择服务时会根据服务\n分配Master角色\n![](/upload/images/20180203//59f5541e-c137-4ca9-a790-02519aafa781.png)\n\n点击“下一步”继续安装\n\n特别注意：\"NIFI 和 superset 不能装在同一台机器上\"\n\n集群安装向导:分配Slaves和Clients,点击下一步\n\n![](/upload/images/20180203//8c69a365-8e86-4112-9537-f37d09e0d456.png)\n\n集群安装向导：定制服务\n\n![](/upload/images/20180203//d6736459-3f0e-4699-b5b8-e483c2530c9c.png)\n\n\n\nAmbari-Metrics組件密码列：123456/ 这样形式来填写\n\n![](/upload/images/20180203//e6b04dd1-6220-4c27-8976-3fd7b2e6d977.png)\n\nLogsearch組件密码列：123456/ 这样形式来填写\n\n![](/upload/images/20180203//d0cca700-5de7-418b-82f0-6b1624da3c14.png)\n\n![](/upload/images/20180203//d0c4e363-134d-4eff-8fc7-7973e7572ad7.png)\n![](/upload/images/20180203//5992cba8-9128-4a40-840e-d20d438d0324.png)\n\nNifi组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//fcad373f-5393-493b-b1a8-df6d757cacd2.png)\n\n\nRegistry 这个密码比较特殊，这个密码是给mysql用户授权的密码 \n密码：R12$%34qw\n\n\n![](/upload/images/20180203//b26bdf66-4069-4021-a725-ecdec4b9e33f.png)\n![](/upload/images/20180322//a332c704-c2cd-4aaf-adb1-8e5104ba2e9f.png)\n![](/upload/images/20180203//68ad30d1-99bb-47a0-9221-a352ce421ada.png)\n\nStreamline组件 和Registry组件 一样 都是需要mysql 给用户授权的那个密码\n密码R12$%34qw\n\n![](/upload/images/20180203//6687fc57-42b0-4ea8-a6f1-a5c4d157ee6c.png)\n![](/upload/images/20180322//2bbf28a0-e519-4685-a613-b20915d53167.png)\n\n![](/upload/images/20180203//314d4443-a8d6-4083-a0f0-9e6cf66b7ecc.png)\nSuperset组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//b5a67a6a-249d-4e41-81dd-fa11201a4353.png)\n![](/upload/images/20180424//f0171731-37f4-40a0-bae5-a448851eae67.png)\nSuperset组件密码列：123qwertyuiop 以这样形式填写\n\n![](/upload/images/20180203//3beb7fe2-683e-4e44-9376-c92437b8428b.png)\n注意：单节点安装Superset和NiFi 要更改Superset端口号，否则会和NiFi端口冲突（如下图更改端口号）\n![](/upload/images/20180413//4617cb9c-ce6f-44b5-886e-20428315aca2.png)\n点击“继续执行”\n![](/upload/images/20180203//7b234518-5ec2-450a-9837-f77cfc6e8f99.png)\n\n检查安装配置\n\n![](/upload/images/20180203//9d5567c6-a1cc-47a3-a86b-3faae0f97dcb.png)\n\n点击“部署”，开始部署组件\n\n![](/upload/images/20180203//2baa3f8b-2c23-41a0-a44f-f9f1a64c9cb0.png)\n\n集群安装向导：安装、启动并测试\n\n\n![](/upload/images/20180203//78ccdb62-86c9-4a91-814b-68d4397d5c34.png)\n\n等待安装完成 \n\n![](/upload/images/20180203//614fdf35-b532-4bef-a5fe-cdc6d8bb5568.png)\n\n点击下一步\n![](/upload/images/20180203//c676a7e1-8884-4fcc-944a-ab59ea296b51.png)\n\n查看服务概要\n\n![](/upload/images/20180203//374ca460-6a2e-4143-b3a7-1f6b8919e31e.png)\n\n点击“完成”\n\n安装成功，查看界面\n\n![](/upload/images/20180203//30c4ffaa-ea15-4c35-b620-ed95c21035d1.png)', '0', '<h1 id=\"h1-crf3-0-\"><a name=\"CRF3.0部署手册\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>CRF3.0部署手册</h1><h1 id=\"h1-u5B89u88C5u73AFu5883u63A8u8350\"><a name=\"安装环境推荐\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装环境推荐</h1><h2 id=\"h2-1-1-\"><a name=\"1.1 硬件环境要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1 硬件环境要求</h2><table>\n<thead>\n<tr>\n<th>推荐</th>\n<th style=\"text-align:center\">小规模硬件推荐：4-10个节点</th>\n<th style=\"text-align:center\">中等规模硬件配置推荐：20+个节点</th>\n<th style=\"text-align:center\">大规模硬件配置推荐：100节点以上</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>处理器cpu</td>\n<td style=\"text-align:center\">2路 8核心XeonE5处理器(3.8GHz)</td>\n<td style=\"text-align:center\">2路 10核心XeonE5处理器(3.8GHz)</td>\n<td style=\"text-align:center\">2路 10核心 XeonE7处理器(3.8GHz)</td>\n</tr>\n<tr>\n<td>内存</td>\n<td style=\"text-align:center\">64G或者以上内存，DDR3L，RRECC</td>\n<td style=\"text-align:center\">128G或者以上内存，DDR3L,RRECC</td>\n<td style=\"text-align:center\">128G或者以上内存，DDR3L,RRECC</td>\n</tr>\n<tr>\n<td>系统盘</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n</tr>\n<tr>\n<td>磁盘接口</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n</tr>\n<tr>\n<td>磁盘</td>\n<td style=\"text-align:center\">12个2T或者6T 7200RPM SATA硬盘</td>\n<td style=\"text-align:center\">12个4T或者6T 7200RPM</td>\n<td style=\"text-align:center\">12个6T  7200RPM SATA</td>\n</tr>\n<tr>\n<td>硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n</tr>\n<tr>\n<td>Raid卡</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n</tr>\n<tr>\n<td>网络</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n</tr>\n<tr>\n<td>电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"h2-1-2-\"><a name=\"1.2 操作系统要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2 操作系统要求</h2><table>\n<thead>\n<tr>\n<th>系统版本</th>\n<th style=\"text-align:center\">CentOS release 7 </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>内核版本</td>\n<td style=\"text-align:center\">3.10.0-327.13.1.el7.x86_64</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"h2-1-3-java-\"><a name=\"1.3 Java环境要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3 Java环境要求</h2><p>如果您的集群的机器上还没有安装JDK，请自主下载安装JDK 1.8（Oracle版本）。</p>\n<pre><code>[root@crf1 jvm]# java  -version \njava version &quot;1.8.0_144&quot;\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n</code></pre><h2 id=\"h2-1-4-\"><a name=\"1.4 支持的浏览器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4 支持的浏览器</h2><table>\n<thead>\n<tr>\n<th>浏览器</th>\n<th style=\"text-align:center\">版本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Internet Explorer</td>\n<td style=\"text-align:center\">8.0 以上</td>\n</tr>\n<tr>\n<td>Chrome</td>\n<td style=\"text-align:center\">23.0 以上</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"h1-u5B89u88C5u57FAu7840u73AFu5883u51C6u5907\"><a name=\"安装基础环境准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装基础环境准备</h1><h3 id=\"h3-2-1-\"><a name=\"2.1 修改主机名\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1 修改主机名</h3><blockquote>\n<p>主机名即计算机的名字（计算机名），主机名有时称为域名。主机名映射到 IP 地址，但是主机名和 IP 地址之间没有一对一关系。对于用户来说，主机名比数字 IP 地址更方便。所以会选择其主机名，用户能很容易地记住这些主机名。</p>\n</blockquote>\n<p>本次测试建立于三台服务器的基础上演示</p>\n<p>192.168.0.245  crf1</p>\n<p>192.168.0.246   crf2</p>\n<p>192.168.0.247   crf3</p>\n<p>修改每台主机的主机名</p>\n<pre><code>\n[root@crf1 ~]# vi /etc/hostname\ncrf1\n\n[root@crf2 ~]# vi /etc/hostname\ncrf2\n\n[root@crf3 ~]# vi /etc/hostname\ncrf3\n</code></pre><h2 id=\"h2-2-2-ip-\"><a name=\"2.2 主机与IP映射\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2 主机与IP映射</h2><blockquote>\n<p>hosts文件是Linux系统中一个负责IP地址与域名快速解析的文件，一般会保存在“/etc”目录下，文件名为“hosts”（不同的linux版本，这个配置文件也可能不同）。hosts文件是一个用于存储计算机网络中节点信息的文件，它可以将主机名映射到相应的IP地址，在没有域名服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的IP地址，否则就需要使用DNS服务程序来解决。通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。</p>\n</blockquote>\n<p>三台服务器均配置hosts文件</p>\n<pre><code>crf1\n[root@crf1 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n-----------------------------------------------------------------------------\ncrf3\n[root@crf3 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n</code></pre><h2 id=\"h2-2-3-\"><a name=\"2.3 安全设置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3 安全设置</h2><h3 id=\"h3-2-3-1-selinux\"><a name=\"2.3.1 关闭SElinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.1 关闭SElinux</h3><pre><code>crf1\n[root@crf1 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf2\n[root@crf2 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf3\n[root@crf3 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n</code></pre><h3 id=\"h3-2-3-2-\"><a name=\"2.3.2 关闭防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.2 关闭防火墙</h3><blockquote>\n<p>防火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。</p>\n</blockquote>\n<pre><code>crf1\n[root@crf1 ~]# systemctl stop firewalld\n\ncrf2\n[root@nx-2 ~]# systemctl stop firewalld\n\ncrf3\n[root@nx-3 ~]# systemctl stop firewalld\n</code></pre><h2 id=\"h2-2-4-\"><a name=\"2.4 免密码登录\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4 免密码登录</h2><blockquote>\n<p>为了方便用户使用，一般会设置免密码登录，当Linux设置免密码登录后，节点跳转时SSH不会询问密码。</p>\n</blockquote>\n<h3 id=\"h3-2-4-1-\"><a name=\"2.4.1 生成私钥和公钥\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.1 生成私钥和公钥</h3><pre><code>crf1\n[root@crf1 ~]# ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n01:f7:8d:da:63:cc:cc:26:6a:ee:82:6c:1e:bd:21:5c root@crf1\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|      . .        |\n|       o . o     |\n|        . o .    |\n|         O       |\n|    E   S X      |\n| . o   . + .     |\n| .+.o o          |\n|  +o.=           |\n| o. .oo          |\n+-----------------+\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n4d:16:c2:15:99:31:f6:87:57:83:12:52:ff:e9:2c:92 root@crf2\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|       ..oOB. ...|\n|        .o+=.o ..|\n|          o +.o  |\n|         +   o. .|\n|        S .    o |\n|            . o  |\n|           E . o |\n|            . .  |\n|                 |\n+-----------------+\n---------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd5:fb:e3:fe:11:a9:6c:0a:69:15:46:e1:79:5d:e7:2c root@crf3\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|           o.   o|\n|          o.. .oo|\n|          .=..E.o|\n|         .. o. ..|\n|        S  ..  o |\n|          o ... .|\n|         +   +o. |\n|        . . o. ..|\n|           . .o..|\n+-----------------+\n</code></pre><h3 id=\"h3-2-4-2-\"><a name=\"2.4.2 将公钥复制到远程主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.2 将公钥复制到远程主机</h3><p>在服务器中的每一台服务器建立服务器之间的ssh免密码登陆。在系统询问Are you sure you want to continue connecting (yes/no)?时输入yes并按回车，在系统询问root<a href=\"https://github.com/crf1\" title=\"&#64;crf1\" class=\"at-link\">@crf1</a>’s password:时输入密码（注意：密码输入时，密码不显示）。</p>\n<pre><code>crf1\n[root@crf1 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf1 ~]# ssh-copy-id crf2\nThe authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf1 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf2\n2The authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n-------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf3 ~]# ssh-copy-id crf2\nThe authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf3 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n</code></pre><h3 id=\"h3-2-5-\"><a name=\"2.5 配置源\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.5 配置源</h3><p>repo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用！</p>\n<pre><code>[root@crf1 ~]# cd /etc/yum.repos.d\n\n[root@crf1 yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/ambari/ambari.repo\n\n[root@crf1 yum.repos.d]# cat ambari.repo \n[redoop-crf3.0]\nName=Redoop’s Distribution for crf, Version 3.0.0\nBaseurl= http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/ambari\ngpgcheck=0\nenabaled=1\n\n[root@crf1 yum.repos.d]# yum clean all\n\nLoaded plugins: fastestmirror\nLoaded plugins: fastestmirror\nCleaning repos: ambari-2.5.1.0 base extras updates\nCleaning up everything\nCleaning up list of fastest mirrors\n</code></pre><h1 id=\"h1--ambari-mysql\"><a name=\"安装ambari和mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装ambari和mysql</h1><p>Ambari的Server程序，主要管理部署在每个节点上的管理监控程序</p>\n<h2 id=\"h2-3-1-ambari-server\"><a name=\"3.1 安装ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.1 安装ambari-server</h2><pre><code>crf1\n[root@crf1 ~]# yum install -y ambari-server\n\nLoaded plugins: fastestmirror\nambari-2.5.1.0                                                       | 2.9 kB  00:00:00\nbase                                                                 | 3.6 kB  00:00:00\nextras                                                               | 3.4 kB  00:00:00\nupdates                                                              | 3.4 kB  00:00:00\n(1/5): ambari-2.5.1.0/primary_db                                     | 8.7 kB  00:00:00\n(2/5): base/7/x86_64/group_gz                                        | 156 kB  00:00:00\n(3/5): extras/7/x86_64/primary_db                                    | 166 kB  00:00:00\n(4/5): base/7/x86_64/primary_db                                      | 5.7 MB  00:00:07\n(5/5): updates/7/x86_64/primary_db                                   | 6.0 MB  00:00:23\nDetermining fastest mirrors\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies........\nInstalled:\n  ambari-server.x86_64 0:2.5.1.0-159\nDependency Installed:\n  postgresql.x86_64 0:9.2.23-3.el7_4            postgresql-libs.x86_64 0:9.2.23-3.el7_4\n  postgresql-server.x86_64 0:9.2.23-3.el7_4\nComplete!\n</code></pre><h2 id=\"h2-3-2-mysql-ambari-mysql-\"><a name=\"3.2 安装mysql将ambari关联mysql数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2 安装mysql将ambari关联mysql数据库</h2><pre><code>[root@crf1 ~]# yum install mysql-connector-java* -y\n\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies\n--&gt; Running transaction check\n    ..................................\n\nDependency Updated:\n  chkconfig.x86_64 0:1.7.4-1.el7                  nspr.x86_64 0:4.13.1-1.0.el7_3\n  nss.x86_64 0:3.28.4-15.el7_4                    nss-softokn.x86_64 0:3.28.3-8.el7_4\n  nss-softokn-freebl.x86_64 0:3.28.3-8.el7_4      nss-sysinit.x86_64 0:3.28.4-15.el7_4\n  nss-tools.x86_64 0:3.28.4-15.el7_4              nss-util.x86_64 0:3.28.4-3.el7\n\nComplete!\n\n[root@crf1~]#sudo ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n\n[root@crf1~]# cd /etc/yum.repos.d/\n[root@crf1~yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/utils/mysql/mysql_57.repo\n\n[root@crf1 yum.repos.d]# ls                    \nambari.repo            CentOS-Media.repo\nCentOS-Base.repo       CentOS-Sources.repo\nCentOS-CR.repo         CentOS-Vault.repo\nCentOS-Debuginfo.repo  mysql_57.repo\nCentOS-fasttrack.repo\n\n [root@crf1yum.repos.d]# yum clean all\nLoaded plugins: fastestmirror\nCleaning repos: base extras mysql-5.7\n              : redoop-crf3.0 updates\nCleaning up everything\nCleaning up list of fastest mirrors\n\n\n[root@crf1 yum.repos.d]# yum install mysql-community-server –y\n\nWarning: RPMDB altered outside of yum.\n  Installing : mysql-community-common-5.7.21-1.el7.x86_64                               1/7\n      ..............................\n\nInstalled:\n  mysql-community-libs.x86_64 0:5.7.21-1.el7\n  mysql-community-libs-compat.x86_64 0:5.7.21-1.el7\n  mysql-community-server.x86_64 0:5.7.21-1.el7\nDependency Installed:\n\n  mysql-community-client.x86_64 0:5.7.21-1.el7 mysql-community-common.x86_64 0:5.7.21-1.el7\n  net-tools.x86_64 0:2.0-0.22.20131004git.el7\n\nReplaced:\n  mariadb-libs.x86_64 1:5.5.44-2.el7.centos\n\nComplete!\n</code></pre><h2 id=\"h2-3-3-mysql\"><a name=\"3.3启动mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3启动mysql</h2><pre><code>[root@crf1 ~]# systemctl  start   mysqld.service\n[root@crf1 ~]# systemctl  enable   mysqld.service\n</code></pre><h2 id=\"h2-3-4-mysql-mysql\"><a name=\"3.4给mysql用户更改密码和配置mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.4给mysql用户更改密码和配置mysql</h2><pre><code>[root@crf1 yum.repos.d]# grep &#39;A temporary password is generated for root@localhost&#39; /var/log/mysqld.log |tail -1\n\n2018-02-02T06:01:02.850616Z 1 [Note] A temporary password is generated for root@localhost: `Jl-l.%hNl4Po`  //红色部分为初始密码\n\n[root@crf1 ~]# # mysqladmin -u root -p password &quot;Redoop123$%^&quot;\nEnter password: Jl-l.%hNl4Po  // 红色为新更改密码\n\n[root@crf1 yum.repos.d]# mysql -u root -p\nEnter password: Redoop123$%^\n\nelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 14\nServer version: 5.7.21\n\nmysql&gt; create database registry;\n\nmysql&gt; create database streamline;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;registry&#39;@&#39;%&#39; IDENTIFIED BY &#39;R12$%34qw&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;streamline&#39;@&#39;%&#39; IDENTIFIED BY &#39;R12$%34qw&#39;;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON registry.* TO &#39;registry&#39;@&#39;%&#39; WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON streamline.* TO &#39;streamline&#39;@&#39;%&#39; WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; commit;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE DATABASE druid DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE DATABASE superset DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;druid&#39;@&#39;%&#39; IDENTIFIED BY &#39;9oNio)ex1ndL&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;superset&#39;@&#39;%&#39; IDENTIFIED BY &#39;9oNio)ex1ndL&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;druid&#39;@&#39;%&#39; WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;superset&#39;@&#39;%&#39; WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; commit;\nQuery OK, 0 rows affected (0.00 sec)\nmysql&gt; exit;\nBye\n</code></pre><h2 id=\"h2-3-5-crf-mpack\"><a name=\"3.5安装CRF版mpack\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.5安装CRF版mpack</h2><pre><code>[root@crf1~]#cd /opt/\n\n[root@crf1 opt~]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/mpack/crf-ambari-mpack-3.0.0.0-512.tar.gz\n\n--2018-02-0214:22:37-- http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/mpack/crf-ambari-mpack-3.0.0.tar.gz\nConnecting to 192.168.0.220:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 56231837 (54M) [application/x-gzip]\nSaving to: ‘CRF-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz’\n100%[==================================================&gt;] 56,231,837   118MB/s   in 0.5s\n2018-02-02 14:22:37 (118 MB/s) - ‘CRF-ambari-mpack-3.0.0.tar.gz’ saved [56231837/56231837]\n\n[root@crf1 opt]# ls\ncrf-ambari-mpack-3.0.0.tar.gz\n\n[root@crf1opt]#ambari-server install-mpack --mpack=/opt/CRF-ambari-mpack-3.0.0.tar.gz --purge --verbose\n\nUsing python  /usr/bin/python\nInstalling management pack\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Installing management pack /opt/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Download management pack to temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Expand management pack at temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512/\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nLooking for available JDKs at /usr/jdk64\nFound: []\nCAUTION: You have specified the --purge option with --purge-list=[&#39;stack-definitions&#39;, &#39;mpacks&#39;]. This will replace all existing stack definitions, management packs currently installed.\nAre you absolutely sure you want to perform the purge [yes/no]? (no)&quot;yes&quot;\n . ......\nINFO: Management pack crf-ambari-mpack-0.1.0.0.3.0.0-512 successfully installed! Please restart ambari-server.\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nAmbari Server &#39;install-mpack&#39; completed successfully.\n</code></pre><h2 id=\"h2-3-6-ambari\"><a name=\"3.6 初始化ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.6 初始化ambari</h2><p>下载JDK</p>\n<p>待安装完成后，便需要对 Ambari Server 做一个简单的配置。执行下面的命令。</p>\n<pre><code>[root@crf1 opt]# cd /var/lib/ambari-server/resources/\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jce_policy-8.zip\n\nSaving to: ‘jce_policy-8.zip’\n100%[==================================================&gt;] 8,409       --.-K/s   in 0s\n2018-02-03 00:18:44 (32.0 MB/s) - ‘jce_policy-8.zip’ saved [8409/8409]\n\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jdk-8u112-linux-x64.tar.gz\n\nSaving to: ‘jdk-8u112-linux-x64.tar.gz’\n100%[==================================================&gt;] 183,212,596 11.1MB/s   in 16s\n2018-02-03 00:19:11 (11.1 MB/s) - ‘jdk-8u112-linux-x64.tar.gz’ saved [183212596/183212596]\n\n[root@crf1 ~]# ambari-server setup\n\n\nUsing python  /usr/bin/python\nSetup ambari-server\nChecking SELinux...\nSELinux status is &#39;disabled&#39;\nCustomize user account for ambari-server daemon [y/n] （点击回车键）\nAdjusting ambari-server permissions and ownership...\nChecking firewall status...\nChecking JDK...\n[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8\n[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7\n[3] Custom JDK\n==============================================================================\nEnter choice (1): &quot;点击回车键&quot;\nJDK already exists, using /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz\nInstalling JDK to /usr/jdk64/\nSuccessfully installed JDK to /usr/jdk64/\nJCE Policy archive already exists, using /var/lib/ambari-server/resources/jce_policy-8.zip\nInstalling JCE policy...\nCompleting setup...\nConfiguring database...\nEnter advanced database configuration [y/n] (点击回车键)\nConfiguring database...\nChecking PostgreSQL...\nRunning initdb: This may take up to a minute.\nInitializing database ... OK\n...........\nAdjusting ambari-server permissions and ownership...\nAmbari Server &#39;setup&#39; completed successfully.\n</code></pre><h2 id=\"h2-3-6-ambari\"><a name=\"3.6启动ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.6启动ambari</h2><pre><code>[root@crf1 ~]# ambari-server start\n\nUsing python  /usr/bin/python\nStarting ambari-server\nAmbari Server running with administrator privileges.\nOrganizing resource files at /var/lib/ambari-server/resources...\nAmbari database consistency check started...\nServer PID at: /var/run/ambari-server/ambari-server.pid\nServer out at: /var/log/ambari-server/ambari-server.out\nServer log at: /var/log/ambari-server/ambari-server.log\nWaiting for server start........................\nServer started listening on 8080\n</code></pre><h2 id=\"h2-3-7-ambari-server-\"><a name=\"3.7检测ambari-server端口\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.7检测ambari-server端口</h2><blockquote>\n<p>注意：要没有lsof服务记得安装，yum -y install lsof </p>\n<pre><code>[root@crf1 ~]#  lsof -i :8080\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\njava    3921 root 1435u  IPv6  24888      0t0  TCP *:webcache (LISTEN)\n</code></pre><h1 id=\"h1-u5B89u88C5u90E8u7F72u96C6u7FA4\"><a name=\"安装部署集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装部署集群</h1><h2 id=\"h2-4-1-\"><a name=\"4.1 配置集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.1 配置集群</h2><p>打开客户端浏览器（推荐使用Google 浏览器），输入安装好的管理节点IP或DNS地址，比如http:// 192.168.0.245:8080/(192.168.0.245是管理节点的IP地址)。访问这个地址，您会看到下面的集群登录页面。以admin的身份登录，密码也是admin。</p>\n<p>注意事项：以下组件依赖于mysql<br>registry  streamline  druid   superset</p>\n</blockquote>\n<p><img src=\"/upload/images/20180203//5de26234-9333-49ae-8716-6795471b9100.png\" alt=\"\"></p>\n<h2 id=\"h2-4-2-crf-\"><a name=\"4.2 安装crf组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.2 安装crf组件</h2><p>第一次进入的时候需要我们自己创建一个集群，点击Launch Install Wizard进行创建进入集群创建向导。</p>\n<p><img src=\"/upload/images/20180203//43297fe9-e20a-4392-b5f0-e8c63800b9c6.png\" alt=\"\"></p>\n<p>集群安装向导：开始<br>为集群取一名字：CRF，输入集群名字后点击“下一步”进入选择安装包</p>\n<p><img src=\"/upload/images/20180203//6ff15a22-ef96-465b-bebd-4ebbb32ee417.png\" alt=\"\"></p>\n<p>集群安装向导：选择软件包<br>选择系统默认的软件包crf3.0，选择OS为redhat7，<br>路径为：<a href=\"http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/\">http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/</a></p>\n<p><img src=\"/upload/images/20180203//384143a6-f2d1-4b0a-86ff-18f9e01a75eb.png\" alt=\"\"></p>\n<p>特别注意源的选择，需要把地址链接复制进去</p>\n<p><img src=\"/upload/images/20180203//d2bff5b3-e2a2-4208-9832-1603346a2fbd.png\" alt=\"\"></p>\n<p>点击下一步<br>填入主机名，复制主机秘钥，到输入框，注册主机<br>如下图：</p>\n<p><img src=\"/upload/images/20180203//df13d12f-b950-40c9-b85a-3d2706c1b3af.png\" alt=\"\"></p>\n<p>点击“注册并确认”</p>\n<p><img src=\"/upload/images/20180203//1c26e646-4a0e-4284-8c94-70cd5f50bcc6.png\" alt=\"\"></p>\n<p>点击“OK”</p>\n<p><img src=\"/upload/images/20180203//0016ab0d-24c3-4b17-a707-1becb189bfc0.png\" alt=\"\"></p>\n<p>主机安装成功，点击“下一步”</p>\n<p>集群安装向导：选择服务</p>\n<p>选择需要安装的服务，选择服务时会根据服务<br>分配Master角色<br><img src=\"/upload/images/20180203//59f5541e-c137-4ca9-a790-02519aafa781.png\" alt=\"\"></p>\n<p>点击“下一步”继续安装</p>\n<p>特别注意：”NIFI 和 superset 不能装在同一台机器上”</p>\n<p>集群安装向导:分配Slaves和Clients,点击下一步</p>\n<p><img src=\"/upload/images/20180203//8c69a365-8e86-4112-9537-f37d09e0d456.png\" alt=\"\"></p>\n<p>集群安装向导：定制服务</p>\n<p><img src=\"/upload/images/20180203//d6736459-3f0e-4699-b5b8-e483c2530c9c.png\" alt=\"\"></p>\n<p>Ambari-Metrics組件密码列：123456/ 这样形式来填写</p>\n<p><img src=\"/upload/images/20180203//e6b04dd1-6220-4c27-8976-3fd7b2e6d977.png\" alt=\"\"></p>\n<p>Logsearch組件密码列：123456/ 这样形式来填写</p>\n<p><img src=\"/upload/images/20180203//d0cca700-5de7-418b-82f0-6b1624da3c14.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180203//d0c4e363-134d-4eff-8fc7-7973e7572ad7.png\" alt=\"\"><br><img src=\"/upload/images/20180203//5992cba8-9128-4a40-840e-d20d438d0324.png\" alt=\"\"></p>\n<p>Nifi组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//fcad373f-5393-493b-b1a8-df6d757cacd2.png\" alt=\"\"></p>\n<p>Registry 这个密码比较特殊，这个密码是给mysql用户授权的密码<br>密码：R12$%34qw</p>\n<p><img src=\"/upload/images/20180203//b26bdf66-4069-4021-a725-ecdec4b9e33f.png\" alt=\"\"><br><img src=\"/upload/images/20180322//a332c704-c2cd-4aaf-adb1-8e5104ba2e9f.png\" alt=\"\"><br><img src=\"/upload/images/20180203//68ad30d1-99bb-47a0-9221-a352ce421ada.png\" alt=\"\"></p>\n<p>Streamline组件 和Registry组件 一样 都是需要mysql 给用户授权的那个密码<br>密码R12$%34qw</p>\n<p><img src=\"/upload/images/20180203//6687fc57-42b0-4ea8-a6f1-a5c4d157ee6c.png\" alt=\"\"><br><img src=\"/upload/images/20180322//2bbf28a0-e519-4685-a613-b20915d53167.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180203//314d4443-a8d6-4083-a0f0-9e6cf66b7ecc.png\" alt=\"\"><br>Superset组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//b5a67a6a-249d-4e41-81dd-fa11201a4353.png\" alt=\"\"><br><img src=\"/upload/images/20180424//f0171731-37f4-40a0-bae5-a448851eae67.png\" alt=\"\"><br>Superset组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//3beb7fe2-683e-4e44-9376-c92437b8428b.png\" alt=\"\"><br>注意：单节点安装Superset和NiFi 要更改Superset端口号，否则会和NiFi端口冲突（如下图更改端口号）<br><img src=\"/upload/images/20180413//4617cb9c-ce6f-44b5-886e-20428315aca2.png\" alt=\"\"><br>点击“继续执行”<br><img src=\"/upload/images/20180203//7b234518-5ec2-450a-9837-f77cfc6e8f99.png\" alt=\"\"></p>\n<p>检查安装配置</p>\n<p><img src=\"/upload/images/20180203//9d5567c6-a1cc-47a3-a86b-3faae0f97dcb.png\" alt=\"\"></p>\n<p>点击“部署”，开始部署组件</p>\n<p><img src=\"/upload/images/20180203//2baa3f8b-2c23-41a0-a44f-f9f1a64c9cb0.png\" alt=\"\"></p>\n<p>集群安装向导：安装、启动并测试</p>\n<p><img src=\"/upload/images/20180203//78ccdb62-86c9-4a91-814b-68d4397d5c34.png\" alt=\"\"></p>\n<p>等待安装完成 </p>\n<p><img src=\"/upload/images/20180203//614fdf35-b532-4bef-a5fe-cdc6d8bb5568.png\" alt=\"\"></p>\n<p>点击下一步<br><img src=\"/upload/images/20180203//c676a7e1-8884-4fcc-944a-ab59ea296b51.png\" alt=\"\"></p>\n<p>查看服务概要</p>\n<p><img src=\"/upload/images/20180203//374ca460-6a2e-4143-b3a7-1f6b8919e31e.png\" alt=\"\"></p>\n<p>点击“完成”</p>\n<p>安装成功，查看界面</p>\n<p><img src=\"/upload/images/20180203//30c4ffaa-ea15-4c35-b620-ed95c21035d1.png\" alt=\"\"># CRF3.0部署手册</p>\n<h1 id=\"h1-u5B89u88C5u73AFu5883u63A8u8350\"><a name=\"安装环境推荐\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装环境推荐</h1><h2 id=\"h2-1-1-\"><a name=\"1.1 硬件环境要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1 硬件环境要求</h2><table>\n<thead>\n<tr>\n<th>推荐</th>\n<th style=\"text-align:center\">小规模硬件推荐：4-10个节点</th>\n<th style=\"text-align:center\">中等规模硬件配置推荐：20+个节点</th>\n<th style=\"text-align:center\">大规模硬件配置推荐：100节点以上</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>处理器cpu</td>\n<td style=\"text-align:center\">2路 8核心XeonE5处理器(3.8GHz)</td>\n<td style=\"text-align:center\">2路 10核心XeonE5处理器(3.8GHz)</td>\n<td style=\"text-align:center\">2路 10核心 XeonE7处理器(3.8GHz)</td>\n</tr>\n<tr>\n<td>内存</td>\n<td style=\"text-align:center\">64G或者以上内存，DDR3L，RRECC</td>\n<td style=\"text-align:center\">128G或者以上内存，DDR3L,RRECC</td>\n<td style=\"text-align:center\">128G或者以上内存，DDR3L,RRECC</td>\n</tr>\n<tr>\n<td>系统盘</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n<td style=\"text-align:center\">2*500G SSD</td>\n</tr>\n<tr>\n<td>磁盘接口</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n<td style=\"text-align:center\">SAS 6GB/s</td>\n</tr>\n<tr>\n<td>磁盘</td>\n<td style=\"text-align:center\">12个2T或者6T 7200RPM SATA硬盘</td>\n<td style=\"text-align:center\">12个4T或者6T 7200RPM</td>\n<td style=\"text-align:center\">12个6T  7200RPM SATA</td>\n</tr>\n<tr>\n<td>硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n<td style=\"text-align:center\">SATA硬盘</td>\n</tr>\n<tr>\n<td>Raid卡</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n<td style=\"text-align:center\">1G缓存支持RAIDO,1,5</td>\n</tr>\n<tr>\n<td>网络</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n<td style=\"text-align:center\">10Gb以太网和千兆以太网</td>\n</tr>\n<tr>\n<td>电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n<td style=\"text-align:center\">1+1冗余电源</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"h2-1-2-\"><a name=\"1.2 操作系统要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2 操作系统要求</h2><table>\n<thead>\n<tr>\n<th>系统版本</th>\n<th style=\"text-align:center\">CentOS release 7 </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>内核版本</td>\n<td style=\"text-align:center\">3.10.0-327.13.1.el7.x86_64</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"h2-1-3-java-\"><a name=\"1.3 Java环境要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3 Java环境要求</h2><p>如果您的集群的机器上还没有安装JDK，请自主下载安装JDK 1.8（Oracle版本）。</p>\n<pre><code>[root@crf1 jvm]# java  -version \njava version &quot;1.8.0_144&quot;\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n</code></pre><h2 id=\"h2-1-4-\"><a name=\"1.4 支持的浏览器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4 支持的浏览器</h2><table>\n<thead>\n<tr>\n<th>浏览器</th>\n<th style=\"text-align:center\">版本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Internet Explorer</td>\n<td style=\"text-align:center\">8.0 以上</td>\n</tr>\n<tr>\n<td>Chrome</td>\n<td style=\"text-align:center\">23.0 以上</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"h1-u5B89u88C5u57FAu7840u73AFu5883u51C6u5907\"><a name=\"安装基础环境准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装基础环境准备</h1><h3 id=\"h3-2-1-\"><a name=\"2.1 修改主机名\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1 修改主机名</h3><blockquote>\n<p>主机名即计算机的名字（计算机名），主机名有时称为域名。主机名映射到 IP 地址，但是主机名和 IP 地址之间没有一对一关系。对于用户来说，主机名比数字 IP 地址更方便。所以会选择其主机名，用户能很容易地记住这些主机名。</p>\n</blockquote>\n<p>本次测试建立于三台服务器的基础上演示</p>\n<p>192.168.0.245  crf1</p>\n<p>192.168.0.246   crf2</p>\n<p>192.168.0.247   crf3</p>\n<p>修改每台主机的主机名</p>\n<pre><code>\n[root@crf1 ~]# vi /etc/hostname\ncrf1\n\n[root@crf2 ~]# vi /etc/hostname\ncrf2\n\n[root@crf3 ~]# vi /etc/hostname\ncrf3\n</code></pre><h2 id=\"h2-2-2-ip-\"><a name=\"2.2 主机与IP映射\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2 主机与IP映射</h2><blockquote>\n<p>hosts文件是Linux系统中一个负责IP地址与域名快速解析的文件，一般会保存在“/etc”目录下，文件名为“hosts”（不同的linux版本，这个配置文件也可能不同）。hosts文件是一个用于存储计算机网络中节点信息的文件，它可以将主机名映射到相应的IP地址，在没有域名服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的IP地址，否则就需要使用DNS服务程序来解决。通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。</p>\n</blockquote>\n<p>三台服务器均配置hosts文件</p>\n<pre><code>crf1\n[root@crf1 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n-----------------------------------------------------------------------------\ncrf3\n[root@crf3 ~]# vi /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.0.245   crf1\n192.168.0.246   crf2\n192.168.0.247   crf3\n</code></pre><h2 id=\"h2-2-3-\"><a name=\"2.3 安全设置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3 安全设置</h2><h3 id=\"h3-2-3-1-selinux\"><a name=\"2.3.1 关闭SElinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.1 关闭SElinux</h3><pre><code>crf1\n[root@crf1 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf2\n[root@crf2 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n\ncrf3\n[root@crf3 ~]# sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n</code></pre><h3 id=\"h3-2-3-2-\"><a name=\"2.3.2 关闭防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3.2 关闭防火墙</h3><blockquote>\n<p>防火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。</p>\n</blockquote>\n<pre><code>crf1\n[root@crf1 ~]# systemctl stop firewalld\n\ncrf2\n[root@nx-2 ~]# systemctl stop firewalld\n\ncrf3\n[root@nx-3 ~]# systemctl stop firewalld\n</code></pre><h2 id=\"h2-2-4-\"><a name=\"2.4 免密码登录\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4 免密码登录</h2><blockquote>\n<p>为了方便用户使用，一般会设置免密码登录，当Linux设置免密码登录后，节点跳转时SSH不会询问密码。</p>\n</blockquote>\n<h3 id=\"h3-2-4-1-\"><a name=\"2.4.1 生成私钥和公钥\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.1 生成私钥和公钥</h3><pre><code>crf1\n[root@crf1 ~]# ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n01:f7:8d:da:63:cc:cc:26:6a:ee:82:6c:1e:bd:21:5c root@crf1\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|      . .        |\n|       o . o     |\n|        . o .    |\n|         O       |\n|    E   S X      |\n| . o   . + .     |\n| .+.o o          |\n|  +o.=           |\n| o. .oo          |\n+-----------------+\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\n4d:16:c2:15:99:31:f6:87:57:83:12:52:ff:e9:2c:92 root@crf2\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|       ..oOB. ...|\n|        .o+=.o ..|\n|          o +.o  |\n|         +   o. .|\n|        S .    o |\n|            . o  |\n|           E . o |\n|            . .  |\n|                 |\n+-----------------+\n---------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd5:fb:e3:fe:11:a9:6c:0a:69:15:46:e1:79:5d:e7:2c root@crf3\nThe key&#39;s randomart image is:\n+--[ RSA 2048]----+\n|           o.   o|\n|          o.. .oo|\n|          .=..E.o|\n|         .. o. ..|\n|        S  ..  o |\n|          o ... .|\n|         +   +o. |\n|        . . o. ..|\n|           . .o..|\n+-----------------+\n</code></pre><h3 id=\"h3-2-4-2-\"><a name=\"2.4.2 将公钥复制到远程主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4.2 将公钥复制到远程主机</h3><p>在服务器中的每一台服务器建立服务器之间的ssh免密码登陆。在系统询问Are you sure you want to continue connecting (yes/no)?时输入yes并按回车，在系统询问root<a href=\"https://github.com/crf1\" title=\"&#64;crf1\" class=\"at-link\">@crf1</a>’s password:时输入密码（注意：密码输入时，密码不显示）。</p>\n<pre><code>crf1\n[root@crf1 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf1 ~]# ssh-copy-id crf2\nThe authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf1 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n---------------------------------------------------------------------------------------\ncrf2\n[root@crf2 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf2\n2The authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf2 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n-------------------------------------------------------------------------------------\n\ncrf3\n[root@crf3 ~]# ssh-copy-id crf1\nThe authenticity of host &#39;crf1 (192.168.0.245)&#39; can&#39;t be established.\nECDSA key fingerprint is 1e:ee:f6:0d:c4:64:8a:02:48:d6:16:12:9d:79:1c:59.\nAre you sure you want to continue connecting (yes/no)? t\nPlease type &#39;yes&#39; or &#39;no&#39;: yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf1&#39;s password: \nPermission denied, please try again.\nroot@crf1&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf1&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n[root@crf3 ~]# ssh-copy-id crf2\nThe authenticity of host &#39;crf2 (192.168.0.246)&#39; can&#39;t be established.\nECDSA key fingerprint is e1:42:64:2e:2c:a8:37:1f:d4:f2:18:db:65:96:09:15.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf2&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf2&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n\n\n[root@crf3 ~]# ssh-copy-id crf3\nThe authenticity of host &#39;crf3 (192.168.0.247)&#39; can&#39;t be established.\nECDSA key fingerprint is b7:f6:12:df:40:30:f0:85:0c:82:0a:9b:47:ea:9f:79.\nAre you sure you want to continue connecting (yes/no)? yes\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nroot@crf3&#39;s password: \nNumber of key(s) added: 1\nNow try logging into the machine, with:   &quot;ssh &#39;crf3&#39;&quot;\nand check to make sure that only the key(s) you wanted were added.\n</code></pre><h3 id=\"h3-2-5-\"><a name=\"2.5 配置源\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.5 配置源</h3><p>repo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用！</p>\n<pre><code>[root@crf1 ~]# cd /etc/yum.repos.d\n\n[root@crf1 yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/ambari/ambari.repo\n\n[root@crf1 yum.repos.d]# cat ambari.repo \n[redoop-crf3.0]\nName=Redoop’s Distribution for crf, Version 3.0.0\nBaseurl= http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/ambari\ngpgcheck=0\nenabaled=1\n\n[root@crf1 yum.repos.d]# yum clean all\n\nLoaded plugins: fastestmirror\nLoaded plugins: fastestmirror\nCleaning repos: ambari-2.5.1.0 base extras updates\nCleaning up everything\nCleaning up list of fastest mirrors\n</code></pre><h1 id=\"h1--ambari-mysql\"><a name=\"安装ambari和mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装ambari和mysql</h1><p>Ambari的Server程序，主要管理部署在每个节点上的管理监控程序</p>\n<h2 id=\"h2-3-1-ambari-server\"><a name=\"3.1 安装ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.1 安装ambari-server</h2><pre><code>crf1\n[root@crf1 ~]# yum install -y ambari-server\n\nLoaded plugins: fastestmirror\nambari-2.5.1.0                                                       | 2.9 kB  00:00:00\nbase                                                                 | 3.6 kB  00:00:00\nextras                                                               | 3.4 kB  00:00:00\nupdates                                                              | 3.4 kB  00:00:00\n(1/5): ambari-2.5.1.0/primary_db                                     | 8.7 kB  00:00:00\n(2/5): base/7/x86_64/group_gz                                        | 156 kB  00:00:00\n(3/5): extras/7/x86_64/primary_db                                    | 166 kB  00:00:00\n(4/5): base/7/x86_64/primary_db                                      | 5.7 MB  00:00:07\n(5/5): updates/7/x86_64/primary_db                                   | 6.0 MB  00:00:23\nDetermining fastest mirrors\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies........\nInstalled:\n  ambari-server.x86_64 0:2.5.1.0-159\nDependency Installed:\n  postgresql.x86_64 0:9.2.23-3.el7_4            postgresql-libs.x86_64 0:9.2.23-3.el7_4\n  postgresql-server.x86_64 0:9.2.23-3.el7_4\nComplete!\n</code></pre><h2 id=\"h2-3-2-mysql-ambari-mysql-\"><a name=\"3.2 安装mysql将ambari关联mysql数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.2 安装mysql将ambari关联mysql数据库</h2><pre><code>[root@crf1 ~]# yum install mysql-connector-java* -y\n\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirror.bit.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.tuna.tsinghua.edu.cn\nResolving Dependencies\n--&gt; Running transaction check\n    ..................................\n\nDependency Updated:\n  chkconfig.x86_64 0:1.7.4-1.el7                  nspr.x86_64 0:4.13.1-1.0.el7_3\n  nss.x86_64 0:3.28.4-15.el7_4                    nss-softokn.x86_64 0:3.28.3-8.el7_4\n  nss-softokn-freebl.x86_64 0:3.28.3-8.el7_4      nss-sysinit.x86_64 0:3.28.4-15.el7_4\n  nss-tools.x86_64 0:3.28.4-15.el7_4              nss-util.x86_64 0:3.28.4-3.el7\n\nComplete!\n\n[root@crf1~]#sudo ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n\n[root@crf1~]# cd /etc/yum.repos.d/\n[root@crf1~yum.repos.d]#wget http://archive.redoop.com/CRF/x86/centos7/utils/mysql/mysql_57.repo\n\n[root@crf1 yum.repos.d]# ls                    \nambari.repo            CentOS-Media.repo\nCentOS-Base.repo       CentOS-Sources.repo\nCentOS-CR.repo         CentOS-Vault.repo\nCentOS-Debuginfo.repo  mysql_57.repo\nCentOS-fasttrack.repo\n\n [root@crf1yum.repos.d]# yum clean all\nLoaded plugins: fastestmirror\nCleaning repos: base extras mysql-5.7\n              : redoop-crf3.0 updates\nCleaning up everything\nCleaning up list of fastest mirrors\n\n\n[root@crf1 yum.repos.d]# yum install mysql-community-server –y\n\nWarning: RPMDB altered outside of yum.\n  Installing : mysql-community-common-5.7.21-1.el7.x86_64                               1/7\n      ..............................\n\nInstalled:\n  mysql-community-libs.x86_64 0:5.7.21-1.el7\n  mysql-community-libs-compat.x86_64 0:5.7.21-1.el7\n  mysql-community-server.x86_64 0:5.7.21-1.el7\nDependency Installed:\n\n  mysql-community-client.x86_64 0:5.7.21-1.el7 mysql-community-common.x86_64 0:5.7.21-1.el7\n  net-tools.x86_64 0:2.0-0.22.20131004git.el7\n\nReplaced:\n  mariadb-libs.x86_64 1:5.5.44-2.el7.centos\n\nComplete!\n</code></pre><h2 id=\"h2-3-3-mysql\"><a name=\"3.3启动mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.3启动mysql</h2><pre><code>[root@crf1 ~]# systemctl  start   mysqld.service\n[root@crf1 ~]# systemctl  enable   mysqld.service\n</code></pre><h2 id=\"h2-3-4-mysql-mysql\"><a name=\"3.4给mysql用户更改密码和配置mysql\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.4给mysql用户更改密码和配置mysql</h2><pre><code>[root@crf1 yum.repos.d]# grep &#39;A temporary password is generated for root@localhost&#39; /var/log/mysqld.log |tail -1\n\n2018-02-02T06:01:02.850616Z 1 [Note] A temporary password is generated for root@localhost: `Jl-l.%hNl4Po`  //红色部分为初始密码\n\n[root@crf1 ~]# # mysqladmin -u root -p password &quot;Redoop123$%^&quot;\nEnter password: Jl-l.%hNl4Po  // 红色为新更改密码\n\n[root@crf1 yum.repos.d]# mysql -u root -p\nEnter password: Redoop123$%^\n\nelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 14\nServer version: 5.7.21\n\nmysql&gt; create database registry;\n\nmysql&gt; create database streamline;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;registry&#39;@&#39;%&#39; IDENTIFIED BY &#39;R12$%34qw&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;streamline&#39;@&#39;%&#39; IDENTIFIED BY &#39;R12$%34qw&#39;;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON registry.* TO &#39;registry&#39;@&#39;%&#39; WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON streamline.* TO &#39;streamline&#39;@&#39;%&#39; WITH GRANT OPTION ;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; commit;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE DATABASE druid DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE DATABASE superset DEFAULT CHARACTER SET utf8;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;druid&#39;@&#39;%&#39; IDENTIFIED BY &#39;9oNio)ex1ndL&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; CREATE USER &#39;superset&#39;@&#39;%&#39; IDENTIFIED BY &#39;9oNio)ex1ndL&#39;;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;druid&#39;@&#39;%&#39; WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;superset&#39;@&#39;%&#39; WITH GRANT OPTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; commit;\nQuery OK, 0 rows affected (0.00 sec)\nmysql&gt; exit;\nBye\n</code></pre><h2 id=\"h2-3-5-crf-mpack\"><a name=\"3.5安装CRF版mpack\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.5安装CRF版mpack</h2><pre><code>[root@crf1~]#cd /opt/\n\n[root@crf1 opt~]#wget http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/mpack/crf-ambari-mpack-3.0.0.0-512.tar.gz\n\n--2018-02-0214:22:37-- http://archive.redoop.com/CRF/x86/centos7/3.0.0.beta/repo/mpack/crf-ambari-mpack-3.0.0.tar.gz\nConnecting to 192.168.0.220:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 56231837 (54M) [application/x-gzip]\nSaving to: ‘CRF-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz’\n100%[==================================================&gt;] 56,231,837   118MB/s   in 0.5s\n2018-02-02 14:22:37 (118 MB/s) - ‘CRF-ambari-mpack-3.0.0.tar.gz’ saved [56231837/56231837]\n\n[root@crf1 opt]# ls\ncrf-ambari-mpack-3.0.0.tar.gz\n\n[root@crf1opt]# ambari-server install-mpack --mpack=/opt/crf-ambari-mpack-3.0.0.0-512.tar.gz --purge --verbose\n\nUsing python  /usr/bin/python\nInstalling management pack\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Installing management pack /opt/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Download management pack to temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512.tar.gz\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Expand management pack at temp location /var/lib/ambari-server/data/tmp/crf-ambari-mpack-0.1.0.0.3.0.0-512/\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nLooking for available JDKs at /usr/jdk64\nFound: []\nCAUTION: You have specified the --purge option with --purge-list=[&#39;stack-definitions&#39;, &#39;mpacks&#39;]. This will replace all existing stack definitions, management packs currently installed.\nAre you absolutely sure you want to perform the purge [yes/no]? (no)&quot;yes&quot;\n . ......\nINFO: Management pack crf-ambari-mpack-0.1.0.0.3.0.0-512 successfully installed! Please restart ambari-server.\nINFO: Loading properties from /etc/ambari-server/conf/ambari.properties\nAmbari Server &#39;install-mpack&#39; completed successfully.\n</code></pre><h2 id=\"h2-3-6-ambari\"><a name=\"3.6 初始化ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.6 初始化ambari</h2><p>下载JDK</p>\n<p>待安装完成后，便需要对 Ambari Server 做一个简单的配置。执行下面的命令。</p>\n<pre><code>[root@crf1 opt]# cd /var/lib/ambari-server/resources/\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jce_policy-8.zip\n\nSaving to: ‘jce_policy-8.zip’\n100%[==================================================&gt;] 8,409       --.-K/s   in 0s\n2018-02-03 00:18:44 (32.0 MB/s) - ‘jce_policy-8.zip’ saved [8409/8409]\n\n\n[root@crf1 resources]# wget http://archive.redoop.com/CRF/x86/centos7/utils/jdk/1.8/jdk-8u112-linux-x64.tar.gz\n\nSaving to: ‘jdk-8u112-linux-x64.tar.gz’\n100%[==================================================&gt;] 183,212,596 11.1MB/s   in 16s\n2018-02-03 00:19:11 (11.1 MB/s) - ‘jdk-8u112-linux-x64.tar.gz’ saved [183212596/183212596]\n\n[root@crf1 ~]# ambari-server setup\n\n\nUsing python  /usr/bin/python\nSetup ambari-server\nChecking SELinux...\nSELinux status is &#39;disabled&#39;\nCustomize user account for ambari-server daemon [y/n] （点击回车键）\nAdjusting ambari-server permissions and ownership...\nChecking firewall status...\nChecking JDK...\n[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8\n[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7\n[3] Custom JDK\n==============================================================================\nEnter choice (1): &quot;点击回车键&quot;\nJDK already exists, using /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz\nInstalling JDK to /usr/jdk64/\nSuccessfully installed JDK to /usr/jdk64/\nJCE Policy archive already exists, using /var/lib/ambari-server/resources/jce_policy-8.zip\nInstalling JCE policy...\nCompleting setup...\nConfiguring database...\nEnter advanced database configuration [y/n] (点击回车键)\nConfiguring database...\nChecking PostgreSQL...\nRunning initdb: This may take up to a minute.\nInitializing database ... OK\n...........\nAdjusting ambari-server permissions and ownership...\nAmbari Server &#39;setup&#39; completed successfully.\n</code></pre><h2 id=\"h2-3-6-ambari\"><a name=\"3.6启动ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.6启动ambari</h2><pre><code>[root@crf1 ~]# ambari-server start\n\nUsing python  /usr/bin/python\nStarting ambari-server\nAmbari Server running with administrator privileges.\nOrganizing resource files at /var/lib/ambari-server/resources...\nAmbari database consistency check started...\nServer PID at: /var/run/ambari-server/ambari-server.pid\nServer out at: /var/log/ambari-server/ambari-server.out\nServer log at: /var/log/ambari-server/ambari-server.log\nWaiting for server start........................\nServer started listening on 8080\n</code></pre><h2 id=\"h2-3-7-ambari-server-\"><a name=\"3.7检测ambari-server端口\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.7检测ambari-server端口</h2><blockquote>\n<p>注意：要没有lsof服务记得安装，yum -y install lsof </p>\n<pre><code>[root@crf1 ~]#  lsof -i :8080\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\njava    3921 root 1435u  IPv6  24888      0t0  TCP *:webcache (LISTEN)\n</code></pre><h1 id=\"h1-u5B89u88C5u90E8u7F72u96C6u7FA4\"><a name=\"安装部署集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装部署集群</h1><h2 id=\"h2-4-1-\"><a name=\"4.1 配置集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.1 配置集群</h2><p>打开客户端浏览器（推荐使用Google 浏览器），输入安装好的管理节点IP或DNS地址，比如http:// 192.168.0.245:8080/(192.168.0.245是管理节点的IP地址)。访问这个地址，您会看到下面的集群登录页面。以admin的身份登录，密码也是admin。</p>\n<p>注意事项：以下组件依赖于mysql<br>registry  streamline  druid   superset</p>\n</blockquote>\n<p><img src=\"/upload/images/20180203//5de26234-9333-49ae-8716-6795471b9100.png\" alt=\"\"></p>\n<h2 id=\"h2-4-2-crf-\"><a name=\"4.2 安装crf组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.2 安装crf组件</h2><p>第一次进入的时候需要我们自己创建一个集群，点击Launch Install Wizard进行创建进入集群创建向导。</p>\n<p><img src=\"/upload/images/20180203//43297fe9-e20a-4392-b5f0-e8c63800b9c6.png\" alt=\"\"></p>\n<p>集群安装向导：开始<br>为集群取一名字：CRF，输入集群名字后点击“下一步”进入选择安装包</p>\n<p><img src=\"/upload/images/20180203//6ff15a22-ef96-465b-bebd-4ebbb32ee417.png\" alt=\"\"></p>\n<p>集群安装向导：选择软件包<br>选择系统默认的软件包crf3.0，选择OS为redhat7，<br>路径为：<a href=\"http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/\">http://archive.redoop.com/CRF/x86/centos7/3.0.0.release/repo/component/</a></p>\n<p><img src=\"/upload/images/20180203//384143a6-f2d1-4b0a-86ff-18f9e01a75eb.png\" alt=\"\"></p>\n<p>特别注意源的选择，需要把地址链接复制进去</p>\n<p><img src=\"/upload/images/20180203//d2bff5b3-e2a2-4208-9832-1603346a2fbd.png\" alt=\"\"></p>\n<p>点击下一步<br>填入主机名，复制主机秘钥，到输入框，注册主机<br>如下图：</p>\n<p><img src=\"/upload/images/20180203//df13d12f-b950-40c9-b85a-3d2706c1b3af.png\" alt=\"\"></p>\n<p>点击“注册并确认”</p>\n<p><img src=\"/upload/images/20180203//1c26e646-4a0e-4284-8c94-70cd5f50bcc6.png\" alt=\"\"></p>\n<p>点击“OK”</p>\n<p><img src=\"/upload/images/20180203//0016ab0d-24c3-4b17-a707-1becb189bfc0.png\" alt=\"\"></p>\n<p>主机安装成功，点击“下一步”</p>\n<p>集群安装向导：选择服务</p>\n<p>选择需要安装的服务，选择服务时会根据服务<br>分配Master角色<br><img src=\"/upload/images/20180203//59f5541e-c137-4ca9-a790-02519aafa781.png\" alt=\"\"></p>\n<p>点击“下一步”继续安装</p>\n<p>特别注意：”NIFI 和 superset 不能装在同一台机器上”</p>\n<p>集群安装向导:分配Slaves和Clients,点击下一步</p>\n<p><img src=\"/upload/images/20180203//8c69a365-8e86-4112-9537-f37d09e0d456.png\" alt=\"\"></p>\n<p>集群安装向导：定制服务</p>\n<p><img src=\"/upload/images/20180203//d6736459-3f0e-4699-b5b8-e483c2530c9c.png\" alt=\"\"></p>\n<p>Ambari-Metrics組件密码列：123456/ 这样形式来填写</p>\n<p><img src=\"/upload/images/20180203//e6b04dd1-6220-4c27-8976-3fd7b2e6d977.png\" alt=\"\"></p>\n<p>Logsearch組件密码列：123456/ 这样形式来填写</p>\n<p><img src=\"/upload/images/20180203//d0cca700-5de7-418b-82f0-6b1624da3c14.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180203//d0c4e363-134d-4eff-8fc7-7973e7572ad7.png\" alt=\"\"><br><img src=\"/upload/images/20180203//5992cba8-9128-4a40-840e-d20d438d0324.png\" alt=\"\"></p>\n<p>Nifi组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//fcad373f-5393-493b-b1a8-df6d757cacd2.png\" alt=\"\"></p>\n<p>Registry 这个密码比较特殊，这个密码是给mysql用户授权的密码<br>密码：R12$%34qw</p>\n<p><img src=\"/upload/images/20180203//b26bdf66-4069-4021-a725-ecdec4b9e33f.png\" alt=\"\"><br><img src=\"/upload/images/20180322//a332c704-c2cd-4aaf-adb1-8e5104ba2e9f.png\" alt=\"\"><br><img src=\"/upload/images/20180203//68ad30d1-99bb-47a0-9221-a352ce421ada.png\" alt=\"\"></p>\n<p>Streamline组件 和Registry组件 一样 都是需要mysql 给用户授权的那个密码<br>密码R12$%34qw</p>\n<p><img src=\"/upload/images/20180203//6687fc57-42b0-4ea8-a6f1-a5c4d157ee6c.png\" alt=\"\"><br><img src=\"/upload/images/20180322//2bbf28a0-e519-4685-a613-b20915d53167.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180203//314d4443-a8d6-4083-a0f0-9e6cf66b7ecc.png\" alt=\"\"><br>Superset组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//b5a67a6a-249d-4e41-81dd-fa11201a4353.png\" alt=\"\"><br><img src=\"/upload/images/20180424//f0171731-37f4-40a0-bae5-a448851eae67.png\" alt=\"\"><br>Superset组件密码列：123qwertyuiop 以这样形式填写</p>\n<p><img src=\"/upload/images/20180203//3beb7fe2-683e-4e44-9376-c92437b8428b.png\" alt=\"\"><br>注意：单节点安装Superset和NiFi 要更改Superset端口号，否则会和NiFi端口冲突（如下图更改端口号）<br><img src=\"/upload/images/20180413//4617cb9c-ce6f-44b5-886e-20428315aca2.png\" alt=\"\"><br>点击“继续执行”<br><img src=\"/upload/images/20180203//7b234518-5ec2-450a-9837-f77cfc6e8f99.png\" alt=\"\"></p>\n<p>检查安装配置</p>\n<p><img src=\"/upload/images/20180203//9d5567c6-a1cc-47a3-a86b-3faae0f97dcb.png\" alt=\"\"></p>\n<p>点击“部署”，开始部署组件</p>\n<p><img src=\"/upload/images/20180203//2baa3f8b-2c23-41a0-a44f-f9f1a64c9cb0.png\" alt=\"\"></p>\n<p>集群安装向导：安装、启动并测试</p>\n<p><img src=\"/upload/images/20180203//78ccdb62-86c9-4a91-814b-68d4397d5c34.png\" alt=\"\"></p>\n<p>等待安装完成 </p>\n<p><img src=\"/upload/images/20180203//614fdf35-b532-4bef-a5fe-cdc6d8bb5568.png\" alt=\"\"></p>\n<p>点击下一步<br><img src=\"/upload/images/20180203//c676a7e1-8884-4fcc-944a-ab59ea296b51.png\" alt=\"\"></p>\n<p>查看服务概要</p>\n<p><img src=\"/upload/images/20180203//374ca460-6a2e-4143-b3a7-1f6b8919e31e.png\" alt=\"\"></p>\n<p>点击“完成”</p>\n<p>安装成功，查看界面</p>\n<p><img src=\"/upload/images/20180203//30c4ffaa-ea15-4c35-b620-ed95c21035d1.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('57', '0', 'Superset通过Postgres进行数据视图展现', '25', '2018-04-28 15:34:03', 'Superset通过Postgres进行数据视图展现', null, '0', '552', null, null, '2018-04-28 15:34:03', '2018-04-28 15:37:07', null, null, '0', '0', '0', '0', '# Superset通过Postgres进行数据视图展现\n\n## 配置postgres数据库\n> 查出postgres数据库是否安装\n\n> psql --version版本为：psql (PostgreSQL) 9.2.23\n\n![](/upload/images/20180428//f76f3fd4-731b-4b8d-8006-824014fd2d78.png)\n\n\n> 如未安装，点击连接进行下载，使用yum安装\nhttps://www.postgresql.org/download/linux/redhat/\n\n## 连接Postgres数据库\n\n>su postgres\n\n>psql   #登录默认用户 没有密码\n\n![](/upload/images/20180428//efa875cb-2482-4263-a64a-f38100d9aa3e.png)\n\n> 查看pgsql用户\n\n> \\du\n\n![](/upload/images/20180428//98eca4fa-797f-4a00-9d03-11c8c556e527.png)\n\n## 创建新的用户root并设置密码\n> create role root with password \'password\';  #创建root用户并设置密码\n\n> \\du\n![](/upload/images/20180428//56114f45-5dee-4e44-aea4-2ceb313f18d8.png)\n\n\n> 修改Postgres的配置文件pg_hba.conf，为root用户加入权限设置\n查找pg_hba.conf\n\n> find / -name pg_hba.conf\n\n![](/upload/images/20180428//4cc42c21-7a78-4ea4-b631-4191de684d0e.png)\n\n## 修改pg_hba.conf配置文件\n```\nvim /var/lib/pgsql/data/pg_hba.conf\n\n找到local   all   postgres  peer，再下面添加\nlocal   all   root    md5\n\n在# IPv4 local connections:添加\nhost    all   root    IP地址/32     trust\n\n在# IPv6 local connections:添加\nhost  all   root    ::1/128      ident\n```\n\n![](/upload/images/20180428//6bec975d-3c30-4a18-ae44-2c6da4c63816.png)\n\n\n# 创建数据库及表\n\n> 用root用户登录pgsql，创建数据库及表（本文采用的默认数据库建表查询）\n\n## 创建数据库\n```\nCREATE DATABASE DBName OWNER dbuser;\n\nCtrl +d 退出用户\nRoot用户登录 \npsql -U root -d postgres\n```\n> 输入密码之后，如下图:\n\n![](/upload/images/20180428//4030df0c-5695-4c52-95dd-c87fe288c903.png)\n\n\n> 备注：-U 用户名\n\n> -d 数据库名\n\n> -h 服务器\n\n> -p 端口\n\n> \\h查看SQL命令的解释，比如\\h select。 \n\\?查看psql命令列表。 \n	\\l列出所有数据库。 \n	\\c [database_name] 连接其他数据库。 \n	\\d列出当前数据库的所有表格。 \n	\\d [table_name]  列出某一张表格的结构。 \n	\\du列出所有用户。 \n	\\e打开文本编辑器。 \n	\\conninfo列出当前数据库和连接的信息。 \n\n## 创建表：test\n\n>CREATE TABLE test (city  varchar(80), temp_lo  int, temp_hi  int, prcp real, date date );\n\n> \\d  #查询库中的表\n\n\n![](/upload/images/20180428//b1b08c0a-8421-4c14-8427-e517118e3f76.png)\n\n\n## 向test表中插入数据，多插入几条不同的信息数据，方便接下来的查询展示\n\n> INSERT INTO test (city, temp_lo, temp_hi, prcp, date)VALUES (\'BEIjing\', 43, 64, 3.8, \'2018-04-19\');\n\n![](/upload/images/20180428//54d3940d-fe90-4434-b201-d55b1fe09f51.png)\n\n>插入成功之后查询表test\n\n> select * from testl;\n\n![](/upload/images/20180428//5e7514f2-1e9c-42c4-97c6-0d3667ef2c2b.png)\n\n\n>查询当前所在的数据库\n\n>\\conninfo\n\n![](/upload/images/20180428//20c027be-1595-409f-96dd-616021373e02.png)\n\n\n\n# Superset数据展现\n\n> 登录Superset客户端\n\n> IP地址:9088(端口根据业务需求进行更改)\n\n> 用户名和密码填写创建组件时的用户和密码\n\n![](/upload/images/20180428//ae982449-e566-491d-915d-5d96c06652c5.png)\n\n> 登录之后，进入主页面\n\n![](/upload/images/20180428//e9a24201-4d4e-4db2-a8fb-0950aac4e919.png)\n\n\n> 选择source，进行创建数据库连接\n\n![](/upload/images/20180428//dd74ddaa-1b54-4dd3-87d1-c289af5aeb85.png)\n\n> 选择Databases\n\n![](/upload/images/20180428//1934fbef-1998-45e3-808f-c6f7bc24cac0.png)\n\n> 点击右上角＋号创建新的连接\n\n![](/upload/images/20180428//cfcf6899-2ef3-4569-9a53-c8c54bfb0622.png)\n\n![](/upload/images/20180428//98eac475-afc1-49f0-8e4b-ed59a304b6e4.png)\n\n>Database：输入数据库名称（postgres）\n\n>SQLAlchemy URI：postgresql://root:root@192.168.0.239:5432/postgres\n\n>输入之后点击test connection进行连接测试\n\n>测试成功之后，弹出对话框：Seems OK!\n\n>方可进行下一步操作\n\n![](/upload/images/20180428//4c8580f7-aee9-43fb-8532-9b479e58b2ff.png)\n\n> 测试成功之后，页面底部会出现数据库中的表名（当前数据库只有test一张表）\n\n![](/upload/images/20180428//ec5422be-15f9-45b4-839a-5bc8ceac0321.png)\n\n> 点击save保存，返回页面\n\n![](/upload/images/20180428//5a419736-ff49-44c6-ac7a-c3eaa53a5006.png)\n\n> 点击sources下拉框中的Tables创建查询表\n\n![](/upload/images/20180428//23081720-ea4e-41f6-aa56-e139623b5a47.png)\n\n> 点击＋号，进行连接要查询的表\n\n![](/upload/images/20180428//f320f4cb-88d2-4744-8b75-4644dc6d9cdb.png)\n\n> 在Databases中选择postgres数据库，\n\n![](/upload/images/20180428//91f77eec-3461-486f-a004-f51984f1a8aa.png)\n\n> 输入查询的表名test，点击save保存；\n\n![](/upload/images/20180428//c6afdea5-171d-43c1-ad3f-f6d45c5dcdb1.png)\n\n> Databases：加载的数据库；\n\n> Schema：模式（默认的就可以）；\n\n> Table Name：查询的表的名称（数据库中的表）；\n\n> 保存成功，页面有提示Added Row；表格中会出现刚刚所添加的表：test\n\n![](/upload/images/20180428//659ca254-5d3a-41cf-9344-2f7a778b9d37.png)\n\n> 点击表名，加载视图展现页面，进行视图展现分析；\n\n![](/upload/images/20180428//bc98c538-de65-4300-81a5-c87a79fdfbfa.png)\n\n![](/upload/images/20180428//35db9e3a-4316-47d7-95c5-8a53a25cf8e3.png)\n\n> 如上图：左侧是视图展示配置页面，右侧是视图显示页面。需左侧配置项配置成功后，方可展示数据图示。\n\n> 备注： \n\n> Datasource&Chart Type：数据源(表)以及要展示的图表类型选择\n 	Time ：数据展示时间(例:2017-12-31至2018-01-18)\n 	GROUP BY :分组展示（聚合查询使用）\n 	NOT GROUPED BY ：（普通查询）\n 	Options：选项（展示时间样式）\n 	SQL ：条件查询（sql语句）\nFilters：增加过滤（查询）条件\n数据展现设置\n\n> 展示图示选择：\n\n![](/upload/images/20180428//a7d76608-caa4-4059-b8a3-7341b5e14cc6.png)\n\n> 时间选择：\n\n> Fixed：选择日期；\n\n> Relative：设置多少天之前的日期；\n\n> Free form：截止目前时间之前的日期；\n\n>本次查询选择所有日期，如下图所示：\n\n![](/upload/images/20180428//c263fc10-8d02-4a9f-b7d7-6f98f9fd2ef6.png)\n\n> 接下来选择\n\n> Query（根据选择的图表类型，选择显示查询条件）：\n\n> Metrics：选择度量单位\n\n> GroupBy：分组条件\n\n![](/upload/images/20180428//2ee9c764-275e-4d20-aa48-d3fcc1e81ada.png)\n\n![](/upload/images/20180428//a2e4e9c6-4f09-46ad-8f3e-4627b01197b1.png)\n\n> 配置这两项之后，基本可以展示图表信息，如果有需求，可以根据需求进行设置配置信息项。\n\n> 点击RuanQuery 进行展现\n\n> 视图展现\n\n> 饼状图示：\n\n![](/upload/images/20180428//854336a1-f7ca-489f-9c68-71978c0a7467.png)\n\n> 柱状图展示：\n![](/upload/images/20180428//35945bcb-6a73-4e76-afce-b39ea2f9cd39.png)\n\n> 表格图示：\n![](/upload/images/20180428//b4951f92-907f-4ab8-9baa-89343c504a3d.png)\n\n![](/upload/images/20180428//13090801-c412-47f1-9000-d84dbdd3c56e.png)\n', '0', '<h1 id=\"h1-superset-postgres-\"><a name=\"Superset通过Postgres进行数据视图展现\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Superset通过Postgres进行数据视图展现</h1><h2 id=\"h2--postgres-\"><a name=\"配置postgres数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置postgres数据库</h2><blockquote>\n<p>查出postgres数据库是否安装</p>\n<p>psql —version版本为：psql (PostgreSQL) 9.2.23</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//f76f3fd4-731b-4b8d-8006-824014fd2d78.png\" alt=\"\"></p>\n<blockquote>\n<p>如未安装，点击连接进行下载，使用yum安装<br><a href=\"https://www.postgresql.org/download/linux/redhat/\">https://www.postgresql.org/download/linux/redhat/</a></p>\n</blockquote>\n<h2 id=\"h2--postgres-\"><a name=\"连接Postgres数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>连接Postgres数据库</h2><blockquote>\n<p>su postgres</p>\n<p>psql   #登录默认用户 没有密码</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//efa875cb-2482-4263-a64a-f38100d9aa3e.png\" alt=\"\"></p>\n<blockquote>\n<p>查看pgsql用户</p>\n<p>\\du</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//98eca4fa-797f-4a00-9d03-11c8c556e527.png\" alt=\"\"></p>\n<h2 id=\"h2--root-\"><a name=\"创建新的用户root并设置密码\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建新的用户root并设置密码</h2><blockquote>\n<p>create role root with password ‘password’;  #创建root用户并设置密码</p>\n<p>\\du<br><img src=\"/upload/images/20180428//56114f45-5dee-4e44-aea4-2ceb313f18d8.png\" alt=\"\"></p>\n<p>修改Postgres的配置文件pg_hba.conf，为root用户加入权限设置<br>查找pg_hba.conf</p>\n<p>find / -name pg_hba.conf</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//4cc42c21-7a78-4ea4-b631-4191de684d0e.png\" alt=\"\"></p>\n<h2 id=\"h2--pg_hba-conf-\"><a name=\"修改pg_hba.conf配置文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改pg_hba.conf配置文件</h2><pre><code>vim /var/lib/pgsql/data/pg_hba.conf\n\n找到local   all   postgres  peer，再下面添加\nlocal   all   root    md5\n\n在# IPv4 local connections:添加\nhost    all   root    IP地址/32     trust\n\n在# IPv6 local connections:添加\nhost  all   root    ::1/128      ident\n</code></pre><p><img src=\"/upload/images/20180428//6bec975d-3c30-4a18-ae44-2c6da4c63816.png\" alt=\"\"></p>\n<h1 id=\"h1-u521Bu5EFAu6570u636Eu5E93u53CAu8868\"><a name=\"创建数据库及表\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建数据库及表</h1><blockquote>\n<p>用root用户登录pgsql，创建数据库及表（本文采用的默认数据库建表查询）</p>\n</blockquote>\n<h2 id=\"h2-u521Bu5EFAu6570u636Eu5E93\"><a name=\"创建数据库\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建数据库</h2><pre><code>CREATE DATABASE DBName OWNER dbuser;\n\nCtrl +d 退出用户\nRoot用户登录 \npsql -U root -d postgres\n</code></pre><blockquote>\n<p>输入密码之后，如下图:</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//4030df0c-5695-4c52-95dd-c87fe288c903.png\" alt=\"\"></p>\n<blockquote>\n<p>备注：-U 用户名</p>\n<p>-d 数据库名</p>\n<p>-h 服务器</p>\n<p>-p 端口</p>\n<p>\\h查看SQL命令的解释，比如\\h select。<br>\\?查看psql命令列表。<br>    \\l列出所有数据库。<br>    \\c [database_name] 连接其他数据库。<br>    \\d列出当前数据库的所有表格。<br>    \\d [table_name]  列出某一张表格的结构。<br>    \\du列出所有用户。<br>    \\e打开文本编辑器。<br>    \\conninfo列出当前数据库和连接的信息。 </p>\n</blockquote>\n<h2 id=\"h2--test\"><a name=\"创建表：test\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建表：test</h2><blockquote>\n<p>CREATE TABLE test (city  varchar(80), temp_lo  int, temp_hi  int, prcp real, date date );</p>\n<p>\\d  #查询库中的表</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//b1b08c0a-8421-4c14-8427-e517118e3f76.png\" alt=\"\"></p>\n<h2 id=\"h2--test-\"><a name=\"向test表中插入数据，多插入几条不同的信息数据，方便接下来的查询展示\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>向test表中插入数据，多插入几条不同的信息数据，方便接下来的查询展示</h2><blockquote>\n<p>INSERT INTO test (city, temp_lo, temp_hi, prcp, date)VALUES (‘BEIjing’, 43, 64, 3.8, ‘2018-04-19’);</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//54d3940d-fe90-4434-b201-d55b1fe09f51.png\" alt=\"\"></p>\n<blockquote>\n<p>插入成功之后查询表test</p>\n<p>select * from testl;</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//5e7514f2-1e9c-42c4-97c6-0d3667ef2c2b.png\" alt=\"\"></p>\n<blockquote>\n<p>查询当前所在的数据库</p>\n<p>\\conninfo</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//20c027be-1595-409f-96dd-616021373e02.png\" alt=\"\"></p>\n<h1 id=\"h1-superset-\"><a name=\"Superset数据展现\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Superset数据展现</h1><blockquote>\n<p>登录Superset客户端</p>\n<p>IP地址:9088(端口根据业务需求进行更改)</p>\n<p>用户名和密码填写创建组件时的用户和密码</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//ae982449-e566-491d-915d-5d96c06652c5.png\" alt=\"\"></p>\n<blockquote>\n<p>登录之后，进入主页面</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//e9a24201-4d4e-4db2-a8fb-0950aac4e919.png\" alt=\"\"></p>\n<blockquote>\n<p>选择source，进行创建数据库连接</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//dd74ddaa-1b54-4dd3-87d1-c289af5aeb85.png\" alt=\"\"></p>\n<blockquote>\n<p>选择Databases</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//1934fbef-1998-45e3-808f-c6f7bc24cac0.png\" alt=\"\"></p>\n<blockquote>\n<p>点击右上角＋号创建新的连接</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//cfcf6899-2ef3-4569-9a53-c8c54bfb0622.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180428//98eac475-afc1-49f0-8e4b-ed59a304b6e4.png\" alt=\"\"></p>\n<blockquote>\n<p>Database：输入数据库名称（postgres）</p>\n<p>SQLAlchemy URI：postgresql://root:<a href=\"mailto:root@192.168.0\">root@192.168.0</a>.239:5432/postgres</p>\n<p>输入之后点击test connection进行连接测试</p>\n<p>测试成功之后，弹出对话框：Seems OK!</p>\n<p>方可进行下一步操作</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//4c8580f7-aee9-43fb-8532-9b479e58b2ff.png\" alt=\"\"></p>\n<blockquote>\n<p>测试成功之后，页面底部会出现数据库中的表名（当前数据库只有test一张表）</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//ec5422be-15f9-45b4-839a-5bc8ceac0321.png\" alt=\"\"></p>\n<blockquote>\n<p>点击save保存，返回页面</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//5a419736-ff49-44c6-ac7a-c3eaa53a5006.png\" alt=\"\"></p>\n<blockquote>\n<p>点击sources下拉框中的Tables创建查询表</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//23081720-ea4e-41f6-aa56-e139623b5a47.png\" alt=\"\"></p>\n<blockquote>\n<p>点击＋号，进行连接要查询的表</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//f320f4cb-88d2-4744-8b75-4644dc6d9cdb.png\" alt=\"\"></p>\n<blockquote>\n<p>在Databases中选择postgres数据库，</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//91f77eec-3461-486f-a004-f51984f1a8aa.png\" alt=\"\"></p>\n<blockquote>\n<p>输入查询的表名test，点击save保存；</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//c6afdea5-171d-43c1-ad3f-f6d45c5dcdb1.png\" alt=\"\"></p>\n<blockquote>\n<p>Databases：加载的数据库；</p>\n<p>Schema：模式（默认的就可以）；</p>\n<p>Table Name：查询的表的名称（数据库中的表）；</p>\n<p>保存成功，页面有提示Added Row；表格中会出现刚刚所添加的表：test</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//659ca254-5d3a-41cf-9344-2f7a778b9d37.png\" alt=\"\"></p>\n<blockquote>\n<p>点击表名，加载视图展现页面，进行视图展现分析；</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//bc98c538-de65-4300-81a5-c87a79fdfbfa.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180428//35db9e3a-4316-47d7-95c5-8a53a25cf8e3.png\" alt=\"\"></p>\n<blockquote>\n<p>如上图：左侧是视图展示配置页面，右侧是视图显示页面。需左侧配置项配置成功后，方可展示数据图示。</p>\n<p>备注： </p>\n<p>Datasource&amp;Chart Type：数据源(表)以及要展示的图表类型选择<br>     Time ：数据展示时间(例:2017-12-31至2018-01-18)<br>     GROUP BY :分组展示（聚合查询使用）<br>     NOT GROUPED BY ：（普通查询）<br>     Options：选项（展示时间样式）<br>     SQL ：条件查询（sql语句）<br>Filters：增加过滤（查询）条件<br>数据展现设置</p>\n<p>展示图示选择：</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//a7d76608-caa4-4059-b8a3-7341b5e14cc6.png\" alt=\"\"></p>\n<blockquote>\n<p>时间选择：</p>\n<p>Fixed：选择日期；</p>\n<p>Relative：设置多少天之前的日期；</p>\n<p>Free form：截止目前时间之前的日期；</p>\n<p>本次查询选择所有日期，如下图所示：</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//c263fc10-8d02-4a9f-b7d7-6f98f9fd2ef6.png\" alt=\"\"></p>\n<blockquote>\n<p>接下来选择</p>\n<p>Query（根据选择的图表类型，选择显示查询条件）：</p>\n<p>Metrics：选择度量单位</p>\n<p>GroupBy：分组条件</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//2ee9c764-275e-4d20-aa48-d3fcc1e81ada.png\" alt=\"\"></p>\n<p><img src=\"/upload/images/20180428//a2e4e9c6-4f09-46ad-8f3e-4627b01197b1.png\" alt=\"\"></p>\n<blockquote>\n<p>配置这两项之后，基本可以展示图表信息，如果有需求，可以根据需求进行设置配置信息项。</p>\n<p>点击RuanQuery 进行展现</p>\n<p>视图展现</p>\n<p>饼状图示：</p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//854336a1-f7ca-489f-9c68-71978c0a7467.png\" alt=\"\"></p>\n<blockquote>\n<p>柱状图展示：<br><img src=\"/upload/images/20180428//35945bcb-6a73-4e76-afce-b39ea2f9cd39.png\" alt=\"\"></p>\n<p>表格图示：<br><img src=\"/upload/images/20180428//b4951f92-907f-4ab8-9baa-89343c504a3d.png\" alt=\"\"></p>\n</blockquote>\n<p><img src=\"/upload/images/20180428//13090801-c412-47f1-9000-d84dbdd3c56e.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('58', '1', 'CRH5.2安装总文档', '14', '2018-04-28 16:24:11', '这是CRH的安装的一个总脉络文档，主要介绍了CRH的环境配置和ambari的安装，或许会有对于各个组件的具体安装和使用方法', null, '0', '220', null, null, '2018-04-28 16:24:11', null, null, null, '0', '0', '0', '0', '# 安装ambari\n执行以下任务来安装ambari。\n-  为安装ambari做好准备。\n- 安装ambari-server\n- 设置ambari-server\n- 启动ambari-server\n## 为ambari的安装做准备\n本节描述您应该准备安装集群的信息和环境使用ambari。Ambari提供了一个端到端的管\n理和监视解决方案管理您 的集群。使用ambari Web UI和REST         api，您可以部署、操作和管理配置更改，并从中心监视集群中的所有节点的服务点。\n### 配置主机名映射\n使用文本编辑器，在集群中的每个主机上打开主机文件，并修改主机名，配置集群主机映射。\n\n```\nvi /etc/hostname\nvi /etc/hosts\n```\n> 注意：\n> 不要从您的主机文件中删除下面的两行。删除或编辑以下行可能会导致需要网络的各种程序功能失败\n> \n> ```\n> 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n> ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n> ```\n\n### 设置集群主机免秘钥登录\n要让ambari服务器自动在所有集群主机上安装ambari代理，您必须在ambari服务器主机和其他所有服务器之间设置无密码的SSH连接。ambari服务器主机使用SSH公钥身份验证进行远程操作访问和安装ambari agent。\n> 注意：\n> 您可以选择在每个集群主机上手动安装ambariAgent。在在这种情况下，您不需要生成和分发SSH密钥\n\n**步骤：**\n\n1. 在ambari服务器主机上生成公共和私有SSH密钥。\n\n```\nssh-keygen\n```\n\n2. 分发主机私钥至ambari服务器的每一个主机。\n\n```\nssh-copy-id nx-1\nssh-copy-id nx-2\nssh-copy-id nx-3\n```\n> 注意：\n> nx-1，nx-2 ，nx-3为主机名（我这里以三节点为例）\n\n### 安装httpd服务\nhttpd是Apache超文本传输协议(HTTP)服务器的主程序。被设计为一个独立运行的后台进程，它会建立一个处理请求的子进程或线程的池。\n\n1. 运行下面命令安装httpd服务：\n\n```\nyum install -y httpd\n```\n2. 启动httpd服务\n\n```\nservice httpd start\n```\n### 关闭ambari服务器每台主机防火墙\n火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。\n\n运行下面命令关闭防火墙\n\n```\nsystemctl stop firewalld\n```\n### 关闭每台主机SElinux\n每台主机关闭安全子系统，可以控制程序访问，重启生效\n\n```\nsed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n```\n### 配置主机的jdk java环境\nJava平台由Java虚拟机（Java Virtual Machine）和Java 应用编程接口（Application Programming Interface、简称API）构成。Java 应用编程接口为Java应用提供了一个独立于操作系统的标准接口，可分为基本部分和扩展部分。在硬件或操作系统平台上安装一个Java平台之后，Java应用程序就可运行。现在Java平台已经嵌入了几乎所有的操作系统。这样Java程序可以只编译一次，就可以在各种系统中运行。\n1. 下载JDK安装包，版本为jdk1.8.0_144，将其放入/usr/lib/jvm/ 目录(目录位置可以修改)下\n2. 解压每台主机下的jdk包。\n\n```\ntar -zxvf jdk-8u144-linux-x64.tar.gz\n```\n\n3. 配置每台主机上的java环境变量\n\n```\nvi /etc/profile.d/jdk.sh\nexport JAVA_HOME=/usr/lib/jvm/jdk1.8.0_144\nexport JRE_HOME=//usr/lib/jvm/jdk1.8.0_144/jre\nexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH\nexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH\n\n```\n\n4. 生效每台主机的jdk环境变量\n\n```\nsource /etc/profile\n```\n\n5. 查看每台主机的jdk环境变量\n```\njava –version\njava version \"1.8.0_144\"\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n```\n## 安装ambari-server\n### 配置CRH源\nepo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用\n1. 进入到/etc /yum.repos.d目录下，加载我们crh所需要的repo文件\n\n```\ncd /etc/yum.repos.d/\nwget +repo文件路径（e.g wget http://archive.redoop.com/crh/rpm/5.1.2.6/CRH/x86_64/centos7/ambari.repo）\n\n```\n\n2. 安装ambari-server\n\n```\nyum clean all\nyum install -y ambari-server\n```\n\n## setup ambari-server\n在启动ambari服务器之前，您必须设置ambari服务器。设置配置Ambari与ambari数据库对话，安装JDK，并允许您定制用户帐户ambari服务器守护进程将运行\n\n执行以下命令设置ambari-server\n\n```\nambari-server setup\n```\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ambari-setup.png)\n## 1.4 启动ambari-server\n1. 在ambari服务器主机上运行以下命令\n\n```\nambari-server start\n```\n\n2. 检查ambari服务器进程:\n\n```\nambari-server status\n```\n\n3. 停止ambari-server服务\n\n```\nambari-server stop\n```\n> 注意：\n> 如果您打算为Hive或Oozie使用现有的数据库实例，那么您必须在安装Hadoop集群之前，准备使用非默认数据库\n# 搭建CRH集群组件\n在你开始了ambari服务之后，你可以在浏览器中打开Ambari的网址，然后启动。\n## 注册CRH ambari服务主机\n**步骤：**\n1. 	在页面输入http:// < your.ambari.server>:8080，进入ambari的web界面。\n2. 使用默认的用户名和密码登录到ambari服务器，用户名：admin，密码：admin，进入系统你可以修改密码。\n3. 在ambari欢迎页面，选择启动安装向导。\n4. 在Get启动步骤中，为您的集群自定义一个名称。\n5.在选择版本界面，选择你所需要的系统，并添加仓库的链接，（链接可以打开ambari.repo查看）\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/CRH-zhuce-zhuji.png)\n\n---\n\n- 仓库地址查看 e.g\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/cangku-dizhi-e.g.png)\n\n6.添加主机名和主机私钥完成主机注册\ne.g \n主机私钥查看\n\n```\ncat ~/.ssh/id_rsa\n```\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/zhuce-zhuji.png)\n\n## 安装配置CRH组件\n- 安装hadoop（HDFS,MAPREDUCE和ZooKeeper）\n- 安装sqoop，storm，flume，kafka\n- 安装hbase , kafka,log search,spark,spark2,zeppelin \n- 安装HIVE, HAWQ, ,infra,atlas,组件\n- 安装Ranger，rangerKMS\n### 安装hadoop（HDFS,MAPREDUCE和ZooKeeper）\n您可以在定制服务步骤中配置hadoop组件选项（包括Hadoop+mapReduce+hdfs+ZooKeeper）\n**步骤**：\n1. 打开添加服务选择hadoop服务（包括Hadoop+mapReduce+hdfs+ZooKeeper）。\n1. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n1. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n1. 查看安装过程中是否正常，完成安装任务。\n\n### 安装sqoop，storm，flume，kafka\n您可以在定制服务步骤中配置sqoop，storm，flume。kafka组件选项\n\n**步骤：**\n1. 打开添加服务选择sqoop，storm，flume。kafka服务。\n1. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n1. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n1. 查看安装过程中是否正常，完成安装任务。\n\n### 安装hbase , kafka,log search,spark,spark2,zeppelin\n您可以在定制服务步骤中配置hbase , kafka,logsearch,spark,spark2,zeppelin组件选项\n\n**步骤：**\n\n1. 打开添加服务选择hbase , kafka,log search,spark,spark2,zeppelin服务。\n1. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n1. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n1. 查看安装过程中是否正常，完成安装任务。\n\n### 安装HIVE, HAWQ, ,infra,atlas,组件\n您可以在定制服务步骤中配置hive，HAWQ，Infra，atlas组件选项\n**步骤：**\n1. 打开添加服务选择hive，HAWQ，Infra，atlas服务。\n1. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n1. 在ambari配置界面过程中，这几个组件需要配置密码，请设置好您们组件所使用的的密码。\n1. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n1. 查看安装过程中是否正常，完成安装任务。\n\n### 安装Ranger，rangerKMS\n在安装Ranger之前需要配置ambari服务主机的数据库配置并保证确保Ambari Infra已成功安装\n1. 在ambari服务主机上安装mariadb数据库\n\n```\nyum install -y mariadb-server\n```\n\n2. 启动mariadb数据库\n\n```\nsystemctl start mariadb\n```\n\n3. 初始化mariadb数据库并设置数据库密码\n\n```\nmysql_secure_installation\n```\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/set-passwd-mariadb.png)\n4. 进入mariadb数据库需要设置数据库允许远程连接\n\n```\nMariaDB [(none)]> grant all on *.* to root@\'%\' identified by \'root\' with grant option;\nMariaDB [(none)]> flush privileges;\n```\n\n5. 按照安装向导执行如下命令\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-yaoqiu.png)\n\n\n```\nambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n```\n\n6. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）\n\n7. 在定制服务时有几个地方需要填写\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-tianxiexinxi.png)\n\n---\n\n- 填写完成后，测试连接是否成功\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-ceshi-lianjie.png)\n\n---\n\n- 最后一个修改地方\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-on-update.png)\n8. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n9. 查看安装过程中是否正常，完成安装任务。\n\n##### **RangerKMS安装**\n在安装RangerKMS之前需要先对jdk做一步操作,否则会RangerKMS安装成功,但是服务会死掉.\n这个是因为用AES加密时，如果密钥大于128, 会抛出java.security.InvalidKeyException: Illegal key size异常。\n\n之后查看日志文件tail -100f /var/log/ranger/kms/catalina.out\n\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-exception.png)\n\n这时候需要我们去http://www.oracle.com/technetwork/java/javase/downloads/index.html oracle官网上下载对应jdk版本的Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files 文件\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/RangerKMS-JDK-RSA-download.png)\n解压以后将local_policy.jar，US_export_policy.jar的文件拷贝到JAVA_HOME/jre/lib/security 替换原来的文件,之后开始安装RangerKMS\n\n1. 打开添加服务选择RangerKMS服务。\n2. 初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。\n3. 在ambari配置界面过程中，需要修改几个部分,修改如下图：\n\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-tianxiexinxi1.png)\n![image](http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-tianxiexinxi2.png)\n4. 如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。\n5. 查看安装过程中是否正常，完成安装任务。\n\n\n', '0', '<h1 id=\"h1--ambari\"><a name=\"安装ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装ambari</h1><p>执行以下任务来安装ambari。</p>\n<ul>\n<li>为安装ambari做好准备。</li><li>安装ambari-server</li><li>设置ambari-server</li><li>启动ambari-server<h2 id=\"h2--ambari-\"><a name=\"为ambari的安装做准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>为ambari的安装做准备</h2>本节描述您应该准备安装集群的信息和环境使用ambari。Ambari提供了一个端到端的管<br>理和监视解决方案管理您 的集群。使用ambari Web UI和REST         api，您可以部署、操作和管理配置更改，并从中心监视集群中的所有节点的服务点。<h3 id=\"h3-u914Du7F6Eu4E3Bu673Au540Du6620u5C04\"><a name=\"配置主机名映射\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置主机名映射</h3>使用文本编辑器，在集群中的每个主机上打开主机文件，并修改主机名，配置集群主机映射。</li></ul>\n<pre><code>vi /etc/hostname\nvi /etc/hosts\n</code></pre><blockquote>\n<p>注意：<br>不要从您的主机文件中删除下面的两行。删除或编辑以下行可能会导致需要网络的各种程序功能失败</p>\n<pre><code>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n</code></pre></blockquote>\n<h3 id=\"h3-u8BBEu7F6Eu96C6u7FA4u4E3Bu673Au514Du79D8u94A5u767Bu5F55\"><a name=\"设置集群主机免秘钥登录\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>设置集群主机免秘钥登录</h3><p>要让ambari服务器自动在所有集群主机上安装ambari代理，您必须在ambari服务器主机和其他所有服务器之间设置无密码的SSH连接。ambari服务器主机使用SSH公钥身份验证进行远程操作访问和安装ambari agent。</p>\n<blockquote>\n<p>注意：<br>您可以选择在每个集群主机上手动安装ambariAgent。在在这种情况下，您不需要生成和分发SSH密钥</p>\n</blockquote>\n<p><strong>步骤：</strong></p>\n<ol>\n<li>在ambari服务器主机上生成公共和私有SSH密钥。</li></ol>\n<pre><code>ssh-keygen\n</code></pre><ol>\n<li>分发主机私钥至ambari服务器的每一个主机。</li></ol>\n<pre><code>ssh-copy-id nx-1\nssh-copy-id nx-2\nssh-copy-id nx-3\n</code></pre><blockquote>\n<p>注意：<br>nx-1，nx-2 ，nx-3为主机名（我这里以三节点为例）</p>\n</blockquote>\n<h3 id=\"h3--httpd-\"><a name=\"安装httpd服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装httpd服务</h3><p>httpd是Apache超文本传输协议(HTTP)服务器的主程序。被设计为一个独立运行的后台进程，它会建立一个处理请求的子进程或线程的池。</p>\n<ol>\n<li>运行下面命令安装httpd服务：</li></ol>\n<pre><code>yum install -y httpd\n</code></pre><ol>\n<li>启动httpd服务</li></ol>\n<pre><code>service httpd start\n</code></pre><h3 id=\"h3--ambari-\"><a name=\"关闭ambari服务器每台主机防火墙\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭ambari服务器每台主机防火墙</h3><p>火墙是一个分离器，一个限制器，也是一个分析器，有效地监控了内部网和Internet之间的任何活动， 保证了内部网络的安全。如需要对外开放一些服务的端口，需要配置关闭防火墙，否则公网无法访问。</p>\n<p>运行下面命令关闭防火墙</p>\n<pre><code>systemctl stop firewalld\n</code></pre><h3 id=\"h3--selinux\"><a name=\"关闭每台主机SElinux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭每台主机SElinux</h3><p>每台主机关闭安全子系统，可以控制程序访问，重启生效</p>\n<pre><code>sed –I ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/selinux/config\n</code></pre><h3 id=\"h3--jdk-java-\"><a name=\"配置主机的jdk java环境\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置主机的jdk java环境</h3><p>Java平台由Java虚拟机（Java Virtual Machine）和Java 应用编程接口（Application Programming Interface、简称API）构成。Java 应用编程接口为Java应用提供了一个独立于操作系统的标准接口，可分为基本部分和扩展部分。在硬件或操作系统平台上安装一个Java平台之后，Java应用程序就可运行。现在Java平台已经嵌入了几乎所有的操作系统。这样Java程序可以只编译一次，就可以在各种系统中运行。</p>\n<ol>\n<li>下载JDK安装包，版本为jdk1.8.0_144，将其放入/usr/lib/jvm/ 目录(目录位置可以修改)下</li><li>解压每台主机下的jdk包。</li></ol>\n<pre><code>tar -zxvf jdk-8u144-linux-x64.tar.gz\n</code></pre><ol>\n<li>配置每台主机上的java环境变量</li></ol>\n<pre><code>vi /etc/profile.d/jdk.sh\nexport JAVA_HOME=/usr/lib/jvm/jdk1.8.0_144\nexport JRE_HOME=//usr/lib/jvm/jdk1.8.0_144/jre\nexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH\nexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH\n</code></pre><ol>\n<li>生效每台主机的jdk环境变量</li></ol>\n<pre><code>source /etc/profile\n</code></pre><ol>\n<li>查看每台主机的jdk环境变量<pre><code>java –version\njava version &quot;1.8.0_144&quot;\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n</code></pre><h2 id=\"h2--ambari-server\"><a name=\"安装ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装ambari-server</h2><h3 id=\"h3--crh-\"><a name=\"配置CRH源\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置CRH源</h3>epo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的细节内容，例如我们将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用</li><li>进入到/etc /yum.repos.d目录下，加载我们crh所需要的repo文件</li></ol>\n<pre><code>cd /etc/yum.repos.d/\nwget +repo文件路径（e.g wget http://archive.redoop.com/crh/rpm/5.1.2.6/CRH/x86_64/centos7/ambari.repo）\n</code></pre><ol>\n<li>安装ambari-server</li></ol>\n<pre><code>yum clean all\nyum install -y ambari-server\n</code></pre><h2 id=\"h2-setup-ambari-server\"><a name=\"setup ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>setup ambari-server</h2><p>在启动ambari服务器之前，您必须设置ambari服务器。设置配置Ambari与ambari数据库对话，安装JDK，并允许您定制用户帐户ambari服务器守护进程将运行</p>\n<p>执行以下命令设置ambari-server</p>\n<pre><code>ambari-server setup\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ambari-setup.png\" alt=\"image\"></p>\n<h2 id=\"h2-1-4-ambari-server\"><a name=\"1.4 启动ambari-server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4 启动ambari-server</h2><ol>\n<li>在ambari服务器主机上运行以下命令</li></ol>\n<pre><code>ambari-server start\n</code></pre><ol>\n<li>检查ambari服务器进程:</li></ol>\n<pre><code>ambari-server status\n</code></pre><ol>\n<li>停止ambari-server服务</li></ol>\n<pre><code>ambari-server stop\n</code></pre><blockquote>\n<p>注意：<br>如果您打算为Hive或Oozie使用现有的数据库实例，那么您必须在安装Hadoop集群之前，准备使用非默认数据库</p>\n<h1 id=\"h1--crh-\"><a name=\"搭建CRH集群组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>搭建CRH集群组件</h1><p>在你开始了ambari服务之后，你可以在浏览器中打开Ambari的网址，然后启动。</p>\n<h2 id=\"h2--crh-ambari-\"><a name=\"注册CRH ambari服务主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>注册CRH ambari服务主机</h2><p><strong>步骤：</strong></p>\n<ol>\n<li>在页面输入http:// &lt; your.ambari.server&gt;:8080，进入ambari的web界面。</li><li>使用默认的用户名和密码登录到ambari服务器，用户名：admin，密码：admin，进入系统你可以修改密码。</li><li>在ambari欢迎页面，选择启动安装向导。</li><li>在Get启动步骤中，为您的集群自定义一个名称。<br>5.在选择版本界面，选择你所需要的系统，并添加仓库的链接，（链接可以打开ambari.repo查看）<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/CRH-zhuce-zhuji.png\" alt=\"image\"></li></ol>\n</blockquote>\n<hr>\n<ul>\n<li>仓库地址查看 e.g<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/cangku-dizhi-e.g.png\" alt=\"image\"></li></ul>\n<p>6.添加主机名和主机私钥完成主机注册<br>e.g<br>主机私钥查看</p>\n<pre><code>cat ~/.ssh/id_rsa\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/zhuce-zhuji.png\" alt=\"image\"></p>\n<h2 id=\"h2--crh-\"><a name=\"安装配置CRH组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装配置CRH组件</h2><ul>\n<li>安装hadoop（HDFS,MAPREDUCE和ZooKeeper）</li><li>安装sqoop，storm，flume，kafka</li><li>安装hbase , kafka,log search,spark,spark2,zeppelin </li><li>安装HIVE, HAWQ, ,infra,atlas,组件</li><li>安装Ranger，rangerKMS<h3 id=\"h3--hadoop-hdfs-mapreduce-zookeeper-\"><a name=\"安装hadoop（HDFS,MAPREDUCE和ZooKeeper）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装hadoop（HDFS,MAPREDUCE和ZooKeeper）</h3>您可以在定制服务步骤中配置hadoop组件选项（包括Hadoop+mapReduce+hdfs+ZooKeeper）<br><strong>步骤</strong>：</li></ul>\n<ol>\n<li>打开添加服务选择hadoop服务（包括Hadoop+mapReduce+hdfs+ZooKeeper）。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h3 id=\"h3--sqoop-storm-flume-kafka\"><a name=\"安装sqoop，storm，flume，kafka\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装sqoop，storm，flume，kafka</h3><p>您可以在定制服务步骤中配置sqoop，storm，flume。kafka组件选项</p>\n<p><strong>步骤：</strong></p>\n<ol>\n<li>打开添加服务选择sqoop，storm，flume。kafka服务。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h3 id=\"h3--hbase-kafka-log-search-spark-spark2-zeppelin\"><a name=\"安装hbase , kafka,log search,spark,spark2,zeppelin\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装hbase , kafka,log search,spark,spark2,zeppelin</h3><p>您可以在定制服务步骤中配置hbase , kafka,logsearch,spark,spark2,zeppelin组件选项</p>\n<p><strong>步骤：</strong></p>\n<ol>\n<li>打开添加服务选择hbase , kafka,log search,spark,spark2,zeppelin服务。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h3 id=\"h3--hive-hawq-infra-atlas-\"><a name=\"安装HIVE, HAWQ, ,infra,atlas,组件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装HIVE, HAWQ, ,infra,atlas,组件</h3><p>您可以在定制服务步骤中配置hive，HAWQ，Infra，atlas组件选项<br><strong>步骤：</strong></p>\n<ol>\n<li>打开添加服务选择hive，HAWQ，Infra，atlas服务。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>在ambari配置界面过程中，这几个组件需要配置密码，请设置好您们组件所使用的的密码。</li><li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h3 id=\"h3--ranger-rangerkms\"><a name=\"安装Ranger，rangerKMS\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装Ranger，rangerKMS</h3><p>在安装Ranger之前需要配置ambari服务主机的数据库配置并保证确保Ambari Infra已成功安装</p>\n<ol>\n<li>在ambari服务主机上安装mariadb数据库</li></ol>\n<pre><code>yum install -y mariadb-server\n</code></pre><ol>\n<li>启动mariadb数据库</li></ol>\n<pre><code>systemctl start mariadb\n</code></pre><ol>\n<li>初始化mariadb数据库并设置数据库密码</li></ol>\n<pre><code>mysql_secure_installation\n</code></pre><p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/set-passwd-mariadb.png\" alt=\"image\"></p>\n<ol>\n<li>进入mariadb数据库需要设置数据库允许远程连接</li></ol>\n<pre><code>MariaDB [(none)]&gt; grant all on *.* to root@&#39;%&#39; identified by &#39;root&#39; with grant option;\nMariaDB [(none)]&gt; flush privileges;\n</code></pre><ol>\n<li>按照安装向导执行如下命令<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-yaoqiu.png\" alt=\"image\"></li></ol>\n<pre><code>ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n</code></pre><ol>\n<li><p>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）</p>\n</li><li><p>在定制服务时有几个地方需要填写<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-tianxiexinxi.png\" alt=\"image\"></p>\n</li></ol>\n<hr>\n<ul>\n<li>填写完成后，测试连接是否成功<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-ceshi-lianjie.png\" alt=\"image\"></li></ul>\n<hr>\n<ul>\n<li>最后一个修改地方<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/ranger-on-update.png\" alt=\"image\"></li></ul>\n<ol>\n<li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n<h5 id=\"h5--strong-rangerkms-strong-\"><a name=\"<strong>RangerKMS安装</strong>\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><strong>RangerKMS安装</strong></h5><p>在安装RangerKMS之前需要先对jdk做一步操作,否则会RangerKMS安装成功,但是服务会死掉.<br>这个是因为用AES加密时，如果密钥大于128, 会抛出java.security.InvalidKeyException: Illegal key size异常。</p>\n<p>之后查看日志文件tail -100f /var/log/ranger/kms/catalina.out</p>\n<p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-exception.png\" alt=\"image\"></p>\n<p>这时候需要我们去<a href=\"http://www.oracle.com/technetwork/java/javase/downloads/index.html\">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a> oracle官网上下载对应jdk版本的Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files 文件<br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/RangerKMS-JDK-RSA-download.png\" alt=\"image\"><br>解压以后将local_policy.jar，US_export_policy.jar的文件拷贝到JAVA_HOME/jre/lib/security 替换原来的文件,之后开始安装RangerKMS</p>\n<ol>\n<li>打开添加服务选择RangerKMS服务。</li><li>初始安装，接受Ambari设定的默认值（包括分配Master，slave分配，服务定制等）。</li><li>在ambari配置界面过程中，需要修改几个部分,修改如下图：</li></ol>\n<p><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-tianxiexinxi1.png\" alt=\"image\"><br><img src=\"http://www.redhub.io/DOC/CRH/raw/887ca023a7586db30ecab0d14a76218a31f8e4a0/CRH%e6%96%87%e6%a1%a3%e6%88%aa%e5%9b%be/CRH5.2%e9%83%a8%e7%bd%b2%e6%96%87%e6%a1%a3image/rangerKMS-tianxiexinxi2.png\" alt=\"image\"></p>\n<ol>\n<li>如果Ambari让你在某些情况下需要你的注意，点击继续执行并检查属性列表并提供所需的信息。</li><li>查看安装过程中是否正常，完成安装任务。</li></ol>\n');
INSERT INTO `tbl_archive` VALUES ('59', '1', 'Ambari 安装', '13', '2018-04-28 17:15:41', 'Ambari 安装文档预览', null, '0', '341', null, null, '2018-04-28 17:15:41', '2018-04-28 17:40:42', null, null, '0', '0', '0', '0', '# 准备\n\n## CRH版本与CPU架构\nCRH不同的版本支持的CPU架构情况不同，下面的表格描述了这些信息：\n\nS = 支持\n\nCRH | x86 | ppc64le | aarch64 | sw64 | mips64el\n---|---|---|---|---|---\n5.0 | S | S | S | S |\n5.1 | S | S | S |\n6.1 | S | S | S |\n\n\n## 最小系统要求\n### 浏览器要求\nAmbari安装向导作为一个基于浏览器的web应用程序运行。为了运行这个工具，你必须有一台运行图形化浏览器的机器。不同操作系统最低浏览器版本要求如下：\n\nOperating System | Browser\n---|---\nLinux | Chrome 56.0.2924.87, 57.0.2987; Firefox 51, 52\nMac OS X | Chrome 56.0.2924.87, 57.0.2987; Firefox 51, 52; Safari 10.0.1, 10.0.3\nWindows* | Chrome 56.0.2924.87, 57.0.2987; Edge 38; Firefox 51.0.1, 52.0; Internet Explorer 10, 11\n\n> 在任何平台，我们建议你更新浏览器到最新版本\n\n\n### 软件要求\n在你的集群中的每一台主机：\n- **yum** 和 **rpm** (RHEL/CentOS/Oracle Linux)\n- **apt** (Ubuntu/Kylin)\n- **scp**, **curl**, **unzip**, **tar**, 和 **wget**\n- **OpenSSL** (v1.01, build 16 or later)\n- **Python**\n  - Python 2.7.x (CentOS 7, Ubuntu 16)\n\n\n### JDK 要求\n\nCPU架构 | JDK | 版本\n---|---|---\nx86 | Oracle | JDK 8, 64-bit (最低 JDK 1.8.0_77), default\nppc64le | Open Source | JDK8+\naarch64 | Open Source | JDK8+\nsw64 | Open Source | JDK8+\nmips64el | Open Source | JDK8+\n\n> JDK 版本选择取决于你选择的CRH Stack。\n\n\n### 数据库要求\nAmbari要求使用一个关系型数据库存储集群配置和拓扑信息。如果你安装CRH Stack中的Hive或者Oozie，他们也要求一个关系型数据库。\n下表展示了Ambari的数据库要求：\n\n数据库 | 版本\n---|---\nPostgreSQL | 9.1.13+，9.3，9.4***\nMariaDB | 10.1*\nMySQL | 5.6****\nOracle | 11gr2，12c**\n\n> 注意：默认情况下，Ambari在Ambari Server主机自动安装一个PostgreSQL实例。可以选择已存在的PostgreSQL，MySQL 或者 Oracle 实例。\n**建议使用Ambari默认安装的PostgreSQL数据库。**\n\n> 重要：Ambari port是8080，应避免该端口被占用。如果想要更改Ambari port，请参考Ambari管理员手册。\n\n\n### 内存要求\nAmbari主机应该拥有至少 **1GB RAM，500MB 剩余空间**。\n在任意主机检查有效内存，运行：\n```\nfree -m\n```\n\n如果你计划在你的集群中安装Ambari Metrics Service(AMS)，你应该查看**Redoop Ambari Metrics配置向导**。一般来说，基于你的集群大小，你计划运行Ambari Metrics Collector的主机应该拥有下表所示的有效内存和磁盘空间：\n\n主机数量 | 有效内存 | 磁盘空间\n---|---|---\n1 | 1024 MB | 10GB\n10 | 1024 MB | 20GB\n50 | 2048 MB | 50GB\n100 | 4096 MB | 100GB\n300 | 4096 MB | 100GB\n500 | 8096 MB | 200GB\n1000 | 12288 MB | 200GB\n2000 | 16384 MB | 500GB\n\n> 注意：使用这些值作为参考指标，在你指定的环境中测试他们。\n\n\n### 包大小和索引(Inode)数量要求\n\nPackages | Size | Inodes\n---|---|---\nAmbari Server | 100MB | 5000\nAmbari Agent | 8MB | 1000\nAmbari Metrics Collector | 225MB | 4000\nAmbari Metrics Monitor | 1MB | 100\nAmbari Metrics Hadoop Sink | 8MB | 100\nAfter Ambari Server Setup | N/A | 4000\nAfter Ambari Server Start | N/A | 500\nAfter Ambari Agent Start | N/A | 200\n\n> 以上数据均为估算值。\n\n\n### 检查最大打开文件描述符(Maximum Open File Descriptors)\n推荐的打开文件描述符的最大数目是10000，或者更多。检查当前打开文件描述符的最大数目，在每台主机上执行以下命令：\n```\nulimit -Sn\nulimit -Hn\n```\n\n如果输出信息显示小于10000，运行以下命令将其设置到适合的值：\n```\nulimit -n 10000\n```\n\n\n\n## 收集信息\n### 在部署一个集群之前，你应该收集以下信息：\n- 在你的集群系统中的每一台主机的全限定域名（FQDN）。Ambari Cluster安装向导支持使用IP地址。你能检查或确认主机的FQDN，通过使用\n\n```\nhostname -f\n```\n> 可以在一个单机上部署所有组件，但是这只适用于初始评估的目的。典型地，你至少准备三台机器：一台master主机和两台slaves主机，作为一个最小化的集群。\n\n- 你想要在每台主机上设置的组件列表\n- 你想要用于存储的基础目录挂载点:\n  - NameNode 数据\n  - DataNodes 数据\n  - Secondary NameNode 数据\n  - Oozie 数据\n  - YARN 数据\n  - ZooKeeper 数据, 如果安装zookeeper\n  - 各种各样的 log, pid, 和 db 文件, 取决于你安装的类型\n> 你必须使用基础目录来为你的组件和Hadoop数据提供持续存储。在一个可能从主机中移除的位置安装组件可能导致集群失败或者数据丢失。例如，不要使用 **/tmp** 作为基础目录路径。\n\n\n\n## 准备环境\n使用Ambari部署你的Redoop CRH stack，你需要准备你的部署环境：\n- 设置免密 SSH\n- 设置服务用户账户\n- 在Cluster和Browser主机激活NTP\n- 检查DNS和NSCD\n- 配置防火墙\n- 关闭SELinux和PackageKit，并检查umask值\n- 下载并设置数据库连接器\n\n### 设置免密 SSH\n**关于这个任务**\n\n为了让Ambari Server在你的所有集群主机上安装Ambari Agents，你必须在Ambari Server主机和集群中所有其他主机之间设置免密连接。Ambari Server主机使用SSH公钥验证去远程访问并安装Ambari Agent。\n\n> 注意：你能选择在集群每个主机上手动安装Ambari Agent。在这种情况下，你不需要生成和分发SSH密钥。\n\n**步骤**\n1. 在Ambari Server主机上生成公钥和私钥。\n\n```\nssh-keygen\n```\n2. 拷贝SSH公钥（id_rsa.pub）到你的目标主机的root账户。\n\n```\n.ssh/id_rsa.pub\n```\n3. 添加SSH公钥到你的目标主机的authorized_keys文件。\n\n```\ncat id_rsa.pub >> authorized_keys\n```\n4. 取决于你的SSH版本，你可能需要在目标主机上设置 .ssh 目录权限为 700 并设置 .ssh 目录下的 authorized_keys 文件权限为 600。\n\n```\nchmod 700 ~/.ssh\n```\n```\nchmod 600 ~/.ssh/authorized_keys\n```\n5. 确认你能从Ambari Server主机使用SSH免密连接到集群中的每一台主机。\n\n```\nssh root@<remote.target.host>\n```\n6. 如果在你第一次连接时，出现下面警告信息，输入 **yes**：\n\n```\nAre you sure you want to continue connecting (yes/no)?\n```\n7. 在你想要运行基于web的Ambari安装向导的机器上保留一个SSH私钥的复制文件。\n> 注意：可以使用一个非root账户，如果那个账户可以不用输入密码执行 **sudo**。\n\n\n### 设置服务用户账户\n每个服务要求一个服务用户账户。Ambari Cluster安装向导创建新的并保留任何存在的服务用户账户，并使用这些账户配置Hadoop服务。创建的服务用户账户应用到本地操作系统上的服务用户账户和LDAP/AD账户。\n\n\n### 在Cluster和Browser主机激活NTP\n包括你集群中的每个节点和你用于访问Ambari Web的机器，这些主机彼此之间必须保持时钟同步。\n安装NTP服务，并保证开机启动。在每台主机上运行以下命令：\n\n**RHEL/CentOS/Oracle 6**\n```\nyum install -y ntp\nchkconfig ntpd on\n```\n**RHEL/CentOS/Oracle 7**\n```\nyum install -y ntp\nsystemctl enable ntpd\n```\n**Ubuntu**\n```\napt-get install ntp\nupdate-rc.d ntp defaults\n```\n**Kylin**\n```\napt-get install ntp\nupdate-rc.d ntp defaults\n```\n\n\n### 检查DNS和NSCD\n**编辑主机hosts文件**\n1. 使用编辑器，打开在你的集群中的每一台主机的hosts文件。例如：\n```\nvi /etc/hosts\n```\n2. 在打开的文件中，追加行，行内容有IP地址和FQDN组成。例如：\n```\n1.2.3.4 <fully.qualified.domain.name>\n```\n\n> 重要：不要从你的hosts文件中移除下列两行。移除或者编辑下列内容，可能造成各种各样的网络问题：\n```\n127.0.0.1 localhost.localdomain localhost\n::1 localhost6.localdomain6 localhost6\n```\n\n**设置主机名**\n1. 通过下述命令，确认主机名被设置，应该会返回你刚刚设置的<fully.qualified.domain.name>：\n```\nhostname -f\n```\n2. 在你的集群中每台机器上使用“hostname”命令设置主机名，例如：\n```\nhostname <fully.qualified.domain.name>\n```\n> 注意：在CentOS 7中，使用“**hostnamectl set-hostname <fully.qualified.domain.name>**”命令永久设置主机名，可跳过下一步操作。\n\n**编辑网络配置文件**\n1. 使用编辑器，在每台主机上打开网络配置文件，并为每台主机设置网络。例如：\n```\nvi /etc/sysconfig/network\n```\n2. 修改HOSTNAME属性来设置FQDN：\n```\nNETWORKING=yes\nHOSTNAME=<fully.qualified.domain.name>\n```\n\n### 配置iptables\n为了使Ambari能够和它部署和管理的主机进行沟通，确认port必须打开并可用。最早的方式是关闭iptables，如下：\n\n**RHEL/CentOS 6**\n```\nchkconfig iptables off\n/etc/init.d/iptables stop\n```\n**RHEL/CentOS 7**\n```\nsystemctl disable firewalld\n```\n**Ubuntu/Kylin**\n```\nsudo ufw disable\nsudo iptables -X\nsudo iptables -t nat -F\nsudo iptables -t nat -X\nsudo iptables -t mangle -F\nsudo iptables -t mangle -X\nsudo iptables -P INPUT ACCEPT\nsudo iptables -P FORWARD ACCEPT\nsudo iptables -P OUTPUT ACCEPT\n```\n\n在设置完成后，你能重启iptables。如果在你的环境中，安全协议阻止关闭iptables，那么在保持要求端口开放和有效的情况下，可以开启iptables。\n\nAmbari会在Ambari Server Setup过程中检查iptables是否在运行。如果iptables正在运行，会出现一个警告，提醒你检查要求的端口是开启并有效的。在集群安装向导的 **主机确认** 步骤，也会对开启iptables的主机发出警告信息。\n\n\n\n### 关闭SELinux和PackageKit，并检查umask值\n1. 为了使Ambari初始化起作用，你必须关闭SELinux。在你的集群中的每台主机，输入：\n```\nsetenforce 0\n```\n> 为了永久关闭SELinux，需要在/etc/selinux/config文件中设置**SELINUX=disabled**\n\n2. 在一个安装主机，运行安装有PackageKit的RHEL/CentOS系统时，使用编辑器打开/etc/ yum/pluginconf.d/refresh-packagekit.conf，做如下改变：\n```\nenabled=0\n```\n> 注意：默认情况下，在Debian, SLES, 或 Ubuntu 系统中，PackageKit是不被激活的。除非你主动激活PackageKit，否则你可以在安装Debian, SLES, 或 Ubuntu系统的主机上跳过这一步。\n\n3. UMASK (User Mask or User file creation MASK)设置默认权限或者基础权限授权，当在Linux上创建一个新文件或文件夹时。大多数Linux发行版设置022作为umask默认值。一个022的umask值为一个新文件或者文件夹授权755的读，写，执行权限。一个022的umask值为一个新文件或者文件夹授权750的读，写，执行权限。\n\nAmbari，CRH支持umask值022(等价于0022)和027(等价于0027)。这些值必须被设置到所有主机。\n\n**UMASK示例**\n\n为你的当前登录会话设置umask：\n```\numask 0022\n```\n检查你的当前umask：\n```\numask\n```\n永久改变所有交互用户的umask：\n```\necho umask 0022 >> /etc/profile\n```\n\n\n### 下载并设置数据库连接器\n像Hive，Ranger和Oozie这些组件要求一个可操作的数据库。在Hive这种情况中，安装期间，你可以选择使用存在的数据库或让Ambari安装一个新的实例。对于Ambari去连接到你选择的数据库，在安装之前，你必须下载必要的数据库驱动和连接器。为了更好的为你的安装或升级作准备，在你的环境中设置数据库连接器。\n\n\n\n# 设置 Repository\n## 获取 Public Repositories\n访问我们的[Public Repository](http://www.redoop.com/front/redoopCRH)，选择合适repository，点击 **下载** 按钮，获取 **repository URL** 。我们也提供了仓库tar包用于下载，访问[Redoop CRH Repositories](http://archive.redoop.com/CRH)，选择合适的CPU架构以及操作系统的仓库tar包进行下载。\n\n## 使用 Local Repository\n如果你的企业集群限制外网访问，你应该考虑使用一个local repository，这使你体验到更多的治理和更好的安装性能。你也能使用一个local repository,为一个集群安装后的操作，比如service的启动和重启操作。使用一个local repository包括获取public repositories，设置repository用于无网络访问或者限制网络访问的环境，和准备Ambari repository配置文件去使用你的新的local repository。\n\n### 设置一个Local Repository\n下载repository tar包，将其放置到你的集群的源服务器上，解压tar包，创建repository。\n\n#### 为设置一个Local Repository做准备\n在设置你的local repository之前，你必须确定满足需求。\n- 选择一个存在的在集群内部或者集群可访问的服务器作为mirror服务器，运行一个其支持的操作系统。\n- 激活你的集群中所有主机与mirror服务器之间的网络访问。\n- 确认mirror服务器安装了一个包管理器，比如 yum (RHEL, CentOS, 和 Oracle Linux), zypper (SLES), 或者 apt-get (Debian 和 Ubuntu)。\n- mirror服务器需要临时访问网络，用来安装一些必要的工具。例如，你使用yum包管理器，安装你的工具：\n```\nyum install yum-utils createrepo\n```\n在满足这些要求后，你就可以按照步骤准备设置你的local repository了。\n\n**步骤**\n1. 创建一个HTTP服务：\n   1. 在mirror服务器上，按照Apache社区网站提供的教程安装一个HTTP服务(比如Apache httpd)。\n   2. 启动并激活服务。\n   3. 确认防火墙设置允许你的集群主机可以访问你的mirror服务器的HTTP服务。\n2. 在你的mirror服务器上为你的web服务创建目录：\n   - 例如，从shell窗口，键入：**mkdir -p /var/www/html/**。\n   - 如果你正在使用一个软链，在你的web服务器上激活 **followsymlinks**。\n3. 创建一个local repository\n   1. 将下载的repository tar包，解压到 **/var/www/html/** 下的指定目录或者软链源目录\n   2. 使用createrepo创建repository repodata信息\n\n\n## 准备Ambari Repository配置文件使用Repository\n**步骤**\n1. 创建并编辑ambari.repo文件，键入以下内容，**<Repository URL>** 替换成 **public repository URL** 或者你的 **local repository URL** 的访问地址：\n```\n[Redoop]\nname=Ambari\nbaseurl=<Repository URL>\ngpgcheck=0\nenabled=1\n```\n\n2. 放置ambari.repo到你的准备安装Ambari Server的主机上\n   1. RHEL/CentOS/Oracle Linux: /etc/yum.repos.d/ambari.repo\n   2. Debain/Ubuntu: /etc/apt/sources.list.d/ambari.list\n\n3. 编辑 **/etc/yum/pluginconf.d/priorities.conf** 文件，添加下列值：\n```\n[main]\nenabled=1\ngpgcheck=0\n```\n\n\n\n# 安装Ambari\n安装Ambari Server到你的集群中的一台主机上，完成下列步骤：\n- 安装 Ambari Server\n- Setup Ambari Server\n\n## 安装 Ambari Server\n根据你的包管理器工具，在你选择的主机的命令行窗口执行安装命令。\n\n包管理器 | 安装命令\n---|---\nyum | yum -y install ambari-server\napt | apt-get -y install ambari-server\n\n\n## Setup Ambari Server\n在启动Ambari Server之前，你 **必须** setup Ambari Server。Setup 配置Ambari信息到Ambari database，安装JDK并允许你自定义运行Ambari Server守护进程的用户。\n\n在你的Ambari主机上运行下面的命令，启动 setup 过程：\n```\nambari-server setup\n```\n\nsetup返回信息：\n1. 如果你没有临时关闭SELinux，你可能得到一个警告。接受默认选项(**y**)，并继续。\n2. 默认情况下，Ambari Server以root用户权限运行。接受ambari-server守护进程的 **Customize user account** 的默认选项(**n**)，继续使用root用户权限。如果你想要创建一个不同的用户或者指定一个之前创建的用户来运行Ambari Server，则在 **Customize user account** 选项选择 **y**，然后提供一个用户名。\n3. 如果你临时关闭iptables，你可能得到一个警告。选择 **y** 继续。\n4. 选择JDK版本。建议选择 **Custom JDK**，然后指定你自定义的 **JAVA_HOME**，另外，你可以选择 **1** 去下载 Oracle JDK 1.8。\n> 注意：JDK版本选择依赖于你的Stack版本，请根据Stack版本准备合适的JDK版本。默认情况下，Ambari Server setup 会下载 Oracle JDK 1.8 并附带 Java Cryptography Extension (JCE) Policy Files。\n5. 如果选择使用默认下载的 Oracle JDK 1.8，你必须接受Oracle的license。JDK会在部署阶段安装。\n6. 检查GPL license同意。为了明确地激活Ambari去下载并安装LZO数据压缩库，你必须回复 **y**。如果你回复 **n**，Ambari将不会自动在你的集群中的任何主机中安装LZO。在这种情况下，你必须确认LZO被安装并被合理配置。如果没有安装并配置LZO，LZO数据压缩库将不是可读的。如果你不想Ambari自动下载并安装LZO，你必须确认你的选择去继续。\n7. 在 **Enter advanced database configuration** 选择 **n** 去为Ambari使用默认的内嵌PostgreSQL数据库。默认PostgreSQL数据库的name是 **ambari**。默认用户名和密码是 **ambari/bigdata**。另外，选择 **y**，可以使用存在的 PostgreSQL, MySQL/MariaDB 或者 Oracle 数据库。如果你使用存在的 PostgreSQL, MySQL/MariaDB 或者 Oracle 数据库实例，使用下列返回信息之一：\n   - 使用一个存在的Oracle实例，选择你拥有的数据库name，用户名和密码，选择 **2**。选择你想要使用的数据库并提供任何要求的信息，包括主机name, port, Service Name 或者 SID, user name, 和 password。\n   - 使用一个存在的MySQL/MariaDB数据库，选择你拥有的数据库name，用户名和密码，选择 **3**。选择你想要使用的数据库并提供任何要求的信息，包括主机name, port, database name, user name, 和 password。\n   - 使用一个存在的PostgreSQL数据库，选择你拥有的数据库name，用户名和密码，选择 **4**。选择你想要使用的数据库并提供任何要求的信息，包括主机name, port, database name, user name, 和 password。\n\n> 在运行 setup 和选择 **Enter advanced database configuration** 时， 你必须准备一个存在的数据库实例。不支持 Microsoft SQL Server 或者 SQL Anywhere 选项。\n\n8. 在 **Proceed with configuring remote database connection properties [y/n]** 选择 **y**。\n9. Setup 完成。\n\n> 注意：如果你的主机使用代理服务器访问网络，你必须配置 Ambari Server 去使用这个代理服务器。\n\n\n\n# 使用Management Packs\nManagement packs允许你部署一种services到你的 Ambari-managed 集群。你能使用management pack去部署一个指定的组件或者service，或者部署一个完全的平台。\n\n通常来说，使用management packs，你需要做下列工作：\n1. 安装 management pack。\n2. 更新 Ambari 中的 repository URL。\n3. 启动 Ambari Server。\n4. 开始 Ambari 安装向导。\n\n\n\n# 安装，配置并部署一个集群\n使用运行在你的浏览器上的 **Ambari集群安装向导** 去安装，配置并部署你的集群，如下：\n- 启动 Ambari Server\n- 登陆 Ambari\n- 开始 Ambari 安装向导\n- 命名你的集群\n- 选择版本\n- 安装选项\n- 确认主机\n- 选择服务\n- 分配 Master\n- 分配 Slaves 和 Clients\n- 定制服务\n- 核查\n- 安装，启动并测试\n- 概要\n\n## 启动 Ambari Server\n- 在 Ambari 主机运行下述命令启动\n```\nambari-server start\n```\n- 检查 Ambari Server 进程\n```\nambari-server status\n```\n- 停止 Ambari Server\n```\nambari-server stop\n```\n\n> 注意：如果你计划为Hive或者Oozie使用一个存在的数据库实例，你必须在安装你的Hadoop集群**之前**准备去用一个存在的数据库。\n\n在 Ambari Server 启动中，Ambari 运行一个统一的数据库检查来寻找问题。如果找到任何问题，Ambari Server 启动将终止并显示以下信息：\n```\nDB configs consistency check failed\n```\n\nAmbari 将数据库检查结果的更多细节写进 **/var/log/ambari-server/ambari-server-check- database.log** 文件。\n\n你可以跳过数据库检查，强制启动 Ambari Server，操作如下：\n```\nambari-server start --skip-database-check\n```\n\n如果你有数据问题，通过选择跳过这个检查，不要对你的集群做任何更改或者升级，直到你矫正了数据统一性问题。\n\n\n## 登陆 Ambari\n**要求**\n\nAmbari Server 必须正在运行。\n\n使用一个web浏览器登陆 Ambari Web。\n\n**步骤**\n1. 在你的web浏览器访问：\n```\nhttp://<your.ambari.server>:8080\n```\n<your.ambari.server> 是你的 Ambari 服务主机名，也可以直接使用 IP。例如，默认的 Ambari 主机位于 http://\nc6401.ambari.apache.org:8080 。\n\n2. 使用默认用户名/密码：admin/admin，登陆Ambari Server。你之后可以改变这些信息。对于一个新集群，集群安装向导展示一个欢迎页面。\n\n\n## 开始 Ambari 安装向导\n在 Ambari欢迎页面，选择 **启动安装向导**。\n![image](https://github.com/Xingwd/picture/raw/master/ambari/install/%E5%90%AF%E5%8A%A8%E5%AE%89%E8%A3%85%E5%90%91%E5%AF%BC.png)\n\n\n## 命名你的集群\n**步骤**\n1. 在 **开始** 页面，命名你的集群，不可在名字中使用空格和特殊字符。\n2. 选择 **下一步**\n\n\n## 选择版本\n在这一步，你将选择软件版本和repository URL。\n\n**选择 Stack**\n\n有效Stack被展示出来，当你选择一个Stack，其有效的服务和服务版本列出来。\n\n![image](https://github.com/Xingwd/picture/raw/master/ambari/install/%E9%80%89%E6%8B%A9Stack.png)\n\n**选择 Version**\n\n每个Stack可以拥有多个版本，通常会展示默认版本的服务列表信息。\n\n![image](https://github.com/Xingwd/picture/raw/master/ambari/install/%E9%80%89%E6%8B%A9Version.png)\n\n**选择 Repositories**\n\n这里可以选择公共仓库(Public repository)和本地仓库(Local Repository)，公共仓库适用于有网络的环境，本地仓库适用于无网络或者网络受限的环境。然后根据你的集群主机的操作系统选择对应的操作系统，填写 **Base URL**。\n\n![image](https://github.com/Xingwd/picture/raw/master/ambari/install/%E9%80%89%E6%8B%A9Repositories.png)\n\n有两个高级repository选项是有效的，通常不会用到。\n- 跳过仓库URL地址验证(高级)：当你点击 **下一步** 时，Ambari会连接repository Base URLs并验证其有效性。如果验证无效，则提示你继续之前必须确认。勾选此选项可以跳过验证。\n- 使用RedHat Satellite/Spacewalk：这个选择只有你在使用本地仓库时，才会被激活。当你为软件repositories选择这个选项，你负责在Satellite/Spacewalk中配置repository途径，并确认为选择的 **stack version** 的repository在集群主机上是有效的。\n\n\n## 安装选项\n为了构建起一个集群，集群安装向导需要一些信息。你需要提供你的每台主机的FQDN。向导也需要你设置免密SSH的私钥。使用主机名和密钥信息，向导能够定位，访问并安全交互集群中的主机。\n\n**步骤**\n1. 在 **目标主机**，输入你的主机名列表，每行一个。你能使用方括号指定大量的主机。例如，host01.domain到host10.domain使用host[01-10].domain。\n2. 如果你想要让Ambari使用SSH在你所有主机上的自动安装Ambari Agent，选择 **请提供您的 SSH私钥 用于自动注册主机** ，然后选择文件或者将私钥信息粘贴到文本框中。\n3. 输入你已经选择的SSH key的用户名。如果你不想要用root，那么你必须提供一个拥有免密sudo权限的用户。如果你的SSH端口不是22，那么修改成你设置的端口号。\n4. 如果你不想要Ambari自动安装Ambari Agent，选择 **执行 手动注册 在主机上 不使用SSH**。\n5. 选择 **注册并确认** 以继续。\n\n\n## 确认主机\n**确认主机** 这一步，Ambari会定位你的集群主机并检查这些主机确认他们有正确目录，包，并请求继续安装。\n\n如果任何主机出现错误，你能通过 **删除** 按钮移除他们。\n\n在屏幕的底部，你可能注意到一些警告，这些警告在检查过程中会偶然遇到。例如，你的主机已经有一个 **wget** 或者 **curl** 的拷贝。选择 **点击这里查看警告** 去查看警告细节。警告页也提供一个能帮助你明白任何你可能偶遇的问题的python脚本并让你运行：\n```\nRerun Checks\n```\n\n当你满意了主机列表，选择 **下一步**。\n\n\n## 选择服务\n基于在 **选择Stack** 步骤选择的Stack，你能看到可安装到集群的services的选择。一个Stack包含许多services。你可以选择安装任何有效的services，或者在之后添加services。集群安装向导默认选择所有有效的services。\n\n从CRH6开始，默认CRH Stack只包含几个基础services，如果想要安装其他services，需要购买其他CRH services mpacks(如 crh-DW-mpack)。\n\n点击服务复选框可以选中服务，再次点击复选框可以取消选中。在选择好服务后，选择 **下一步** 进行安装。\n\n![image](https://github.com/Xingwd/picture/raw/master/ambari/install/%E9%80%89%E6%8B%A9Services.png)\n\n\n## 分配 Master\n集群安装向导为选中的services分配master组件到你的集群中的合适的主机，并在 **分配Masters** 展示分配详情。右边展示services和当前主机。左边展示当前master组件被分配的主机，标示每台主机的CPU核数和内存大小。\n\n1. 为一个services改变主机分配，为那个service从下拉菜单选择一个主机名。\n2. 当你满意了分配，选择 **下一步**。\n\n\n## 分配 Slaves 和 Clients\n集群安装向导分配slave组件，像 Datanodes，NodeManagers，和 RegionServers，到你的集群中的合适的主机。它也可以规划选择主机去安装clients。\n\n**步骤**\n1. 使用 **all** 或者 **none** 去选中某列的所有主机或者取消某列中选中的主机。\n2. 使用复选框选择指定的主机。\n3. 当你满意了分配，选择 **下一步**。\n\n\n## 定制服务\n在这一步，你可以对你选择的services进行配置，当然也可以直接使用默认配置。当时 **Passwords** 配置项必须由你来进行配置。\n\n\n## 核查\n这一步展示你的分配方案，检查并确认所有信息是准确的。如果你需要做改变，使用左边的选项返回分配步骤进行重新分配。\n\n要打印你的信息作为以后参考，选择 **打印**。\n\n当你满意了你的选择，选择 **部署**。\n\n\n## 安装，启动并测试\n这一步会安装选中的services的软件包，启动服务并测试。\n\n\n## 概要\n这一步完成的任务的总览，选择 **完成**，进入Ambari Web，可以看到已安装的services。 ', '0', '<h1 id=\"h1-u51C6u5907\"><a name=\"准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>准备</h1><h2 id=\"h2-crh-cpu-\"><a name=\"CRH版本与CPU架构\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>CRH版本与CPU架构</h2><p>CRH不同的版本支持的CPU架构情况不同，下面的表格描述了这些信息：</p>\n<p>S = 支持</p>\n<table>\n<thead>\n<tr>\n<th>CRH</th>\n<th>x86</th>\n<th>ppc64le</th>\n<th>aarch64</th>\n<th>sw64</th>\n<th>mips64el</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>5.0</td>\n<td>S</td>\n<td>S</td>\n<td>S</td>\n<td>S</td>\n<td></td>\n</tr>\n<tr>\n<td>5.1</td>\n<td>S</td>\n<td>S</td>\n<td>S</td>\n<td></td>\n</tr>\n<tr>\n<td>6.1</td>\n<td>S</td>\n<td>S</td>\n<td>S</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"h2-u6700u5C0Fu7CFBu7EDFu8981u6C42\"><a name=\"最小系统要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>最小系统要求</h2><h3 id=\"h3-u6D4Fu89C8u5668u8981u6C42\"><a name=\"浏览器要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>浏览器要求</h3><p>Ambari安装向导作为一个基于浏览器的web应用程序运行。为了运行这个工具，你必须有一台运行图形化浏览器的机器。不同操作系统最低浏览器版本要求如下：</p>\n<table>\n<thead>\n<tr>\n<th>Operating System</th>\n<th>Browser</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Linux</td>\n<td>Chrome 56.0.2924.87, 57.0.2987; Firefox 51, 52</td>\n</tr>\n<tr>\n<td>Mac OS X</td>\n<td>Chrome 56.0.2924.87, 57.0.2987; Firefox 51, 52; Safari 10.0.1, 10.0.3</td>\n</tr>\n<tr>\n<td>Windows*</td>\n<td>Chrome 56.0.2924.87, 57.0.2987; Edge 38; Firefox 51.0.1, 52.0; Internet Explorer 10, 11</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>在任何平台，我们建议你更新浏览器到最新版本</p>\n</blockquote>\n<h3 id=\"h3-u8F6Fu4EF6u8981u6C42\"><a name=\"软件要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>软件要求</h3><p>在你的集群中的每一台主机：</p>\n<ul>\n<li><strong>yum</strong> 和 <strong>rpm</strong> (RHEL/CentOS/Oracle Linux)</li><li><strong>apt</strong> (Ubuntu/Kylin)</li><li><strong>scp</strong>, <strong>curl</strong>, <strong>unzip</strong>, <strong>tar</strong>, 和 <strong>wget</strong></li><li><strong>OpenSSL</strong> (v1.01, build 16 or later)</li><li><strong>Python</strong><ul>\n<li>Python 2.7.x (CentOS 7, Ubuntu 16)</li></ul>\n</li></ul>\n<h3 id=\"h3-jdk-\"><a name=\"JDK 要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>JDK 要求</h3><table>\n<thead>\n<tr>\n<th>CPU架构</th>\n<th>JDK</th>\n<th>版本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>x86</td>\n<td>Oracle</td>\n<td>JDK 8, 64-bit (最低 JDK 1.8.0_77), default</td>\n</tr>\n<tr>\n<td>ppc64le</td>\n<td>Open Source</td>\n<td>JDK8+</td>\n</tr>\n<tr>\n<td>aarch64</td>\n<td>Open Source</td>\n<td>JDK8+</td>\n</tr>\n<tr>\n<td>sw64</td>\n<td>Open Source</td>\n<td>JDK8+</td>\n</tr>\n<tr>\n<td>mips64el</td>\n<td>Open Source</td>\n<td>JDK8+</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>JDK 版本选择取决于你选择的CRH Stack。</p>\n</blockquote>\n<h3 id=\"h3-u6570u636Eu5E93u8981u6C42\"><a name=\"数据库要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>数据库要求</h3><p>Ambari要求使用一个关系型数据库存储集群配置和拓扑信息。如果你安装CRH Stack中的Hive或者Oozie，他们也要求一个关系型数据库。<br>下表展示了Ambari的数据库要求：</p>\n<table>\n<thead>\n<tr>\n<th>数据库</th>\n<th>版本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>PostgreSQL</td>\n<td>9.1.13+，9.3，9.4<em>*</em></td>\n</tr>\n<tr>\n<td>MariaDB</td>\n<td>10.1*</td>\n</tr>\n<tr>\n<td>MySQL</td>\n<td>5.6<em>**</em></td>\n</tr>\n<tr>\n<td>Oracle</td>\n<td>11gr2，12c**</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>注意：默认情况下，Ambari在Ambari Server主机自动安装一个PostgreSQL实例。可以选择已存在的PostgreSQL，MySQL 或者 Oracle 实例。<br><strong>建议使用Ambari默认安装的PostgreSQL数据库。</strong></p>\n<p>重要：Ambari port是8080，应避免该端口被占用。如果想要更改Ambari port，请参考Ambari管理员手册。</p>\n</blockquote>\n<h3 id=\"h3-u5185u5B58u8981u6C42\"><a name=\"内存要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>内存要求</h3><p>Ambari主机应该拥有至少 <strong>1GB RAM，500MB 剩余空间</strong>。<br>在任意主机检查有效内存，运行：</p>\n<pre><code>free -m\n</code></pre><p>如果你计划在你的集群中安装Ambari Metrics Service(AMS)，你应该查看<strong>Redoop Ambari Metrics配置向导</strong>。一般来说，基于你的集群大小，你计划运行Ambari Metrics Collector的主机应该拥有下表所示的有效内存和磁盘空间：</p>\n<table>\n<thead>\n<tr>\n<th>主机数量</th>\n<th>有效内存</th>\n<th>磁盘空间</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>1024 MB</td>\n<td>10GB</td>\n</tr>\n<tr>\n<td>10</td>\n<td>1024 MB</td>\n<td>20GB</td>\n</tr>\n<tr>\n<td>50</td>\n<td>2048 MB</td>\n<td>50GB</td>\n</tr>\n<tr>\n<td>100</td>\n<td>4096 MB</td>\n<td>100GB</td>\n</tr>\n<tr>\n<td>300</td>\n<td>4096 MB</td>\n<td>100GB</td>\n</tr>\n<tr>\n<td>500</td>\n<td>8096 MB</td>\n<td>200GB</td>\n</tr>\n<tr>\n<td>1000</td>\n<td>12288 MB</td>\n<td>200GB</td>\n</tr>\n<tr>\n<td>2000</td>\n<td>16384 MB</td>\n<td>500GB</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>注意：使用这些值作为参考指标，在你指定的环境中测试他们。</p>\n</blockquote>\n<h3 id=\"h3--inode-\"><a name=\"包大小和索引(Inode)数量要求\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>包大小和索引(Inode)数量要求</h3><table>\n<thead>\n<tr>\n<th>Packages</th>\n<th>Size</th>\n<th>Inodes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ambari Server</td>\n<td>100MB</td>\n<td>5000</td>\n</tr>\n<tr>\n<td>Ambari Agent</td>\n<td>8MB</td>\n<td>1000</td>\n</tr>\n<tr>\n<td>Ambari Metrics Collector</td>\n<td>225MB</td>\n<td>4000</td>\n</tr>\n<tr>\n<td>Ambari Metrics Monitor</td>\n<td>1MB</td>\n<td>100</td>\n</tr>\n<tr>\n<td>Ambari Metrics Hadoop Sink</td>\n<td>8MB</td>\n<td>100</td>\n</tr>\n<tr>\n<td>After Ambari Server Setup</td>\n<td>N/A</td>\n<td>4000</td>\n</tr>\n<tr>\n<td>After Ambari Server Start</td>\n<td>N/A</td>\n<td>500</td>\n</tr>\n<tr>\n<td>After Ambari Agent Start</td>\n<td>N/A</td>\n<td>200</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>以上数据均为估算值。</p>\n</blockquote>\n<h3 id=\"h3--maximum-open-file-descriptors-\"><a name=\"检查最大打开文件描述符(Maximum Open File Descriptors)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>检查最大打开文件描述符(Maximum Open File Descriptors)</h3><p>推荐的打开文件描述符的最大数目是10000，或者更多。检查当前打开文件描述符的最大数目，在每台主机上执行以下命令：</p>\n<pre><code>ulimit -Sn\nulimit -Hn\n</code></pre><p>如果输出信息显示小于10000，运行以下命令将其设置到适合的值：</p>\n<pre><code>ulimit -n 10000\n</code></pre><h2 id=\"h2-u6536u96C6u4FE1u606F\"><a name=\"收集信息\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>收集信息</h2><h3 id=\"h3--\"><a name=\"在部署一个集群之前，你应该收集以下信息：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在部署一个集群之前，你应该收集以下信息：</h3><ul>\n<li>在你的集群系统中的每一台主机的全限定域名（FQDN）。Ambari Cluster安装向导支持使用IP地址。你能检查或确认主机的FQDN，通过使用</li></ul>\n<pre><code>hostname -f\n</code></pre><blockquote>\n<p>可以在一个单机上部署所有组件，但是这只适用于初始评估的目的。典型地，你至少准备三台机器：一台master主机和两台slaves主机，作为一个最小化的集群。</p>\n</blockquote>\n<ul>\n<li>你想要在每台主机上设置的组件列表</li><li>你想要用于存储的基础目录挂载点:<ul>\n<li>NameNode 数据</li><li>DataNodes 数据</li><li>Secondary NameNode 数据</li><li>Oozie 数据</li><li>YARN 数据</li><li>ZooKeeper 数据, 如果安装zookeeper</li><li>各种各样的 log, pid, 和 db 文件, 取决于你安装的类型<blockquote>\n<p>你必须使用基础目录来为你的组件和Hadoop数据提供持续存储。在一个可能从主机中移除的位置安装组件可能导致集群失败或者数据丢失。例如，不要使用 <strong>/tmp</strong> 作为基础目录路径。</p>\n</blockquote>\n</li></ul>\n</li></ul>\n<h2 id=\"h2-u51C6u5907u73AFu5883\"><a name=\"准备环境\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>准备环境</h2><p>使用Ambari部署你的Redoop CRH stack，你需要准备你的部署环境：</p>\n<ul>\n<li>设置免密 SSH</li><li>设置服务用户账户</li><li>在Cluster和Browser主机激活NTP</li><li>检查DNS和NSCD</li><li>配置防火墙</li><li>关闭SELinux和PackageKit，并检查umask值</li><li>下载并设置数据库连接器</li></ul>\n<h3 id=\"h3--ssh\"><a name=\"设置免密 SSH\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>设置免密 SSH</h3><p><strong>关于这个任务</strong></p>\n<p>为了让Ambari Server在你的所有集群主机上安装Ambari Agents，你必须在Ambari Server主机和集群中所有其他主机之间设置免密连接。Ambari Server主机使用SSH公钥验证去远程访问并安装Ambari Agent。</p>\n<blockquote>\n<p>注意：你能选择在集群每个主机上手动安装Ambari Agent。在这种情况下，你不需要生成和分发SSH密钥。</p>\n</blockquote>\n<p><strong>步骤</strong></p>\n<ol>\n<li>在Ambari Server主机上生成公钥和私钥。</li></ol>\n<pre><code>ssh-keygen\n</code></pre><ol>\n<li>拷贝SSH公钥（id_rsa.pub）到你的目标主机的root账户。</li></ol>\n<pre><code>.ssh/id_rsa.pub\n</code></pre><ol>\n<li>添加SSH公钥到你的目标主机的authorized_keys文件。</li></ol>\n<pre><code>cat id_rsa.pub &gt;&gt; authorized_keys\n</code></pre><ol>\n<li>取决于你的SSH版本，你可能需要在目标主机上设置 .ssh 目录权限为 700 并设置 .ssh 目录下的 authorized_keys 文件权限为 600。</li></ol>\n<pre><code>chmod 700 ~/.ssh\n</code></pre><pre><code>chmod 600 ~/.ssh/authorized_keys\n</code></pre><ol>\n<li>确认你能从Ambari Server主机使用SSH免密连接到集群中的每一台主机。</li></ol>\n<pre><code>ssh root@&lt;remote.target.host&gt;\n</code></pre><ol>\n<li>如果在你第一次连接时，出现下面警告信息，输入 <strong>yes</strong>：</li></ol>\n<pre><code>Are you sure you want to continue connecting (yes/no)?\n</code></pre><ol>\n<li>在你想要运行基于web的Ambari安装向导的机器上保留一个SSH私钥的复制文件。<blockquote>\n<p>注意：可以使用一个非root账户，如果那个账户可以不用输入密码执行 <strong>sudo</strong>。</p>\n</blockquote>\n</li></ol>\n<h3 id=\"h3-u8BBEu7F6Eu670Du52A1u7528u6237u8D26u6237\"><a name=\"设置服务用户账户\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>设置服务用户账户</h3><p>每个服务要求一个服务用户账户。Ambari Cluster安装向导创建新的并保留任何存在的服务用户账户，并使用这些账户配置Hadoop服务。创建的服务用户账户应用到本地操作系统上的服务用户账户和LDAP/AD账户。</p>\n<h3 id=\"h3--cluster-browser-ntp\"><a name=\"在Cluster和Browser主机激活NTP\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在Cluster和Browser主机激活NTP</h3><p>包括你集群中的每个节点和你用于访问Ambari Web的机器，这些主机彼此之间必须保持时钟同步。<br>安装NTP服务，并保证开机启动。在每台主机上运行以下命令：</p>\n<p><strong>RHEL/CentOS/Oracle 6</strong></p>\n<pre><code>yum install -y ntp\nchkconfig ntpd on\n</code></pre><p><strong>RHEL/CentOS/Oracle 7</strong></p>\n<pre><code>yum install -y ntp\nsystemctl enable ntpd\n</code></pre><p><strong>Ubuntu</strong></p>\n<pre><code>apt-get install ntp\nupdate-rc.d ntp defaults\n</code></pre><p><strong>Kylin</strong></p>\n<pre><code>apt-get install ntp\nupdate-rc.d ntp defaults\n</code></pre><h3 id=\"h3--dns-nscd\"><a name=\"检查DNS和NSCD\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>检查DNS和NSCD</h3><p><strong>编辑主机hosts文件</strong></p>\n<ol>\n<li>使用编辑器，打开在你的集群中的每一台主机的hosts文件。例如：<pre><code>vi /etc/hosts\n</code></pre></li><li>在打开的文件中，追加行，行内容有IP地址和FQDN组成。例如：<pre><code>1.2.3.4 &lt;fully.qualified.domain.name&gt;\n</code></pre></li></ol>\n<blockquote>\n<p>重要：不要从你的hosts文件中移除下列两行。移除或者编辑下列内容，可能造成各种各样的网络问题：</p>\n<pre><code>127.0.0.1 localhost.localdomain localhost\n::1 localhost6.localdomain6 localhost6\n</code></pre></blockquote>\n<p><strong>设置主机名</strong></p>\n<ol>\n<li>通过下述命令，确认主机名被设置，应该会返回你刚刚设置的&lt;fully.qualified.domain.name&gt;：<pre><code>hostname -f\n</code></pre></li><li>在你的集群中每台机器上使用“hostname”命令设置主机名，例如：<pre><code>hostname &lt;fully.qualified.domain.name&gt;\n</code></pre><blockquote>\n<p>注意：在CentOS 7中，使用“<strong>hostnamectl set-hostname &lt;fully.qualified.domain.name&gt;</strong>”命令永久设置主机名，可跳过下一步操作。</p>\n</blockquote>\n</li></ol>\n<p><strong>编辑网络配置文件</strong></p>\n<ol>\n<li>使用编辑器，在每台主机上打开网络配置文件，并为每台主机设置网络。例如：<pre><code>vi /etc/sysconfig/network\n</code></pre></li><li>修改HOSTNAME属性来设置FQDN：<pre><code>NETWORKING=yes\nHOSTNAME=&lt;fully.qualified.domain.name&gt;\n</code></pre></li></ol>\n<h3 id=\"h3--iptables\"><a name=\"配置iptables\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置iptables</h3><p>为了使Ambari能够和它部署和管理的主机进行沟通，确认port必须打开并可用。最早的方式是关闭iptables，如下：</p>\n<p><strong>RHEL/CentOS 6</strong></p>\n<pre><code>chkconfig iptables off\n/etc/init.d/iptables stop\n</code></pre><p><strong>RHEL/CentOS 7</strong></p>\n<pre><code>systemctl disable firewalld\n</code></pre><p><strong>Ubuntu/Kylin</strong></p>\n<pre><code>sudo ufw disable\nsudo iptables -X\nsudo iptables -t nat -F\nsudo iptables -t nat -X\nsudo iptables -t mangle -F\nsudo iptables -t mangle -X\nsudo iptables -P INPUT ACCEPT\nsudo iptables -P FORWARD ACCEPT\nsudo iptables -P OUTPUT ACCEPT\n</code></pre><p>在设置完成后，你能重启iptables。如果在你的环境中，安全协议阻止关闭iptables，那么在保持要求端口开放和有效的情况下，可以开启iptables。</p>\n<p>Ambari会在Ambari Server Setup过程中检查iptables是否在运行。如果iptables正在运行，会出现一个警告，提醒你检查要求的端口是开启并有效的。在集群安装向导的 <strong>主机确认</strong> 步骤，也会对开启iptables的主机发出警告信息。</p>\n<h3 id=\"h3--selinux-packagekit-umask-\"><a name=\"关闭SELinux和PackageKit，并检查umask值\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭SELinux和PackageKit，并检查umask值</h3><ol>\n<li><p>为了使Ambari初始化起作用，你必须关闭SELinux。在你的集群中的每台主机，输入：</p>\n<pre><code>setenforce 0\n</code></pre><blockquote>\n<p>为了永久关闭SELinux，需要在/etc/selinux/config文件中设置<strong>SELINUX=disabled</strong></p>\n</blockquote>\n</li><li><p>在一个安装主机，运行安装有PackageKit的RHEL/CentOS系统时，使用编辑器打开/etc/ yum/pluginconf.d/refresh-packagekit.conf，做如下改变：</p>\n<pre><code>enabled=0\n</code></pre><blockquote>\n<p>注意：默认情况下，在Debian, SLES, 或 Ubuntu 系统中，PackageKit是不被激活的。除非你主动激活PackageKit，否则你可以在安装Debian, SLES, 或 Ubuntu系统的主机上跳过这一步。</p>\n</blockquote>\n</li><li><p>UMASK (User Mask or User file creation MASK)设置默认权限或者基础权限授权，当在Linux上创建一个新文件或文件夹时。大多数Linux发行版设置022作为umask默认值。一个022的umask值为一个新文件或者文件夹授权755的读，写，执行权限。一个022的umask值为一个新文件或者文件夹授权750的读，写，执行权限。</p>\n</li></ol>\n<p>Ambari，CRH支持umask值022(等价于0022)和027(等价于0027)。这些值必须被设置到所有主机。</p>\n<p><strong>UMASK示例</strong></p>\n<p>为你的当前登录会话设置umask：</p>\n<pre><code>umask 0022\n</code></pre><p>检查你的当前umask：</p>\n<pre><code>umask\n</code></pre><p>永久改变所有交互用户的umask：</p>\n<pre><code>echo umask 0022 &gt;&gt; /etc/profile\n</code></pre><h3 id=\"h3-u4E0Bu8F7Du5E76u8BBEu7F6Eu6570u636Eu5E93u8FDEu63A5u5668\"><a name=\"下载并设置数据库连接器\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>下载并设置数据库连接器</h3><p>像Hive，Ranger和Oozie这些组件要求一个可操作的数据库。在Hive这种情况中，安装期间，你可以选择使用存在的数据库或让Ambari安装一个新的实例。对于Ambari去连接到你选择的数据库，在安装之前，你必须下载必要的数据库驱动和连接器。为了更好的为你的安装或升级作准备，在你的环境中设置数据库连接器。</p>\n<h1 id=\"h1--repository\"><a name=\"设置 Repository\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>设置 Repository</h1><h2 id=\"h2--public-repositories\"><a name=\"获取 Public Repositories\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>获取 Public Repositories</h2><p>访问我们的<a href=\"http://www.redoop.com/front/redoopCRH\">Public Repository</a>，选择合适repository，点击 <strong>下载</strong> 按钮，获取 <strong>repository URL</strong> 。我们也提供了仓库tar包用于下载，访问<a href=\"http://archive.redoop.com/CRH\">Redoop CRH Repositories</a>，选择合适的CPU架构以及操作系统的仓库tar包进行下载。</p>\n<h2 id=\"h2--local-repository\"><a name=\"使用 Local Repository\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>使用 Local Repository</h2><p>如果你的企业集群限制外网访问，你应该考虑使用一个local repository，这使你体验到更多的治理和更好的安装性能。你也能使用一个local repository,为一个集群安装后的操作，比如service的启动和重启操作。使用一个local repository包括获取public repositories，设置repository用于无网络访问或者限制网络访问的环境，和准备Ambari repository配置文件去使用你的新的local repository。</p>\n<h3 id=\"h3--local-repository\"><a name=\"设置一个Local Repository\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>设置一个Local Repository</h3><p>下载repository tar包，将其放置到你的集群的源服务器上，解压tar包，创建repository。</p>\n<h4 id=\"h4--local-repository-\"><a name=\"为设置一个Local Repository做准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>为设置一个Local Repository做准备</h4><p>在设置你的local repository之前，你必须确定满足需求。</p>\n<ul>\n<li>选择一个存在的在集群内部或者集群可访问的服务器作为mirror服务器，运行一个其支持的操作系统。</li><li>激活你的集群中所有主机与mirror服务器之间的网络访问。</li><li>确认mirror服务器安装了一个包管理器，比如 yum (RHEL, CentOS, 和 Oracle Linux), zypper (SLES), 或者 apt-get (Debian 和 Ubuntu)。</li><li>mirror服务器需要临时访问网络，用来安装一些必要的工具。例如，你使用yum包管理器，安装你的工具：<pre><code>yum install yum-utils createrepo\n</code></pre>在满足这些要求后，你就可以按照步骤准备设置你的local repository了。</li></ul>\n<p><strong>步骤</strong></p>\n<ol>\n<li>创建一个HTTP服务：<ol>\n<li>在mirror服务器上，按照Apache社区网站提供的教程安装一个HTTP服务(比如Apache httpd)。</li><li>启动并激活服务。</li><li>确认防火墙设置允许你的集群主机可以访问你的mirror服务器的HTTP服务。</li></ol>\n</li><li>在你的mirror服务器上为你的web服务创建目录：<ul>\n<li>例如，从shell窗口，键入：<strong>mkdir -p /var/www/html/</strong>。</li><li>如果你正在使用一个软链，在你的web服务器上激活 <strong>followsymlinks</strong>。</li></ul>\n</li><li>创建一个local repository<ol>\n<li>将下载的repository tar包，解压到 <strong>/var/www/html/</strong> 下的指定目录或者软链源目录</li><li>使用createrepo创建repository repodata信息</li></ol>\n</li></ol>\n<h2 id=\"h2--ambari-repository-repository\"><a name=\"准备Ambari Repository配置文件使用Repository\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>准备Ambari Repository配置文件使用Repository</h2><p><strong>步骤</strong></p>\n<ol>\n<li><p>创建并编辑ambari.repo文件，键入以下内容，<strong>&lt;Repository URL&gt;</strong> 替换成 <strong>public repository URL</strong> 或者你的 <strong>local repository URL</strong> 的访问地址：</p>\n<pre><code>[Redoop]\nname=Ambari\nbaseurl=&lt;Repository URL&gt;\ngpgcheck=0\nenabled=1\n</code></pre></li><li><p>放置ambari.repo到你的准备安装Ambari Server的主机上</p>\n<ol>\n<li>RHEL/CentOS/Oracle Linux: /etc/yum.repos.d/ambari.repo</li><li>Debain/Ubuntu: /etc/apt/sources.list.d/ambari.list</li></ol>\n</li><li><p>编辑 <strong>/etc/yum/pluginconf.d/priorities.conf</strong> 文件，添加下列值：</p>\n<pre><code>[main]\nenabled=1\ngpgcheck=0\n</code></pre></li></ol>\n<h1 id=\"h1--ambari\"><a name=\"安装Ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装Ambari</h1><p>安装Ambari Server到你的集群中的一台主机上，完成下列步骤：</p>\n<ul>\n<li>安装 Ambari Server</li><li>Setup Ambari Server</li></ul>\n<h2 id=\"h2--ambari-server\"><a name=\"安装 Ambari Server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装 Ambari Server</h2><p>根据你的包管理器工具，在你选择的主机的命令行窗口执行安装命令。</p>\n<table>\n<thead>\n<tr>\n<th>包管理器</th>\n<th>安装命令</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>yum</td>\n<td>yum -y install ambari-server</td>\n</tr>\n<tr>\n<td>apt</td>\n<td>apt-get -y install ambari-server</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"h2-setup-ambari-server\"><a name=\"Setup Ambari Server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Setup Ambari Server</h2><p>在启动Ambari Server之前，你 <strong>必须</strong> setup Ambari Server。Setup 配置Ambari信息到Ambari database，安装JDK并允许你自定义运行Ambari Server守护进程的用户。</p>\n<p>在你的Ambari主机上运行下面的命令，启动 setup 过程：</p>\n<pre><code>ambari-server setup\n</code></pre><p>setup返回信息：</p>\n<ol>\n<li>如果你没有临时关闭SELinux，你可能得到一个警告。接受默认选项(<strong>y</strong>)，并继续。</li><li>默认情况下，Ambari Server以root用户权限运行。接受ambari-server守护进程的 <strong>Customize user account</strong> 的默认选项(<strong>n</strong>)，继续使用root用户权限。如果你想要创建一个不同的用户或者指定一个之前创建的用户来运行Ambari Server，则在 <strong>Customize user account</strong> 选项选择 <strong>y</strong>，然后提供一个用户名。</li><li>如果你临时关闭iptables，你可能得到一个警告。选择 <strong>y</strong> 继续。</li><li>选择JDK版本。建议选择 <strong>Custom JDK</strong>，然后指定你自定义的 <strong>JAVA_HOME</strong>，另外，你可以选择 <strong>1</strong> 去下载 Oracle JDK 1.8。<blockquote>\n<p>注意：JDK版本选择依赖于你的Stack版本，请根据Stack版本准备合适的JDK版本。默认情况下，Ambari Server setup 会下载 Oracle JDK 1.8 并附带 Java Cryptography Extension (JCE) Policy Files。</p>\n</blockquote>\n</li><li>如果选择使用默认下载的 Oracle JDK 1.8，你必须接受Oracle的license。JDK会在部署阶段安装。</li><li>检查GPL license同意。为了明确地激活Ambari去下载并安装LZO数据压缩库，你必须回复 <strong>y</strong>。如果你回复 <strong>n</strong>，Ambari将不会自动在你的集群中的任何主机中安装LZO。在这种情况下，你必须确认LZO被安装并被合理配置。如果没有安装并配置LZO，LZO数据压缩库将不是可读的。如果你不想Ambari自动下载并安装LZO，你必须确认你的选择去继续。</li><li>在 <strong>Enter advanced database configuration</strong> 选择 <strong>n</strong> 去为Ambari使用默认的内嵌PostgreSQL数据库。默认PostgreSQL数据库的name是 <strong>ambari</strong>。默认用户名和密码是 <strong>ambari/bigdata</strong>。另外，选择 <strong>y</strong>，可以使用存在的 PostgreSQL, MySQL/MariaDB 或者 Oracle 数据库。如果你使用存在的 PostgreSQL, MySQL/MariaDB 或者 Oracle 数据库实例，使用下列返回信息之一：<ul>\n<li>使用一个存在的Oracle实例，选择你拥有的数据库name，用户名和密码，选择 <strong>2</strong>。选择你想要使用的数据库并提供任何要求的信息，包括主机name, port, Service Name 或者 SID, user name, 和 password。</li><li>使用一个存在的MySQL/MariaDB数据库，选择你拥有的数据库name，用户名和密码，选择 <strong>3</strong>。选择你想要使用的数据库并提供任何要求的信息，包括主机name, port, database name, user name, 和 password。</li><li>使用一个存在的PostgreSQL数据库，选择你拥有的数据库name，用户名和密码，选择 <strong>4</strong>。选择你想要使用的数据库并提供任何要求的信息，包括主机name, port, database name, user name, 和 password。</li></ul>\n</li></ol>\n<blockquote>\n<p>在运行 setup 和选择 <strong>Enter advanced database configuration</strong> 时， 你必须准备一个存在的数据库实例。不支持 Microsoft SQL Server 或者 SQL Anywhere 选项。</p>\n</blockquote>\n<ol>\n<li>在 <strong>Proceed with configuring remote database connection properties [y/n]</strong> 选择 <strong>y</strong>。</li><li>Setup 完成。</li></ol>\n<blockquote>\n<p>注意：如果你的主机使用代理服务器访问网络，你必须配置 Ambari Server 去使用这个代理服务器。</p>\n</blockquote>\n<h1 id=\"h1--management-packs\"><a name=\"使用Management Packs\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>使用Management Packs</h1><p>Management packs允许你部署一种services到你的 Ambari-managed 集群。你能使用management pack去部署一个指定的组件或者service，或者部署一个完全的平台。</p>\n<p>通常来说，使用management packs，你需要做下列工作：</p>\n<ol>\n<li>安装 management pack。</li><li>更新 Ambari 中的 repository URL。</li><li>启动 Ambari Server。</li><li>开始 Ambari 安装向导。</li></ol>\n<h1 id=\"h1--\"><a name=\"安装，配置并部署一个集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装，配置并部署一个集群</h1><p>使用运行在你的浏览器上的 <strong>Ambari集群安装向导</strong> 去安装，配置并部署你的集群，如下：</p>\n<ul>\n<li>启动 Ambari Server</li><li>登陆 Ambari</li><li>开始 Ambari 安装向导</li><li>命名你的集群</li><li>选择版本</li><li>安装选项</li><li>确认主机</li><li>选择服务</li><li>分配 Master</li><li>分配 Slaves 和 Clients</li><li>定制服务</li><li>核查</li><li>安装，启动并测试</li><li>概要</li></ul>\n<h2 id=\"h2--ambari-server\"><a name=\"启动 Ambari Server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>启动 Ambari Server</h2><ul>\n<li>在 Ambari 主机运行下述命令启动<pre><code>ambari-server start\n</code></pre></li><li>检查 Ambari Server 进程<pre><code>ambari-server status\n</code></pre></li><li>停止 Ambari Server<pre><code>ambari-server stop\n</code></pre></li></ul>\n<blockquote>\n<p>注意：如果你计划为Hive或者Oozie使用一个存在的数据库实例，你必须在安装你的Hadoop集群<strong>之前</strong>准备去用一个存在的数据库。</p>\n</blockquote>\n<p>在 Ambari Server 启动中，Ambari 运行一个统一的数据库检查来寻找问题。如果找到任何问题，Ambari Server 启动将终止并显示以下信息：</p>\n<pre><code>DB configs consistency check failed\n</code></pre><p>Ambari 将数据库检查结果的更多细节写进 <strong>/var/log/ambari-server/ambari-server-check- database.log</strong> 文件。</p>\n<p>你可以跳过数据库检查，强制启动 Ambari Server，操作如下：</p>\n<pre><code>ambari-server start --skip-database-check\n</code></pre><p>如果你有数据问题，通过选择跳过这个检查，不要对你的集群做任何更改或者升级，直到你矫正了数据统一性问题。</p>\n<h2 id=\"h2--ambari\"><a name=\"登陆 Ambari\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>登陆 Ambari</h2><p><strong>要求</strong></p>\n<p>Ambari Server 必须正在运行。</p>\n<p>使用一个web浏览器登陆 Ambari Web。</p>\n<p><strong>步骤</strong></p>\n<ol>\n<li><p>在你的web浏览器访问：</p>\n<pre><code>http://&lt;your.ambari.server&gt;:8080\n</code></pre><p>&lt;your.ambari.server&gt; 是你的 Ambari 服务主机名，也可以直接使用 IP。例如，默认的 Ambari 主机位于 http://<br>c6401.ambari.apache.org:8080 。</p>\n</li><li><p>使用默认用户名/密码：admin/admin，登陆Ambari Server。你之后可以改变这些信息。对于一个新集群，集群安装向导展示一个欢迎页面。</p>\n</li></ol>\n<h2 id=\"h2--ambari-\"><a name=\"开始 Ambari 安装向导\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>开始 Ambari 安装向导</h2><p>在 Ambari欢迎页面，选择 <strong>启动安装向导</strong>。<br><img src=\"https://github.com/Xingwd/picture/raw/master/ambari/install/%E5%90%AF%E5%8A%A8%E5%AE%89%E8%A3%85%E5%90%91%E5%AF%BC.png\" alt=\"image\"></p>\n<h2 id=\"h2-u547Du540Du4F60u7684u96C6u7FA4\"><a name=\"命名你的集群\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>命名你的集群</h2><p><strong>步骤</strong></p>\n<ol>\n<li>在 <strong>开始</strong> 页面，命名你的集群，不可在名字中使用空格和特殊字符。</li><li>选择 <strong>下一步</strong></li></ol>\n<h2 id=\"h2-u9009u62E9u7248u672C\"><a name=\"选择版本\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>选择版本</h2><p>在这一步，你将选择软件版本和repository URL。</p>\n<p><strong>选择 Stack</strong></p>\n<p>有效Stack被展示出来，当你选择一个Stack，其有效的服务和服务版本列出来。</p>\n<p><img src=\"https://github.com/Xingwd/picture/raw/master/ambari/install/%E9%80%89%E6%8B%A9Stack.png\" alt=\"image\"></p>\n<p><strong>选择 Version</strong></p>\n<p>每个Stack可以拥有多个版本，通常会展示默认版本的服务列表信息。</p>\n<p><img src=\"https://github.com/Xingwd/picture/raw/master/ambari/install/%E9%80%89%E6%8B%A9Version.png\" alt=\"image\"></p>\n<p><strong>选择 Repositories</strong></p>\n<p>这里可以选择公共仓库(Public repository)和本地仓库(Local Repository)，公共仓库适用于有网络的环境，本地仓库适用于无网络或者网络受限的环境。然后根据你的集群主机的操作系统选择对应的操作系统，填写 <strong>Base URL</strong>。</p>\n<p><img src=\"https://github.com/Xingwd/picture/raw/master/ambari/install/%E9%80%89%E6%8B%A9Repositories.png\" alt=\"image\"></p>\n<p>有两个高级repository选项是有效的，通常不会用到。</p>\n<ul>\n<li>跳过仓库URL地址验证(高级)：当你点击 <strong>下一步</strong> 时，Ambari会连接repository Base URLs并验证其有效性。如果验证无效，则提示你继续之前必须确认。勾选此选项可以跳过验证。</li><li>使用RedHat Satellite/Spacewalk：这个选择只有你在使用本地仓库时，才会被激活。当你为软件repositories选择这个选项，你负责在Satellite/Spacewalk中配置repository途径，并确认为选择的 <strong>stack version</strong> 的repository在集群主机上是有效的。</li></ul>\n<h2 id=\"h2-u5B89u88C5u9009u9879\"><a name=\"安装选项\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装选项</h2><p>为了构建起一个集群，集群安装向导需要一些信息。你需要提供你的每台主机的FQDN。向导也需要你设置免密SSH的私钥。使用主机名和密钥信息，向导能够定位，访问并安全交互集群中的主机。</p>\n<p><strong>步骤</strong></p>\n<ol>\n<li>在 <strong>目标主机</strong>，输入你的主机名列表，每行一个。你能使用方括号指定大量的主机。例如，host01.domain到host10.domain使用host[01-10].domain。</li><li>如果你想要让Ambari使用SSH在你所有主机上的自动安装Ambari Agent，选择 <strong>请提供您的 SSH私钥 用于自动注册主机</strong> ，然后选择文件或者将私钥信息粘贴到文本框中。</li><li>输入你已经选择的SSH key的用户名。如果你不想要用root，那么你必须提供一个拥有免密sudo权限的用户。如果你的SSH端口不是22，那么修改成你设置的端口号。</li><li>如果你不想要Ambari自动安装Ambari Agent，选择 <strong>执行 手动注册 在主机上 不使用SSH</strong>。</li><li>选择 <strong>注册并确认</strong> 以继续。</li></ol>\n<h2 id=\"h2-u786Eu8BA4u4E3Bu673A\"><a name=\"确认主机\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>确认主机</h2><p><strong>确认主机</strong> 这一步，Ambari会定位你的集群主机并检查这些主机确认他们有正确目录，包，并请求继续安装。</p>\n<p>如果任何主机出现错误，你能通过 <strong>删除</strong> 按钮移除他们。</p>\n<p>在屏幕的底部，你可能注意到一些警告，这些警告在检查过程中会偶然遇到。例如，你的主机已经有一个 <strong>wget</strong> 或者 <strong>curl</strong> 的拷贝。选择 <strong>点击这里查看警告</strong> 去查看警告细节。警告页也提供一个能帮助你明白任何你可能偶遇的问题的python脚本并让你运行：</p>\n<pre><code>Rerun Checks\n</code></pre><p>当你满意了主机列表，选择 <strong>下一步</strong>。</p>\n<h2 id=\"h2-u9009u62E9u670Du52A1\"><a name=\"选择服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>选择服务</h2><p>基于在 <strong>选择Stack</strong> 步骤选择的Stack，你能看到可安装到集群的services的选择。一个Stack包含许多services。你可以选择安装任何有效的services，或者在之后添加services。集群安装向导默认选择所有有效的services。</p>\n<p>从CRH6开始，默认CRH Stack只包含几个基础services，如果想要安装其他services，需要购买其他CRH services mpacks(如 crh-DW-mpack)。</p>\n<p>点击服务复选框可以选中服务，再次点击复选框可以取消选中。在选择好服务后，选择 <strong>下一步</strong> 进行安装。</p>\n<p><img src=\"https://github.com/Xingwd/picture/raw/master/ambari/install/%E9%80%89%E6%8B%A9Services.png\" alt=\"image\"></p>\n<h2 id=\"h2--master\"><a name=\"分配 Master\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>分配 Master</h2><p>集群安装向导为选中的services分配master组件到你的集群中的合适的主机，并在 <strong>分配Masters</strong> 展示分配详情。右边展示services和当前主机。左边展示当前master组件被分配的主机，标示每台主机的CPU核数和内存大小。</p>\n<ol>\n<li>为一个services改变主机分配，为那个service从下拉菜单选择一个主机名。</li><li>当你满意了分配，选择 <strong>下一步</strong>。</li></ol>\n<h2 id=\"h2--slaves-clients\"><a name=\"分配 Slaves 和 Clients\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>分配 Slaves 和 Clients</h2><p>集群安装向导分配slave组件，像 Datanodes，NodeManagers，和 RegionServers，到你的集群中的合适的主机。它也可以规划选择主机去安装clients。</p>\n<p><strong>步骤</strong></p>\n<ol>\n<li>使用 <strong>all</strong> 或者 <strong>none</strong> 去选中某列的所有主机或者取消某列中选中的主机。</li><li>使用复选框选择指定的主机。</li><li>当你满意了分配，选择 <strong>下一步</strong>。</li></ol>\n<h2 id=\"h2-u5B9Au5236u670Du52A1\"><a name=\"定制服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>定制服务</h2><p>在这一步，你可以对你选择的services进行配置，当然也可以直接使用默认配置。当时 <strong>Passwords</strong> 配置项必须由你来进行配置。</p>\n<h2 id=\"h2-u6838u67E5\"><a name=\"核查\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>核查</h2><p>这一步展示你的分配方案，检查并确认所有信息是准确的。如果你需要做改变，使用左边的选项返回分配步骤进行重新分配。</p>\n<p>要打印你的信息作为以后参考，选择 <strong>打印</strong>。</p>\n<p>当你满意了你的选择，选择 <strong>部署</strong>。</p>\n<h2 id=\"h2--\"><a name=\"安装，启动并测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装，启动并测试</h2><p>这一步会安装选中的services的软件包，启动服务并测试。</p>\n<h2 id=\"h2-u6982u8981\"><a name=\"概要\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>概要</h2><p>这一步完成的任务的总览，选择 <strong>完成</strong>，进入Ambari Web，可以看到已安装的services。 </p>\n');
INSERT INTO `tbl_archive` VALUES ('60', '0', 'go-ethereum使用简介', '13', '2018-05-09 14:18:49', '---#前言本篇文章简单介绍使用go-ethereum连接以太坊的主网和测试网以及一些基础开发须知，着重介绍如何搭建一个私网的以太坊，至于以太坊应用开发，有机会的话，将在后面的文章中重点介绍。本篇文章中包含笔者花费大量心血理解并整理的配置和参数说明资料，望可以为诸位道友提供一些帮助。#安装GoEthereum可以安装的操作系统平台有MacOSX，Windows以及Linux/Unix。详情请看[I', null, '0', '650', null, null, '2018-05-09 14:18:49', null, null, null, '0', '0', '0', '0', '---\n\n# 前言\n本篇文章简单介绍使用go-ethereum连接以太坊的主网和测试网以及一些基础开发须知，着重介绍如何搭建一个私网的以太坊，至于以太坊应用开发，有机会的话，将在后面的文章中重点介绍。\n\n本篇文章中包含笔者花费大量心血理解并整理的配置和参数说明资料，望可以为诸位道友提供一些帮助。\n\n\n# 安装\nGo Ethereum可以安装的操作系统平台有Mac OS X，Windows以及Linux/Unix。详情请看[Installation Instructions](https://github.com/ethereum/go-ethereum/wiki/Building-Ethereum)。\n\n这里介绍在Linux上，从go-ethereum源码构建的安装流程。官方提到的Linux/Unix平台包括Ubuntu，Arch和FreeBSD。这里以Ubuntu为例。\n\n\n## 编译环境准备\n编译环境要求有 **Go** 和 **C编译程序**。安装方法如下：\n```\napt-get install -y build-essential golang\n```\n\n## 获取源码并编译\n### 获取源码\n切换到你准备编译go-ethereum源码的目录，执行命令：\n```\ngit clone https://github.com/ethereum/go-ethereum\n```\n上述命令会clone go-ethereum的主干分支代码，该分支代码是持续开发代码，如果想要使用发布代码，参见[go-ethereum release](https://github.com/ethereum/go-ethereum/releases)。这里以当时最新的发布代码 **v1.8.7** 为例：\n1. 下载代码\n```\nwget https://github.com/ethereum/go-ethereum/archive/v1.8.7.tar.gz\n```\n2. 解压\n```\ntar zxvf v1.8.7.tar.gz\n```\n将解压后的代码移动到你准备编译go-ethereum源码的目录。\n\n\n### 编译源码\n当你准备好go-ethereum的源码后，进入go-ethereum源码工程顶级目录，执行命令：\n```\nmake geth\n```\n(**推荐**)如果你想要编译出所有工具，执行：\n```\nmake all\n```\n编译完成后，所有工具可以在 *build/bin* 目录下找到，将这些二进制文件取出来放到你选好的安装目录，或者就在原来的位置放着，这里我放到 */opt/xingweidong/eth/bin* 目录下，接下来根据你的喜好设置系统环境变量，添加如下内容：\n```\nexport ETH_HOME=/opt/xingweidong/eth\nexport PATH=$PATH:$ETH_HOME/bin\n```\n别忘了使用 *source /etc/profile* 或者其他你喜欢的方法更新你的环境变量信息。\n\n\n# 运行geth\ngeth命令，主要的Ethereum CLI客户端，是Ethereum网(main-, test- 或 private网)的入口，有能力作为一个full node(默认)存档节点(保留所有历史数据)或者一个light node(现场检索数据)节点运行。经由暴露在HTTP, WebSocket 或 IPC传输的顶部的JSON RPC端点，它可以被其他过程用作Ethereum网的网关。\n\n\n> 提示：查看 geth 所有命令行选项使用 **geth --help** 或者查看 [CLI Wiki page](https://github.com/ethereum/go-ethereum/wiki/Command-Line-Options)。\n\n\n## Ethereum main网的full node\n目前为止，大多数情况是人们想要简单地与Ethereum网进行交互：创建账户；转移资金；部署并与合约交互。对于这种特殊的使用情况，用户不关心以前的历史数据，所以我们能快速的同步当前的Ethereum网状态。执行命令：\n```\ngeth console\n```\n命令作用：\n- 开始 geth 进入快速同步模式(默认模式，可以使用 **--syncmode** 选项改变同步模式)，由于它为了避免处理整个Ethereum网的历史数据，会下载大量的事务数据，所以会占用大量CPU资源。\n- 启动 Geth 内在的交互式 [JavaScript console](https://github.com/ethereum/go-ethereum/wiki/JavaScript-Console)，(经由 **console** 子命令)通过这个，你能调用所有官方 [web3 methods](https://github.com/ethereum/wiki/wiki/JavaScript-API) 以及Geth自己的 [management APIs](https://github.com/ethereum/go-ethereum/wiki/Management-APIs)。这个也是可选的，如果你离开，你能使用 **geth attach** 连接一个已经存在的 Geth 实例。\n\n\n## Ethereum test网的full node\n向开发者过渡，如果你想要创造合约，你几乎肯定想要在没有任何真实资金的情况下做到这一点，直到你掌握整个系统。换句话说，代替连接到Ethereum main网，你会想要加入到一个 test网，它是和 main网完全等价的，只需要：\n```\ngeth --testnet console\n```\n**console**子命令与上面的含义完全相同并且它们在一个测试网上也同样有用。如果你跳到这一步，请看上面对它们的解释。\n\n然而，指定 **--testnet** 将重新配置你的 Geth 实例一小部分：\n- 代替使用默认数据目录(例如Linux上的 **～/.ethereum**)，Geth将会深入一层目录创建 **testnet** 子文件夹(在Linux上是 **~/.ethereum/testnet**)。注意，在OSX和Linux上，这也意味着连接一个运行的testnet节点要求使用一个自定义的端点，因为 **geth attach** 默认将连接一个生产节点。例如：**geth attach <datadir>/testnet/geth.ipc**。Windows用户不受影响。\n- 代替连接 Ethereum main网，客户端将连接到一个 test网，使用不同的P2P bootnodes，不同的网络ID和创世状态。\n\n> 注意：尽管有一些内部安全措施防止main网和test网的交易互换，你也应该确认总是为测试资产和真实资产使用分开的账户。除非你手动移动账户，Geth将默认正确分开两个网络，并且在它们之间将不会有任何账户可用。\n\n\n## Rinkeby test网的full node\n上述测试网络是基于ethash工作证明共识算法的跨客户端网络。因此，由于网络的低难度/安全性，它有一定的额外开销，并且更容易受到重组攻击。Go Ethereum还支持连接到称为Rinkeby的权威证明测试网络（由社区成员运营）。这个网络更轻，更安全，但只受到go-ethereum的支持。\n```\ngeth --rinkeby console\n```\n\n\n## 配置\n代替传递大量选项给 geth 二进制，你能传递一个配置文件经由：\n```\ngeth --config /path/to/your_config.toml\n```\n为了理解这个文件的写法，你能使用 **dumpconfig** 子命令export你的现有配置：\n```\ngeth --your-favourite-flags dumpconfig\neg：geth --testnet dumpconfig\n```\n\n> 注意：这个只在 geth v1.6.0以及以上版本有效。\n\n### Docker quick start\n通过使用Docker，你可以在你的机器上快速启动Ethereum并运行：\n```\ndocker run -d --name ethereum-node -v /Users/alice/ethereum:/root \\\n           -p 8545:8545 -p 30303:30303 \\\n           ethereum/client-go\n```\n上述命令将以快速同步模式启动geth，并具有1GB的DB内存容量。它也将在你的home目录下创建一个永久卷来储存你的区块链和映射的默认端口。还有一个 **alpine** 标签可用于image的精简版本。\n\n如果你想要从其他容器或主机访问RPC，不要忘了 **--rpcaddr 0.0.0.0**。默认情况下，**geth** 绑定本地接口并且不可从外访问RPC端点。\n\n\n## 可编程接口 Geth nodes\n作为一个开发者，你将想要及早开始经由你自己的程序而不是手动控制台与Geth和Ethereum网交互。为此，Geth已经内置支持一个基于APIs([standard APIs](https://github.com/ethereum/wiki/wiki/JSON-RPC) 和 [Geth specific APIs](https://github.com/ethereum/go-ethereum/wiki/Management-APIs))的JSON-RPC。它能够经由HTTP, WebSockets 和 IPC (unix sockets on unix based platforms, and named pipes on Windows)暴露。\n\nIPC接口默认是激活的并暴露所有Geth支持的APIs，然而HTTP 和 WS接口需要手动激活并且由于安全原因只能暴露一个APIs子集。这些可以根据你的需要打开或关闭并被配置。\n\n详情请看 [Programatically interfacing Geth nodes](https://github.com/ethereum/go-ethereum#programatically-interfacing-geth-nodes)\n\n\n\n## 操作一个私网\n维护你自己的私网是十分复杂的，因为在一个正规的网络中，大量配置的获取和授权需要手动设置。下面，我们建立一个简单的私网以太坊。\n\n说明：为了使下面创建私网以太坊的步骤更加直白，笔者将默认使用以下的geth选项值(请自行查看选项含义)：\n- --datadir /root/privatenet/.ethereum\n- --config config/privatenet.toml\n\n\n在开始之前，笔者先介绍一下如何创建以太坊账户：\n- 创建主网以太坊账户，执行命令：\n```\ngeth account new\n```\n- 创建私网以太坊账户，执行命令：\n```\ngeth --datadir /root/privatenet/.ethereum account new\n```\n\n按照提示输入账户密码即可。\n\n> 注意：创建私网以太坊账户时，务必指定 **--datadir** 选项，否则会默认创建主网以太坊账户。\n\n\n\n### 定义一个私有的创世状态\n首先，你需要创造你的网络的所有节点需要意识到并同意的创世状态。这个由一个小JSON文件组成(例如，称它为 **genesis.json**)：\n```\n{\n  \"config\": {\n        \"chainId\": 15,\n        \"homesteadBlock\": 0,\n        \"eip155Block\": 0,\n        \"eip158Block\": 0\n    },\n  \"alloc\"      : {},\n  \"coinbase\"   : \"0x0000000000000000000000000000000000000000\",\n  \"difficulty\" : \"0x20000\",\n  \"extraData\"  : \"\",\n  \"gasLimit\"   : \"0x2fefd8\",\n  \"nonce\"      : \"0x0000000000001993\",\n  \"mixhash\"    : \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"timestamp\"  : \"0x00\"\n}\n```\n\n参数说明(*下表是笔者参考go-ethereum源码README和ethereum_yellow_paper整理所得，如有错误，请帮忙指正*)：\n\n参数 | 描述\n---|---\nalloc | 可以预置账号以及账号的以太币数量\ncoinbase | 区块受益者地址，可以设置成已存在的账户。后面挖出的区块的受益者将是挖掘出那个区块的账户(矿工)\ndifficulty | 代表当前区块的难度等级(十六进制)，这里定义创世区块的难度等级，难度等级越高，挖矿越难。后面生成的区块难度等级根据前一个区块的难度等级和时间戳计算得到\nextraData | 一个包含这个区块相关数据的字节数组，任意填写。必须是32位以内\ngasLimit | 执行这个事务应该被使用的gas的最大量。这个在任何计算被做之前是预付的，并且在之后不会增加\nnonce | 代表从这个地址发送的事务数目，或者在关联代码的账户情况下，这代表这个账户创造的合约数目。(在Yellow Paper中对nonce有多处描述，这里选择了4.1章节的描述，)\nmixhash | 一个256位的hash，由nonce合并，证明在这个区块上已经执行足够量的计算\nparentHash | 前一个(父级)区块的header的keccak256算法hash\ntimestamp | 这个区块开始的Unix的time()和合理输出\n\n\n上面这些域应该可以满足大多数需求，不过我们建议改变 **nonce** 为一些随机值，这样你就能阻止不知名的远程节点访问你。如果你想要为了更早测试，预储备一些账户，你能在 **alloc** 域进行账户配置：\n```\n\"alloc\": {\n  \"0x0000000000000000000000000000000000000001\": {\"balance\": \"111111111\"},\n  \"0x0000000000000000000000000000000000000002\": {\"balance\": \"222222222\"}\n}\n```\n\n随着创世状态定义在上面的JSON文件，你应该在启动每个节点之前，优先初始化它，以确认所有区块链参数被正确设置：\n```\ngeth --datadir /root/privatenet/.ethereum init genesis.json\n```\n\n\n### 启动bootstrap\n当所有你想要运行的节点初始化到期望的创世状态，你将需要开始一个bootstrap节点，其他节点可以使用它在你的网络或因特网中找到彼此。干净的方式是配置并运行一个独立的bootnode：\n1. 每个ethereum节点，包括一个bootnode，通过一个enode标识符联系。这些标识符源自一个key。于是你将需要给bootnode这样一个key。因为我们当前没有这样的key，所以我们可以在bootnode启动前生成一个key(并存储它到一个文件)：\n```\nbootnode -genkey bootnode.key\n```\n2. 为了bootnode每次启动都使用相同的enode，需要在bootnode启动时指定一个key：\n```\nbootnode -nodekey bootnode.key\n```\n\n当bootnode上线，它将展示一个 [enode URL](https://github.com/ethereum/wiki/wiki/enode-url-format)，例如：\n```\nINFO [05-09|01:47:05] UDP listener up                          self=enode://75535ebac1f5b2a644edb134dbe91c6c288353be1a5301864edae529630b35c5ff0c0ae9e07b2bcdef578c3ac1b72b2cda105c061c2c77067f1fd8ec54d852b7@[::]:30301\n```\n其他节点可以使用这个 enode URL 连接它并交换对等信息。确认用你的外部访问IP替换展示的IP地址信息(很可能是 [::])去得到真正的 enode URL。例如：\n```\nenode://75535ebac1f5b2a644edb134dbe91c6c288353be1a5301864edae529630b35c5ff0c0ae9e07b2bcdef578c3ac1b72b2cda105c061c2c77067f1fd8ec54d852b7@192.168.1.214:30301\n```\n保存这个准确的 enode URL 到你的一个文本中或者其他什么地方，下面需要用到。\n\n> 注意：你也可以使用完全成熟的Geth节点作为引导节点，但这是不太推荐的方式。\n\n\n### 定义一个配置文件\n为了成员节点启动时使用的配置一致，需要写一个配置文件，例如 privatenet.toml(参考自 **testnet** 的配置, 执行命令 *geth --testnet dumpconfig* 可见)：\n```\n# Note: this config doesn\'t contain the genesis block.\n\n[Eth]\nNetworkId = 3369\nDatabaseCache = 768\nGasPrice = 18000000000\n\n[Eth.Ethash]\nCacheDir = \"ethash\"\nCachesInMem = 2\nCachesOnDisk = 3\nDatasetDir = \"/root/privatenet/.ethash\"\nDatasetsInMem = 1\nDatasetsOnDisk = 2\n\n[Eth.TxPool]\nNoLocals = false\nJournal = \"transactions.rlp\"\nRejournal = 3600000000000\nPriceLimit = 1\nPriceBump = 10\nAccountSlots = 16\nGlobalSlots = 4096\nAccountQueue = 64\nGlobalQueue = 1024\nLifetime = 10800000000000\n\n[Eth.GPO]\nBlocks = 20\nPercentile = 60\n\n[Shh]\nMaxMessageSize = 1048576\nMinimumAcceptedPOW = 2e-01\n\n[Node]\nDataDir = \"/root/privatenet/.ethereum\"\nIPCPath = \"geth.ipc\"\nHTTPPort = 8545\nHTTPVirtualHosts = [\"localhost\"]\nHTTPModules = [\"net\", \"web3\", \"eth\", \"shh\"]\nWSPort = 8546\nWSModules = [\"net\", \"web3\", \"eth\", \"shh\"]\n\n[Node.P2P]\nMaxPeers = 25\nNoDiscovery = false\nBootstrapNodes = [\"enode://75535ebac1f5b2a644edb134dbe91c6c288353be1a5301864edae529630b35c5ff0c0ae9e07b2bcdef578c3ac1b72b2cda105c061c2c77067f1fd8ec54d852b7@1\n92.168.1.214:30301\"]StaticNodes = []\nTrustedNodes = []\nListenAddr = \":30303\"\nEnableMsgEvents = false\n\n[Dashboard]\nHost = \"localhost\"\nPort = 8080\nRefresh = 5000000000\n```\n\n配置说明(*下表是笔者参考geth参数说明和go-ethereum相关配置项代码整理所得，如有错误，请帮忙指正*)：\n\n域 | 配置项 | 对应参数 | 说明\n---|---|---|---\nEth | NetworkId | --networkid value | Network标识符(integer类型，1=Frontier，2=Morden(disused)，3=Ropsten，4=Rinkeby)，默认为1。如果建立在私网上，使用另外的任意值，比如：3369\nEth | DatabaseCache | null | (个人理解)为database申请的系统内存，单位为MB，最小值和默认值是16MB\nEth | GasPrice | --gasprice “18000000000” | 接受挖掘事务的最低gas价格。可能指miner的报酬\nEth.Ethash | CacheDir | --ethash.cachedir | 存储ethash证明缓存的目录(默认在 *datadir* 目录里)\nEth.Ethash | CachesInMem | --ethash.cachesinmem value | 保留在内存中的最新ethash缓存的数目(每16MB)(默认：2)。\nEth.Ethash | CachesOnDisk | --ethash.cachesondisk value |  保留在磁盘中的最新ethash缓存的数目(每16MB)(默认：3)。\nEth.Ethash | DatasetDir | --ethash.dagdir \"/home/karalabe/.ethash\" | 存储ethash挖掘DAGs的目录(默认在home目录里)\nEth.Ethash | DatasetsInMem | --ethash.dagsinmem value | 保留在内存中的最新ethash挖掘DAGs(每1+GB)(默认：1)。\nEth.Ethash | DatasetsOnDisk | --ethash.dagsondisk value | 保留在磁盘中的最新ethash挖掘DAGs(每1+GB)(默认：2)。\nEth.TxPool | NoLocals | --txpool.nolocals | 免除本地提交事务的费用\nEth.TxPool | Journal | --txpool.journal value | 用于节点重启的本地事务磁盘日志(默认：\"transactions.rlp\")\nEth.TxPool | Rejournal | --txpool.rejournal value | 重新生成本地事务日志的时间间隔(默认：1h0m0s)\nEth.TxPool | PriceLimit | --txpool.pricelimit value | 强制接纳入池的最小gas价格限制(默认：1)\nEth.TxPool | PriceBump | --txpool.pricebump value | 替代一个已经存在的事务的价格碰撞百分比(默认：10)\nEth.TxPool | AccountSlots | --txpool.accountslots value | 每个账户担保的可执行事务时隙的最小数目(默认：16)\nEth.TxPool | GlobalSlots | --txpool.globalslots value | 所有账户的可执行事务时隙的最大数目(默认：4096)\nEth.TxPool | AccountQueue | --txpool.accountqueue value | 每个账户许可的非可执行事务时隙的最大数目(默认：64)\nEth.TxPool | GlobalQueue | --txpool.globalqueue | 所有账户的非可执行事务时隙的最大数目(默认：1024)\nEth.TxPool | Lifetime | --txpool.lifetime value | 非可执行事务的排队最大时间(默认：3h0m0s)\nEth.GPO | Blocks | --gpoblocks value | 检查gas价格的最新区块的数目(默认：10)\nEth.GPO | Percentile | --gpopercentile value | 建议的gas价格是一组最新事务gas价格的百分位(默认：50)\nShh | MaxMessageSize | --shh.maxmessagesize value | 可接受的最大信息大小(默认：1048576)\nShh | MinimumAcceptedPOW | --shh.pow value | 可接受的最小POW(默认：0.2)\nNode | DataDir | --datadir \"/home/karalabe/.ethereum\" | databases和keystore的数据目录\nNode | IPCPath | --ipcpath | datadir里的IPC socket/pipe的文件名\nNode | HTTPPort | --rpcport value | HTTP-RPC服务监听端口(默认：8545)\nNode | HTTPVirtualHosts | --rpcaddr value | HTTP-RPC服务监听接口(默认：\"localhost\")\nNode | HTTPModules | null | 经由HTTP RPC接口暴露的API modules列表\nNode | WSPort | --wsport value | WS-RPC 服务监听端口(默认：8546)\nNode | WSModules | null | 经由websocket RPC接口暴露的API　modules列表，如果modules是空的，所有指向public的RPC API端点将会被暴露\nNode.P2P | MaxPeers | --maxpeers value | network peers的最大数目(如果设置为0，network失效)(默认：25)\nNode.P2P | NoDiscovery | --nodiscover | 使peer发现机制无效(手动peer添加)。**这里设置为false，以便使用这个配置文件的新节点可以被发现**。\nNode.P2P | BootstrapNodes | --bootnodes value | 逗号分割的P2P discovery bootstrap enode URLs(对于 light servers，设置 v4+v5 代替)。**将上面启动bootnodes时获取的enode URL替换IP后添加到这里**。\nNode.P2P | BootstrapNodesV5 | --bootnodesv5 value | 逗号分割的P2P v5 discovery bootstrap enode URLs(light server，light nodes)\nNode.P2P | StaticNodes | null | 配置作为static nodes的节点enode URLs列表\nNode.P2P | TrustedNodes | null | 配置作为trusted nodes的节点enode URLs列表\nNode.P2P | ListenAddr | --port | network监听端口(默认：30303)\nNode.P2P | EnableMsgEvents | null | 如果EnableMsgEvents被设置，服务器将发出PeerEvents，无论一个peer何时发送或接收一条信息\nDashboard | Host | null | 启动dashboard服务的主机接口，如果这个域为空，则没有dashboard将被启动\nDashboard | Port | null | 启动dashboard服务的TCP端口数字。默认0值是有效的，并将使用一个随机端口数字(用于临时节点)\nDashboard | Refresh | null | 数据更新的刷新速率，chartEntry将被经常收集\n\n在你的操作目录创建config文件夹，将写好的配置文件privatenet.toml移动到config目录里。\n\n\n### 启动你的成员节点\n以太坊的成员节点，之间是完全对等的，每个节点都可以有多个账户。\n\n启动私网以太坊的成员节点：\n```\ngeth --config config/privatenet.toml\n```\n连接到刚刚启动的或者已经在运行的node，开始一个交互式JavaScript环境：\n```\ngeth attach privatenet/.ethereum/geth.ipc\n```\n\n**官方说明：** 当bootnode运转起来并且外部可达(你能尝试 *telnet <ip> <port>* 去确认它的确可达)，开始随后的Geth节点，为了对等发现，经由 **--bootnodes** 选项指向bootnode。保持你的私网的数据目录单独将很可能是明智的选择，所以也指定一个自定义的 **--datadir** 选项。\n```\ngeth --datadir=path/to/custom/data/folder --bootnodes=<bootnode-enode-url-from-above>\n```\n\n> 注意：因为你的网络将被从main和test网完全切除，所以你将需要配置一个 **miner** 去处理交易并为你创造新块。\n\n\n### 运行一个私有的miner\n公共Ethereum网的mining是一个复杂的任务，因为它唯一可行的是使用GPUs，要求一个OpenCL 或 CUDA激活 **ethminer** 实例。更多信息请查阅 [EtherMining subreddit](https://www.reddit.com/r/EtherMining/)和 [Genoil miner](https://github.com/Genoil/cpp-ethereum) 仓库。\n\n然而在一个私网的设置，一个单一的 CPU miner实例是足够满足实际需求的，因为它不需要沉重的资源(考虑到运行在一个单一的线程上，也不需要多个)就能在一个正确的间隔内生产一个稳定的区块流(stable stream of blocks)。为mining开始一个Geth实例，指定你通常使用的选项运行它，通过以下方法扩展：\n```\ngeth --config config/privatenet.toml --mine --minerthreads=1 --etherbase=0x0000000000000000000000000000000000000000\n```\n这将开始mining区块并在一个单一CPU线程上交易，存入所有事件到一个 **--etherbase** 选项指定的账户，如果不指定账户，则会默认指定当前节点上的第一个账户。你能进一步调节mining，通过(**--targetgaslimit**)改变默认gas限制区块并且在(**--gasprice**)处接受价格交易。\n\n另外，也可以在交互式JavaScript环境中控制mining实例：\n- 开始一个4线程的mining实例：\n```\nminer.start(4)\n```\n- 停止mining实例：\n```\nminer.stop()\n```\n\n更多Mining相关信息，请参看[Mining](https://github.com/ethereum/go-ethereum/wiki/Mining)\n\n\n至此，私网以太坊搭建完成，感谢阅读！\n\n\n---\n**原创不易，与君共勉！**\n\n*所有玩世不恭的生灵，都有一颗至真至纯的心！*', '0', '<hr>\n<h1 id=\"h1-u524Du8A00\"><a name=\"前言\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>前言</h1><p>本篇文章简单介绍使用go-ethereum连接以太坊的主网和测试网以及一些基础开发须知，着重介绍如何搭建一个私网的以太坊，至于以太坊应用开发，有机会的话，将在后面的文章中重点介绍。</p>\n<p>本篇文章中包含笔者花费大量心血理解并整理的配置和参数说明资料，望可以为诸位道友提供一些帮助。</p>\n<h1 id=\"h1-u5B89u88C5\"><a name=\"安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装</h1><p>Go Ethereum可以安装的操作系统平台有Mac OS X，Windows以及Linux/Unix。详情请看<a href=\"https://github.com/ethereum/go-ethereum/wiki/Building-Ethereum\">Installation Instructions</a>。</p>\n<p>这里介绍在Linux上，从go-ethereum源码构建的安装流程。官方提到的Linux/Unix平台包括Ubuntu，Arch和FreeBSD。这里以Ubuntu为例。</p>\n<h2 id=\"h2-u7F16u8BD1u73AFu5883u51C6u5907\"><a name=\"编译环境准备\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>编译环境准备</h2><p>编译环境要求有 <strong>Go</strong> 和 <strong>C编译程序</strong>。安装方法如下：</p>\n<pre><code>apt-get install -y build-essential golang\n</code></pre><h2 id=\"h2-u83B7u53D6u6E90u7801u5E76u7F16u8BD1\"><a name=\"获取源码并编译\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>获取源码并编译</h2><h3 id=\"h3-u83B7u53D6u6E90u7801\"><a name=\"获取源码\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>获取源码</h3><p>切换到你准备编译go-ethereum源码的目录，执行命令：</p>\n<pre><code>git clone https://github.com/ethereum/go-ethereum\n</code></pre><p>上述命令会clone go-ethereum的主干分支代码，该分支代码是持续开发代码，如果想要使用发布代码，参见<a href=\"https://github.com/ethereum/go-ethereum/releases\">go-ethereum release</a>。这里以当时最新的发布代码 <strong>v1.8.7</strong> 为例：</p>\n<ol>\n<li>下载代码<pre><code>wget https://github.com/ethereum/go-ethereum/archive/v1.8.7.tar.gz\n</code></pre></li><li>解压<pre><code>tar zxvf v1.8.7.tar.gz\n</code></pre>将解压后的代码移动到你准备编译go-ethereum源码的目录。</li></ol>\n<h3 id=\"h3-u7F16u8BD1u6E90u7801\"><a name=\"编译源码\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>编译源码</h3><p>当你准备好go-ethereum的源码后，进入go-ethereum源码工程顶级目录，执行命令：</p>\n<pre><code>make geth\n</code></pre><p>(<strong>推荐</strong>)如果你想要编译出所有工具，执行：</p>\n<pre><code>make all\n</code></pre><p>编译完成后，所有工具可以在 <em>build/bin</em> 目录下找到，将这些二进制文件取出来放到你选好的安装目录，或者就在原来的位置放着，这里我放到 <em>/opt/xingweidong/eth/bin</em> 目录下，接下来根据你的喜好设置系统环境变量，添加如下内容：</p>\n<pre><code>export ETH_HOME=/opt/xingweidong/eth\nexport PATH=$PATH:$ETH_HOME/bin\n</code></pre><p>别忘了使用 <em>source /etc/profile</em> 或者其他你喜欢的方法更新你的环境变量信息。</p>\n<h1 id=\"h1--geth\"><a name=\"运行geth\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>运行geth</h1><p>geth命令，主要的Ethereum CLI客户端，是Ethereum网(main-, test- 或 private网)的入口，有能力作为一个full node(默认)存档节点(保留所有历史数据)或者一个light node(现场检索数据)节点运行。经由暴露在HTTP, WebSocket 或 IPC传输的顶部的JSON RPC端点，它可以被其他过程用作Ethereum网的网关。</p>\n<blockquote>\n<p>提示：查看 geth 所有命令行选项使用 <strong>geth —help</strong> 或者查看 <a href=\"https://github.com/ethereum/go-ethereum/wiki/Command-Line-Options\">CLI Wiki page</a>。</p>\n</blockquote>\n<h2 id=\"h2-ethereum-main-full-node\"><a name=\"Ethereum main网的full node\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Ethereum main网的full node</h2><p>目前为止，大多数情况是人们想要简单地与Ethereum网进行交互：创建账户；转移资金；部署并与合约交互。对于这种特殊的使用情况，用户不关心以前的历史数据，所以我们能快速的同步当前的Ethereum网状态。执行命令：</p>\n<pre><code>geth console\n</code></pre><p>命令作用：</p>\n<ul>\n<li>开始 geth 进入快速同步模式(默认模式，可以使用 <strong>—syncmode</strong> 选项改变同步模式)，由于它为了避免处理整个Ethereum网的历史数据，会下载大量的事务数据，所以会占用大量CPU资源。</li><li>启动 Geth 内在的交互式 <a href=\"https://github.com/ethereum/go-ethereum/wiki/JavaScript-Console\">JavaScript console</a>，(经由 <strong>console</strong> 子命令)通过这个，你能调用所有官方 <a href=\"https://github.com/ethereum/wiki/wiki/JavaScript-API\">web3 methods</a> 以及Geth自己的 <a href=\"https://github.com/ethereum/go-ethereum/wiki/Management-APIs\">management APIs</a>。这个也是可选的，如果你离开，你能使用 <strong>geth attach</strong> 连接一个已经存在的 Geth 实例。</li></ul>\n<h2 id=\"h2-ethereum-test-full-node\"><a name=\"Ethereum test网的full node\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Ethereum test网的full node</h2><p>向开发者过渡，如果你想要创造合约，你几乎肯定想要在没有任何真实资金的情况下做到这一点，直到你掌握整个系统。换句话说，代替连接到Ethereum main网，你会想要加入到一个 test网，它是和 main网完全等价的，只需要：</p>\n<pre><code>geth --testnet console\n</code></pre><p><strong>console</strong>子命令与上面的含义完全相同并且它们在一个测试网上也同样有用。如果你跳到这一步，请看上面对它们的解释。</p>\n<p>然而，指定 <strong>—testnet</strong> 将重新配置你的 Geth 实例一小部分：</p>\n<ul>\n<li>代替使用默认数据目录(例如Linux上的 <strong>～/.ethereum</strong>)，Geth将会深入一层目录创建 <strong>testnet</strong> 子文件夹(在Linux上是 <strong>~/.ethereum/testnet</strong>)。注意，在OSX和Linux上，这也意味着连接一个运行的testnet节点要求使用一个自定义的端点，因为 <strong>geth attach</strong> 默认将连接一个生产节点。例如：<strong>geth attach &lt;datadir&gt;/testnet/geth.ipc</strong>。Windows用户不受影响。</li><li>代替连接 Ethereum main网，客户端将连接到一个 test网，使用不同的P2P bootnodes，不同的网络ID和创世状态。</li></ul>\n<blockquote>\n<p>注意：尽管有一些内部安全措施防止main网和test网的交易互换，你也应该确认总是为测试资产和真实资产使用分开的账户。除非你手动移动账户，Geth将默认正确分开两个网络，并且在它们之间将不会有任何账户可用。</p>\n</blockquote>\n<h2 id=\"h2-rinkeby-test-full-node\"><a name=\"Rinkeby test网的full node\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Rinkeby test网的full node</h2><p>上述测试网络是基于ethash工作证明共识算法的跨客户端网络。因此，由于网络的低难度/安全性，它有一定的额外开销，并且更容易受到重组攻击。Go Ethereum还支持连接到称为Rinkeby的权威证明测试网络（由社区成员运营）。这个网络更轻，更安全，但只受到go-ethereum的支持。</p>\n<pre><code>geth --rinkeby console\n</code></pre><h2 id=\"h2-u914Du7F6E\"><a name=\"配置\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>配置</h2><p>代替传递大量选项给 geth 二进制，你能传递一个配置文件经由：</p>\n<pre><code>geth --config /path/to/your_config.toml\n</code></pre><p>为了理解这个文件的写法，你能使用 <strong>dumpconfig</strong> 子命令export你的现有配置：</p>\n<pre><code>geth --your-favourite-flags dumpconfig\neg：geth --testnet dumpconfig\n</code></pre><blockquote>\n<p>注意：这个只在 geth v1.6.0以及以上版本有效。</p>\n</blockquote>\n<h3 id=\"h3-docker-quick-start\"><a name=\"Docker quick start\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Docker quick start</h3><p>通过使用Docker，你可以在你的机器上快速启动Ethereum并运行：</p>\n<pre><code>docker run -d --name ethereum-node -v /Users/alice/ethereum:/root \\\n           -p 8545:8545 -p 30303:30303 \\\n           ethereum/client-go\n</code></pre><p>上述命令将以快速同步模式启动geth，并具有1GB的DB内存容量。它也将在你的home目录下创建一个永久卷来储存你的区块链和映射的默认端口。还有一个 <strong>alpine</strong> 标签可用于image的精简版本。</p>\n<p>如果你想要从其他容器或主机访问RPC，不要忘了 <strong>—rpcaddr 0.0.0.0</strong>。默认情况下，<strong>geth</strong> 绑定本地接口并且不可从外访问RPC端点。</p>\n<h2 id=\"h2--geth-nodes\"><a name=\"可编程接口 Geth nodes\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>可编程接口 Geth nodes</h2><p>作为一个开发者，你将想要及早开始经由你自己的程序而不是手动控制台与Geth和Ethereum网交互。为此，Geth已经内置支持一个基于APIs(<a href=\"https://github.com/ethereum/wiki/wiki/JSON-RPC\">standard APIs</a> 和 <a href=\"https://github.com/ethereum/go-ethereum/wiki/Management-APIs\">Geth specific APIs</a>)的JSON-RPC。它能够经由HTTP, WebSockets 和 IPC (unix sockets on unix based platforms, and named pipes on Windows)暴露。</p>\n<p>IPC接口默认是激活的并暴露所有Geth支持的APIs，然而HTTP 和 WS接口需要手动激活并且由于安全原因只能暴露一个APIs子集。这些可以根据你的需要打开或关闭并被配置。</p>\n<p>详情请看 <a href=\"https://github.com/ethereum/go-ethereum#programatically-interfacing-geth-nodes\">Programatically interfacing Geth nodes</a></p>\n<h2 id=\"h2-u64CDu4F5Cu4E00u4E2Au79C1u7F51\"><a name=\"操作一个私网\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>操作一个私网</h2><p>维护你自己的私网是十分复杂的，因为在一个正规的网络中，大量配置的获取和授权需要手动设置。下面，我们建立一个简单的私网以太坊。</p>\n<p>说明：为了使下面创建私网以太坊的步骤更加直白，笔者将默认使用以下的geth选项值(请自行查看选项含义)：</p>\n<ul>\n<li>—datadir /root/privatenet/.ethereum</li><li>—config config/privatenet.toml</li></ul>\n<p>在开始之前，笔者先介绍一下如何创建以太坊账户：</p>\n<ul>\n<li>创建主网以太坊账户，执行命令：<pre><code>geth account new\n</code></pre></li><li>创建私网以太坊账户，执行命令：<pre><code>geth --datadir /root/privatenet/.ethereum account new\n</code></pre></li></ul>\n<p>按照提示输入账户密码即可。</p>\n<blockquote>\n<p>注意：创建私网以太坊账户时，务必指定 <strong>—datadir</strong> 选项，否则会默认创建主网以太坊账户。</p>\n</blockquote>\n<h3 id=\"h3-u5B9Au4E49u4E00u4E2Au79C1u6709u7684u521Bu4E16u72B6u6001\"><a name=\"定义一个私有的创世状态\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>定义一个私有的创世状态</h3><p>首先，你需要创造你的网络的所有节点需要意识到并同意的创世状态。这个由一个小JSON文件组成(例如，称它为 <strong>genesis.json</strong>)：</p>\n<pre><code>{\n  &quot;config&quot;: {\n        &quot;chainId&quot;: 15,\n        &quot;homesteadBlock&quot;: 0,\n        &quot;eip155Block&quot;: 0,\n        &quot;eip158Block&quot;: 0\n    },\n  &quot;alloc&quot;      : {},\n  &quot;coinbase&quot;   : &quot;0x0000000000000000000000000000000000000000&quot;,\n  &quot;difficulty&quot; : &quot;0x20000&quot;,\n  &quot;extraData&quot;  : &quot;&quot;,\n  &quot;gasLimit&quot;   : &quot;0x2fefd8&quot;,\n  &quot;nonce&quot;      : &quot;0x0000000000001993&quot;,\n  &quot;mixhash&quot;    : &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,\n  &quot;parentHash&quot; : &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,\n  &quot;timestamp&quot;  : &quot;0x00&quot;\n}\n</code></pre><p>参数说明(<em>下表是笔者参考go-ethereum源码README和ethereum_yellow_paper整理所得，如有错误，请帮忙指正</em>)：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>alloc</td>\n<td>可以预置账号以及账号的以太币数量</td>\n</tr>\n<tr>\n<td>coinbase</td>\n<td>区块受益者地址，可以设置成已存在的账户。后面挖出的区块的受益者将是挖掘出那个区块的账户(矿工)</td>\n</tr>\n<tr>\n<td>difficulty</td>\n<td>代表当前区块的难度等级(十六进制)，这里定义创世区块的难度等级，难度等级越高，挖矿越难。后面生成的区块难度等级根据前一个区块的难度等级和时间戳计算得到</td>\n</tr>\n<tr>\n<td>extraData</td>\n<td>一个包含这个区块相关数据的字节数组，任意填写。必须是32位以内</td>\n</tr>\n<tr>\n<td>gasLimit</td>\n<td>执行这个事务应该被使用的gas的最大量。这个在任何计算被做之前是预付的，并且在之后不会增加</td>\n</tr>\n<tr>\n<td>nonce</td>\n<td>代表从这个地址发送的事务数目，或者在关联代码的账户情况下，这代表这个账户创造的合约数目。(在Yellow Paper中对nonce有多处描述，这里选择了4.1章节的描述，)</td>\n</tr>\n<tr>\n<td>mixhash</td>\n<td>一个256位的hash，由nonce合并，证明在这个区块上已经执行足够量的计算</td>\n</tr>\n<tr>\n<td>parentHash</td>\n<td>前一个(父级)区块的header的keccak256算法hash</td>\n</tr>\n<tr>\n<td>timestamp</td>\n<td>这个区块开始的Unix的time()和合理输出</td>\n</tr>\n</tbody>\n</table>\n<p>上面这些域应该可以满足大多数需求，不过我们建议改变 <strong>nonce</strong> 为一些随机值，这样你就能阻止不知名的远程节点访问你。如果你想要为了更早测试，预储备一些账户，你能在 <strong>alloc</strong> 域进行账户配置：</p>\n<pre><code>&quot;alloc&quot;: {\n  &quot;0x0000000000000000000000000000000000000001&quot;: {&quot;balance&quot;: &quot;111111111&quot;},\n  &quot;0x0000000000000000000000000000000000000002&quot;: {&quot;balance&quot;: &quot;222222222&quot;}\n}\n</code></pre><p>随着创世状态定义在上面的JSON文件，你应该在启动每个节点之前，优先初始化它，以确认所有区块链参数被正确设置：</p>\n<pre><code>geth --datadir /root/privatenet/.ethereum init genesis.json\n</code></pre><h3 id=\"h3--bootstrap\"><a name=\"启动bootstrap\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>启动bootstrap</h3><p>当所有你想要运行的节点初始化到期望的创世状态，你将需要开始一个bootstrap节点，其他节点可以使用它在你的网络或因特网中找到彼此。干净的方式是配置并运行一个独立的bootnode：</p>\n<ol>\n<li>每个ethereum节点，包括一个bootnode，通过一个enode标识符联系。这些标识符源自一个key。于是你将需要给bootnode这样一个key。因为我们当前没有这样的key，所以我们可以在bootnode启动前生成一个key(并存储它到一个文件)：<pre><code>bootnode -genkey bootnode.key\n</code></pre></li><li>为了bootnode每次启动都使用相同的enode，需要在bootnode启动时指定一个key：<pre><code>bootnode -nodekey bootnode.key\n</code></pre></li></ol>\n<p>当bootnode上线，它将展示一个 <a href=\"https://github.com/ethereum/wiki/wiki/enode-url-format\">enode URL</a>，例如：</p>\n<pre><code>INFO [05-09|01:47:05] UDP listener up                          self=enode://75535ebac1f5b2a644edb134dbe91c6c288353be1a5301864edae529630b35c5ff0c0ae9e07b2bcdef578c3ac1b72b2cda105c061c2c77067f1fd8ec54d852b7@[::]:30301\n</code></pre><p>其他节点可以使用这个 enode URL 连接它并交换对等信息。确认用你的外部访问IP替换展示的IP地址信息(很可能是 [::])去得到真正的 enode URL。例如：</p>\n<pre><code>enode://75535ebac1f5b2a644edb134dbe91c6c288353be1a5301864edae529630b35c5ff0c0ae9e07b2bcdef578c3ac1b72b2cda105c061c2c77067f1fd8ec54d852b7@192.168.1.214:30301\n</code></pre><p>保存这个准确的 enode URL 到你的一个文本中或者其他什么地方，下面需要用到。</p>\n<blockquote>\n<p>注意：你也可以使用完全成熟的Geth节点作为引导节点，但这是不太推荐的方式。</p>\n</blockquote>\n<h3 id=\"h3-u5B9Au4E49u4E00u4E2Au914Du7F6Eu6587u4EF6\"><a name=\"定义一个配置文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>定义一个配置文件</h3><p>为了成员节点启动时使用的配置一致，需要写一个配置文件，例如 privatenet.toml(参考自 <strong>testnet</strong> 的配置, 执行命令 <em>geth —testnet dumpconfig</em> 可见)：</p>\n<pre><code># Note: this config doesn&#39;t contain the genesis block.\n\n[Eth]\nNetworkId = 3369\nDatabaseCache = 768\nGasPrice = 18000000000\n\n[Eth.Ethash]\nCacheDir = &quot;ethash&quot;\nCachesInMem = 2\nCachesOnDisk = 3\nDatasetDir = &quot;/root/privatenet/.ethash&quot;\nDatasetsInMem = 1\nDatasetsOnDisk = 2\n\n[Eth.TxPool]\nNoLocals = false\nJournal = &quot;transactions.rlp&quot;\nRejournal = 3600000000000\nPriceLimit = 1\nPriceBump = 10\nAccountSlots = 16\nGlobalSlots = 4096\nAccountQueue = 64\nGlobalQueue = 1024\nLifetime = 10800000000000\n\n[Eth.GPO]\nBlocks = 20\nPercentile = 60\n\n[Shh]\nMaxMessageSize = 1048576\nMinimumAcceptedPOW = 2e-01\n\n[Node]\nDataDir = &quot;/root/privatenet/.ethereum&quot;\nIPCPath = &quot;geth.ipc&quot;\nHTTPPort = 8545\nHTTPVirtualHosts = [&quot;localhost&quot;]\nHTTPModules = [&quot;net&quot;, &quot;web3&quot;, &quot;eth&quot;, &quot;shh&quot;]\nWSPort = 8546\nWSModules = [&quot;net&quot;, &quot;web3&quot;, &quot;eth&quot;, &quot;shh&quot;]\n\n[Node.P2P]\nMaxPeers = 25\nNoDiscovery = false\nBootstrapNodes = [&quot;enode://75535ebac1f5b2a644edb134dbe91c6c288353be1a5301864edae529630b35c5ff0c0ae9e07b2bcdef578c3ac1b72b2cda105c061c2c77067f1fd8ec54d852b7@1\n92.168.1.214:30301&quot;]StaticNodes = []\nTrustedNodes = []\nListenAddr = &quot;:30303&quot;\nEnableMsgEvents = false\n\n[Dashboard]\nHost = &quot;localhost&quot;\nPort = 8080\nRefresh = 5000000000\n</code></pre><p>配置说明(<em>下表是笔者参考geth参数说明和go-ethereum相关配置项代码整理所得，如有错误，请帮忙指正</em>)：</p>\n<table>\n<thead>\n<tr>\n<th>域</th>\n<th>配置项</th>\n<th>对应参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Eth</td>\n<td>NetworkId</td>\n<td>—networkid value</td>\n<td>Network标识符(integer类型，1=Frontier，2=Morden(disused)，3=Ropsten，4=Rinkeby)，默认为1。如果建立在私网上，使用另外的任意值，比如：3369</td>\n</tr>\n<tr>\n<td>Eth</td>\n<td>DatabaseCache</td>\n<td>null</td>\n<td>(个人理解)为database申请的系统内存，单位为MB，最小值和默认值是16MB</td>\n</tr>\n<tr>\n<td>Eth</td>\n<td>GasPrice</td>\n<td>—gasprice “18000000000”</td>\n<td>接受挖掘事务的最低gas价格。可能指miner的报酬</td>\n</tr>\n<tr>\n<td>Eth.Ethash</td>\n<td>CacheDir</td>\n<td>—ethash.cachedir</td>\n<td>存储ethash证明缓存的目录(默认在 <em>datadir</em> 目录里)</td>\n</tr>\n<tr>\n<td>Eth.Ethash</td>\n<td>CachesInMem</td>\n<td>—ethash.cachesinmem value</td>\n<td>保留在内存中的最新ethash缓存的数目(每16MB)(默认：2)。</td>\n</tr>\n<tr>\n<td>Eth.Ethash</td>\n<td>CachesOnDisk</td>\n<td>—ethash.cachesondisk value</td>\n<td>保留在磁盘中的最新ethash缓存的数目(每16MB)(默认：3)。</td>\n</tr>\n<tr>\n<td>Eth.Ethash</td>\n<td>DatasetDir</td>\n<td>—ethash.dagdir “/home/karalabe/.ethash”</td>\n<td>存储ethash挖掘DAGs的目录(默认在home目录里)</td>\n</tr>\n<tr>\n<td>Eth.Ethash</td>\n<td>DatasetsInMem</td>\n<td>—ethash.dagsinmem value</td>\n<td>保留在内存中的最新ethash挖掘DAGs(每1+GB)(默认：1)。</td>\n</tr>\n<tr>\n<td>Eth.Ethash</td>\n<td>DatasetsOnDisk</td>\n<td>—ethash.dagsondisk value</td>\n<td>保留在磁盘中的最新ethash挖掘DAGs(每1+GB)(默认：2)。</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>NoLocals</td>\n<td>—txpool.nolocals</td>\n<td>免除本地提交事务的费用</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>Journal</td>\n<td>—txpool.journal value</td>\n<td>用于节点重启的本地事务磁盘日志(默认：”transactions.rlp”)</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>Rejournal</td>\n<td>—txpool.rejournal value</td>\n<td>重新生成本地事务日志的时间间隔(默认：1h0m0s)</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>PriceLimit</td>\n<td>—txpool.pricelimit value</td>\n<td>强制接纳入池的最小gas价格限制(默认：1)</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>PriceBump</td>\n<td>—txpool.pricebump value</td>\n<td>替代一个已经存在的事务的价格碰撞百分比(默认：10)</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>AccountSlots</td>\n<td>—txpool.accountslots value</td>\n<td>每个账户担保的可执行事务时隙的最小数目(默认：16)</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>GlobalSlots</td>\n<td>—txpool.globalslots value</td>\n<td>所有账户的可执行事务时隙的最大数目(默认：4096)</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>AccountQueue</td>\n<td>—txpool.accountqueue value</td>\n<td>每个账户许可的非可执行事务时隙的最大数目(默认：64)</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>GlobalQueue</td>\n<td>—txpool.globalqueue</td>\n<td>所有账户的非可执行事务时隙的最大数目(默认：1024)</td>\n</tr>\n<tr>\n<td>Eth.TxPool</td>\n<td>Lifetime</td>\n<td>—txpool.lifetime value</td>\n<td>非可执行事务的排队最大时间(默认：3h0m0s)</td>\n</tr>\n<tr>\n<td>Eth.GPO</td>\n<td>Blocks</td>\n<td>—gpoblocks value</td>\n<td>检查gas价格的最新区块的数目(默认：10)</td>\n</tr>\n<tr>\n<td>Eth.GPO</td>\n<td>Percentile</td>\n<td>—gpopercentile value</td>\n<td>建议的gas价格是一组最新事务gas价格的百分位(默认：50)</td>\n</tr>\n<tr>\n<td>Shh</td>\n<td>MaxMessageSize</td>\n<td>—shh.maxmessagesize value</td>\n<td>可接受的最大信息大小(默认：1048576)</td>\n</tr>\n<tr>\n<td>Shh</td>\n<td>MinimumAcceptedPOW</td>\n<td>—shh.pow value</td>\n<td>可接受的最小POW(默认：0.2)</td>\n</tr>\n<tr>\n<td>Node</td>\n<td>DataDir</td>\n<td>—datadir “/home/karalabe/.ethereum”</td>\n<td>databases和keystore的数据目录</td>\n</tr>\n<tr>\n<td>Node</td>\n<td>IPCPath</td>\n<td>—ipcpath</td>\n<td>datadir里的IPC socket/pipe的文件名</td>\n</tr>\n<tr>\n<td>Node</td>\n<td>HTTPPort</td>\n<td>—rpcport value</td>\n<td>HTTP-RPC服务监听端口(默认：8545)</td>\n</tr>\n<tr>\n<td>Node</td>\n<td>HTTPVirtualHosts</td>\n<td>—rpcaddr value</td>\n<td>HTTP-RPC服务监听接口(默认：”localhost”)</td>\n</tr>\n<tr>\n<td>Node</td>\n<td>HTTPModules</td>\n<td>null</td>\n<td>经由HTTP RPC接口暴露的API modules列表</td>\n</tr>\n<tr>\n<td>Node</td>\n<td>WSPort</td>\n<td>—wsport value</td>\n<td>WS-RPC 服务监听端口(默认：8546)</td>\n</tr>\n<tr>\n<td>Node</td>\n<td>WSModules</td>\n<td>null</td>\n<td>经由websocket RPC接口暴露的API　modules列表，如果modules是空的，所有指向public的RPC API端点将会被暴露</td>\n</tr>\n<tr>\n<td>Node.P2P</td>\n<td>MaxPeers</td>\n<td>—maxpeers value</td>\n<td>network peers的最大数目(如果设置为0，network失效)(默认：25)</td>\n</tr>\n<tr>\n<td>Node.P2P</td>\n<td>NoDiscovery</td>\n<td>—nodiscover</td>\n<td>使peer发现机制无效(手动peer添加)。<strong>这里设置为false，以便使用这个配置文件的新节点可以被发现</strong>。</td>\n</tr>\n<tr>\n<td>Node.P2P</td>\n<td>BootstrapNodes</td>\n<td>—bootnodes value</td>\n<td>逗号分割的P2P discovery bootstrap enode URLs(对于 light servers，设置 v4+v5 代替)。<strong>将上面启动bootnodes时获取的enode URL替换IP后添加到这里</strong>。</td>\n</tr>\n<tr>\n<td>Node.P2P</td>\n<td>BootstrapNodesV5</td>\n<td>—bootnodesv5 value</td>\n<td>逗号分割的P2P v5 discovery bootstrap enode URLs(light server，light nodes)</td>\n</tr>\n<tr>\n<td>Node.P2P</td>\n<td>StaticNodes</td>\n<td>null</td>\n<td>配置作为static nodes的节点enode URLs列表</td>\n</tr>\n<tr>\n<td>Node.P2P</td>\n<td>TrustedNodes</td>\n<td>null</td>\n<td>配置作为trusted nodes的节点enode URLs列表</td>\n</tr>\n<tr>\n<td>Node.P2P</td>\n<td>ListenAddr</td>\n<td>—port</td>\n<td>network监听端口(默认：30303)</td>\n</tr>\n<tr>\n<td>Node.P2P</td>\n<td>EnableMsgEvents</td>\n<td>null</td>\n<td>如果EnableMsgEvents被设置，服务器将发出PeerEvents，无论一个peer何时发送或接收一条信息</td>\n</tr>\n<tr>\n<td>Dashboard</td>\n<td>Host</td>\n<td>null</td>\n<td>启动dashboard服务的主机接口，如果这个域为空，则没有dashboard将被启动</td>\n</tr>\n<tr>\n<td>Dashboard</td>\n<td>Port</td>\n<td>null</td>\n<td>启动dashboard服务的TCP端口数字。默认0值是有效的，并将使用一个随机端口数字(用于临时节点)</td>\n</tr>\n<tr>\n<td>Dashboard</td>\n<td>Refresh</td>\n<td>null</td>\n<td>数据更新的刷新速率，chartEntry将被经常收集</td>\n</tr>\n</tbody>\n</table>\n<p>在你的操作目录创建config文件夹，将写好的配置文件privatenet.toml移动到config目录里。</p>\n<h3 id=\"h3-u542Fu52A8u4F60u7684u6210u5458u8282u70B9\"><a name=\"启动你的成员节点\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>启动你的成员节点</h3><p>以太坊的成员节点，之间是完全对等的，每个节点都可以有多个账户。</p>\n<p>启动私网以太坊的成员节点：</p>\n<pre><code>geth --config config/privatenet.toml\n</code></pre><p>连接到刚刚启动的或者已经在运行的node，开始一个交互式JavaScript环境：</p>\n<pre><code>geth attach privatenet/.ethereum/geth.ipc\n</code></pre><p><strong>官方说明：</strong> 当bootnode运转起来并且外部可达(你能尝试 <em>telnet &lt;ip&gt; &lt;port&gt;</em> 去确认它的确可达)，开始随后的Geth节点，为了对等发现，经由 <strong>—bootnodes</strong> 选项指向bootnode。保持你的私网的数据目录单独将很可能是明智的选择，所以也指定一个自定义的 <strong>—datadir</strong> 选项。</p>\n<pre><code>geth --datadir=path/to/custom/data/folder --bootnodes=&lt;bootnode-enode-url-from-above&gt;\n</code></pre><blockquote>\n<p>注意：因为你的网络将被从main和test网完全切除，所以你将需要配置一个 <strong>miner</strong> 去处理交易并为你创造新块。</p>\n</blockquote>\n<h3 id=\"h3--miner\"><a name=\"运行一个私有的miner\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>运行一个私有的miner</h3><p>公共Ethereum网的mining是一个复杂的任务，因为它唯一可行的是使用GPUs，要求一个OpenCL 或 CUDA激活 <strong>ethminer</strong> 实例。更多信息请查阅 <a href=\"https://www.reddit.com/r/EtherMining/\">EtherMining subreddit</a>和 <a href=\"https://github.com/Genoil/cpp-ethereum\">Genoil miner</a> 仓库。</p>\n<p>然而在一个私网的设置，一个单一的 CPU miner实例是足够满足实际需求的，因为它不需要沉重的资源(考虑到运行在一个单一的线程上，也不需要多个)就能在一个正确的间隔内生产一个稳定的区块流(stable stream of blocks)。为mining开始一个Geth实例，指定你通常使用的选项运行它，通过以下方法扩展：</p>\n<pre><code>geth --config config/privatenet.toml --mine --minerthreads=1 --etherbase=0x0000000000000000000000000000000000000000\n</code></pre><p>这将开始mining区块并在一个单一CPU线程上交易，存入所有事件到一个 <strong>—etherbase</strong> 选项指定的账户，如果不指定账户，则会默认指定当前节点上的第一个账户。你能进一步调节mining，通过(<strong>—targetgaslimit</strong>)改变默认gas限制区块并且在(<strong>—gasprice</strong>)处接受价格交易。</p>\n<p>另外，也可以在交互式JavaScript环境中控制mining实例：</p>\n<ul>\n<li>开始一个4线程的mining实例：<pre><code>miner.start(4)\n</code></pre></li><li>停止mining实例：<pre><code>miner.stop()\n</code></pre></li></ul>\n<p>更多Mining相关信息，请参看<a href=\"https://github.com/ethereum/go-ethereum/wiki/Mining\">Mining</a></p>\n<p>至此，私网以太坊搭建完成，感谢阅读！</p>\n<hr>\n<p><strong>原创不易，与君共勉！</strong></p>\n<p><em>所有玩世不恭的生灵，都有一颗至真至纯的心！</em></p>\n');
INSERT INTO `tbl_archive` VALUES ('61', '0', 'envi在XLearning中的集成示例-NDVI指数的计算', '24', '2018-06-05 15:09:55', '1.在XLearning的example下新建envi文件夹。将testNDVI.sh脚本拷贝到envi文件夹下，将test_NDVI.task拷贝到/usr/local/harris/envi55/custom_code目录下。testNDVI.sh脚本编写参考ENVI帮助里ENVI> Programming > ProgrammingGuide > RunENVIAnalyticsattheC', null, '0', '233', null, null, '2018-06-05 15:09:55', '2018-06-05 15:11:53', null, null, '0', '0', '0', '0', '1.在XLearning的example下新建envi文件夹。\r\n将testNDVI.sh脚本拷贝到envi文件夹下，将test_NDVI.task拷贝到/usr/local/harris/envi55/custom_code目录下。\r\ntestNDVI.sh脚本编写参考ENVI帮助里 ENVI > Programming > Programming Guide > Run ENVI Analytics at the Command Line > Bash Shell Script Example\r\ntestNDVI.sh脚本\r\n```shell\r\n# ! /bin/bash\r\n\r\n \r\n\r\n#-------\r\n\r\n# Usage\r\n\r\n#-------\r\n\r\nusage () {\r\n\r\n   echo \"Usage:\"\r\n\r\n   echo \"\"\r\n\r\n   echo \" example_spectral_index.sh inputRasterFilename spectralIndex outputRasterFilename\"\r\n\r\n   echo \"\"\r\n\r\n   echo \"Example:\"\r\n\r\n   echo \"\"\r\n\r\n   echo \" ./example_spectral_index.sh \\\"/data/input.dat\\\" \\\"Normalized Difference Vegetation Index\\\" \\\"/data/output.dat\\\"\"\r\n\r\n \r\n\r\n   exit 1\r\n\r\n}\r\n\r\n \r\n\r\n#----------------\r\n\r\n# Input arguments\r\n\r\n#----------------\r\n\r\ninput_file=$1\r\necho $1\r\noutput_raster_uri=$2\r\n\r\n \r\n\r\nif [[ -z ${input_file} ]]\r\n\r\nthen\r\n\r\n   usage\r\n\r\nfi\r\n\r\n \r\n\r\nif [[ -z ${output_raster_uri} ]]\r\n\r\nthen\r\n\r\n   usage\r\n\r\nfi\r\n\r\n \r\n\r\n#---------------------------------------------\r\n\r\n# Build input JSON describing the task to run.\r\n\r\n#---------------------------------------------\r\n\r\ninput_json=\'{\'\r\n\r\ninput_json+=\'   \"taskName\"        : \"test_NDVI\"\'\r\n\r\ninput_json+=\'  ,\"inputParameters\" : {\'\r\n\r\ninput_json+=\'       \"input_raster\":\'\r\n\r\ninput_json+=\'                {\"url\" : \"\'${input_file}\'\", \"factory\":\"URLRaster\"}\'\r\n\r\ninput_json+=\'    ,\"output_raster_uri\": \"\'${output_raster_uri}\'\"\'\r\n\r\ninput_json+=\'    }\'\r\n\r\ninput_json+=\'}\'\r\necho $input_json\r\necho \"dddeo0ejdfojeiojdf\"\r\n#echo ${input_json} | jq .\r\n\r\n \r\n\r\n#--------------------------------------------\r\n\r\n# Find the location of the envitaskengine executable\r\n\r\n# relative to the location of this script.\r\n\r\n#----------------------------------\r\nSOURCE=\"${BASH_SOURCE[0]}\"\r\n\r\n# resolve $SOURCE until the file is no longer a symlink\r\n\r\nwhile [ -h \"$SOURCE\" ]; do\r\n\r\n  DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\"\r\n\r\n  SOURCE=\"$(readlink \"$SOURCE\")\"\r\n\r\n  # if $SOURCE was a relative symlink, we need to resolve\r\n\r\n  # it relative to the path where the symlink file was located\r\n\r\n  [[ $SOURCE != /* ]] && SOURCE=\"$DIR/$SOURCE\"\r\n\r\ndone\r\n\r\nDIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\"\r\n\r\n \r\n\r\nLOC=\"$( cd -P \"$DIR\" && cd -P /usr/local/harris/envi && pwd )\"\r\n\r\n \r\n\r\n#--------------\r\n\r\n# Run the task.\r\n\r\n# Task output JSON will be written to stdout.\r\n\r\n#--------------\r\n\r\necho ${input_json} | \"${LOC}/bin/envitaskengine\"\r\n\r\n```\r\n注意input_json中的taskName。\r\n2.将输入数据S2A_10m_yanjiuqu_reflectance.dat 上传到hadoop中的/tmp/data/envi目录下\r\nhadoop fs -put S2A_10m_yanjiuqu_reflectance.dat  /tmp/data/envi\r\n3.编写run.sh 脚本\r\n```shell\r\n#/bin/sh\r\n$XLEARNING_HOME/bin/xl-submit \\\r\n   --app-type \"envi\" \\\r\n   --app-name \"envi_NDVI\" \\\r\n   --input /tmp/data/envi#infile \\\r\n   --output /tmp/envi_NDVI_output#outfile \\\r\n   --files testNDVI.sh \\\r\n   --launch-cmd \"sh testNDVI.sh ./infile/S2A_10m_yanjiuqu_reflectance.dat /mnt/hdfslink/tmp/enviNDVI_output/testNDVI_output.dat\" \\\r\n   --worker-memory 2G \\\r\n   --worker-cores 2 \\\r\n   --queue default \\\r\n```\r\n/tmp/envi_NDVI_output目录保存的是xlearning运行时container的信息，/tmp/enviNDVI_output目录保存的生成的NDVI.dat结果文件。\r\n4.运行run.sh\r\n![](/upload/images/20180605//b35a59c2-af76-4072-87c6-1873ed5a215a.jpg)\r\n![](/upload/images/20180605//a95a3577-f171-42e2-9223-7c3ca5a00949.jpg)\r\n![](/upload/images/20180605//fa9bb69a-ff5f-4538-8f40-e2c18200b923.jpg)', '0', '<p>1.在XLearning的example下新建envi文件夹。<br>将testNDVI.sh脚本拷贝到envi文件夹下，将test_NDVI.task拷贝到/usr/local/harris/envi55/custom_code目录下。<br>testNDVI.sh脚本编写参考ENVI帮助里 ENVI &gt; Programming &gt; Programming Guide &gt; Run ENVI Analytics at the Command Line &gt; Bash Shell Script Example<br>testNDVI.sh脚本</p>\r\n<pre><code class=\"lang-shell\"># ! /bin/bash\r\n\r\n\r\n\r\n#-------\r\n\r\n# Usage\r\n\r\n#-------\r\n\r\nusage () {\r\n\r\n   echo &quot;Usage:&quot;\r\n\r\n   echo &quot;&quot;\r\n\r\n   echo &quot; example_spectral_index.sh inputRasterFilename spectralIndex outputRasterFilename&quot;\r\n\r\n   echo &quot;&quot;\r\n\r\n   echo &quot;Example:&quot;\r\n\r\n   echo &quot;&quot;\r\n\r\n   echo &quot; ./example_spectral_index.sh \\&quot;/data/input.dat\\&quot; \\&quot;Normalized Difference Vegetation Index\\&quot; \\&quot;/data/output.dat\\&quot;&quot;\r\n\r\n\r\n\r\n   exit 1\r\n\r\n}\r\n\r\n\r\n\r\n#----------------\r\n\r\n# Input arguments\r\n\r\n#----------------\r\n\r\ninput_file=$1\r\necho $1\r\noutput_raster_uri=$2\r\n\r\n\r\n\r\nif [[ -z ${input_file} ]]\r\n\r\nthen\r\n\r\n   usage\r\n\r\nfi\r\n\r\n\r\n\r\nif [[ -z ${output_raster_uri} ]]\r\n\r\nthen\r\n\r\n   usage\r\n\r\nfi\r\n\r\n\r\n\r\n#---------------------------------------------\r\n\r\n# Build input JSON describing the task to run.\r\n\r\n#---------------------------------------------\r\n\r\ninput_json=&#39;{&#39;\r\n\r\ninput_json+=&#39;   &quot;taskName&quot;        : &quot;test_NDVI&quot;&#39;\r\n\r\ninput_json+=&#39;  ,&quot;inputParameters&quot; : {&#39;\r\n\r\ninput_json+=&#39;       &quot;input_raster&quot;:&#39;\r\n\r\ninput_json+=&#39;                {&quot;url&quot; : &quot;&#39;${input_file}&#39;&quot;, &quot;factory&quot;:&quot;URLRaster&quot;}&#39;\r\n\r\ninput_json+=&#39;    ,&quot;output_raster_uri&quot;: &quot;&#39;${output_raster_uri}&#39;&quot;&#39;\r\n\r\ninput_json+=&#39;    }&#39;\r\n\r\ninput_json+=&#39;}&#39;\r\necho $input_json\r\necho &quot;dddeo0ejdfojeiojdf&quot;\r\n#echo ${input_json} | jq .\r\n\r\n\r\n\r\n#--------------------------------------------\r\n\r\n# Find the location of the envitaskengine executable\r\n\r\n# relative to the location of this script.\r\n\r\n#----------------------------------\r\nSOURCE=&quot;${BASH_SOURCE[0]}&quot;\r\n\r\n# resolve $SOURCE until the file is no longer a symlink\r\n\r\nwhile [ -h &quot;$SOURCE&quot; ]; do\r\n\r\n  DIR=&quot;$( cd -P &quot;$( dirname &quot;$SOURCE&quot; )&quot; &amp;&amp; pwd )&quot;\r\n\r\n  SOURCE=&quot;$(readlink &quot;$SOURCE&quot;)&quot;\r\n\r\n  # if $SOURCE was a relative symlink, we need to resolve\r\n\r\n  # it relative to the path where the symlink file was located\r\n\r\n  [[ $SOURCE != /* ]] &amp;&amp; SOURCE=&quot;$DIR/$SOURCE&quot;\r\n\r\ndone\r\n\r\nDIR=&quot;$( cd -P &quot;$( dirname &quot;$SOURCE&quot; )&quot; &amp;&amp; pwd )&quot;\r\n\r\n\r\n\r\nLOC=&quot;$( cd -P &quot;$DIR&quot; &amp;&amp; cd -P /usr/local/harris/envi &amp;&amp; pwd )&quot;\r\n\r\n\r\n\r\n#--------------\r\n\r\n# Run the task.\r\n\r\n# Task output JSON will be written to stdout.\r\n\r\n#--------------\r\n\r\necho ${input_json} | &quot;${LOC}/bin/envitaskengine&quot;\r\n</code></pre>\r\n<p>注意input_json中的taskName。<br>2.将输入数据S2A_10m_yanjiuqu_reflectance.dat 上传到hadoop中的/tmp/data/envi目录下<br>hadoop fs -put S2A_10m_yanjiuqu_reflectance.dat  /tmp/data/envi<br>3.编写run.sh 脚本</p>\r\n<pre><code class=\"lang-shell\">#/bin/sh\r\n$XLEARNING_HOME/bin/xl-submit \\\r\n   --app-type &quot;envi&quot; \\\r\n   --app-name &quot;envi_NDVI&quot; \\\r\n   --input /tmp/data/envi#infile \\\r\n   --output /tmp/envi_NDVI_output#outfile \\\r\n   --files testNDVI.sh \\\r\n   --launch-cmd &quot;sh testNDVI.sh ./infile/S2A_10m_yanjiuqu_reflectance.dat /mnt/hdfslink/tmp/enviNDVI_output/testNDVI_output.dat&quot; \\\r\n   --worker-memory 2G \\\r\n   --worker-cores 2 \\\r\n   --queue default \\\r\n</code></pre>\r\n<p>/tmp/envi_NDVI_output目录保存的是xlearning运行时container的信息，/tmp/enviNDVI_output目录保存的生成的NDVI.dat结果文件。<br>4.运行run.sh<br><img src=\"/upload/images/20180605//b35a59c2-af76-4072-87c6-1873ed5a215a.jpg\" alt=\"\"><br><img src=\"/upload/images/20180605//a95a3577-f171-42e2-9223-7c3ca5a00949.jpg\" alt=\"\"><br><img src=\"/upload/images/20180605//fa9bb69a-ff5f-4538-8f40-e2c18200b923.jpg\" alt=\"\"></p>\r\n');
INSERT INTO `tbl_archive` VALUES ('62', '0', 'Sentinel-2（哨兵）卫星遥感数据下载', '8', '2018-06-09 18:23:50', '1.查询每天产品ID列表awss3lss3://sentinel-s2-l1c/products/2018/6/9/2.遍历产品ID并通过sentinelhub.aws工具下载sentinelhub.aws--productS2B_MSIL1C_20180609T052649_N0206_R105_T45VXH_20180609T081339-f/data/ESA_Products参考材料:htt', null, '0', '569', null, null, '2018-06-09 18:23:50', '2018-06-09 20:59:54', null, null, '0', '0', '0', '0', '#### 1.Sentinel-2 AWS 数据地址\nhttps://registry.opendata.aws/sentinel-2/\n\n#### 2.查询每天产品ID列表\naws s3 ls s3://sentinel-s2-l1c/products/2018/6/9/\n\n![](/upload/images/20180609//4bbc8692-d35f-45ed-b9b1-bb3b367501a7.jpg)\n\n#### 3.遍历产品ID并通过sentinelhub.aws 工具下载\nsentinelhub.aws --product S2B_MSIL1C_20180609T052649_N0206_R105_T45VXH_20180609T081339 -f /data/ESA_Products\n\n![](/upload/images/20180609//2dad0f56-a8da-4b0a-b0e2-fca346d0ffab.jpg)\n\n参考材料:\nhttp://sentinelhub-py.readthedocs.io/en/latest/aws_cli.html#sentinel-2-l1c-products \nhttps://blog.csdn.net/giskekezhou/article/details/80107057\nhttps://blog.csdn.net/theonegis/article/details/80089375\nhttps://theonegis.gitbook.io/geopy/python-ji-chu/kong-jian-shu-ju-chu-li-huan-jing-da-jian\n注意事项,需要升级 python 到 python3.5\n', '0', '<h4 id=\"h4-1-sentinel-2-aws-\"><a name=\"1.Sentinel-2 AWS 数据地址\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.Sentinel-2 AWS 数据地址</h4><p><a href=\"https://registry.opendata.aws/sentinel-2/\">https://registry.opendata.aws/sentinel-2/</a></p>\n<h4 id=\"h4-2-id-\"><a name=\"2.查询每天产品ID列表\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.查询每天产品ID列表</h4><p>aws s3 ls s3://sentinel-s2-l1c/products/2018/6/9/</p>\n<p><img src=\"/upload/images/20180609//4bbc8692-d35f-45ed-b9b1-bb3b367501a7.jpg\" alt=\"\"></p>\n<h4 id=\"h4-3-id-sentinelhub-aws-\"><a name=\"3.遍历产品ID并通过sentinelhub.aws 工具下载\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.遍历产品ID并通过sentinelhub.aws 工具下载</h4><p>sentinelhub.aws —product S2B_MSIL1C_20180609T052649_N0206_R105_T45VXH_20180609T081339 -f /data/ESA_Products</p>\n<p><img src=\"/upload/images/20180609//2dad0f56-a8da-4b0a-b0e2-fca346d0ffab.jpg\" alt=\"\"></p>\n<p>参考材料:<br><a href=\"http://sentinelhub-py.readthedocs.io/en/latest/aws_cli.html#sentinel-2-l1c-products\">http://sentinelhub-py.readthedocs.io/en/latest/aws_cli.html#sentinel-2-l1c-products</a><br><a href=\"https://blog.csdn.net/giskekezhou/article/details/80107057\">https://blog.csdn.net/giskekezhou/article/details/80107057</a><br><a href=\"https://blog.csdn.net/theonegis/article/details/80089375\">https://blog.csdn.net/theonegis/article/details/80089375</a><br><a href=\"https://theonegis.gitbook.io/geopy/python-ji-chu/kong-jian-shu-ju-chu-li-huan-jing-da-jian\">https://theonegis.gitbook.io/geopy/python-ji-chu/kong-jian-shu-ju-chu-li-huan-jing-da-jian</a><br>注意事项,需要升级 python 到 python3.5</p>\n');
INSERT INTO `tbl_archive` VALUES ('63', '0', 'GDAL-读写Sentinel-2遥感图像计算NDVI ', '8', '2018-06-10 16:24:42', 'GDAL是空间数据处理的开源包，支持多种数据格式的读写。遥感图像是一种带大地坐标的栅格数据，遥感图像的栅格模型包含以下两部分的内容：栅格矩阵：由正方形或者矩形栅格点组成，每个栅格点所对应的数值为该点的像元值，在遥感图像中用于表示地物属性值；遥感图像有单波段与多波段，波段表示地物属性的种类，每个波段表示地物一种属性。大地坐标：空间数据参考表示地图的投影信息；仿射矩阵能将行列坐标映射到面坐标上。GDA', null, '0', '537', null, null, '2018-06-10 16:24:42', '2018-06-12 09:11:56', null, null, '0', '0', '0', '0', 'GDAL是空间数据处理的开源包，支持多种数据格式的读写。遥感图像是一种带大地坐标的栅格数据，遥感图像的栅格模型包含以下两部分的内容：\n\n栅格矩阵：由正方形或者矩形栅格点组成，每个栅格点所对应的数值为该点的像元值，在遥感图像中用于表示地物属性值；遥感图像有单波段与多波段，波段表示地物属性的种类，每个波段表示地物一种属性。\n\n大地坐标：空间数据参考表示地图的投影信息；仿射矩阵能将行列坐标映射到面坐标上。\n\n卫星数据: 欧空局 Sentinel-2\n[![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Sentinel_2-IMG_5873-white_%28crop%29.jpg/275px-Sentinel_2-IMG_5873-white_%28crop%29.jpg)](https://en.wikipedia.org/wiki/Sentinel-2)\nhttps://en.wikipedia.org/wiki/Sentinel-2\nhttp://blog.sina.com.cn/s/blog_43f446fb0102x7iy.html\n\n波段列表:\nSentinel-2 Bands 	Central Wavelength (µm) 	Resolution (m) 	Bandwidth (nm)\nBand 1 – Coastal aerosol 	0.443 	60 	27/45 (2A/2B)\nBand 2 – Blue 	0.490 	10 	98\nBand 3 – Green 	0.560 	10 	45/46 (2A/2B)\nBand 4 – Red 	0.665 	10 	38/39 (2A/2B)\nBand 5 – Vegetation Red Edge 	0.705 	20 	19/20 (2A/2B)\nBand 6 – Vegetation Red Edge 	0.740 	20 	18\nBand 7 – Vegetation Red Edge 	0.783 	20 	28\nBand 8 – NIR 	0.842 	10 	115\nBand 8A – Narrow NIR 	0.865 	20 	20\nBand 9 – Water vapour 	0.945 	60 	20\nBand 10 – SWIR – Cirrus 	1.375 	60 	20\nBand 11 – SWIR 	1.610 	20 	90\nBand 12 – SWIR 	2.190 	20 	180\n\n\n下载数据\n```bash\nsentinelhub.aws --product\naws s3 ls s3://sentinel-s2-l1c/products/2018/6/10/\nsentinelhub.aws -f /data/sl/ --bands B03,B08 --product S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715 \n```\n\n下载地址\n/data/sl/S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B03.jp2\n/data/sl/S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B08.jp2\n\n\n\n在GDAL遥感影像读写的基础上，我们可以进行遥感图像的各种公式计算和统计分析。\n例如我们所熟知的计算NDVI（归一化植被指数）\n\n##### 归一化植被指数（Normalized Difference Vegetation Index——NDVI）\n\nNDVI众所周知的一种植被指数，在LAI值很高，即植被茂密时其灵敏度会降低。其计算公式为：\n\nNDVI= ENVI下植被指数模型详解                          (式1)\n[![](http://www.harrisgeospatial.com/docs/html/images/Spectral/SpectralIndexFormulaRDVI.gif)](http://www.harrisgeospatial.com/docs/BroadbandGreenness.html#NDVI)\n值的范围是-1~1，一般绿色植被区的范围是0.2~0.8。\n\n\nGDAL读写遥感数据的代码：\nvi NDVI.py\n\n```python\nfrom osgeo import gdal\nimport numpy as np\nimport os\nimport sys\n\nclass GRID:\n\n    #读图像文件\n    def read_img(self,filename):\n        dataset=gdal.Open(filename)       #打开文件\n\n        im_width = dataset.RasterXSize    #栅格矩阵的列数\n        im_height = dataset.RasterYSize   #栅格矩阵的行数\n\n        im_geotrans = dataset.GetGeoTransform()  #仿射矩阵\n        im_proj = dataset.GetProjection() #地图投影信息\n        im_data = dataset.ReadAsArray(0,0,im_width,im_height) #将数据写成数组，对应栅格矩阵\n\n        del dataset \n        return im_proj,im_geotrans,im_data\n\n    #写文件，以写成tif为例\n    def write_img(self,filename,im_proj,im_geotrans,im_data):\n        #gdal数据类型包括\n        #gdal.GDT_Byte, \n        #gdal .GDT_UInt16, gdal.GDT_Int16, gdal.GDT_UInt32, gdal.GDT_Int32,\n        #gdal.GDT_Float32, gdal.GDT_Float64\n\n        #判断栅格数据的数据类型\n        if \'int8\' in im_data.dtype.name:\n            datatype = gdal.GDT_Byte\n        elif \'int16\' in im_data.dtype.name:\n            datatype = gdal.GDT_UInt16\n        else:\n            datatype = gdal.GDT_Float32\n\n        #判读数组维数\n        if len(im_data.shape) == 3:\n            im_bands, im_height, im_width = im_data.shape\n        else:\n            im_bands, (im_height, im_width) = 1,im_data.shape \n\n        #创建文件\n        driver = gdal.GetDriverByName(\"GTiff\")            #数据类型必须有，因为要计算需要多大内存空间\n        dataset = driver.Create(filename, im_width, im_height, im_bands, datatype)\n\n        dataset.SetGeoTransform(im_geotrans)              #写入仿射变换参数\n        dataset.SetProjection(im_proj)                    #写入投影\n\n        if im_bands == 1:\n            dataset.GetRasterBand(1).WriteArray(im_data)  #写入数组数据\n        else:\n            for i in range(im_bands):\n                dataset.GetRasterBand(i+1).WriteArray(im_data[i])\n\n        del dataset\n\nif __name__ == \"__main__\":\n    os.chdir(r\'/data/sl/\')                        #切换路径到待处理图像所在文件夹\n    run = GRID()\n	B04 = sys.argv[1]\n	B08 = sys.argv[2]\n	NDVI_R=sys.argv[3]\n    #proj3,geotrans3,data3 = run.read_img(\'S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B03.jp2\')        #读数据 B03\n	proj4,geotrans4,data4 = run.read_img(B04)\n    print proj4\n    print geotrans4\n    print data4\n    print data4.shape\n    #run.write_img(\'T52NFH_20180610T015619_B03_Rewrite.tif\',proj3,geotrans3,data3) #写数据\n\n	#proj8,geotrans8,data8 = run.read_img(\'S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B08.jp2\')        #读数据 B08\n	proj8,geotrans8,data8 = run.read_img(B08)        #读数据 B08\n\n	data4 = data4.astype(np.float)\n	data8 = data8.astype(np.float)\n	ndvi = (data8-data4)/(data8+data4)                        #B08为近红外波段；B03为红波段\n	run.write_img(NDVI_R,proj4,geotrans4,ndvi) #写为ndvi图像\n```\n\n运行 GDAL\n```bash\ndocker pull geodata/gdal\ndocker run -it --rm -v /data/sl/:/data/sl geodata/gdal:latest python /data/sl/NDVI.py S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B03.jp2 S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B08.jp2 T52NFH_20180610T015619_ndvi.tif\n```\n\n当然，这是理想的NDVI，实际处理NDVI还会遇到一些其他要处理的问题。例如NDVI值应该在区间[-1，1]内，但实际中会出现大于1或小于-1的情况，或者某些像点是坏点，出现空值nan，需要进一步的配套处理。\n\n原图：\nhttp://www.earthgreenindex.com/T52NFH_20180610T015619_B03.jp2\nhttp://www.earthgreenindex.com/T52NFH_20180610T015619_B08.jp2\n\n计算结果:\nhttp://www.earthgreenindex.com/T52NFH_20180610T015619_ndvi.tif\n\nhttp://www.earthgreenindex.com/L1C_T48WWE_A006580_20180610T045654_ndvi.tif\n\n\n结果通过ENVI打开，New Raster Color Slice\n\n![](/upload/images/20180610//e518d4cb-667d-422a-88ee-d6c04460da94.png)\n\n\n参考材料：\nhttps://blog.csdn.net/vonuo/article/details/74783291\nhttp://blog.sina.com.cn/s/blog_764b1e9d01010n32.html\nhttps://blog.csdn.net/huludan/article/details/52641090\nhttp://www.gdal.org/\nhttps://www.sentinel-hub.com/\nhttp://www.redoop.net/group/topic/55\n\n\n\n\n\n\n\n\n\n\n\n', '1', '<p>GDAL是空间数据处理的开源包，支持多种数据格式的读写。遥感图像是一种带大地坐标的栅格数据，遥感图像的栅格模型包含以下两部分的内容：</p>\n<p>栅格矩阵：由正方形或者矩形栅格点组成，每个栅格点所对应的数值为该点的像元值，在遥感图像中用于表示地物属性值；遥感图像有单波段与多波段，波段表示地物属性的种类，每个波段表示地物一种属性。</p>\n<p>大地坐标：空间数据参考表示地图的投影信息；仿射矩阵能将行列坐标映射到面坐标上。</p>\n<p>卫星数据: 欧空局 Sentinel-2<br><a href=\"https://en.wikipedia.org/wiki/Sentinel-2\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Sentinel_2-IMG_5873-white_%28crop%29.jpg/275px-Sentinel_2-IMG_5873-white_%28crop%29.jpg\" alt=\"\"></a><br><a href=\"https://en.wikipedia.org/wiki/Sentinel-2\">https://en.wikipedia.org/wiki/Sentinel-2</a><br><a href=\"http://blog.sina.com.cn/s/blog_43f446fb0102x7iy.html\">http://blog.sina.com.cn/s/blog_43f446fb0102x7iy.html</a></p>\n<p>波段列表:<br>Sentinel-2 Bands     Central Wavelength (µm)     Resolution (m)     Bandwidth (nm)<br>Band 1 – Coastal aerosol     0.443     60     27/45 (2A/2B)<br>Band 2 – Blue     0.490     10     98<br>Band 3 – Green     0.560     10     45/46 (2A/2B)<br>Band 4 – Red     0.665     10     38/39 (2A/2B)<br>Band 5 – Vegetation Red Edge     0.705     20     19/20 (2A/2B)<br>Band 6 – Vegetation Red Edge     0.740     20     18<br>Band 7 – Vegetation Red Edge     0.783     20     28<br>Band 8 – NIR     0.842     10     115<br>Band 8A – Narrow NIR     0.865     20     20<br>Band 9 – Water vapour     0.945     60     20<br>Band 10 – SWIR – Cirrus     1.375     60     20<br>Band 11 – SWIR     1.610     20     90<br>Band 12 – SWIR     2.190     20     180</p>\n<p>下载数据</p>\n<pre><code class=\"lang-bash\">sentinelhub.aws --product\naws s3 ls s3://sentinel-s2-l1c/products/2018/6/10/\nsentinelhub.aws -f /data/sl/ --bands B03,B08 --product S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715\n</code></pre>\n<p>下载地址<br>/data/sl/S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B03.jp2<br>/data/sl/S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B08.jp2</p>\n<p>在GDAL遥感影像读写的基础上，我们可以进行遥感图像的各种公式计算和统计分析。<br>例如我们所熟知的计算NDVI（归一化植被指数）</p>\n<h5 id=\"h5--normalized-difference-vegetation-index-ndvi-\"><a name=\"归一化植被指数（Normalized Difference Vegetation Index——NDVI）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>归一化植被指数（Normalized Difference Vegetation Index——NDVI）</h5><p>NDVI众所周知的一种植被指数，在LAI值很高，即植被茂密时其灵敏度会降低。其计算公式为：</p>\n<p>NDVI= ENVI下植被指数模型详解                          (式1)<br><a href=\"http://www.harrisgeospatial.com/docs/BroadbandGreenness.html#NDVI\"><img src=\"http://www.harrisgeospatial.com/docs/html/images/Spectral/SpectralIndexFormulaRDVI.gif\" alt=\"\"></a><br>值的范围是-1~1，一般绿色植被区的范围是0.2~0.8。</p>\n<p>GDAL读写遥感数据的代码：<br>vi NDVI.py</p>\n<pre><code class=\"lang-python\">from osgeo import gdal\nimport numpy as np\nimport os\nimport sys\n\nclass GRID:\n\n    #读图像文件\n    def read_img(self,filename):\n        dataset=gdal.Open(filename)       #打开文件\n\n        im_width = dataset.RasterXSize    #栅格矩阵的列数\n        im_height = dataset.RasterYSize   #栅格矩阵的行数\n\n        im_geotrans = dataset.GetGeoTransform()  #仿射矩阵\n        im_proj = dataset.GetProjection() #地图投影信息\n        im_data = dataset.ReadAsArray(0,0,im_width,im_height) #将数据写成数组，对应栅格矩阵\n\n        del dataset \n        return im_proj,im_geotrans,im_data\n\n    #写文件，以写成tif为例\n    def write_img(self,filename,im_proj,im_geotrans,im_data):\n        #gdal数据类型包括\n        #gdal.GDT_Byte, \n        #gdal .GDT_UInt16, gdal.GDT_Int16, gdal.GDT_UInt32, gdal.GDT_Int32,\n        #gdal.GDT_Float32, gdal.GDT_Float64\n\n        #判断栅格数据的数据类型\n        if &#39;int8&#39; in im_data.dtype.name:\n            datatype = gdal.GDT_Byte\n        elif &#39;int16&#39; in im_data.dtype.name:\n            datatype = gdal.GDT_UInt16\n        else:\n            datatype = gdal.GDT_Float32\n\n        #判读数组维数\n        if len(im_data.shape) == 3:\n            im_bands, im_height, im_width = im_data.shape\n        else:\n            im_bands, (im_height, im_width) = 1,im_data.shape \n\n        #创建文件\n        driver = gdal.GetDriverByName(&quot;GTiff&quot;)            #数据类型必须有，因为要计算需要多大内存空间\n        dataset = driver.Create(filename, im_width, im_height, im_bands, datatype)\n\n        dataset.SetGeoTransform(im_geotrans)              #写入仿射变换参数\n        dataset.SetProjection(im_proj)                    #写入投影\n\n        if im_bands == 1:\n            dataset.GetRasterBand(1).WriteArray(im_data)  #写入数组数据\n        else:\n            for i in range(im_bands):\n                dataset.GetRasterBand(i+1).WriteArray(im_data[i])\n\n        del dataset\n\nif __name__ == &quot;__main__&quot;:\n    os.chdir(r&#39;/data/sl/&#39;)                        #切换路径到待处理图像所在文件夹\n    run = GRID()\n    B04 = sys.argv[1]\n    B08 = sys.argv[2]\n    NDVI_R=sys.argv[3]\n    #proj3,geotrans3,data3 = run.read_img(&#39;S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B03.jp2&#39;)        #读数据 B03\n    proj4,geotrans4,data4 = run.read_img(B04)\n    print proj4\n    print geotrans4\n    print data4\n    print data4.shape\n    #run.write_img(&#39;T52NFH_20180610T015619_B03_Rewrite.tif&#39;,proj3,geotrans3,data3) #写数据\n\n    #proj8,geotrans8,data8 = run.read_img(&#39;S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B08.jp2&#39;)        #读数据 B08\n    proj8,geotrans8,data8 = run.read_img(B08)        #读数据 B08\n\n    data4 = data4.astype(np.float)\n    data8 = data8.astype(np.float)\n    ndvi = (data8-data4)/(data8+data4)                        #B08为近红外波段；B03为红波段\n    run.write_img(NDVI_R,proj4,geotrans4,ndvi) #写为ndvi图像\n</code></pre>\n<p>运行 GDAL</p>\n<pre><code class=\"lang-bash\">docker pull geodata/gdal\ndocker run -it --rm -v /data/sl/:/data/sl geodata/gdal:latest python /data/sl/NDVI.py S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B03.jp2 S2B_MSIL1C_20180610T015619_N0206_R117_T52NFH_20180610T032715.SAFE/GRANULE/L1C_T52NFH_A006578_20180610T015618/IMG_DATA/T52NFH_20180610T015619_B08.jp2 T52NFH_20180610T015619_ndvi.tif\n</code></pre>\n<p>当然，这是理想的NDVI，实际处理NDVI还会遇到一些其他要处理的问题。例如NDVI值应该在区间[-1，1]内，但实际中会出现大于1或小于-1的情况，或者某些像点是坏点，出现空值nan，需要进一步的配套处理。</p>\n<p>原图：<br><a href=\"http://www.earthgreenindex.com/T52NFH_20180610T015619_B03.jp2\">http://www.earthgreenindex.com/T52NFH_20180610T015619_B03.jp2</a><br><a href=\"http://www.earthgreenindex.com/T52NFH_20180610T015619_B08.jp2\">http://www.earthgreenindex.com/T52NFH_20180610T015619_B08.jp2</a></p>\n<p>计算结果:<br><a href=\"http://www.earthgreenindex.com/T52NFH_20180610T015619_ndvi.tif\">http://www.earthgreenindex.com/T52NFH_20180610T015619_ndvi.tif</a></p>\n<p><a href=\"http://www.earthgreenindex.com/L1C_T48WWE_A006580_20180610T045654_ndvi.tif\">http://www.earthgreenindex.com/L1C_T48WWE_A006580_20180610T045654_ndvi.tif</a></p>\n<p>结果通过ENVI打开，New Raster Color Slice</p>\n<p><img src=\"/upload/images/20180610//e518d4cb-667d-422a-88ee-d6c04460da94.png\" alt=\"\"></p>\n<p>参考材料：<br><a href=\"https://blog.csdn.net/vonuo/article/details/74783291\">https://blog.csdn.net/vonuo/article/details/74783291</a><br><a href=\"http://blog.sina.com.cn/s/blog_764b1e9d01010n32.html\">http://blog.sina.com.cn/s/blog_764b1e9d01010n32.html</a><br><a href=\"https://blog.csdn.net/huludan/article/details/52641090\">https://blog.csdn.net/huludan/article/details/52641090</a><br><a href=\"http://www.gdal.org/\">http://www.gdal.org/</a><br><a href=\"https://www.sentinel-hub.com/\">https://www.sentinel-hub.com/</a><br><a href=\"http://www.redoop.net/group/topic/55\">http://www.redoop.net/group/topic/55</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('64', '0', 'PostgreSQL+PostGis+GeoServer+OpenstreetMap (卫星图片数据地图贴图展现)', '8', '2018-06-13 18:06:31', 'PostgreSQL+PostGis+GeoServer+OpenstreetMap(卫星图片数据地图贴图展现)项目需求准备使用资源卫星（landsta8）的图片数据，实时更新数据到HDFS文件系统中，然后对图片数据进行栅格化，栅格化后的数据还保留在HDFS文件系统中，同时能导入到PostGis这样的空间数据库中，然后把OpenStreetMap的地图原图入库，通过GeoServer把栅格图和地图', null, '0', '409', null, null, '2018-06-13 18:06:31', '2018-07-20 18:55:40', null, null, '0', '0', '0', '0', '### 应用介绍\n\n> 这是一个整体的应用，用笔记记录呢，不可能整体的一下全部记下来，我这里分模块记录。整体的需求是这样的。\n\n> 准备使用资源卫星（landsta8）的图片数据，实时更新数据到HDFS文件系统中，然后对图片数据进行栅格化，栅格化后的数据还保留在HDFS文件系统中，同时能导入到PostGis这样的空间数据库中，然后把OpenStreetMap的地图原图入库，通过GeoServer把栅格图和地图贴合做可视化。\n\n> 我这边把整体简单化了一下做一个整体的Demo，所以是这样的，下载OpenStreetMap的一部分数据，导入到空间数据库中，先显示出地图来。然后下载landsta8的图片数据进行栅格化，然后入库，最后把栅格化数据和地图贴合展现，最后整体过程的数据存放到HDFS文件系统。\n\n\n### 第一步把地图原图可视化\n\n[1] 选择软件及平台\n\n```\n选择的平台为CRH大数据基础平台，软件使用PostgreSQL、PostGis、GeoServer。平台和操作系统已经安装完成，这里就不赘述了。\n```\n\n[2] 实施过程\n\n 1. 安装PostgreSQL，详见[Centos7.2安装PostGreSQL9.5](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/Centos7.2%E5%AE%89%E8%A3%85PostGreSQL9.5.md)\n\n 2. 简单配置PosgreSQL，详见[PostGreSQL9.5的简单配置](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/PostGreSQL9.5%E7%9A%84%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE.md)\n\n 3. 在Window上安装一个客户端，详见[PostgreSQL9.5的pgAdmin客户端安装使用](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/PostgreSQL9.5%E7%9A%84pgAdmin%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8.md) 这一步可以跳过的,若不需要.\n\n 4. 安装PostGis，详见[Centos7.2安装部署PostGis2.4.4](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/Centos7.2%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2PostGis2.4.4.md)\n\n 5. 部署osm2pgsql，详见[Centos7.2部署osm2pgsql-0.94.0](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/Centos7.2%E9%83%A8%E7%BD%B2osm2pgsql-0.94.0.md)\n\n 6. 下载中国地图及海图,导入数据到PostGis, 详见[PostGis2.4.4导入中国地图数据](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/PostGis2.4.4%E5%AF%BC%E5%85%A5%E4%B8%AD%E5%9B%BD%E5%9C%B0%E5%9B%BE%E6%95%B0%E6%8D%AE.md)\n\n 7. 安装部署GeoServer，详见[Centos7.2部署GeoServer2.13.x](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/Centos7.2%E9%83%A8%E7%BD%B2GeoServer2.13.x.md)\n\n 8. 简单配置GeoServer2.13, 详见[GeoServer2.13的简单配置](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/GeoServer2.13%E7%9A%84%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE.md)\n\n 9. 导入图层数据, 详见[GeoServer2.13数据图层导入](https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/GeoServer2.13%E6%95%B0%E6%8D%AE%E5%9B%BE%E5%B1%82%E5%AF%BC%E5%85%A5.md)\n \n 10.导入海图和中美洲地图\n shp2pgsql -s 3857 -I -D water_polygons.shp ocean_all | psql -d demogisdb -U demo -W 12345678\n grant select on all tables in schema public to demo;\n \n \nCREATE DATABASE cagisdb OWNER demo;\nosm2pgsql -s -U demo -H 127.0.0.1 -P 5432 -W -d cagisdb central-america-latest.osm.pbf --style /home/postgresql_data/openstreetmap-carto-master/openstreetmap-carto.styl\ngrant select on all tables in schema public to demo;\n\n', '0', '<h3 id=\"h3-u5E94u7528u4ECBu7ECD\"><a name=\"应用介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>应用介绍</h3><blockquote>\n<p>这是一个整体的应用，用笔记记录呢，不可能整体的一下全部记下来，我这里分模块记录。整体的需求是这样的。</p>\n<p>准备使用资源卫星（landsta8）的图片数据，实时更新数据到HDFS文件系统中，然后对图片数据进行栅格化，栅格化后的数据还保留在HDFS文件系统中，同时能导入到PostGis这样的空间数据库中，然后把OpenStreetMap的地图原图入库，通过GeoServer把栅格图和地图贴合做可视化。</p>\n<p>我这边把整体简单化了一下做一个整体的Demo，所以是这样的，下载OpenStreetMap的一部分数据，导入到空间数据库中，先显示出地图来。然后下载landsta8的图片数据进行栅格化，然后入库，最后把栅格化数据和地图贴合展现，最后整体过程的数据存放到HDFS文件系统。</p>\n</blockquote>\n<h3 id=\"h3-u7B2Cu4E00u6B65u628Au5730u56FEu539Fu56FEu53EFu89C6u5316\"><a name=\"第一步把地图原图可视化\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>第一步把地图原图可视化</h3><p>[1] 选择软件及平台</p>\n<pre><code>选择的平台为CRH大数据基础平台，软件使用PostgreSQL、PostGis、GeoServer。平台和操作系统已经安装完成，这里就不赘述了。\n</code></pre><p>[2] 实施过程</p>\n<ol>\n<li><p>安装PostgreSQL，详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/Centos7.2%E5%AE%89%E8%A3%85PostGreSQL9.5.md\">Centos7.2安装PostGreSQL9.5</a></p>\n</li><li><p>简单配置PosgreSQL，详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/PostGreSQL9.5%E7%9A%84%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE.md\">PostGreSQL9.5的简单配置</a></p>\n</li><li><p>在Window上安装一个客户端，详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/PostgreSQL9.5%E7%9A%84pgAdmin%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8.md\">PostgreSQL9.5的pgAdmin客户端安装使用</a> 这一步可以跳过的,若不需要.</p>\n</li><li><p>安装PostGis，详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/Centos7.2%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2PostGis2.4.4.md\">Centos7.2安装部署PostGis2.4.4</a></p>\n</li><li><p>部署osm2pgsql，详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/Centos7.2%E9%83%A8%E7%BD%B2osm2pgsql-0.94.0.md\">Centos7.2部署osm2pgsql-0.94.0</a></p>\n</li><li><p>下载中国地图及海图,导入数据到PostGis, 详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/PostGis2.4.4%E5%AF%BC%E5%85%A5%E4%B8%AD%E5%9B%BD%E5%9C%B0%E5%9B%BE%E6%95%B0%E6%8D%AE.md\">PostGis2.4.4导入中国地图数据</a></p>\n</li><li><p>安装部署GeoServer，详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/Centos7.2%E9%83%A8%E7%BD%B2GeoServer2.13.x.md\">Centos7.2部署GeoServer2.13.x</a></p>\n</li><li><p>简单配置GeoServer2.13, 详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/GeoServer2.13%E7%9A%84%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE.md\">GeoServer2.13的简单配置</a></p>\n</li><li><p>导入图层数据, 详见<a href=\"https://github.com/ItdeerLab/itdeerlab-notes/blob/notes/PostGresql/UserGuide/GeoServer2.13%E6%95%B0%E6%8D%AE%E5%9B%BE%E5%B1%82%E5%AF%BC%E5%85%A5.md\">GeoServer2.13数据图层导入</a></p>\n<p>10.导入海图和中美洲地图<br>shp2pgsql -s 3857 -I -D water_polygons.shp ocean_all | psql -d demogisdb -U demo -W 12345678<br>grant select on all tables in schema public to demo;</p>\n</li></ol>\n<p>CREATE DATABASE cagisdb OWNER demo;<br>osm2pgsql -s -U demo -H 127.0.0.1 -P 5432 -W -d cagisdb central-america-latest.osm.pbf —style /home/postgresql_data/openstreetmap-carto-master/openstreetmap-carto.styl<br>grant select on all tables in schema public to demo;</p>\n');
INSERT INTO `tbl_archive` VALUES ('65', '0', 'Sentinel-2（哨兵）卫星遥感数据下载脚本 scihubwget.py ', '8', '2018-09-13 19:36:07', 'scihubwget.py  下载脚本', null, '0', '521', null, null, '2018-09-13 19:36:07', '2018-09-13 19:38:58', null, null, '0', '0', '0', '0', '编写代码 vi scihubwget.py \n通过 https://scihub.copernicus.eu 注册用户\n修改代码中用户名和密码部分。\n```shell\nvi scihubwget.py \n```\n\n```python\n#!/usr/bin/python\n# -*- coding: UTF-8 -*-\nfrom xml.dom.minidom import parse\nimport xml.dom.minidom\nfrom pprint import pprint\nimport os,sys\n\nxfile = sys.argv[1]\n\ndef dump(obj):\n  \'\'\'return a printable representation of an object for debugging\'\'\'\n  newobj=obj\n  if \'__dict__\' in dir(obj):\n    newobj=obj.__dict__\n    if \' object at \' in str(obj) and not newobj.has_key(\'__type__\'):\n      newobj[\'__type__\']=str(obj)\n    for attr in newobj:\n      newobj[attr]=dump(newobj[attr])\n  return newobj\n \n# 使用minidom解析器打开 XML 文档\nDOMTree = xml.dom.minidom.parse(xfile)\ncollection = DOMTree.documentElement\n\npprint(dump(DOMTree))\n\n\n\nif collection.hasAttribute(\"shelf\"):\n   print \"Root element : %s\" % collection.getAttribute(\"shelf\")\n \n# 在集合中获取所有电影\nfiles = collection.getElementsByTagName(\"file\")\n\n#pprint(dump(files))\n\n# 打印每部电影的详细信息\nfor file in files:\n   print \"*****File*****\"\n   if file.hasAttribute(\"name\"):\n      print \"Name: %s\" % file.getAttribute(\"name\")\n\n#   print(dump(file)) \n\n   hash = file.getElementsByTagName(\'hash\')[0]\n   print \"Hash: %s\" % hash.childNodes[0].data\n   size = file.getElementsByTagName(\'size\')[0]\n   print \"Size: %s\" % size.childNodes[0].data\n   url = file.getElementsByTagName(\'url\')[0]\n   print \"Url: %s\" % url.childNodes[0].data\n   #cmd = \'sh xwget.sh %s \"%s\"\' % (file.getAttribute(\"name\"),url.childNodes[0].data)\n   cmd = \'wget --no-check-certificate  --user=\"XXX\" --password=\"XXXXXX\"  --continue --output-document=./%s \"%s\"\' % (file.getAttribute(\"name\"),url.childNodes[0].data)\n   cmd = cmd.replace(\'$\',\'\\$\')\n   print cmd\n   os.system(cmd)\n\n```\n\n通过 https://scihub.copernicus.eu 订购订单并下载订单XML\n如下fiji 地区:\n保存为fiji.meta4\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?><metalink xmlns=\"urn:ietf:params:xml:ns:metalink\"><file name=\"S2A_MSIL1C_20180820T223011_N0206_R072_T60KVF_20180821T013410.zip\"><hash type=\"MD5\">7FF7CDC41D9957660E97B5A6E958EEE3</hash><size>653709780</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'c89b12b8-34ef-48cc-a73d-8d49f74e9d84\')/$value</url></file><file name=\"S2B_MSIL1C_20180723T221939_N0206_R029_T60KXG_20180723T234222.zip\"><hash type=\"MD5\">E49B16016083C6B1D45C5CDBE4A08E06</hash><size>367099669</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'b0f84d47-7d42-4bf1-8354-4c21ab8281bb\')/$value</url></file><file name=\"S2B_MSIL1C_20180723T221939_N0206_R029_T01KAA_20180723T234222.zip\"><hash type=\"MD5\">CD3835C670CE6CEFD81B8A2D486565FC</hash><size>556567147</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'62c026ae-7649-4485-9c5e-5ecf388da441\')/$value</url></file><file name=\"S2A_MSIL1C_20180718T221941_N0206_R029_T60KXG_20180719T012324.zip\"><hash type=\"MD5\">9E76717F02081361ADB6B8DB952D5900</hash><size>365977281</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'61ae91a6-3e3c-4318-b366-42e0fee71c3f\')/$value</url></file><file name=\"S2A_MSIL1C_20180718T221941_N0206_R029_T60KYD_20180719T012324.zip\"><hash type=\"MD5\">DC775AC65320AE299731EB4771A27CB7</hash><size>514944039</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'cb1aedf9-41ac-4118-a796-8841ed9ad570\')/$value</url></file><file name=\"S2B_MSIL1C_20180723T221939_N0206_R029_T60KYG_20180723T234222.zip\"><hash type=\"MD5\">C40A6FDA85D77EE5FC7A2C2985084F0C</hash><size>633722290</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'9983c616-7d6d-43cf-99d8-eeb41e42f9aa\')/$value</url></file><file name=\"S2A_MSIL1C_20180820T223011_N0206_R072_T60KWF_20180821T013410.zip\"><hash type=\"MD5\">168C713A1E7FED63EF297931F9289008</hash><size>744384335</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'77da6be6-ddfb-4a64-ad58-085c07a6fb7f\')/$value</url></file><file name=\"S2A_MSIL1C_20180718T221941_N0206_R029_T60KYF_20180719T012324.zip\"><hash type=\"MD5\">520C60045E8C5ABC5D7402D3672B65A6</hash><size>536672925</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'2a4570db-7da9-4bf0-aaa6-f05c7628b9ea\')/$value</url></file><file name=\"S2B_MSIL1C_20180723T221939_N0206_R029_T01KAB_20180723T234222.zip\"><hash type=\"MD5\">F0F840525A4299A89CA4E1E7B9F31B0A</hash><size>619616606</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'5bd582f2-46cb-42bf-8f59-a7eee241559b\')/$value</url></file><file name=\"S2A_MSIL1C_20180820T223011_N0206_R072_T60KXF_20180821T013410.zip\"><hash type=\"MD5\">F114A59E23559E493C8B78C19DC5869D</hash><size>389240920</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'c7af1712-915a-41ad-8365-90de4d7b46f0\')/$value</url></file><file name=\"S2A_MSIL1C_20180820T223011_N0206_R072_T60KWG_20180821T013410.zip\"><hash type=\"MD5\">B06C64998DD48267A894DEC9CA2C14FD</hash><size>623745202</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'f1409cea-a0d8-4bf6-9f47-a36ae9234e92\')/$value</url></file><file name=\"S2A_MSIL1C_20180820T223011_N0206_R072_T60KWE_20180821T013410.zip\"><hash type=\"MD5\">20EF9E82308BA8C19759AFE3D14BB0EE</hash><size>589192578</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'da9064f8-5186-408c-8da5-3347d4ae5b76\')/$value</url></file><file name=\"S2A_MSIL1C_20180718T221941_N0206_R029_T60KXD_20180719T012324.zip\"><hash type=\"MD5\">700CCCFBC15EC3A15E9ED75D126E3C1D</hash><size>535158293</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'8d643a6f-b156-416c-a188-d07c7763927e\')/$value</url></file><file name=\"S2A_MSIL1C_20180820T223011_N0206_R072_T60KXG_20180821T013410.zip\"><hash type=\"MD5\">318D8E55E82889F0BB59AD382F3091E2</hash><size>392340691</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'d087fd4e-32ba-49ab-b26b-6fb6746691d6\')/$value</url></file><file name=\"S2A_MSIL1C_20180618T221941_N0206_R029_T60KXF_20180619T012402.zip\"><hash type=\"MD5\">3CAD843E1C0DC7D9F5BC7FAED62884A6</hash><size>558455765</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'710aacec-4eda-41f1-a2a5-133cb3138849\')/$value</url></file><file name=\"S2A_MSIL1C_20180718T221941_N0206_R029_T60KXE_20180719T012324.zip\"><hash type=\"MD5\">5895F5C900309D84C8CC8E638E1F5977</hash><size>535879741</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'c711c442-b36b-4a55-9151-a99e36cdde5c\')/$value</url></file><file name=\"S2A_MSIL1C_20180320T221941_N0206_R029_T60KXE_20180320T232853.zip\"><hash type=\"MD5\">465AD65A400672E54AD857D20C7C9BEB</hash><size>605166474</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'1af9a486-418e-4e5b-a6da-a8c439311966\')/$value</url></file><file name=\"S2B_MSIL1C_20180908T220909_N0206_R129_T01KBV_20180909T010455.zip\"><hash type=\"MD5\">0EE74F76C3691A01B7B431C556563222</hash><size>418445243</size><url>https://scihub.copernicus.eu/dhus/odata/v1/Products(\'63534132-fa5b-4e65-9392-f77380d50345\')/$value</url></file></metalink>\n\n```\n执行 python scihubwget.py fiji.meta4\n```shell\npython scihubwget.py fiji.meta4\n```\n数据下载在本地目录\n', '0', '<p>编写代码 vi scihubwget.py<br>通过 <a href=\"https://scihub.copernicus.eu\">https://scihub.copernicus.eu</a> 注册用户<br>修改代码中用户名和密码部分。</p>\n<pre><code class=\"lang-shell\">vi scihubwget.py\n</code></pre>\n<pre><code class=\"lang-python\">#!/usr/bin/python\n# -*- coding: UTF-8 -*-\nfrom xml.dom.minidom import parse\nimport xml.dom.minidom\nfrom pprint import pprint\nimport os,sys\n\nxfile = sys.argv[1]\n\ndef dump(obj):\n  &#39;&#39;&#39;return a printable representation of an object for debugging&#39;&#39;&#39;\n  newobj=obj\n  if &#39;__dict__&#39; in dir(obj):\n    newobj=obj.__dict__\n    if &#39; object at &#39; in str(obj) and not newobj.has_key(&#39;__type__&#39;):\n      newobj[&#39;__type__&#39;]=str(obj)\n    for attr in newobj:\n      newobj[attr]=dump(newobj[attr])\n  return newobj\n\n# 使用minidom解析器打开 XML 文档\nDOMTree = xml.dom.minidom.parse(xfile)\ncollection = DOMTree.documentElement\n\npprint(dump(DOMTree))\n\n\n\nif collection.hasAttribute(&quot;shelf&quot;):\n   print &quot;Root element : %s&quot; % collection.getAttribute(&quot;shelf&quot;)\n\n# 在集合中获取所有电影\nfiles = collection.getElementsByTagName(&quot;file&quot;)\n\n#pprint(dump(files))\n\n# 打印每部电影的详细信息\nfor file in files:\n   print &quot;*****File*****&quot;\n   if file.hasAttribute(&quot;name&quot;):\n      print &quot;Name: %s&quot; % file.getAttribute(&quot;name&quot;)\n\n#   print(dump(file)) \n\n   hash = file.getElementsByTagName(&#39;hash&#39;)[0]\n   print &quot;Hash: %s&quot; % hash.childNodes[0].data\n   size = file.getElementsByTagName(&#39;size&#39;)[0]\n   print &quot;Size: %s&quot; % size.childNodes[0].data\n   url = file.getElementsByTagName(&#39;url&#39;)[0]\n   print &quot;Url: %s&quot; % url.childNodes[0].data\n   #cmd = &#39;sh xwget.sh %s &quot;%s&quot;&#39; % (file.getAttribute(&quot;name&quot;),url.childNodes[0].data)\n   cmd = &#39;wget --no-check-certificate  --user=&quot;XXX&quot; --password=&quot;XXXXXX&quot;  --continue --output-document=./%s &quot;%s&quot;&#39; % (file.getAttribute(&quot;name&quot;),url.childNodes[0].data)\n   cmd = cmd.replace(&#39;$&#39;,&#39;\\$&#39;)\n   print cmd\n   os.system(cmd)\n</code></pre>\n<p>通过 <a href=\"https://scihub.copernicus.eu\">https://scihub.copernicus.eu</a> 订购订单并下载订单XML<br>如下fiji 地区:<br>保存为fiji.meta4</p>\n<pre><code class=\"lang-xml\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;metalink xmlns=&quot;urn:ietf:params:xml:ns:metalink&quot;&gt;&lt;file name=&quot;S2A_MSIL1C_20180820T223011_N0206_R072_T60KVF_20180821T013410.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;7FF7CDC41D9957660E97B5A6E958EEE3&lt;/hash&gt;&lt;size&gt;653709780&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;c89b12b8-34ef-48cc-a73d-8d49f74e9d84&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2B_MSIL1C_20180723T221939_N0206_R029_T60KXG_20180723T234222.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;E49B16016083C6B1D45C5CDBE4A08E06&lt;/hash&gt;&lt;size&gt;367099669&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;b0f84d47-7d42-4bf1-8354-4c21ab8281bb&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2B_MSIL1C_20180723T221939_N0206_R029_T01KAA_20180723T234222.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;CD3835C670CE6CEFD81B8A2D486565FC&lt;/hash&gt;&lt;size&gt;556567147&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;62c026ae-7649-4485-9c5e-5ecf388da441&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180718T221941_N0206_R029_T60KXG_20180719T012324.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;9E76717F02081361ADB6B8DB952D5900&lt;/hash&gt;&lt;size&gt;365977281&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;61ae91a6-3e3c-4318-b366-42e0fee71c3f&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180718T221941_N0206_R029_T60KYD_20180719T012324.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;DC775AC65320AE299731EB4771A27CB7&lt;/hash&gt;&lt;size&gt;514944039&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;cb1aedf9-41ac-4118-a796-8841ed9ad570&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2B_MSIL1C_20180723T221939_N0206_R029_T60KYG_20180723T234222.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;C40A6FDA85D77EE5FC7A2C2985084F0C&lt;/hash&gt;&lt;size&gt;633722290&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;9983c616-7d6d-43cf-99d8-eeb41e42f9aa&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180820T223011_N0206_R072_T60KWF_20180821T013410.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;168C713A1E7FED63EF297931F9289008&lt;/hash&gt;&lt;size&gt;744384335&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;77da6be6-ddfb-4a64-ad58-085c07a6fb7f&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180718T221941_N0206_R029_T60KYF_20180719T012324.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;520C60045E8C5ABC5D7402D3672B65A6&lt;/hash&gt;&lt;size&gt;536672925&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;2a4570db-7da9-4bf0-aaa6-f05c7628b9ea&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2B_MSIL1C_20180723T221939_N0206_R029_T01KAB_20180723T234222.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;F0F840525A4299A89CA4E1E7B9F31B0A&lt;/hash&gt;&lt;size&gt;619616606&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;5bd582f2-46cb-42bf-8f59-a7eee241559b&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180820T223011_N0206_R072_T60KXF_20180821T013410.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;F114A59E23559E493C8B78C19DC5869D&lt;/hash&gt;&lt;size&gt;389240920&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;c7af1712-915a-41ad-8365-90de4d7b46f0&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180820T223011_N0206_R072_T60KWG_20180821T013410.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;B06C64998DD48267A894DEC9CA2C14FD&lt;/hash&gt;&lt;size&gt;623745202&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;f1409cea-a0d8-4bf6-9f47-a36ae9234e92&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180820T223011_N0206_R072_T60KWE_20180821T013410.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;20EF9E82308BA8C19759AFE3D14BB0EE&lt;/hash&gt;&lt;size&gt;589192578&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;da9064f8-5186-408c-8da5-3347d4ae5b76&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180718T221941_N0206_R029_T60KXD_20180719T012324.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;700CCCFBC15EC3A15E9ED75D126E3C1D&lt;/hash&gt;&lt;size&gt;535158293&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;8d643a6f-b156-416c-a188-d07c7763927e&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180820T223011_N0206_R072_T60KXG_20180821T013410.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;318D8E55E82889F0BB59AD382F3091E2&lt;/hash&gt;&lt;size&gt;392340691&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;d087fd4e-32ba-49ab-b26b-6fb6746691d6&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180618T221941_N0206_R029_T60KXF_20180619T012402.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;3CAD843E1C0DC7D9F5BC7FAED62884A6&lt;/hash&gt;&lt;size&gt;558455765&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;710aacec-4eda-41f1-a2a5-133cb3138849&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180718T221941_N0206_R029_T60KXE_20180719T012324.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;5895F5C900309D84C8CC8E638E1F5977&lt;/hash&gt;&lt;size&gt;535879741&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;c711c442-b36b-4a55-9151-a99e36cdde5c&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2A_MSIL1C_20180320T221941_N0206_R029_T60KXE_20180320T232853.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;465AD65A400672E54AD857D20C7C9BEB&lt;/hash&gt;&lt;size&gt;605166474&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;1af9a486-418e-4e5b-a6da-a8c439311966&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;file name=&quot;S2B_MSIL1C_20180908T220909_N0206_R129_T01KBV_20180909T010455.zip&quot;&gt;&lt;hash type=&quot;MD5&quot;&gt;0EE74F76C3691A01B7B431C556563222&lt;/hash&gt;&lt;size&gt;418445243&lt;/size&gt;&lt;url&gt;https://scihub.copernicus.eu/dhus/odata/v1/Products(&#39;63534132-fa5b-4e65-9392-f77380d50345&#39;)/$value&lt;/url&gt;&lt;/file&gt;&lt;/metalink&gt;\n</code></pre>\n<p>执行 python scihubwget.py fiji.meta4</p>\n<pre><code class=\"lang-shell\">python scihubwget.py fiji.meta4\n</code></pre>\n<p>数据下载在本地目录</p>\n');
INSERT INTO `tbl_archive` VALUES ('66', '0', 'Ambari 库表统计语句', '8', '2018-09-20 13:49:16', 'Ambari运行时间过久，速度会减慢，通过MLSQL我们可以快速排查Ambari的表空间。```sqlconnectjdbcwheretruncate=\"true\"andurl=\"jdbc:postgresql://127.0.0.1:5432/ambari?socketTimeout=1&connectTimeout=1\"anddriver=\"org.postgresql.Driver\"andu', null, '0', '193', null, null, '2018-09-20 13:49:16', '2018-09-26 15:20:21', null, null, '0', '0', '0', '0', 'Ambari 运行时间过久，速度会减慢，通过 MLSQL 我们可以快速排查 Ambari 的表空间。\n```sql\nconnect jdbc where  \ntruncate=\"true\"\nand url=\"jdbc:postgresql://127.0.0.1:5432/ambari?socketTimeout=1&connectTimeout=1\"\nand driver=\"org.postgresql.Driver\"\nand user=\"ambari\"\nand password=\"bigdata\"\nas ambari;\n\nload jdbc.`ambari.user` as user;\nload jdbc.`ambari.qrtz_locks` as qrtz_locks;\n\nselect \'user\' as name, count(*) as c from user  as user\nunion all\nselect \'qrtz_locks\' as qrtz_locks,count(*) as c from qrtz_locks  as  qrtz_locks;\n\n\nload jdbc.`ambari.extension` as extension;\nload jdbc.`ambari.extensionlink` as extensionlink;\nload jdbc.`ambari.clusters` as clusters;\nload jdbc.`ambari.controller` as controller;\nload jdbc.`ambari.adminresourcetype` as adminresourcetype;\nload jdbc.`ambari.clusterconfig` as clusterconfig;\nload jdbc.`ambari.adminresource` as adminresource;\nload jdbc.`ambari.stack` as stack;\nload jdbc.`ambari.serviceconfighosts` as serviceconfighosts;\nload jdbc.`ambari.serviceconfig` as serviceconfig;\nload jdbc.`ambari.serviceconfigmapping` as serviceconfigmapping;\nload jdbc.`ambari.hostcomponentdesiredstate` as hostcomponentdesiredstate;\nload jdbc.`ambari.hosts` as hosts;\nload jdbc.`ambari.clusterstate` as clusterstate;\nload jdbc.`ambari.clusterservices` as clusterservices;\nload jdbc.`ambari.servicecomponentdesiredstate` as servicecomponentdesiredstate;\nload jdbc.`ambari.hostcomponentstate` as hostcomponentstate;\nload jdbc.`ambari.hoststate` as hoststate;\nload jdbc.`ambari.host_version` as host_version;\nload jdbc.`ambari.groups` as groups;\nload jdbc.`ambari.servicedesiredstate` as servicedesiredstate;\nload jdbc.`ambari.adminprincipaltype` as adminprincipaltype;\nload jdbc.`ambari.users` as users;\nload jdbc.`ambari.members` as members;\nload jdbc.`ambari.repo_version` as repo_version;\nload jdbc.`ambari.adminprincipal` as adminprincipal;\nload jdbc.`ambari.host_role_command` as host_role_command;\nload jdbc.`ambari.stage` as stage;\nload jdbc.`ambari.requestschedule` as requestschedule;\nload jdbc.`ambari.request` as request;\nload jdbc.`ambari.execution_command` as execution_command;\nload jdbc.`ambari.role_success_criteria` as role_success_criteria;\nload jdbc.`ambari.ambari_sequences` as ambari_sequences;\nload jdbc.`ambari.requestresourcefilter` as requestresourcefilter;\nload jdbc.`ambari.requestoperationlevel` as requestoperationlevel;\nload jdbc.`ambari.clusterhostmapping` as clusterhostmapping;\nload jdbc.`ambari.key_value_store` as key_value_store;\nload jdbc.`ambari.configgroup` as configgroup;\nload jdbc.`ambari.hostconfigmapping` as hostconfigmapping;\nload jdbc.`ambari.metainfo` as metainfo;\nload jdbc.`ambari.confgroupclusterconfigmapping` as confgroupclusterconfigmapping;\nload jdbc.`ambari.configgrouphostmapping` as configgrouphostmapping;\nload jdbc.`ambari.requestschedulebatchrequest` as requestschedulebatchrequest;\nload jdbc.`ambari.hostgroup` as hostgroup;\nload jdbc.`ambari.hostgroup_configuration` as hostgroup_configuration;\nload jdbc.`ambari.viewmain` as viewmain;\nload jdbc.`ambari.hostgroup_component` as hostgroup_component;\nload jdbc.`ambari.viewurl` as viewurl;\nload jdbc.`ambari.blueprint_configuration` as blueprint_configuration;\nload jdbc.`ambari.blueprint` as blueprint;\nload jdbc.`ambari.viewinstance` as viewinstance;\nload jdbc.`ambari.blueprint_setting` as blueprint_setting;\nload jdbc.`ambari.viewinstancedata` as viewinstancedata;\nload jdbc.`ambari.viewinstanceproperty` as viewinstanceproperty;\nload jdbc.`ambari.viewparameter` as viewparameter;\nload jdbc.`ambari.adminpermission` as adminpermission;\nload jdbc.`ambari.roleauthorization` as roleauthorization;\nload jdbc.`ambari.viewresource` as viewresource;\nload jdbc.`ambari.viewentity` as viewentity;\nload jdbc.`ambari.adminprivilege` as adminprivilege;\nload jdbc.`ambari.permission_roleauthorization` as permission_roleauthorization;\nload jdbc.`ambari.widget` as widget;\nload jdbc.`ambari.widget_layout` as widget_layout;\nload jdbc.`ambari.widget_layout_user_widget` as widget_layout_user_widget;\nload jdbc.`ambari.artifact` as artifact;\nload jdbc.`ambari.topology_hostgroup` as topology_hostgroup;\nload jdbc.`ambari.topology_host_task` as topology_host_task;\nload jdbc.`ambari.topology_logical_request` as topology_logical_request;\nload jdbc.`ambari.topology_logical_task` as topology_logical_task;\nload jdbc.`ambari.topology_host_info` as topology_host_info;\nload jdbc.`ambari.topology_request` as topology_request;\nload jdbc.`ambari.setting` as setting;\nload jdbc.`ambari.topology_host_request` as topology_host_request;\nload jdbc.`ambari.remoteambaricluster` as remoteambaricluster;\nload jdbc.`ambari.remoteambariclusterservice` as remoteambariclusterservice;\nload jdbc.`ambari.ambari_operation_history` as ambari_operation_history;\nload jdbc.`ambari.kerberos_descriptor` as kerberos_descriptor;\nload jdbc.`ambari.upgrade` as upgrade;\nload jdbc.`ambari.upgrade_group` as upgrade_group;\nload jdbc.`ambari.upgrade_item` as upgrade_item;\nload jdbc.`ambari.upgrade_history` as upgrade_history;\nload jdbc.`ambari.kerberos_principal` as kerberos_principal;\nload jdbc.`ambari.servicecomponent_version` as servicecomponent_version;\nload jdbc.`ambari.kerberos_principal_host` as kerberos_principal_host;\nload jdbc.`ambari.alert_definition` as alert_definition;\nload jdbc.`ambari.alert_group` as alert_group;\nload jdbc.`ambari.alert_grouping` as alert_grouping;\nload jdbc.`ambari.alert_current` as alert_current;\nload jdbc.`ambari.alert_target` as alert_target;\nload jdbc.`ambari.alert_target_states` as alert_target_states;\nload jdbc.`ambari.alert_history` as alert_history;\nload jdbc.`ambari.alert_group_target` as alert_group_target;\nload jdbc.`ambari.alert_notice` as alert_notice;\nload jdbc.`ambari.qrtz_job_details` as qrtz_job_details;\nload jdbc.`ambari.qrtz_triggers` as qrtz_triggers;\nload jdbc.`ambari.qrtz_simple_triggers` as qrtz_simple_triggers;\nload jdbc.`ambari.qrtz_cron_triggers` as qrtz_cron_triggers;\nload jdbc.`ambari.qrtz_simprop_triggers` as qrtz_simprop_triggers;\nload jdbc.`ambari.qrtz_blob_triggers` as qrtz_blob_triggers;\nload jdbc.`ambari.qrtz_calendars` as qrtz_calendars;\nload jdbc.`ambari.qrtz_paused_trigger_grps` as qrtz_paused_trigger_grps;\nload jdbc.`ambari.qrtz_fired_triggers` as qrtz_fired_triggers;\nload jdbc.`ambari.qrtz_scheduler_state` as qrtz_scheduler_state;\nload jdbc.`ambari.qrtz_locks` as qrtz_locks;\n\nselect \"extension\" as name,count(*) as c from extension  as  extension union all \nselect \"extensionlink\" as name,count(*) as c from extensionlink  as  extensionlink union all \nselect \"clusters\" as name,count(*) as c from clusters  as  clusters union all \nselect \"controller\" as name,count(*) as c from controller  as  controller union all \nselect \"adminresourcetype\" as name,count(*) as c from adminresourcetype  as  adminresourcetype union all \nselect \"clusterconfig\" as name,count(*) as c from clusterconfig  as  clusterconfig union all \nselect \"adminresource\" as name,count(*) as c from adminresource  as  adminresource union all \nselect \"stack\" as name,count(*) as c from stack  as  stack union all \nselect \"serviceconfighosts\" as name,count(*) as c from serviceconfighosts  as  serviceconfighosts union all \nselect \"serviceconfig\" as name,count(*) as c from serviceconfig  as  serviceconfig union all \nselect \"serviceconfigmapping\" as name,count(*) as c from serviceconfigmapping  as  serviceconfigmapping union all \nselect \"hostcomponentdesiredstate\" as name,count(*) as c from hostcomponentdesiredstate  as  hostcomponentdesiredstate union all \nselect \"hosts\" as name,count(*) as c from hosts  as  hosts union all \nselect \"clusterstate\" as name,count(*) as c from clusterstate  as  clusterstate union all \nselect \"clusterservices\" as name,count(*) as c from clusterservices  as  clusterservices union all \nselect \"servicecomponentdesiredstate\" as name,count(*) as c from servicecomponentdesiredstate  as  servicecomponentdesiredstate union all \nselect \"hostcomponentstate\" as name,count(*) as c from hostcomponentstate  as  hostcomponentstate union all \nselect \"hoststate\" as name,count(*) as c from hoststate  as  hoststate union all \nselect \"host_version\" as name,count(*) as c from host_version  as  host_version union all \nselect \"groups\" as name,count(*) as c from groups  as  groups union all \nselect \"servicedesiredstate\" as name,count(*) as c from servicedesiredstate  as  servicedesiredstate union all \nselect \"adminprincipaltype\" as name,count(*) as c from adminprincipaltype  as  adminprincipaltype union all \nselect \"users\" as name,count(*) as c from users  as  users union all \nselect \"members\" as name,count(*) as c from members  as  members union all \nselect \"repo_version\" as name,count(*) as c from repo_version  as  repo_version union all \nselect \"adminprincipal\" as name,count(*) as c from adminprincipal  as  adminprincipal union all \nselect \"host_role_command\" as name,count(*) as c from host_role_command  as  host_role_command union all \nselect \"stage\" as name,count(*) as c from stage  as  stage union all \nselect \"requestschedule\" as name,count(*) as c from requestschedule  as  requestschedule union all \nselect \"request\" as name,count(*) as c from request  as  request union all \nselect \"execution_command\" as name,count(*) as c from execution_command  as  execution_command union all \nselect \"role_success_criteria\" as name,count(*) as c from role_success_criteria  as  role_success_criteria union all \nselect \"ambari_sequences\" as name,count(*) as c from ambari_sequences  as  ambari_sequences union all \nselect \"requestresourcefilter\" as name,count(*) as c from requestresourcefilter  as  requestresourcefilter union all \nselect \"requestoperationlevel\" as name,count(*) as c from requestoperationlevel  as  requestoperationlevel union all \nselect \"clusterhostmapping\" as name,count(*) as c from clusterhostmapping  as  clusterhostmapping union all \nselect \"key_value_store\" as name,count(*) as c from key_value_store  as  key_value_store union all \nselect \"configgroup\" as name,count(*) as c from configgroup  as  configgroup union all \nselect \"hostconfigmapping\" as name,count(*) as c from hostconfigmapping  as  hostconfigmapping union all \nselect \"metainfo\" as name,count(*) as c from metainfo  as  metainfo union all \nselect \"confgroupclusterconfigmapping\" as name,count(*) as c from confgroupclusterconfigmapping  as  confgroupclusterconfigmapping union all \nselect \"configgrouphostmapping\" as name,count(*) as c from configgrouphostmapping  as  configgrouphostmapping union all \nselect \"requestschedulebatchrequest\" as name,count(*) as c from requestschedulebatchrequest  as  requestschedulebatchrequest union all \nselect \"hostgroup\" as name,count(*) as c from hostgroup  as  hostgroup union all \nselect \"hostgroup_configuration\" as name,count(*) as c from hostgroup_configuration  as  hostgroup_configuration union all \nselect \"viewmain\" as name,count(*) as c from viewmain  as  viewmain union all \nselect \"hostgroup_component\" as name,count(*) as c from hostgroup_component  as  hostgroup_component union all \nselect \"viewurl\" as name,count(*) as c from viewurl  as  viewurl union all \nselect \"blueprint_configuration\" as name,count(*) as c from blueprint_configuration  as  blueprint_configuration union all \nselect \"blueprint\" as name,count(*) as c from blueprint  as  blueprint union all \nselect \"viewinstance\" as name,count(*) as c from viewinstance  as  viewinstance union all \nselect \"blueprint_setting\" as name,count(*) as c from blueprint_setting  as  blueprint_setting union all \nselect \"viewinstancedata\" as name,count(*) as c from viewinstancedata  as  viewinstancedata union all \nselect \"viewinstanceproperty\" as name,count(*) as c from viewinstanceproperty  as  viewinstanceproperty union all \nselect \"viewparameter\" as name,count(*) as c from viewparameter  as  viewparameter union all \nselect \"adminpermission\" as name,count(*) as c from adminpermission  as  adminpermission union all \nselect \"roleauthorization\" as name,count(*) as c from roleauthorization  as  roleauthorization union all \nselect \"viewresource\" as name,count(*) as c from viewresource  as  viewresource union all \nselect \"viewentity\" as name,count(*) as c from viewentity  as  viewentity union all \nselect \"adminprivilege\" as name,count(*) as c from adminprivilege  as  adminprivilege union all \nselect \"permission_roleauthorization\" as name,count(*) as c from permission_roleauthorization  as  permission_roleauthorization union all \nselect \"widget\" as name,count(*) as c from widget  as  widget union all \nselect \"widget_layout\" as name,count(*) as c from widget_layout  as  widget_layout union all \nselect \"widget_layout_user_widget\" as name,count(*) as c from widget_layout_user_widget  as  widget_layout_user_widget union all \nselect \"artifact\" as name,count(*) as c from artifact  as  artifact union all \nselect \"topology_hostgroup\" as name,count(*) as c from topology_hostgroup  as  topology_hostgroup union all \nselect \"topology_host_task\" as name,count(*) as c from topology_host_task  as  topology_host_task union all \nselect \"topology_logical_request\" as name,count(*) as c from topology_logical_request  as  topology_logical_request union all \nselect \"topology_logical_task\" as name,count(*) as c from topology_logical_task  as  topology_logical_task union all \nselect \"topology_host_info\" as name,count(*) as c from topology_host_info  as  topology_host_info union all \nselect \"topology_request\" as name,count(*) as c from topology_request  as  topology_request union all \nselect \"setting\" as name,count(*) as c from setting  as  setting union all \nselect \"topology_host_request\" as name,count(*) as c from topology_host_request  as  topology_host_request union all \nselect \"remoteambaricluster\" as name,count(*) as c from remoteambaricluster  as  remoteambaricluster union all \nselect \"remoteambariclusterservice\" as name,count(*) as c from remoteambariclusterservice  as  remoteambariclusterservice union all \nselect \"ambari_operation_history\" as name,count(*) as c from ambari_operation_history  as  ambari_operation_history union all \nselect \"kerberos_descriptor\" as name,count(*) as c from kerberos_descriptor  as  kerberos_descriptor union all \nselect \"upgrade\" as name,count(*) as c from upgrade  as  upgrade union all \nselect \"upgrade_group\" as name,count(*) as c from upgrade_group  as  upgrade_group union all \nselect \"upgrade_item\" as name,count(*) as c from upgrade_item  as  upgrade_item union all \nselect \"upgrade_history\" as name,count(*) as c from upgrade_history  as  upgrade_history union all \nselect \"kerberos_principal\" as name,count(*) as c from kerberos_principal  as  kerberos_principal union all \nselect \"servicecomponent_version\" as name,count(*) as c from servicecomponent_version  as  servicecomponent_version union all \nselect \"kerberos_principal_host\" as name,count(*) as c from kerberos_principal_host  as  kerberos_principal_host union all \nselect \"alert_definition\" as name,count(*) as c from alert_definition  as  alert_definition union all \nselect \"alert_group\" as name,count(*) as c from alert_group  as  alert_group union all \nselect \"alert_grouping\" as name,count(*) as c from alert_grouping  as  alert_grouping union all \nselect \"alert_current\" as name,count(*) as c from alert_current  as  alert_current union all \nselect \"alert_target\" as name,count(*) as c from alert_target  as  alert_target union all \nselect \"alert_target_states\" as name,count(*) as c from alert_target_states  as  alert_target_states union all \nselect \"alert_history\" as name,count(*) as c from alert_history  as  alert_history union all \nselect \"alert_group_target\" as name,count(*) as c from alert_group_target  as  alert_group_target union all \nselect \"alert_notice\" as name,count(*) as c from alert_notice  as  alert_notice union all \nselect \"qrtz_job_details\" as name,count(*) as c from qrtz_job_details  as  qrtz_job_details union all \nselect \"qrtz_triggers\" as name,count(*) as c from qrtz_triggers  as  qrtz_triggers union all \nselect \"qrtz_simple_triggers\" as name,count(*) as c from qrtz_simple_triggers  as  qrtz_simple_triggers union all \nselect \"qrtz_cron_triggers\" as name,count(*) as c from qrtz_cron_triggers  as  qrtz_cron_triggers union all \nselect \"qrtz_simprop_triggers\" as name,count(*) as c from qrtz_simprop_triggers  as  qrtz_simprop_triggers union all \nselect \"qrtz_blob_triggers\" as name,count(*) as c from qrtz_blob_triggers  as  qrtz_blob_triggers union all \nselect \"qrtz_calendars\" as name,count(*) as c from qrtz_calendars  as  qrtz_calendars union all \nselect \"qrtz_paused_trigger_grps\" as name,count(*) as c from qrtz_paused_trigger_grps  as  qrtz_paused_trigger_grps union all \nselect \"qrtz_fired_triggers\" as name,count(*) as c from qrtz_fired_triggers  as  qrtz_fired_triggers union all \nselect \"qrtz_scheduler_state\" as name,count(*) as c from qrtz_scheduler_state  as  qrtz_scheduler_state union all \nselect \"qrtz_locks\" as name,count(*) as c from qrtz_locks  as  qrtz_locks as ambari_tables_count;\n\nsave overwrite ambari_tables_count\nas jdbc.`ambari.ambari_tables_count`\noptions truncate=\"true\"\nand url=\"jdbc:mysql://127.0.0.1:3307/ambari\"\nand driver=\"com.mysql.jdbc.Driver\"\nand user=\"root\"\nand password=\"\";\n\n\nconnect jdbc where  \ntruncate=\"true\" \nand url=\"jdbc:mysql://127.0.0.1:3307/ambari\" \nand driver=\"com.mysql.jdbc.Driver\" \nand user=\"root\" \nand password=\"\" \nas mysql;\n\nload jdbc.`mysql.ambari_tables_count` as ambari_tables_count;\n\nselect * from ambari_tables_count order by c desc as ambari_tables_count;\n\nselect c.name as cname,c.c as cc,a.name,a.c from (select name,c from ambari_tables_count) as c\nleft join\na\non  c.name=a.name as d\n;\n```\n\n\n', '0', '<p>Ambari 运行时间过久，速度会减慢，通过 MLSQL 我们可以快速排查 Ambari 的表空间。</p>\n<pre><code class=\"lang-sql\">connect jdbc where  \ntruncate=&quot;true&quot;\nand url=&quot;jdbc:postgresql://127.0.0.1:5432/ambari?socketTimeout=1&amp;connectTimeout=1&quot;\nand driver=&quot;org.postgresql.Driver&quot;\nand user=&quot;ambari&quot;\nand password=&quot;bigdata&quot;\nas ambari;\n\nload jdbc.`ambari.user` as user;\nload jdbc.`ambari.qrtz_locks` as qrtz_locks;\n\nselect &#39;user&#39; as name, count(*) as c from user  as user\nunion all\nselect &#39;qrtz_locks&#39; as qrtz_locks,count(*) as c from qrtz_locks  as  qrtz_locks;\n\n\nload jdbc.`ambari.extension` as extension;\nload jdbc.`ambari.extensionlink` as extensionlink;\nload jdbc.`ambari.clusters` as clusters;\nload jdbc.`ambari.controller` as controller;\nload jdbc.`ambari.adminresourcetype` as adminresourcetype;\nload jdbc.`ambari.clusterconfig` as clusterconfig;\nload jdbc.`ambari.adminresource` as adminresource;\nload jdbc.`ambari.stack` as stack;\nload jdbc.`ambari.serviceconfighosts` as serviceconfighosts;\nload jdbc.`ambari.serviceconfig` as serviceconfig;\nload jdbc.`ambari.serviceconfigmapping` as serviceconfigmapping;\nload jdbc.`ambari.hostcomponentdesiredstate` as hostcomponentdesiredstate;\nload jdbc.`ambari.hosts` as hosts;\nload jdbc.`ambari.clusterstate` as clusterstate;\nload jdbc.`ambari.clusterservices` as clusterservices;\nload jdbc.`ambari.servicecomponentdesiredstate` as servicecomponentdesiredstate;\nload jdbc.`ambari.hostcomponentstate` as hostcomponentstate;\nload jdbc.`ambari.hoststate` as hoststate;\nload jdbc.`ambari.host_version` as host_version;\nload jdbc.`ambari.groups` as groups;\nload jdbc.`ambari.servicedesiredstate` as servicedesiredstate;\nload jdbc.`ambari.adminprincipaltype` as adminprincipaltype;\nload jdbc.`ambari.users` as users;\nload jdbc.`ambari.members` as members;\nload jdbc.`ambari.repo_version` as repo_version;\nload jdbc.`ambari.adminprincipal` as adminprincipal;\nload jdbc.`ambari.host_role_command` as host_role_command;\nload jdbc.`ambari.stage` as stage;\nload jdbc.`ambari.requestschedule` as requestschedule;\nload jdbc.`ambari.request` as request;\nload jdbc.`ambari.execution_command` as execution_command;\nload jdbc.`ambari.role_success_criteria` as role_success_criteria;\nload jdbc.`ambari.ambari_sequences` as ambari_sequences;\nload jdbc.`ambari.requestresourcefilter` as requestresourcefilter;\nload jdbc.`ambari.requestoperationlevel` as requestoperationlevel;\nload jdbc.`ambari.clusterhostmapping` as clusterhostmapping;\nload jdbc.`ambari.key_value_store` as key_value_store;\nload jdbc.`ambari.configgroup` as configgroup;\nload jdbc.`ambari.hostconfigmapping` as hostconfigmapping;\nload jdbc.`ambari.metainfo` as metainfo;\nload jdbc.`ambari.confgroupclusterconfigmapping` as confgroupclusterconfigmapping;\nload jdbc.`ambari.configgrouphostmapping` as configgrouphostmapping;\nload jdbc.`ambari.requestschedulebatchrequest` as requestschedulebatchrequest;\nload jdbc.`ambari.hostgroup` as hostgroup;\nload jdbc.`ambari.hostgroup_configuration` as hostgroup_configuration;\nload jdbc.`ambari.viewmain` as viewmain;\nload jdbc.`ambari.hostgroup_component` as hostgroup_component;\nload jdbc.`ambari.viewurl` as viewurl;\nload jdbc.`ambari.blueprint_configuration` as blueprint_configuration;\nload jdbc.`ambari.blueprint` as blueprint;\nload jdbc.`ambari.viewinstance` as viewinstance;\nload jdbc.`ambari.blueprint_setting` as blueprint_setting;\nload jdbc.`ambari.viewinstancedata` as viewinstancedata;\nload jdbc.`ambari.viewinstanceproperty` as viewinstanceproperty;\nload jdbc.`ambari.viewparameter` as viewparameter;\nload jdbc.`ambari.adminpermission` as adminpermission;\nload jdbc.`ambari.roleauthorization` as roleauthorization;\nload jdbc.`ambari.viewresource` as viewresource;\nload jdbc.`ambari.viewentity` as viewentity;\nload jdbc.`ambari.adminprivilege` as adminprivilege;\nload jdbc.`ambari.permission_roleauthorization` as permission_roleauthorization;\nload jdbc.`ambari.widget` as widget;\nload jdbc.`ambari.widget_layout` as widget_layout;\nload jdbc.`ambari.widget_layout_user_widget` as widget_layout_user_widget;\nload jdbc.`ambari.artifact` as artifact;\nload jdbc.`ambari.topology_hostgroup` as topology_hostgroup;\nload jdbc.`ambari.topology_host_task` as topology_host_task;\nload jdbc.`ambari.topology_logical_request` as topology_logical_request;\nload jdbc.`ambari.topology_logical_task` as topology_logical_task;\nload jdbc.`ambari.topology_host_info` as topology_host_info;\nload jdbc.`ambari.topology_request` as topology_request;\nload jdbc.`ambari.setting` as setting;\nload jdbc.`ambari.topology_host_request` as topology_host_request;\nload jdbc.`ambari.remoteambaricluster` as remoteambaricluster;\nload jdbc.`ambari.remoteambariclusterservice` as remoteambariclusterservice;\nload jdbc.`ambari.ambari_operation_history` as ambari_operation_history;\nload jdbc.`ambari.kerberos_descriptor` as kerberos_descriptor;\nload jdbc.`ambari.upgrade` as upgrade;\nload jdbc.`ambari.upgrade_group` as upgrade_group;\nload jdbc.`ambari.upgrade_item` as upgrade_item;\nload jdbc.`ambari.upgrade_history` as upgrade_history;\nload jdbc.`ambari.kerberos_principal` as kerberos_principal;\nload jdbc.`ambari.servicecomponent_version` as servicecomponent_version;\nload jdbc.`ambari.kerberos_principal_host` as kerberos_principal_host;\nload jdbc.`ambari.alert_definition` as alert_definition;\nload jdbc.`ambari.alert_group` as alert_group;\nload jdbc.`ambari.alert_grouping` as alert_grouping;\nload jdbc.`ambari.alert_current` as alert_current;\nload jdbc.`ambari.alert_target` as alert_target;\nload jdbc.`ambari.alert_target_states` as alert_target_states;\nload jdbc.`ambari.alert_history` as alert_history;\nload jdbc.`ambari.alert_group_target` as alert_group_target;\nload jdbc.`ambari.alert_notice` as alert_notice;\nload jdbc.`ambari.qrtz_job_details` as qrtz_job_details;\nload jdbc.`ambari.qrtz_triggers` as qrtz_triggers;\nload jdbc.`ambari.qrtz_simple_triggers` as qrtz_simple_triggers;\nload jdbc.`ambari.qrtz_cron_triggers` as qrtz_cron_triggers;\nload jdbc.`ambari.qrtz_simprop_triggers` as qrtz_simprop_triggers;\nload jdbc.`ambari.qrtz_blob_triggers` as qrtz_blob_triggers;\nload jdbc.`ambari.qrtz_calendars` as qrtz_calendars;\nload jdbc.`ambari.qrtz_paused_trigger_grps` as qrtz_paused_trigger_grps;\nload jdbc.`ambari.qrtz_fired_triggers` as qrtz_fired_triggers;\nload jdbc.`ambari.qrtz_scheduler_state` as qrtz_scheduler_state;\nload jdbc.`ambari.qrtz_locks` as qrtz_locks;\n\nselect &quot;extension&quot; as name,count(*) as c from extension  as  extension union all \nselect &quot;extensionlink&quot; as name,count(*) as c from extensionlink  as  extensionlink union all \nselect &quot;clusters&quot; as name,count(*) as c from clusters  as  clusters union all \nselect &quot;controller&quot; as name,count(*) as c from controller  as  controller union all \nselect &quot;adminresourcetype&quot; as name,count(*) as c from adminresourcetype  as  adminresourcetype union all \nselect &quot;clusterconfig&quot; as name,count(*) as c from clusterconfig  as  clusterconfig union all \nselect &quot;adminresource&quot; as name,count(*) as c from adminresource  as  adminresource union all \nselect &quot;stack&quot; as name,count(*) as c from stack  as  stack union all \nselect &quot;serviceconfighosts&quot; as name,count(*) as c from serviceconfighosts  as  serviceconfighosts union all \nselect &quot;serviceconfig&quot; as name,count(*) as c from serviceconfig  as  serviceconfig union all \nselect &quot;serviceconfigmapping&quot; as name,count(*) as c from serviceconfigmapping  as  serviceconfigmapping union all \nselect &quot;hostcomponentdesiredstate&quot; as name,count(*) as c from hostcomponentdesiredstate  as  hostcomponentdesiredstate union all \nselect &quot;hosts&quot; as name,count(*) as c from hosts  as  hosts union all \nselect &quot;clusterstate&quot; as name,count(*) as c from clusterstate  as  clusterstate union all \nselect &quot;clusterservices&quot; as name,count(*) as c from clusterservices  as  clusterservices union all \nselect &quot;servicecomponentdesiredstate&quot; as name,count(*) as c from servicecomponentdesiredstate  as  servicecomponentdesiredstate union all \nselect &quot;hostcomponentstate&quot; as name,count(*) as c from hostcomponentstate  as  hostcomponentstate union all \nselect &quot;hoststate&quot; as name,count(*) as c from hoststate  as  hoststate union all \nselect &quot;host_version&quot; as name,count(*) as c from host_version  as  host_version union all \nselect &quot;groups&quot; as name,count(*) as c from groups  as  groups union all \nselect &quot;servicedesiredstate&quot; as name,count(*) as c from servicedesiredstate  as  servicedesiredstate union all \nselect &quot;adminprincipaltype&quot; as name,count(*) as c from adminprincipaltype  as  adminprincipaltype union all \nselect &quot;users&quot; as name,count(*) as c from users  as  users union all \nselect &quot;members&quot; as name,count(*) as c from members  as  members union all \nselect &quot;repo_version&quot; as name,count(*) as c from repo_version  as  repo_version union all \nselect &quot;adminprincipal&quot; as name,count(*) as c from adminprincipal  as  adminprincipal union all \nselect &quot;host_role_command&quot; as name,count(*) as c from host_role_command  as  host_role_command union all \nselect &quot;stage&quot; as name,count(*) as c from stage  as  stage union all \nselect &quot;requestschedule&quot; as name,count(*) as c from requestschedule  as  requestschedule union all \nselect &quot;request&quot; as name,count(*) as c from request  as  request union all \nselect &quot;execution_command&quot; as name,count(*) as c from execution_command  as  execution_command union all \nselect &quot;role_success_criteria&quot; as name,count(*) as c from role_success_criteria  as  role_success_criteria union all \nselect &quot;ambari_sequences&quot; as name,count(*) as c from ambari_sequences  as  ambari_sequences union all \nselect &quot;requestresourcefilter&quot; as name,count(*) as c from requestresourcefilter  as  requestresourcefilter union all \nselect &quot;requestoperationlevel&quot; as name,count(*) as c from requestoperationlevel  as  requestoperationlevel union all \nselect &quot;clusterhostmapping&quot; as name,count(*) as c from clusterhostmapping  as  clusterhostmapping union all \nselect &quot;key_value_store&quot; as name,count(*) as c from key_value_store  as  key_value_store union all \nselect &quot;configgroup&quot; as name,count(*) as c from configgroup  as  configgroup union all \nselect &quot;hostconfigmapping&quot; as name,count(*) as c from hostconfigmapping  as  hostconfigmapping union all \nselect &quot;metainfo&quot; as name,count(*) as c from metainfo  as  metainfo union all \nselect &quot;confgroupclusterconfigmapping&quot; as name,count(*) as c from confgroupclusterconfigmapping  as  confgroupclusterconfigmapping union all \nselect &quot;configgrouphostmapping&quot; as name,count(*) as c from configgrouphostmapping  as  configgrouphostmapping union all \nselect &quot;requestschedulebatchrequest&quot; as name,count(*) as c from requestschedulebatchrequest  as  requestschedulebatchrequest union all \nselect &quot;hostgroup&quot; as name,count(*) as c from hostgroup  as  hostgroup union all \nselect &quot;hostgroup_configuration&quot; as name,count(*) as c from hostgroup_configuration  as  hostgroup_configuration union all \nselect &quot;viewmain&quot; as name,count(*) as c from viewmain  as  viewmain union all \nselect &quot;hostgroup_component&quot; as name,count(*) as c from hostgroup_component  as  hostgroup_component union all \nselect &quot;viewurl&quot; as name,count(*) as c from viewurl  as  viewurl union all \nselect &quot;blueprint_configuration&quot; as name,count(*) as c from blueprint_configuration  as  blueprint_configuration union all \nselect &quot;blueprint&quot; as name,count(*) as c from blueprint  as  blueprint union all \nselect &quot;viewinstance&quot; as name,count(*) as c from viewinstance  as  viewinstance union all \nselect &quot;blueprint_setting&quot; as name,count(*) as c from blueprint_setting  as  blueprint_setting union all \nselect &quot;viewinstancedata&quot; as name,count(*) as c from viewinstancedata  as  viewinstancedata union all \nselect &quot;viewinstanceproperty&quot; as name,count(*) as c from viewinstanceproperty  as  viewinstanceproperty union all \nselect &quot;viewparameter&quot; as name,count(*) as c from viewparameter  as  viewparameter union all \nselect &quot;adminpermission&quot; as name,count(*) as c from adminpermission  as  adminpermission union all \nselect &quot;roleauthorization&quot; as name,count(*) as c from roleauthorization  as  roleauthorization union all \nselect &quot;viewresource&quot; as name,count(*) as c from viewresource  as  viewresource union all \nselect &quot;viewentity&quot; as name,count(*) as c from viewentity  as  viewentity union all \nselect &quot;adminprivilege&quot; as name,count(*) as c from adminprivilege  as  adminprivilege union all \nselect &quot;permission_roleauthorization&quot; as name,count(*) as c from permission_roleauthorization  as  permission_roleauthorization union all \nselect &quot;widget&quot; as name,count(*) as c from widget  as  widget union all \nselect &quot;widget_layout&quot; as name,count(*) as c from widget_layout  as  widget_layout union all \nselect &quot;widget_layout_user_widget&quot; as name,count(*) as c from widget_layout_user_widget  as  widget_layout_user_widget union all \nselect &quot;artifact&quot; as name,count(*) as c from artifact  as  artifact union all \nselect &quot;topology_hostgroup&quot; as name,count(*) as c from topology_hostgroup  as  topology_hostgroup union all \nselect &quot;topology_host_task&quot; as name,count(*) as c from topology_host_task  as  topology_host_task union all \nselect &quot;topology_logical_request&quot; as name,count(*) as c from topology_logical_request  as  topology_logical_request union all \nselect &quot;topology_logical_task&quot; as name,count(*) as c from topology_logical_task  as  topology_logical_task union all \nselect &quot;topology_host_info&quot; as name,count(*) as c from topology_host_info  as  topology_host_info union all \nselect &quot;topology_request&quot; as name,count(*) as c from topology_request  as  topology_request union all \nselect &quot;setting&quot; as name,count(*) as c from setting  as  setting union all \nselect &quot;topology_host_request&quot; as name,count(*) as c from topology_host_request  as  topology_host_request union all \nselect &quot;remoteambaricluster&quot; as name,count(*) as c from remoteambaricluster  as  remoteambaricluster union all \nselect &quot;remoteambariclusterservice&quot; as name,count(*) as c from remoteambariclusterservice  as  remoteambariclusterservice union all \nselect &quot;ambari_operation_history&quot; as name,count(*) as c from ambari_operation_history  as  ambari_operation_history union all \nselect &quot;kerberos_descriptor&quot; as name,count(*) as c from kerberos_descriptor  as  kerberos_descriptor union all \nselect &quot;upgrade&quot; as name,count(*) as c from upgrade  as  upgrade union all \nselect &quot;upgrade_group&quot; as name,count(*) as c from upgrade_group  as  upgrade_group union all \nselect &quot;upgrade_item&quot; as name,count(*) as c from upgrade_item  as  upgrade_item union all \nselect &quot;upgrade_history&quot; as name,count(*) as c from upgrade_history  as  upgrade_history union all \nselect &quot;kerberos_principal&quot; as name,count(*) as c from kerberos_principal  as  kerberos_principal union all \nselect &quot;servicecomponent_version&quot; as name,count(*) as c from servicecomponent_version  as  servicecomponent_version union all \nselect &quot;kerberos_principal_host&quot; as name,count(*) as c from kerberos_principal_host  as  kerberos_principal_host union all \nselect &quot;alert_definition&quot; as name,count(*) as c from alert_definition  as  alert_definition union all \nselect &quot;alert_group&quot; as name,count(*) as c from alert_group  as  alert_group union all \nselect &quot;alert_grouping&quot; as name,count(*) as c from alert_grouping  as  alert_grouping union all \nselect &quot;alert_current&quot; as name,count(*) as c from alert_current  as  alert_current union all \nselect &quot;alert_target&quot; as name,count(*) as c from alert_target  as  alert_target union all \nselect &quot;alert_target_states&quot; as name,count(*) as c from alert_target_states  as  alert_target_states union all \nselect &quot;alert_history&quot; as name,count(*) as c from alert_history  as  alert_history union all \nselect &quot;alert_group_target&quot; as name,count(*) as c from alert_group_target  as  alert_group_target union all \nselect &quot;alert_notice&quot; as name,count(*) as c from alert_notice  as  alert_notice union all \nselect &quot;qrtz_job_details&quot; as name,count(*) as c from qrtz_job_details  as  qrtz_job_details union all \nselect &quot;qrtz_triggers&quot; as name,count(*) as c from qrtz_triggers  as  qrtz_triggers union all \nselect &quot;qrtz_simple_triggers&quot; as name,count(*) as c from qrtz_simple_triggers  as  qrtz_simple_triggers union all \nselect &quot;qrtz_cron_triggers&quot; as name,count(*) as c from qrtz_cron_triggers  as  qrtz_cron_triggers union all \nselect &quot;qrtz_simprop_triggers&quot; as name,count(*) as c from qrtz_simprop_triggers  as  qrtz_simprop_triggers union all \nselect &quot;qrtz_blob_triggers&quot; as name,count(*) as c from qrtz_blob_triggers  as  qrtz_blob_triggers union all \nselect &quot;qrtz_calendars&quot; as name,count(*) as c from qrtz_calendars  as  qrtz_calendars union all \nselect &quot;qrtz_paused_trigger_grps&quot; as name,count(*) as c from qrtz_paused_trigger_grps  as  qrtz_paused_trigger_grps union all \nselect &quot;qrtz_fired_triggers&quot; as name,count(*) as c from qrtz_fired_triggers  as  qrtz_fired_triggers union all \nselect &quot;qrtz_scheduler_state&quot; as name,count(*) as c from qrtz_scheduler_state  as  qrtz_scheduler_state union all \nselect &quot;qrtz_locks&quot; as name,count(*) as c from qrtz_locks  as  qrtz_locks as ambari_tables_count;\n\nsave overwrite ambari_tables_count\nas jdbc.`ambari.ambari_tables_count`\noptions truncate=&quot;true&quot;\nand url=&quot;jdbc:mysql://127.0.0.1:3307/ambari&quot;\nand driver=&quot;com.mysql.jdbc.Driver&quot;\nand user=&quot;root&quot;\nand password=&quot;&quot;;\n\n\nconnect jdbc where  \ntruncate=&quot;true&quot; \nand url=&quot;jdbc:mysql://127.0.0.1:3307/ambari&quot; \nand driver=&quot;com.mysql.jdbc.Driver&quot; \nand user=&quot;root&quot; \nand password=&quot;&quot; \nas mysql;\n\nload jdbc.`mysql.ambari_tables_count` as ambari_tables_count;\n\nselect * from ambari_tables_count order by c desc as ambari_tables_count;\n\nselect c.name as cname,c.c as cc,a.name,a.c from (select name,c from ambari_tables_count) as c\nleft join\na\non  c.name=a.name as d\n;\n</code></pre>\n');
INSERT INTO `tbl_archive` VALUES ('67', '0', 'hadoop集群死机原因排查故障及解决', '25', '2018-09-28 10:30:04', 'hadoop集群 50台集群 50台集群经常出现死机情况。', null, '0', '297', null, null, '2018-09-28 10:30:04', '2018-09-28 11:31:08', null, null, '0', '0', '0', '0', '###由于系统工程师排查系统缓存太大要求优化系统修改以下参数。\n###1. 把vm.dirty_background_ratio = 10修改为vm.dirty_background_ratio = 5\n###2. 把vm.dirty_ratio = 20修改为vm.dirty_ratio = 2\n### 3. sysctl  -p  生效\n### 4. 由于以上配置临时配置想要永久生效需要写到配置文件中，另外由于机器太多一台一台机器写工作量比较大，用以下办法比较快速的更改。\n### 5. 首先在linux系统中写一个文本文本里面写上 你要更改的机器ip地址\n### 6.我写的是 目录为 （/niu/servers）\n### 7.我们进入 /niu/目录下面\n### 8.用for语句循环去写在配置文件中（/etc/sysctl.conf）\n### 9.for循环语句添加vm.dirty_background_ratio = 5\nfor i in `cat servers`;do ssh -fn $i \"echo vm.dirty_background_ratio = 5 >> /etc/sysctl.conf\";done\n### 10.for语句循环添加vm.dirty_ratio = 2\nfor i in `cat servers`;do ssh -fn $i \"echo vm.dirty_ratio = 2 >> /etc/sysctl.conf\";done\n### 11.for语句循环生效\nfor i in `cat servers`;do ssh  -fn $i \"sysctl -p \";done\n### 12.for语句循环是否生效更改\nfor i in `cat servers`;do ssh -fn $i  \"sysctl  -a | grep vm.dirty_background_ratio = 5\";done \n### 13.for语句循环是否生效更改\nfor i in `cat servers`;do ssh -fn $i  \"sysctl  -a | grep vm.dirty_ratio = 2\";done ', '0', '<h3 id=\"h3--\"><a name=\"由于系统工程师排查系统缓存太大要求优化系统修改以下参数。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>由于系统工程师排查系统缓存太大要求优化系统修改以下参数。</h3><h3 id=\"h3-1-vm-dirty_background_ratio-10-vm-dirty_background_ratio-5\"><a name=\"1. 把vm.dirty_background_ratio = 10修改为vm.dirty_background_ratio = 5\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1. 把vm.dirty_background_ratio = 10修改为vm.dirty_background_ratio = 5</h3><h3 id=\"h3-2-vm-dirty_ratio-20-vm-dirty_ratio-2\"><a name=\"2. 把vm.dirty_ratio = 20修改为vm.dirty_ratio = 2\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2. 把vm.dirty_ratio = 20修改为vm.dirty_ratio = 2</h3><h3 id=\"h3-3-sysctl-p-\"><a name=\"3. sysctl  -p  生效\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3. sysctl  -p  生效</h3><h3 id=\"h3-4-\"><a name=\"4. 由于以上配置临时配置想要永久生效需要写到配置文件中，另外由于机器太多一台一台机器写工作量比较大，用以下办法比较快速的更改。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4. 由于以上配置临时配置想要永久生效需要写到配置文件中，另外由于机器太多一台一台机器写工作量比较大，用以下办法比较快速的更改。</h3><h3 id=\"h3-5-linux-ip-\"><a name=\"5. 首先在linux系统中写一个文本文本里面写上 你要更改的机器ip地址\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5. 首先在linux系统中写一个文本文本里面写上 你要更改的机器ip地址</h3><h3 id=\"h3-6-niu-servers-\"><a name=\"6.我写的是 目录为 （/niu/servers）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6.我写的是 目录为 （/niu/servers）</h3><h3 id=\"h3-7-niu-\"><a name=\"7.我们进入 /niu/目录下面\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.我们进入 /niu/目录下面</h3><h3 id=\"h3-8-for-etc-sysctl-conf-\"><a name=\"8.用for语句循环去写在配置文件中（/etc/sysctl.conf）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>8.用for语句循环去写在配置文件中（/etc/sysctl.conf）</h3><h3 id=\"h3-9-for-vm-dirty_background_ratio-5\"><a name=\"9.for循环语句添加vm.dirty_background_ratio = 5\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>9.for循环语句添加vm.dirty_background_ratio = 5</h3><p>for i in <code>cat servers</code>;do ssh -fn $i “echo vm.dirty_background_ratio = 5 &gt;&gt; /etc/sysctl.conf”;done</p>\n<h3 id=\"h3-10-for-vm-dirty_ratio-2\"><a name=\"10.for语句循环添加vm.dirty_ratio = 2\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>10.for语句循环添加vm.dirty_ratio = 2</h3><p>for i in <code>cat servers</code>;do ssh -fn $i “echo vm.dirty_ratio = 2 &gt;&gt; /etc/sysctl.conf”;done</p>\n<h3 id=\"h3-11-for-\"><a name=\"11.for语句循环生效\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>11.for语句循环生效</h3><p>for i in <code>cat servers</code>;do ssh  -fn $i “sysctl -p “;done</p>\n<h3 id=\"h3-12-for-\"><a name=\"12.for语句循环是否生效更改\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>12.for语句循环是否生效更改</h3><p>for i in <code>cat servers</code>;do ssh -fn $i  “sysctl  -a | grep vm.dirty_background_ratio = 5”;done </p>\n<h3 id=\"h3-13-for-\"><a name=\"13.for语句循环是否生效更改\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>13.for语句循环是否生效更改</h3><p>for i in <code>cat servers</code>;do ssh -fn $i  “sysctl  -a | grep vm.dirty_ratio = 2”;done </p>\n');
INSERT INTO `tbl_archive` VALUES ('68', '0', 'CRH 产品客户问题', '8', '2018-11-30 18:41:16', 'CRH产品客户问题##问：```请教一个技术问题，我用flume从Windows采集文件到hdfs，怎样修改进去hdfs的文件名？我不想用默认的```![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/1.jpg?raw=true)##答：```FlumeData是前缀', null, '0', '98', null, null, '2018-11-30 18:41:16', null, null, null, '0', '0', '0', '0', 'CRH 产品客户问题\n## 问：\n\n```\n请教一个技术问题，我用flume从Windows采集文件到hdfs，怎样修改进去hdfs的文件名？我不想用默认的\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/1.jpg?raw=true)\n\n## 答：\n\n```\nFlumeData是前缀，这个前缀是默认的，自己也可修改，后缀是一串数字，这串数字是时间的信息 :前缀修改的话需要改配置文件。在配置文件中添加agent1.sinks.hdfs_sink.hdfs.filePrefix = %{fileName}  #把原来的文件名作为前缀\n重启flume\n```\n\n# 2018年9月20日（已解决）\n\n## 问：\n\n```\n你好，我想往大数据平台的hdfs用户下上传文件，好像不能用ftp工具直接连啊？\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/2.png?raw=true)\n\n## 答：\n\n```\n请问您使用的是哪一个用户，使用ftp进行文件传输，请使用root用户。\n```\n\n## 问：\n\n```\n还有一个问题，我用一个wordcount测试下spark，但是报的连接错误\n\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/3.png?raw=true)\n\n## 答：\n\n```\n端口改为8020\n```\n\n## 问：\n\n```\n8020是固定端口吗？\n```\n\n## 答：\n\n```\n可以在界面的hdfs配置里面查看和变更，默认是8020\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/4.png?raw=true)\n\n# 2018年9月25日（已解决）\n\n## 问：\n\n```\n赵工，这个箭头是什么意思啊？\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/5.png?raw=true)\n\n## 答：\n\n```\n箭头是软链接。\n```\n\n## 问：\n\n```\n\n```\n\n\n\n## 答:\n\n```\n/etc/flume/*/*/是配置文件的真实生成目录，/etc/crh/*/flume/conf也需要配置文件，所以在就创建了软连接 直接引用过来了\n```\n\n## 问：\n\n```\n那我应该在/etc/flume/修改配置文件吗？\n```\n\n## 答：\n\n```\n所有的配置文件都在界面上修改，不然会被回滚。\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/6.png?raw=true)\n\n# 2018年10月11日（已解决）\n\n## 问：\n\n```\n我用hive统计的结果自动生成在了红框的目录下，但是这个用户属于hive，我用hdfs用户进不去\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/7.png?raw=true)\n\n## 答：\n\n```\n\n没有写权限，请赋予写权限，执行：hdfs dfs -chmod 755 /hive\n\n```\n\n## 问：\n\n```\nhive查询结果保存成文件也是报错\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/8.png?raw=true)\n\n## 答：\n\n```\n因为你现在的操作用户是hdfs用户，/data目录的用户 用户组是root root吧，是权限问题\n```\n\n## 问：\n\n```\n/data 确实是属于root,那怎么改？\n```\n\n## 答：\n\n```\n在root用户下修改/data目录的所有者\nchown hdfs:hdfs -R /data\n重新执行\n\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/13.png?raw=true)\n\n\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/11.png?raw=true)\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/12.png?raw=true)\n\n## 问：\n\n```\n可以了，但是还有一个疑问，好像我不能保存成指定的文件名？\n```\n\n## 答：\n\n```\n我看了一下官网 好像没有办法 不能指定输出文件的格式。\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/14.png?raw=true)\n\n# 2018年10月12日（已解决）\n\n## 问：\n\n```\n遇到一个问题，sqoop迁移hive数据到oracle，报错超时，每次都是运行到map为100%的时候卡着，报错信息里面说让装这个东西。\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/15.jpg?raw=true)\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/16.jpg?raw=true)\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/17.png?raw=true)\n\n## 答：\n\n```\n首先警告问题不影响大局，暂时不用解决，关于map超时的问题，通过查看日志报一下错误：考虑权限问题：\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/18.png?raw=true)\n\n\n\n```\n使用system用户登陆到oracle数据库中，给操作用户赋予以下权限\ngrant connect to 操作用户;\ngrant resource to 操作用户;\ngrant dba to 操作用户;\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/19.png?raw=true)\n\n# 2018年11月7日（已解决）\n\n# 问：\n\n```\nspark执行任务的时候超时，连接被拒绝\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/20.png?raw=true)\n\n# 答：\n\n```\n从截图看出访问不到HDFS文件系统的原因导致的错误 。从以下几个方面排查问题：1.端口是否正确 2.namenode是否正常启动 3.高可用集群哪个节点的namenode为active。经过排查，属于问题3，解决办法：1.将主机换成active namenode所在的机器。2.切换一下active namenode:具体做法重启一下active namenode\n```\n\n# 2018年11月8日（已解决）\n\n# 问：\n\n```\n\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/21.png?raw=true)\n\n```\nproducer 9092    consumer 2181\n```\n\n# 答：\n\n```\n请将生产者的端口改为：6667\n```\n\n# 2018年11月29日（已解决）\n\n# 问：\n\n```\n用Navicat连接下集群的mysql，查看hive元数据信息，为什么没权限啊？\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/22.png?raw=true)\n\n# 答：\n\n```\n登陆到mysql，执行以下命令\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/23.png?raw=true)\n\n# 结果\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/24.png?raw=true)\n\n# 答：\n\n```\n请将连接的主机名改为test02\n```\n\n# 问：\n\n```\n为什么显示的是mariaDB，而不是mysql\n```\n\n![](https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/25.jpg?raw=true)\n\n# 答：\n\n```\n和mysql是一样的  用法也完全相同\n```\n\n', '0', '<p>CRH 产品客户问题</p>\n<h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>请教一个技术问题，我用flume从Windows采集文件到hdfs，怎样修改进去hdfs的文件名？我不想用默认的\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/1.jpg?raw=true\" alt=\"\"></p>\n<h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>FlumeData是前缀，这个前缀是默认的，自己也可修改，后缀是一串数字，这串数字是时间的信息 :前缀修改的话需要改配置文件。在配置文件中添加agent1.sinks.hdfs_sink.hdfs.filePrefix = %{fileName}  #把原来的文件名作为前缀\n重启flume\n</code></pre><h1 id=\"h1-2018-9-20-\"><a name=\"2018年9月20日（已解决）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2018年9月20日（已解决）</h1><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>你好，我想往大数据平台的hdfs用户下上传文件，好像不能用ftp工具直接连啊？\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/2.png?raw=true\" alt=\"\"></p>\n<h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>请问您使用的是哪一个用户，使用ftp进行文件传输，请使用root用户。\n</code></pre><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>还有一个问题，我用一个wordcount测试下spark，但是报的连接错误\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/3.png?raw=true\" alt=\"\"></p>\n<h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>端口改为8020\n</code></pre><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>8020是固定端口吗？\n</code></pre><h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>可以在界面的hdfs配置里面查看和变更，默认是8020\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/4.png?raw=true\" alt=\"\"></p>\n<h1 id=\"h1-2018-9-25-\"><a name=\"2018年9月25日（已解决）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2018年9月25日（已解决）</h1><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>赵工，这个箭头是什么意思啊？\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/5.png?raw=true\" alt=\"\"></p>\n<h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>箭头是软链接。\n</code></pre><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>\n\n</code></pre><h2 id=\"h2--\"><a name=\"答:\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答:</h2><pre><code>/etc/flume/*/*/是配置文件的真实生成目录，/etc/crh/*/flume/conf也需要配置文件，所以在就创建了软连接 直接引用过来了\n</code></pre><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>那我应该在/etc/flume/修改配置文件吗？\n</code></pre><h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>所有的配置文件都在界面上修改，不然会被回滚。\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/6.png?raw=true\" alt=\"\"></p>\n<h1 id=\"h1-2018-10-11-\"><a name=\"2018年10月11日（已解决）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2018年10月11日（已解决）</h1><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>我用hive统计的结果自动生成在了红框的目录下，但是这个用户属于hive，我用hdfs用户进不去\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/7.png?raw=true\" alt=\"\"></p>\n<h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>\n没有写权限，请赋予写权限，执行：hdfs dfs -chmod 755 /hive\n</code></pre><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>hive查询结果保存成文件也是报错\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/8.png?raw=true\" alt=\"\"></p>\n<h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>因为你现在的操作用户是hdfs用户，/data目录的用户 用户组是root root吧，是权限问题\n</code></pre><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>/data 确实是属于root,那怎么改？\n</code></pre><h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>在root用户下修改/data目录的所有者\nchown hdfs:hdfs -R /data\n重新执行\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/13.png?raw=true\" alt=\"\"></p>\n<p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/11.png?raw=true\" alt=\"\"></p>\n<p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/12.png?raw=true\" alt=\"\"></p>\n<h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>可以了，但是还有一个疑问，好像我不能保存成指定的文件名？\n</code></pre><h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>我看了一下官网 好像没有办法 不能指定输出文件的格式。\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/14.png?raw=true\" alt=\"\"></p>\n<h1 id=\"h1-2018-10-12-\"><a name=\"2018年10月12日（已解决）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2018年10月12日（已解决）</h1><h2 id=\"h2--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h2><pre><code>遇到一个问题，sqoop迁移hive数据到oracle，报错超时，每次都是运行到map为100%的时候卡着，报错信息里面说让装这个东西。\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/15.jpg?raw=true\" alt=\"\"></p>\n<p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/16.jpg?raw=true\" alt=\"\"></p>\n<p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/17.png?raw=true\" alt=\"\"></p>\n<h2 id=\"h2--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h2><pre><code>首先警告问题不影响大局，暂时不用解决，关于map超时的问题，通过查看日志报一下错误：考虑权限问题：\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/18.png?raw=true\" alt=\"\"></p>\n<pre><code>使用system用户登陆到oracle数据库中，给操作用户赋予以下权限\ngrant connect to 操作用户;\ngrant resource to 操作用户;\ngrant dba to 操作用户;\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/19.png?raw=true\" alt=\"\"></p>\n<h1 id=\"h1-2018-11-7-\"><a name=\"2018年11月7日（已解决）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2018年11月7日（已解决）</h1><h1 id=\"h1--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h1><pre><code>spark执行任务的时候超时，连接被拒绝\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/20.png?raw=true\" alt=\"\"></p>\n<h1 id=\"h1--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h1><pre><code>从截图看出访问不到HDFS文件系统的原因导致的错误 。从以下几个方面排查问题：1.端口是否正确 2.namenode是否正常启动 3.高可用集群哪个节点的namenode为active。经过排查，属于问题3，解决办法：1.将主机换成active namenode所在的机器。2.切换一下active namenode:具体做法重启一下active namenode\n</code></pre><h1 id=\"h1-2018-11-8-\"><a name=\"2018年11月8日（已解决）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2018年11月8日（已解决）</h1><h1 id=\"h1--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h1><pre><code>\n\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/21.png?raw=true\" alt=\"\"></p>\n<pre><code>producer 9092    consumer 2181\n</code></pre><h1 id=\"h1--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h1><pre><code>请将生产者的端口改为：6667\n</code></pre><h1 id=\"h1-2018-11-29-\"><a name=\"2018年11月29日（已解决）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2018年11月29日（已解决）</h1><h1 id=\"h1--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h1><pre><code>用Navicat连接下集群的mysql，查看hive元数据信息，为什么没权限啊？\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/22.png?raw=true\" alt=\"\"></p>\n<h1 id=\"h1--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h1><pre><code>登陆到mysql，执行以下命令\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/23.png?raw=true\" alt=\"\"></p>\n<h1 id=\"h1-u7ED3u679C\"><a name=\"结果\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>结果</h1><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/24.png?raw=true\" alt=\"\"></p>\n<h1 id=\"h1--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h1><pre><code>请将连接的主机名改为test02\n</code></pre><h1 id=\"h1--\"><a name=\"问：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>问：</h1><pre><code>为什么显示的是mariaDB，而不是mysql\n</code></pre><p><img src=\"https://github.com/sdjok/CRH_pictures/blob/master/%E6%97%A0%E9%94%A1%E5%94%AE%E5%90%8E/25.jpg?raw=true\" alt=\"\"></p>\n<h1 id=\"h1--\"><a name=\"答：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>答：</h1><pre><code>和mysql是一样的  用法也完全相同\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('69', '0', 'redhat6.5部署cacti监控软件', '25', '2019-01-03 13:58:34', 'cacti监控Linux机器CPU,内存，磁盘等，后面还会写到怎样去监控磁盘IO读写情况等。', null, '0', '121', null, null, '2019-01-03 13:58:34', '2019-01-03 14:16:22', null, null, '0', '0', '0', '0', '# 概述 \n### cacti 是用 php 语言实现的一个软件，它的主要功能是用 snmp 服务获取数据，然后 用 rrdtool 储存和更新数据，当用户需要查看数据的时候用 rrdtool 生成图表呈现给 用户。因此，snmp 和 rrdtool 是 cacti 的关键。Snmp 关系着数据的收集，rrdtool 关 系着数据存储和图表的生成。 \n### Mysql 配合 PHP 程序存储一些变量数据并对变量数据进行调用，如：主机名、主机 ip、 snmp 团体名、端口号、模板信息等变量。 \n### snmp 抓到数据不是存储在 mysql 中，而是存在 rrdtool 生成的 rrd 文件中（在 cacti 根目录的 rra 文件夹下）。rrdtool 对数据的更新和存储就是对 rrd 文件的处理，rrd 文件是大小固定的档案文件（Round Robin Archive），它能够存储的数据笔数在创 建时就已经定义。关于 RRDTool 的知识请参阅 RRDTool 教学。\n\n#Cacti 的架构及工作流程 \n### Cacti 的架构\n![](/upload/images/20190103//1389a09e-fb5e-4ef9-8520-9a6aa7bead94.jpg)\n### Cacti 的工作流程\n![](/upload/images/20190103//4da73826-f70c-4a12-bb35-f9390095791e.jpg)\n#安装cacti\n### 环境\n```\nRedhat6.5\nHttpd+Snmp-5.5.-60+Php +Mysql\nCacti-0.88b \n```\n特别提示\nsnmp版本不能低于snmp-5.5_60\n\n### 安装基础服务(LAMP)\n```\n安装mysql\n   yum -y install mysql-server\n   Installed:\n   mysql-server.x86_64 0:5.1.73-7.el6\n \n   Dependency Installed:\n   perl-DBD-MySQL.x86_64 0:4.013-3.el6                perl-DBI.x86_64    0:1.609-4.el6\n\n   Complete!\n```\n```\n安装httpd服务\nyum -y install httpd\nInstalled:\nhttpd.x86_64 0:2.2.15-54.el6.centos\nDependency Installed:\napr.x86_64 0:1.3.9-5.el6_2                     apr-util.x86_64 0:1.3.9-3.el6_0.1      apr-util-ldap.x86_64 0:1.3.9-3.el6_0.1     \nhttpd-tools.x86_64 0:2.2.15-54.el6.centos      mailcap.noarch        0:2.1.31-2.el6\nComplete!\n```\n```\n安装php服务\n   yum -y install php php-mysql \n   Installed: \n   php.x86_64 0:5.3.3-48.el6_8\n   php-mysql.x86_64 0:5.3.3-48.el6_8\n  \n   Dependency Installed: \n   php-cli.x86_64 0:5.3.3-48.el6_8 \n   php-common.x86_64 0:5.3.3-48.el6_8 \n   php-pdo.x86_64 0:5.3.3-48.el6_8 \n \n Complete!\n```\n检查以下软件是否安装成功\n```\n  [root@monitor-cacti ~]# rpm -qa |egrep \'php|httpd|mysql\' \n mysql-5.1.73-7.el6.x86_64 \n php-common-5.3.3-48.el6_8.x86_64 \n php-pdo-5.3.3-48.el6_8.x86_64 \n php-5.3.3-48.el6_8.x86_64 \n mysql-libs-5.1.73-7.el6.x86_64 \n mysql-server-5.1.73-7.el6.x86_64 \n httpd-tools-2.2.15-54.el6.centos.x86_64 \n httpd-2.2.15-54.el6.centos.x86_64\n php-cli-5.3.3-48.el6_8.x86_64\n php-mysql-5.3.3-48.el6_8.x86_6412 \n[root@monitor-cacti ~]#\n````\n安装需要的库文件\n```\nyum -y install zlib freetype libjpeg fontconfig gd libxml2 zlib freetype libjpeg fontconfig gd libxml2 php-gd \n 输出： \n Installed: \n fontconfig.x86_64 0:2.8.0-5.el6 freetype.x86_64 0:2.3.11-17.el6  gd.x86_64 0:2.0.35-11.el6 libjpeg-turbo.x86_64 0:1.2.1-3.el6_5 \n php-gd.x86_64 0:5.3.3-48.el6_8  \n  \n Dependency Installed:\n libX11.x86_64 0:1.6.3-2.el6     libX11-common.noarch 0:1.6.3-2.el6     libXau.x86_64 0:1.0.6-4.el6  libXpm.x86_64 0:3.5.10-2.el6  \n libpng.x86_64 2:1.2.49-2.el6_7  libxcb.x86_64 0:1.11-2.el6           Updated:\nlibxml2.x86_64 0:2.7.6-21.el6_8.1                                      Complete!\n```\n如果yum安装都出现了Complete! 说明安装的没有问题.\n### 安装rrd工具\n```\n yum -y install rrdtool rrdtool-devel\n```\n### 安装并配置监控需要的snmp工具\n安装Snmp\n```\nyum -y install net-snmp net-snmp-devel net-snmp-utils\n```\n配置Snmp\n```\nvim /etc/snmp/snmpd.conf\ncom2sec notConfigUser  default       public\n改为：com2sec notConfigUser  127.0.0.1       public\naccess  notConfigGroup \"\"      any       noauth    exact  systemview none none\n改为：access  notConfigGroup \"\"      any       noauth    exact  all none none\n#view all    included  .1                               80  去掉注释\n```\n启动服务并加如开机启动\n```\nservice httpd start\nservice mysqld start\nservice snmpd start\nchkconfig httpd on\nchkconfig mysqld on\nchkconfig snmpd on\n```\n### 安装cacti\n```\nwget http://www.cacti.net/downloads/cacti-0.8.7e.tar.gz\ntar zxf cacti-0.8.8b-cn.tar.gz -C /var/www/html/\ncd /var/www/html/\nmv cacti-0.8.8b-cn/ cacti\n```\n初始化数据库\n```\nmysql -u root\nmysql> create database cacti;\nmysql> grant all on cacti.* to cacti@localhost identified by \'cacti\';\nmysql> grant all on cacti.* to cacti@\'127.0.0.1\' identified by \'cacti\';\nmysql> flush privileges;\nmysql> use cacti；\nmysql> source /var/www/html/cacti/cacti.sql;\nmysql> quit\n```\n配置cacti\n```\nvim /var/www/html/cacti/include/config.php \n$database_type = \"mysql\";\n$database_default = \"cacti\";\n$database_hostname = \"localhost\";\n$database_username = \"cacti\";\n$database_password = \"cacti\";\n$database_port = \"3306\"; \n```\n把配置文件里改成和上面一样的就可以了.\n\n设置相关权限和计划任务.\n```\nuseradd cacti -d /var/www/html/cacti -s /sbin/nologin\nchown -R cacti /var/www/html/cacti/rra /var/www/html/cacti/log\necho \'*/5 * * * * root /usr/bin/php /var/www/html/cacti/poller.php > /dev/null 2>&1\' >> /etc/crontab\n```\n### 初始化cacti\n访问你的cacti.地址如下.IP替换成你的服务器ip\nhttp://IP/cacti\n![](/upload/images/20190103//3a863725-4bb7-4ce3-b658-93f4f6f08ba4.png)\n\n如果显示的页面和这个一样.说明你前面配置的没有问题了.\n直接点击next>>\n![](/upload/images/20190103//b674c6e5-5968-4b80-a315-eac5da115e4e.png)\n如果都显示ok则可以点击finish.如果有not found 则要看看是哪个命令或者路径不对.\nfinsh之后就是登录界面了,用户名和密码都是admin.\n![](/upload/images/20190103//fea96d36-ae8c-4749-a563-975ee09a36bd.png)\n\n\n第一次登录需要修改密码.如下\n![](/upload/images/20190103//25cd81cd-97b0-4b32-a323-ef255e880189.png)\n填入新密码保存即可.\n这样cacti就安装完成了.\n\n', '0', '<h1 id=\"h1-u6982u8FF0\"><a name=\"概述\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>概述</h1><h3 id=\"h3-cacti-php-snmp-rrdtool-rrdtool-snmp-rrdtool-cacti-snmp-rrdtool-\"><a name=\"cacti 是用 php 语言实现的一个软件，它的主要功能是用 snmp 服务获取数据，然后 用 rrdtool 储存和更新数据，当用户需要查看数据的时候用 rrdtool 生成图表呈现给 用户。因此，snmp 和 rrdtool 是 cacti 的关键。Snmp 关系着数据的收集，rrdtool 关 系着数据存储和图表的生成。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>cacti 是用 php 语言实现的一个软件，它的主要功能是用 snmp 服务获取数据，然后 用 rrdtool 储存和更新数据，当用户需要查看数据的时候用 rrdtool 生成图表呈现给 用户。因此，snmp 和 rrdtool 是 cacti 的关键。Snmp 关系着数据的收集，rrdtool 关 系着数据存储和图表的生成。</h3><h3 id=\"h3-mysql-php-ip-snmp-\"><a name=\"Mysql 配合 PHP 程序存储一些变量数据并对变量数据进行调用，如：主机名、主机 ip、 snmp 团体名、端口号、模板信息等变量。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Mysql 配合 PHP 程序存储一些变量数据并对变量数据进行调用，如：主机名、主机 ip、 snmp 团体名、端口号、模板信息等变量。</h3><h3 id=\"h3-snmp-mysql-rrdtool-rrd-cacti-rra-rrdtool-rrd-rrd-round-robin-archive-rrdtool-rrdtool-\"><a name=\"snmp 抓到数据不是存储在 mysql 中，而是存在 rrdtool 生成的 rrd 文件中（在 cacti 根目录的 rra 文件夹下）。rrdtool 对数据的更新和存储就是对 rrd 文件的处理，rrd 文件是大小固定的档案文件（Round Robin Archive），它能够存储的数据笔数在创 建时就已经定义。关于 RRDTool 的知识请参阅 RRDTool 教学。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>snmp 抓到数据不是存储在 mysql 中，而是存在 rrdtool 生成的 rrd 文件中（在 cacti 根目录的 rra 文件夹下）。rrdtool 对数据的更新和存储就是对 rrd 文件的处理，rrd 文件是大小固定的档案文件（Round Robin Archive），它能够存储的数据笔数在创 建时就已经定义。关于 RRDTool 的知识请参阅 RRDTool 教学。</h3><h1 id=\"h1-cacti-\"><a name=\"Cacti 的架构及工作流程\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Cacti 的架构及工作流程</h1><h3 id=\"h3-cacti-\"><a name=\"Cacti 的架构\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Cacti 的架构</h3><p><img src=\"/upload/images/20190103//1389a09e-fb5e-4ef9-8520-9a6aa7bead94.jpg\" alt=\"\"></p>\n<h3 id=\"h3-cacti-\"><a name=\"Cacti 的工作流程\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Cacti 的工作流程</h3><p><img src=\"/upload/images/20190103//4da73826-f70c-4a12-bb35-f9390095791e.jpg\" alt=\"\"></p>\n<h1 id=\"h1--cacti\"><a name=\"安装cacti\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装cacti</h1><h3 id=\"h3-u73AFu5883\"><a name=\"环境\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>环境</h3><pre><code>Redhat6.5\nHttpd+Snmp-5.5.-60+Php +Mysql\nCacti-0.88b\n</code></pre><p>特别提示<br>snmp版本不能低于snmp-5.5_60</p>\n<h3 id=\"h3--lamp-\"><a name=\"安装基础服务(LAMP)\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装基础服务(LAMP)</h3><pre><code>安装mysql\n   yum -y install mysql-server\n   Installed:\n   mysql-server.x86_64 0:5.1.73-7.el6\n\n   Dependency Installed:\n   perl-DBD-MySQL.x86_64 0:4.013-3.el6                perl-DBI.x86_64    0:1.609-4.el6\n\n   Complete!\n</code></pre><pre><code>安装httpd服务\nyum -y install httpd\nInstalled:\nhttpd.x86_64 0:2.2.15-54.el6.centos\nDependency Installed:\napr.x86_64 0:1.3.9-5.el6_2                     apr-util.x86_64 0:1.3.9-3.el6_0.1      apr-util-ldap.x86_64 0:1.3.9-3.el6_0.1     \nhttpd-tools.x86_64 0:2.2.15-54.el6.centos      mailcap.noarch        0:2.1.31-2.el6\nComplete!\n</code></pre><pre><code>安装php服务\n   yum -y install php php-mysql \n   Installed: \n   php.x86_64 0:5.3.3-48.el6_8\n   php-mysql.x86_64 0:5.3.3-48.el6_8\n\n   Dependency Installed: \n   php-cli.x86_64 0:5.3.3-48.el6_8 \n   php-common.x86_64 0:5.3.3-48.el6_8 \n   php-pdo.x86_64 0:5.3.3-48.el6_8 \n\n Complete!\n</code></pre><p>检查以下软件是否安装成功</p>\n<pre><code>  [root@monitor-cacti ~]# rpm -qa |egrep &#39;php|httpd|mysql&#39; \n mysql-5.1.73-7.el6.x86_64 \n php-common-5.3.3-48.el6_8.x86_64 \n php-pdo-5.3.3-48.el6_8.x86_64 \n php-5.3.3-48.el6_8.x86_64 \n mysql-libs-5.1.73-7.el6.x86_64 \n mysql-server-5.1.73-7.el6.x86_64 \n httpd-tools-2.2.15-54.el6.centos.x86_64 \n httpd-2.2.15-54.el6.centos.x86_64\n php-cli-5.3.3-48.el6_8.x86_64\n php-mysql-5.3.3-48.el6_8.x86_6412 \n[root@monitor-cacti ~]#\n`\n</code></pre><p>安装需要的库文件</p>\n<pre><code>yum -y install zlib freetype libjpeg fontconfig gd libxml2 zlib freetype libjpeg fontconfig gd libxml2 php-gd \n 输出： \n Installed: \n fontconfig.x86_64 0:2.8.0-5.el6 freetype.x86_64 0:2.3.11-17.el6  gd.x86_64 0:2.0.35-11.el6 libjpeg-turbo.x86_64 0:1.2.1-3.el6_5 \n php-gd.x86_64 0:5.3.3-48.el6_8  \n\n Dependency Installed:\n libX11.x86_64 0:1.6.3-2.el6     libX11-common.noarch 0:1.6.3-2.el6     libXau.x86_64 0:1.0.6-4.el6  libXpm.x86_64 0:3.5.10-2.el6  \n libpng.x86_64 2:1.2.49-2.el6_7  libxcb.x86_64 0:1.11-2.el6           Updated:\nlibxml2.x86_64 0:2.7.6-21.el6_8.1                                      Complete!\n</code></pre><p>如果yum安装都出现了Complete! 说明安装的没有问题.</p>\n<h3 id=\"h3--rrd-\"><a name=\"安装rrd工具\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装rrd工具</h3><pre><code> yum -y install rrdtool rrdtool-devel\n</code></pre><h3 id=\"h3--snmp-\"><a name=\"安装并配置监控需要的snmp工具\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装并配置监控需要的snmp工具</h3><p>安装Snmp</p>\n<pre><code>yum -y install net-snmp net-snmp-devel net-snmp-utils\n</code></pre><p>配置Snmp</p>\n<pre><code>vim /etc/snmp/snmpd.conf\ncom2sec notConfigUser  default       public\n改为：com2sec notConfigUser  127.0.0.1       public\naccess  notConfigGroup &quot;&quot;      any       noauth    exact  systemview none none\n改为：access  notConfigGroup &quot;&quot;      any       noauth    exact  all none none\n#view all    included  .1                               80  去掉注释\n</code></pre><p>启动服务并加如开机启动</p>\n<pre><code>service httpd start\nservice mysqld start\nservice snmpd start\nchkconfig httpd on\nchkconfig mysqld on\nchkconfig snmpd on\n</code></pre><h3 id=\"h3--cacti\"><a name=\"安装cacti\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>安装cacti</h3><pre><code>wget http://www.cacti.net/downloads/cacti-0.8.7e.tar.gz\ntar zxf cacti-0.8.8b-cn.tar.gz -C /var/www/html/\ncd /var/www/html/\nmv cacti-0.8.8b-cn/ cacti\n</code></pre><p>初始化数据库</p>\n<pre><code>mysql -u root\nmysql&gt; create database cacti;\nmysql&gt; grant all on cacti.* to cacti@localhost identified by &#39;cacti&#39;;\nmysql&gt; grant all on cacti.* to cacti@&#39;127.0.0.1&#39; identified by &#39;cacti&#39;;\nmysql&gt; flush privileges;\nmysql&gt; use cacti；\nmysql&gt; source /var/www/html/cacti/cacti.sql;\nmysql&gt; quit\n</code></pre><p>配置cacti</p>\n<pre><code>vim /var/www/html/cacti/include/config.php \n$database_type = &quot;mysql&quot;;\n$database_default = &quot;cacti&quot;;\n$database_hostname = &quot;localhost&quot;;\n$database_username = &quot;cacti&quot;;\n$database_password = &quot;cacti&quot;;\n$database_port = &quot;3306&quot;;\n</code></pre><p>把配置文件里改成和上面一样的就可以了.</p>\n<p>设置相关权限和计划任务.</p>\n<pre><code>useradd cacti -d /var/www/html/cacti -s /sbin/nologin\nchown -R cacti /var/www/html/cacti/rra /var/www/html/cacti/log\necho &#39;*/5 * * * * root /usr/bin/php /var/www/html/cacti/poller.php &gt; /dev/null 2&gt;&amp;1&#39; &gt;&gt; /etc/crontab\n</code></pre><h3 id=\"h3--cacti\"><a name=\"初始化cacti\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>初始化cacti</h3><p>访问你的cacti.地址如下.IP替换成你的服务器ip<br><a href=\"http://IP/cacti\">http://IP/cacti</a><br><img src=\"/upload/images/20190103//3a863725-4bb7-4ce3-b658-93f4f6f08ba4.png\" alt=\"\"></p>\n<p>如果显示的页面和这个一样.说明你前面配置的没有问题了.<br>直接点击next&gt;&gt;<br><img src=\"/upload/images/20190103//b674c6e5-5968-4b80-a315-eac5da115e4e.png\" alt=\"\"><br>如果都显示ok则可以点击finish.如果有not found 则要看看是哪个命令或者路径不对.<br>finsh之后就是登录界面了,用户名和密码都是admin.<br><img src=\"/upload/images/20190103//fea96d36-ae8c-4749-a563-975ee09a36bd.png\" alt=\"\"></p>\n<p>第一次登录需要修改密码.如下<br><img src=\"/upload/images/20190103//25cd81cd-97b0-4b32-a323-ef255e880189.png\" alt=\"\"><br>填入新密码保存即可.<br>这样cacti就安装完成了.</p>\n');
INSERT INTO `tbl_archive` VALUES ('70', '0', 'Linux 命令', '8', '2019-01-05 19:34:25', '##Linux命令####批量创建1000个文件夹test01-test1000mkdir-ptest{01..1000}', null, '0', '58', null, null, '2019-01-05 19:34:25', '2019-01-05 20:25:51', null, null, '0', '0', '0', '0', '##Linux  命令\n####批量创建1000个文件夹 test01 - test1000\n	 mkdir -p test{01..1000}\n####关闭Hadoop Audit日志\n	hadoop daemonlog -setlevel cloud01:50070 org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit ERROR', '0', '<h2 id=\"h2-linux-\"><a name=\"Linux  命令\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Linux  命令</h2><h4 id=\"h4--1000-test01-test1000\"><a name=\"批量创建1000个文件夹 test01 - test1000\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>批量创建1000个文件夹 test01 - test1000</h4><pre><code> mkdir -p test{01..1000}\n</code></pre><h4 id=\"h4--hadoop-audit-\"><a name=\"关闭Hadoop Audit日志\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭Hadoop Audit日志</h4><pre><code>hadoop daemonlog -setlevel cloud01:50070 org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit ERROR\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('71', '0', '关于hadoop ls fuse 目录 遇到过多文件速度慢的问题', '8', '2019-01-05 21:18:16', '##挂载HDFS到目录下面hadoop-fuse-dfsdfs://cloud01:8020/mnt/hdfs-oentry_timeout=60-oattribute_timeout=60##在/mnt/hdfs/testfuse下面生成10000个文件。cd/mnt/hdfs/testfusemkdir-ptest{01..10000}##测试/mnt/hdfs/testfuse下面速度tim', null, '0', '189', null, null, '2019-01-05 21:18:16', '2019-01-09 15:07:11', null, null, '0', '0', '0', '0', '##社区里面关于这方面也有讨论\n	https://github.com/apache/hadoop/tree/trunk/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/doc\n	https://issues.apache.org/jira/browse/HDFS-424\n	1. if you alias `ls` to `ls --color=auto` and try listing a directory with lots (over thousands) of files, expect it to be slow and at 10s of thousands, expect it to be very very slow.  This is because `--color=auto` causes ls to stat every file in the directory. Since fuse-dfs does not cache attribute entries when doing a readdir, \n	this is very slow. see [https://issues.apache.org/jira/browse/HADOOP-3797 HADOOP-3797]\n	\n##复现的方法\n##挂载HDFS 到目录下面\n	hadoop-fuse-dfs dfs://cloud01:8020 /mnt/hdfs -oentry_timeout=60 -oattribute_timeout=60\n	此处缓存时间不宜设置太短，会对 NameNode 产生较大压力\n##在 /mnt/hdfs/testfuse 下面生成10000个文件。\n	 cd /mnt/hdfs/testfuse\n	 mkdir -p test{01..10000}\n## 测试 /mnt/hdfs/testfuse 下面速度\n	time hadoop fs -ls /testfuse/\n		real	0m4.861s\n		user	0m13.535s\n		sys	0m0.760s\n	time ll /mnt/hdfs/testfuse/\n		real	0m55.314s\n		user	0m0.198s\n		sys	0m0.307s\n		\n	通过返回时间可以看到 使用 hadoop fs 命令 比 fuse  文件下面要快十倍。\n\n\n\n##通过查看 audit 日志可以看到 ll /hdfs/hdfs/testfuse 操作大量的访问行为 getfileinfo listStatus\n	tail -f hdfs-audit.log\n	2019-01-05 20:28:34,677 INFO FSNamesystem.audit: allowed=true	ugi=root (auth:SIMPLE)	ip=/192.168.0.82	cmd=getfileinfo	src=/testfuse/test13	dst=null	perm=null	proto=rpc\n	2019-01-05 20:28:34,678 INFO FSNamesystem.audit: allowed=true	ugi=root (auth:SIMPLE)	ip=/192.168.0.82	cmd=listStatus	src=/testfuse/test13	dst=null	perm=null	proto=rpc\n##通过查看 audit 日志可以看到 hadoop fs -ls /testfuse 操作大量的访问行为 包含一个 getfileinfo 包含少量，目测10几个 listStatus\n	2019-01-05 21:26:14,973 INFO FSNamesystem.audit: allowed=true	ugi=root (auth:SIMPLE)	ip=/192.168.0.82	cmd=getfileinfo	src=/testfuse	dst=null	perm=null	proto=rpc\n	2019-01-05 21:26:15,039 INFO FSNamesystem.audit: allowed=true	ugi=root (auth:SIMPLE)	ip=/192.168.0.82	cmd=listStatus	src=/testfuse	dst=null	perm=null	proto=rpc\n\n##基本判断 两个操作的差异 是对 fuse 操作有子文件夹递归访问现象，但 hadoop fs -ls 则没有，两者在获取数据量上有大差异，解决思路如下:\n	1.分析 ls 源代码，并减少递归访问子文件夹\n	2.排查 程序中 ls 的操作,并修改为 hadoop fs -ls 操作。\n	3.修改 https://github.com/apache/hadoop/tree/trunk/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs 中对 fuse_impls_readdir.c 的实现。\n	4.修改 fuse 的 ls 实现方法\n		参考:https://blog.csdn.net/dillanzhou/article/details/82856358\n		\n		\n##关于 NameNode RPC 问题导致整体HDFS/Fuse 性能说明\n	现象:清理包含大量目录的文件夹, NameNode RPC 时间从 200ms 减少到 5ms 以内。\n	NameNode RPC 是影响 Hadoop HDFS 响应速度的关键要素。\n	dfs.namenode.handler.count 默认为 10,参考文档配置如下：\n	python -c \'import math ; print int(math.log(N) * 20)\' \n	', '0', '<h2 id=\"h2-u793Eu533Au91CCu9762u5173u4E8Eu8FD9u65B9u9762u4E5Fu6709u8BA8u8BBA\"><a name=\"社区里面关于这方面也有讨论\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>社区里面关于这方面也有讨论</h2><pre><code>https://github.com/apache/hadoop/tree/trunk/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/doc\nhttps://issues.apache.org/jira/browse/HDFS-424\n1. if you alias `ls` to `ls --color=auto` and try listing a directory with lots (over thousands) of files, expect it to be slow and at 10s of thousands, expect it to be very very slow.  This is because `--color=auto` causes ls to stat every file in the directory. Since fuse-dfs does not cache attribute entries when doing a readdir, \nthis is very slow. see [https://issues.apache.org/jira/browse/HADOOP-3797 HADOOP-3797]\n</code></pre><h2 id=\"h2-u590Du73B0u7684u65B9u6CD5\"><a name=\"复现的方法\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>复现的方法</h2><h2 id=\"h2--hdfs-\"><a name=\"挂载HDFS 到目录下面\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>挂载HDFS 到目录下面</h2><pre><code>hadoop-fuse-dfs dfs://cloud01:8020 /mnt/hdfs -oentry_timeout=60 -oattribute_timeout=60\n此处缓存时间不宜设置太短，会对 NameNode 产生较大压力\n</code></pre><h2 id=\"h2--mnt-hdfs-testfuse-10000-\"><a name=\"在 /mnt/hdfs/testfuse 下面生成10000个文件。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在 /mnt/hdfs/testfuse 下面生成10000个文件。</h2><pre><code> cd /mnt/hdfs/testfuse\n mkdir -p test{01..10000}\n</code></pre><h2 id=\"h2--mnt-hdfs-testfuse-\"><a name=\"测试 /mnt/hdfs/testfuse 下面速度\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>测试 /mnt/hdfs/testfuse 下面速度</h2><pre><code>time hadoop fs -ls /testfuse/\n    real    0m4.861s\n    user    0m13.535s\n    sys    0m0.760s\ntime ll /mnt/hdfs/testfuse/\n    real    0m55.314s\n    user    0m0.198s\n    sys    0m0.307s\n\n通过返回时间可以看到 使用 hadoop fs 命令 比 fuse  文件下面要快十倍。\n</code></pre><h2 id=\"h2--audit-ll-hdfs-hdfs-testfuse-getfileinfo-liststatus\"><a name=\"通过查看 audit 日志可以看到 ll /hdfs/hdfs/testfuse 操作大量的访问行为 getfileinfo listStatus\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>通过查看 audit 日志可以看到 ll /hdfs/hdfs/testfuse 操作大量的访问行为 getfileinfo listStatus</h2><pre><code>tail -f hdfs-audit.log\n2019-01-05 20:28:34,677 INFO FSNamesystem.audit: allowed=true    ugi=root (auth:SIMPLE)    ip=/192.168.0.82    cmd=getfileinfo    src=/testfuse/test13    dst=null    perm=null    proto=rpc\n2019-01-05 20:28:34,678 INFO FSNamesystem.audit: allowed=true    ugi=root (auth:SIMPLE)    ip=/192.168.0.82    cmd=listStatus    src=/testfuse/test13    dst=null    perm=null    proto=rpc\n</code></pre><h2 id=\"h2--audit-hadoop-fs-ls-testfuse-getfileinfo-10-liststatus\"><a name=\"通过查看 audit 日志可以看到 hadoop fs -ls /testfuse 操作大量的访问行为 包含一个 getfileinfo 包含少量，目测10几个 listStatus\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>通过查看 audit 日志可以看到 hadoop fs -ls /testfuse 操作大量的访问行为 包含一个 getfileinfo 包含少量，目测10几个 listStatus</h2><pre><code>2019-01-05 21:26:14,973 INFO FSNamesystem.audit: allowed=true    ugi=root (auth:SIMPLE)    ip=/192.168.0.82    cmd=getfileinfo    src=/testfuse    dst=null    perm=null    proto=rpc\n2019-01-05 21:26:15,039 INFO FSNamesystem.audit: allowed=true    ugi=root (auth:SIMPLE)    ip=/192.168.0.82    cmd=listStatus    src=/testfuse    dst=null    perm=null    proto=rpc\n</code></pre><h2 id=\"h2--fuse-hadoop-fs-ls-\"><a name=\"基本判断 两个操作的差异 是对 fuse 操作有子文件夹递归访问现象，但 hadoop fs -ls 则没有，两者在获取数据量上有大差异，解决思路如下:\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>基本判断 两个操作的差异 是对 fuse 操作有子文件夹递归访问现象，但 hadoop fs -ls 则没有，两者在获取数据量上有大差异，解决思路如下:</h2><pre><code>1.分析 ls 源代码，并减少递归访问子文件夹\n2.排查 程序中 ls 的操作,并修改为 hadoop fs -ls 操作。\n3.修改 https://github.com/apache/hadoop/tree/trunk/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs 中对 fuse_impls_readdir.c 的实现。\n4.修改 fuse 的 ls 实现方法\n    参考:https://blog.csdn.net/dillanzhou/article/details/82856358\n</code></pre><h2 id=\"h2--namenode-rpc-hdfs-fuse-\"><a name=\"关于 NameNode RPC 问题导致整体HDFS/Fuse 性能说明\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关于 NameNode RPC 问题导致整体HDFS/Fuse 性能说明</h2><pre><code>现象:清理包含大量目录的文件夹, NameNode RPC 时间从 200ms 减少到 5ms 以内。\nNameNode RPC 是影响 Hadoop HDFS 响应速度的关键要素。\ndfs.namenode.handler.count 默认为 10,参考文档配置如下：\npython -c &#39;import math ; print int(math.log(N) * 20)&#39; \n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('73', '0', 'Centos7 RPM 安装oracle 18.3c', '8', '2019-01-09 22:20:33', 'oracle于今日发布了oracledatabase18c的RPM安装包，特来体验一把。https://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html选择Linux版本，进入Linux版本之后选择RPM下载：操作系统：##1.下载预先安装的包：#curl-ooracle-database-pre', null, '0', '86', null, null, '2019-01-09 22:20:33', '2019-01-12 21:31:53', null, null, '0', '0', '0', '0', 'oracle于今日发布了oracle database 18c的RPM安装包，特来体验一把。\n\nhttps://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html\n\n选择Linux版本，进入Linux版本之后选择RPM下载：\n\n    操作系统：centos 7.2\n     \n##1.下载预先安装的包：\n    #curl -o oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm https://yum.oracle.com/repo/OracleLinux/OL7/latest/x86_64/getPackage/oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm\n    -- 下载oracle的安装包：\n    # wget http://download.oracle.com/otn/linux/oracle18c/180000/oracle-database-ee-18c-1.0-1.x86_64.rpm?AuthParam=1539962668_5311e130d1cfb704834cf88b9c9c5e5c\n    #  mv oracle-database-ee-18c-1.0-1.x86_64.rpm\\?AuthParam\\=1539962668_5311e130d1cfb704834cf88b9c9c5e5c oracle-database-ee-18c-1.0-1.x86_64.rpm\n     \n##2.安装\n    ## yum -y localinstall oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm\n    会自动安装依赖的软件包。\n    Dependencies Resolved\n     \n    ======================================================================================================\n     Package                        Arch   Version                        Repository                 Size\n    ======================================================================================================\n    Installing:\n     oracle-database-preinstall-18c x86_64 1.0-1.el7                      /oracle-database-preinstall-18c-1.0-1.el7.x86_64\n                                                                                                     55 k\n    Installing for dependencies:\n     bc                             x86_64 1.06.95-13.el7                 base                      115 k\n     bind-libs                      x86_64 32:9.9.4-61.el7_5.1            updates                   1.0 M\n     bind-utils                     x86_64 32:9.9.4-61.el7_5.1            updates                   204 k\n     compat-libcap1                 x86_64 1.10-7.el7                     base                       19 k\n     compat-libstdc++-33            x86_64 3.2.3-72.el7                   base                      191 k\n     glibc-devel                    x86_64 2.17-222.el7                   base                      1.1 M\n     glibc-headers                  x86_64 2.17-222.el7                   base                      678 k\n     gssproxy                       x86_64 0.7.0-17.el7                   base                      108 k\n     kernel-headers                 x86_64 3.10.0-862.14.4.el7            updates                   7.1 M\n     keyutils                       x86_64 1.5.8-3.el7                    base                       54 k\n     ksh                            x86_64 20120801-137.el7               base                      885 k\n     libICE                         x86_64 1.0.9-9.el7                    base                       66 k\n     libSM                          x86_64 1.2.2-2.el7                    base                       39 k\n     libX11                         x86_64 1.6.5-1.el7                    base                      606 k\n     libX11-common                  noarch 1.6.5-1.el7                    base                      164 k\n     libXau                         x86_64 1.0.8-2.1.el7                  base                       29 k\n     libXext                        x86_64 1.3.3-3.el7                    base                       39 k\n     libXi                          x86_64 1.7.9-1.el7                    base                       40 k\n     libXinerama                    x86_64 1.1.3-2.1.el7                  base                       14 k\n     libXmu                         x86_64 1.1.2-2.el7                    base                       71 k\n     libXrandr                      x86_64 1.5.1-2.el7                    base                       27 k\n     libXrender                     x86_64 0.9.10-1.el7                   base                       26 k\n     libXt                          x86_64 1.1.5-3.el7                    base                      173 k\n     libXtst                        x86_64 1.2.3-1.el7                    base                       20 k\n     libXv                          x86_64 1.0.11-1.el7                   base                       18 k\n     libXxf86dga                    x86_64 1.1.4-2.1.el7                  base                       19 k\n     libXxf86misc                   x86_64 1.0.3-7.1.el7                  base                       19 k\n     libXxf86vm                     x86_64 1.1.4-1.el7                    base                       18 k\n     libaio                         x86_64 0.3.109-13.el7                 base                       24 k\n     libaio-devel                   x86_64 0.3.109-13.el7                 base                       13 k\n     libbasicobjects                x86_64 0.1.1-29.el7                   base                       25 k\n     libcollection                  x86_64 0.7.0-29.el7                   base                       41 k\n     libdmx                         x86_64 1.1.3-3.el7                    base                       16 k\n     libevent                       x86_64 2.0.21-4.el7                   base                      214 k\n     libini_config                  x86_64 1.3.1-29.el7                   base                       63 k\n     libnfsidmap                    x86_64 0.25-19.el7                    base                       50 k\n     libpath_utils                  x86_64 0.2.1-29.el7                   base                       28 k\n     libref_array                   x86_64 0.1.5-29.el7                   base                       26 k\n     libstdc++-devel                x86_64 4.8.5-28.el7_5.1               updates                   1.5 M\n     libtirpc                       x86_64 0.2.4-0.10.el7                 base                       88 k\n     libverto-libevent              x86_64 0.2.5-4.el7                    base                      8.9 k\n     libxcb                         x86_64 1.12-1.el7                     base                      211 k\n     lm_sensors-libs                x86_64 3.4.0-4.20160601gitf9185e5.el7 base                       41 k\n     mailx                          x86_64 12.5-19.el7                    base                      245 k\n     net-tools                      x86_64 2.0-0.22.20131004git.el7       base                      305 k\n     nfs-utils                      x86_64 1:1.3.0-0.54.el7               base                      407 k\n     psmisc                         x86_64 22.20-15.el7                   base                      141 k\n     quota                          x86_64 1:4.01-17.el7                  base                      179 k\n     quota-nls                      noarch 1:4.01-17.el7                  base                       90 k\n     rpcbind                        x86_64 0.2.0-44.el7                   base                       59 k\n     smartmontools                  x86_64 1:6.5-1.el7                    base                      460 k\n     sysstat                        x86_64 10.1.5-13.el7                  base                      310 k\n     tcp_wrappers                   x86_64 7.6-77.el7                     base                       78 k\n     unzip                          x86_64 6.0-19.el7                     base                      170 k\n     xorg-x11-utils                 x86_64 7.5-22.el7                     base                      114 k\n     xorg-x11-xauth                 x86_64 1:1.0.9-1.el7                  base                       30 k\n    Updating for dependencies:\n     bind-libs-lite                 x86_64 32:9.9.4-61.el7_5.1            updates                   734 k\n     bind-license                   noarch 32:9.9.4-61.el7_5.1            updates                    85 k\n     libstdc++                      x86_64 4.8.5-28.el7_5.1               updates                   303 k\n     \n    Transaction Summary\n    ======================================================================================================\n    Install  1 Package  (+56 Dependent packages)\n    Upgrade             (  3 Dependent packages)\n     \n     \n     \n     \n##3.安装oracle-database-servrer:\n    # rpm -ivh oracle-database-ee-18c-1.0-1.x86_64.rpm \n    warning: oracle-database-ee-18c-1.0-1.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID ec551f03: NOKEY\n    Preparing...                          ################################# [100%]\n    Updating / installing...\n       1:oracle-database-ee-18c-1.0-1     ################################# [100%]\n    [INFO] Executing post installation scripts...\n    [INFO] Oracle home installed successfully and ready to be configured.\n    To configure a sample Oracle Database you can execute the following service configuration script as root: /etc/init.d/oracledb_ORCLCDB-18c configure\n     \n    注意：上述安装部署比较耗时,需要耐心等待。\n    real 5m55.326s\n    user 5m41.209s\n    sys 0m12.905s\n     \n##4.参看配置文件：\n    # cat /etc/sysconfig/oracledb_ORCLCDB-18c.conf\n    #This is a configuration file to setup the Oracle Database. \n    #It is used when running \'/etc/init.d/oracledb_ORCLCDB configure\'.\n    #Please use this file to modify the default listener port and the\n    #Oracle data location.\n     \n    # LISTENER_PORT: Database listener\n    LISTENER_PORT=1521\n     \n    # ORACLE_DATA_LOCATION: Database oradata location\n    ORACLE_DATA_LOCATION=/opt/oracle/oradata\n     \n    # EM_EXPRESS_PORT: Oracle EM Express listener\n    EM_EXPRESS_PORT=5500\n     \n##5.配置：\n    ## /etc/init.d/oracledb_ORCLCDB-18c configure\n    执行脚本之后将创建一个容器数据库(ORCLCDB)和一个可插拔数据库(ORCLPDB1),并且配置的默认监听端口是1521.\n     \n    --详细信息：\n    Configuring Oracle Database ORCLCDB.\n    Prepare for db operation\n    8% complete\n    Copying database files\n    31% complete\n    Creating and starting Oracle instance\n    32% complete\n    36% complete\n    40% complete\n    43% complete\n    46% complete\n    Completing Database Creation\n    51% complete\n    54% complete\n    Creating Pluggable Databases\n    58% complete\n    77% complete\n    Executing Post Configuration Actions\n    100% complete\n    Database creation complete. For details check the logfiles at:\n     /opt/oracle/cfgtoollogs/dbca/ORCLCDB.\n    Database Information:\n    Global Database Name:ORCLCDB\n    System Identifier(SID):ORCLCDB\n    Look at the log file \"/opt/oracle/cfgtoollogs/dbca/ORCLCDB/ORCLCDB.log\" for further details.\n    Database configuration completed successfully. The passwords were auto generated, you must change them by connecting to the database using \'sqlplus / as sysdba\' as the oracle user.\n    --参考时间：\n    real 10m52.464s\n    user 0m49.829s\n    sys 0m4.022s\n##6.进程和端口查看：\n    #端口查看\n    # netstat -nultp  | grep -E \'1521|5500\'\n    tcp6       0      0 :::1521                 :::*                    LISTEN      590400/tnslsnr      \n    tcp6       0      0 :::5500                 :::*                    LISTEN      590400/tnslsnr \n    # ps -ef | grep -i orcl | grep -v grep\n    oracle   604203      1  0 00:08 ?00:00:00 ora_pmon_ORCLCDB\n    oracle   604205      1  0 00:08 ?00:00:00 ora_clmn_ORCLCDB\n    oracle   604207      1  0 00:08 ?00:00:00 ora_psp0_ORCLCDB\n    oracle   604210      1  0 00:08 ?00:00:00 ora_vktm_ORCLCDB\n    oracle   604214      1  0 00:08 ?00:00:00 ora_gen0_ORCLCDB\n    oracle   604216      1  2 00:08 ?00:00:04 ora_mman_ORCLCDB\n    oracle   604220      1  0 00:08 ?00:00:00 ora_gen1_ORCLCDB\n    oracle   604223      1  0 00:08 ?00:00:00 ora_diag_ORCLCDB\n    oracle   604225      1  0 00:08 ?00:00:00 ora_ofsd_ORCLCDB\n    oracle   604228      1  0 00:08 ?00:00:00 ora_dbrm_ORCLCDB\n    oracle   604230      1  0 00:08 ?00:00:00 ora_vkrm_ORCLCDB\n    oracle   604232      1  0 00:08 ?00:00:00 ora_svcb_ORCLCDB\n    oracle   604234      1  0 00:08 ?00:00:00 ora_pman_ORCLCDB\n    oracle   604236      1  0 00:08 ?00:00:01 ora_dia0_ORCLCDB\n    oracle   604238      1  0 00:08 ?00:00:00 ora_dbw0_ORCLCDB\n    oracle   604240      1  0 00:08 ?00:00:00 ora_dbw1_ORCLCDB\n    oracle   604242      1  0 00:08 ?00:00:00 ora_dbw2_ORCLCDB\n    oracle   604244      1  0 00:08 ?00:00:00 ora_dbw3_ORCLCDB\n    oracle   604246      1  0 00:08 ?00:00:00 ora_dbw4_ORCLCDB\n    oracle   604248      1  0 00:08 ?00:00:00 ora_dbw5_ORCLCDB\n    oracle   604250      1  0 00:08 ?00:00:00 ora_lgwr_ORCLCDB\n    oracle   604252      1  0 00:08 ?00:00:00 ora_ckpt_ORCLCDB\n    oracle   604254      1  0 00:08 ?00:00:00 ora_lg00_ORCLCDB\n    oracle   604256      1  0 00:08 ?00:00:00 ora_smon_ORCLCDB\n    oracle   604258      1  0 00:08 ?00:00:00 ora_lg01_ORCLCDB\n    oracle   604260      1  0 00:08 ?00:00:00 ora_smco_ORCLCDB\n    oracle   604262      1  0 00:08 ?00:00:00 ora_reco_ORCLCDB\n    oracle   604264      1  0 00:08 ?00:00:00 ora_w000_ORCLCDB\n    oracle   604266      1  0 00:08 ?00:00:00 ora_lreg_ORCLCDB\n    oracle   604268      1  0 00:08 ?00:00:00 ora_w001_ORCLCDB\n    oracle   604270      1  0 00:08 ?00:00:00 ora_pxmn_ORCLCDB\n    oracle   604274      1  0 00:08 ?00:00:01 ora_mmon_ORCLCDB\n    oracle   604276      1  0 00:08 ?00:00:00 ora_mmnl_ORCLCDB\n    oracle   604278      1  0 00:08 ?00:00:00 ora_d000_ORCLCDB\n    oracle   604280      1  0 00:08 ?00:00:00 ora_s000_ORCLCDB\n    oracle   604282      1  0 00:08 ?00:00:00 ora_tmon_ORCLCDB\n    oracle   604304      1  0 00:08 ?00:00:00 ora_m000_ORCLCDB\n    oracle   604306      1  0 00:08 ?00:00:00 ora_m001_ORCLCDB\n    oracle   604321      1  0 00:08 ?00:00:00 ora_tt00_ORCLCDB\n    oracle   604323      1  0 00:08 ?00:00:00 ora_tt01_ORCLCDB\n    oracle   604325      1  0 00:08 ?00:00:00 ora_tt02_ORCLCDB\n    ......\n##7.切换账号登录系统：\n    # su - oracle\n    ERROR:\n    ORA-12162: TNS:net service name is incorrectly specified\n    原因：\n    $ echo $ORACLE_HOME\n    /opt/oracle/product/18c/dbhome_1\n    $ echo $ORACLE_SID\n    $\n    解决办法：\n    $ export ORACLE_SID=ORCLCDB\n    $ ./sqlplus / as sysdba\n    SQL*Plus: Release 18.0.0.0.0 - Production on Sat Oct 20 00:30:17 2018\n    Version 18.3.0.0.0\n     \n    Copyright (c) 1982, 2018, Oracle.  All rights reserved.\n     \n     \n    Connected to:\n    Oracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production\n    Version 18.3.0.0.0\n     \n    --版本查询：\n    SQL> select banner from sys.v_$version;\n     \n    BANNER\n    --------------------------------------------------------------------------------\n    Oracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production\n     \n    SQL> select * from v$version;\n     \n    BANNER\n    --------------------------------------------------------------------------------\n    BANNER_FULL\n    ------------------------------------------------------------------------------------------------------------------------------------------------------\n    BANNER_LEGACY     CON_ID\n    -------------------------------------------------------------------------------- ----------\n    Oracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production\n    Oracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production\n    Version 18.3.0.0.0\n    Oracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production  0\n     \n##8.若需要正常使用还需要配置环境变量：\n    # cat /etc/profile.d/oracle.sh \n    #/bin/bash\n    export ORACLE_HOME=/opt/oracle/product/18c/dbhome_1\n    export PATH=$PATH:$ORACLE_HOME/bin\n    export ORACLE_SID=ORCLCDB\n    # source  /etc/profile.d/oracle.sh \n    $ sqlplus / as sysdba\n     \n##9.若在虚拟机中安装体验rpm包的oracle：\n    $ du -sh /opt/\n    12G /opt/\n    /opt 目录至少需要12G，此外还需要考虑RPM的oracle安装文件。\n     \n     \n    --删除oracle实例：\n    以oracle的账号登录删除实例，删除监听，再以root的账号删除软件。\n    $ cd $ORACLE_HOME/bin \n    $ ./dbca\n    $ cd $ORACLE_HOME/bin \n    $ ./netca\n    # yum -y remove oracle-database-ee-18c\n    参考文档：\n    https://docs.oracle.com/en/database/oracle/oracle-database/18/ladbi/running-rpm-packages-to-install-oracle-database.html#GUID-BB7C11E3-D385-4A2F-9EAF-75F4F0AACF02\n--------------------- \n\n##10.TNS:lost contact 错误\n	[oracle@cloud02 bin]$ $ORACLE_HOME/bin/sqlplus / as sysdba\n	SQL*Plus: Release 18.0.0.0.0 - Production on Sat Jan 12 21:19:04 2019\n	Version 18.3.0.0.0\n	Copyright (c) 1982, 2018, Oracle.  All rights reserved.\n	ERROR:\n	ORA-12547: TNS:lost contact\n\n', '0', '<p>oracle于今日发布了oracle database 18c的RPM安装包，特来体验一把。</p>\n<p><a href=\"https://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html\">https://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html</a></p>\n<p>选择Linux版本，进入Linux版本之后选择RPM下载：</p>\n<pre><code>操作系统：centos 7.2\n</code></pre><h2 id=\"h2-1-\"><a name=\"1.下载预先安装的包：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.下载预先安装的包：</h2><pre><code>#curl -o oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm https://yum.oracle.com/repo/OracleLinux/OL7/latest/x86_64/getPackage/oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm\n-- 下载oracle的安装包：\n# wget http://download.oracle.com/otn/linux/oracle18c/180000/oracle-database-ee-18c-1.0-1.x86_64.rpm?AuthParam=1539962668_5311e130d1cfb704834cf88b9c9c5e5c\n#  mv oracle-database-ee-18c-1.0-1.x86_64.rpm\\?AuthParam\\=1539962668_5311e130d1cfb704834cf88b9c9c5e5c oracle-database-ee-18c-1.0-1.x86_64.rpm\n</code></pre><h2 id=\"h2-2-\"><a name=\"2.安装\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.安装</h2><pre><code>## yum -y localinstall oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm\n会自动安装依赖的软件包。\nDependencies Resolved\n\n======================================================================================================\n Package                        Arch   Version                        Repository                 Size\n======================================================================================================\nInstalling:\n oracle-database-preinstall-18c x86_64 1.0-1.el7                      /oracle-database-preinstall-18c-1.0-1.el7.x86_64\n                                                                                                 55 k\nInstalling for dependencies:\n bc                             x86_64 1.06.95-13.el7                 base                      115 k\n bind-libs                      x86_64 32:9.9.4-61.el7_5.1            updates                   1.0 M\n bind-utils                     x86_64 32:9.9.4-61.el7_5.1            updates                   204 k\n compat-libcap1                 x86_64 1.10-7.el7                     base                       19 k\n compat-libstdc++-33            x86_64 3.2.3-72.el7                   base                      191 k\n glibc-devel                    x86_64 2.17-222.el7                   base                      1.1 M\n glibc-headers                  x86_64 2.17-222.el7                   base                      678 k\n gssproxy                       x86_64 0.7.0-17.el7                   base                      108 k\n kernel-headers                 x86_64 3.10.0-862.14.4.el7            updates                   7.1 M\n keyutils                       x86_64 1.5.8-3.el7                    base                       54 k\n ksh                            x86_64 20120801-137.el7               base                      885 k\n libICE                         x86_64 1.0.9-9.el7                    base                       66 k\n libSM                          x86_64 1.2.2-2.el7                    base                       39 k\n libX11                         x86_64 1.6.5-1.el7                    base                      606 k\n libX11-common                  noarch 1.6.5-1.el7                    base                      164 k\n libXau                         x86_64 1.0.8-2.1.el7                  base                       29 k\n libXext                        x86_64 1.3.3-3.el7                    base                       39 k\n libXi                          x86_64 1.7.9-1.el7                    base                       40 k\n libXinerama                    x86_64 1.1.3-2.1.el7                  base                       14 k\n libXmu                         x86_64 1.1.2-2.el7                    base                       71 k\n libXrandr                      x86_64 1.5.1-2.el7                    base                       27 k\n libXrender                     x86_64 0.9.10-1.el7                   base                       26 k\n libXt                          x86_64 1.1.5-3.el7                    base                      173 k\n libXtst                        x86_64 1.2.3-1.el7                    base                       20 k\n libXv                          x86_64 1.0.11-1.el7                   base                       18 k\n libXxf86dga                    x86_64 1.1.4-2.1.el7                  base                       19 k\n libXxf86misc                   x86_64 1.0.3-7.1.el7                  base                       19 k\n libXxf86vm                     x86_64 1.1.4-1.el7                    base                       18 k\n libaio                         x86_64 0.3.109-13.el7                 base                       24 k\n libaio-devel                   x86_64 0.3.109-13.el7                 base                       13 k\n libbasicobjects                x86_64 0.1.1-29.el7                   base                       25 k\n libcollection                  x86_64 0.7.0-29.el7                   base                       41 k\n libdmx                         x86_64 1.1.3-3.el7                    base                       16 k\n libevent                       x86_64 2.0.21-4.el7                   base                      214 k\n libini_config                  x86_64 1.3.1-29.el7                   base                       63 k\n libnfsidmap                    x86_64 0.25-19.el7                    base                       50 k\n libpath_utils                  x86_64 0.2.1-29.el7                   base                       28 k\n libref_array                   x86_64 0.1.5-29.el7                   base                       26 k\n libstdc++-devel                x86_64 4.8.5-28.el7_5.1               updates                   1.5 M\n libtirpc                       x86_64 0.2.4-0.10.el7                 base                       88 k\n libverto-libevent              x86_64 0.2.5-4.el7                    base                      8.9 k\n libxcb                         x86_64 1.12-1.el7                     base                      211 k\n lm_sensors-libs                x86_64 3.4.0-4.20160601gitf9185e5.el7 base                       41 k\n mailx                          x86_64 12.5-19.el7                    base                      245 k\n net-tools                      x86_64 2.0-0.22.20131004git.el7       base                      305 k\n nfs-utils                      x86_64 1:1.3.0-0.54.el7               base                      407 k\n psmisc                         x86_64 22.20-15.el7                   base                      141 k\n quota                          x86_64 1:4.01-17.el7                  base                      179 k\n quota-nls                      noarch 1:4.01-17.el7                  base                       90 k\n rpcbind                        x86_64 0.2.0-44.el7                   base                       59 k\n smartmontools                  x86_64 1:6.5-1.el7                    base                      460 k\n sysstat                        x86_64 10.1.5-13.el7                  base                      310 k\n tcp_wrappers                   x86_64 7.6-77.el7                     base                       78 k\n unzip                          x86_64 6.0-19.el7                     base                      170 k\n xorg-x11-utils                 x86_64 7.5-22.el7                     base                      114 k\n xorg-x11-xauth                 x86_64 1:1.0.9-1.el7                  base                       30 k\nUpdating for dependencies:\n bind-libs-lite                 x86_64 32:9.9.4-61.el7_5.1            updates                   734 k\n bind-license                   noarch 32:9.9.4-61.el7_5.1            updates                    85 k\n libstdc++                      x86_64 4.8.5-28.el7_5.1               updates                   303 k\n\nTransaction Summary\n======================================================================================================\nInstall  1 Package  (+56 Dependent packages)\nUpgrade             (  3 Dependent packages)\n</code></pre><h2 id=\"h2-3-oracle-database-servrer-\"><a name=\"3.安装oracle-database-servrer:\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3.安装oracle-database-servrer:</h2><pre><code># rpm -ivh oracle-database-ee-18c-1.0-1.x86_64.rpm \nwarning: oracle-database-ee-18c-1.0-1.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID ec551f03: NOKEY\nPreparing...                          ################################# [100%]\nUpdating / installing...\n   1:oracle-database-ee-18c-1.0-1     ################################# [100%]\n[INFO] Executing post installation scripts...\n[INFO] Oracle home installed successfully and ready to be configured.\nTo configure a sample Oracle Database you can execute the following service configuration script as root: /etc/init.d/oracledb_ORCLCDB-18c configure\n\n注意：上述安装部署比较耗时,需要耐心等待。\nreal 5m55.326s\nuser 5m41.209s\nsys 0m12.905s\n</code></pre><h2 id=\"h2-4-\"><a name=\"4.参看配置文件：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.参看配置文件：</h2><pre><code># cat /etc/sysconfig/oracledb_ORCLCDB-18c.conf\n#This is a configuration file to setup the Oracle Database. \n#It is used when running &#39;/etc/init.d/oracledb_ORCLCDB configure&#39;.\n#Please use this file to modify the default listener port and the\n#Oracle data location.\n\n# LISTENER_PORT: Database listener\nLISTENER_PORT=1521\n\n# ORACLE_DATA_LOCATION: Database oradata location\nORACLE_DATA_LOCATION=/opt/oracle/oradata\n\n# EM_EXPRESS_PORT: Oracle EM Express listener\nEM_EXPRESS_PORT=5500\n</code></pre><h2 id=\"h2-5-\"><a name=\"5.配置：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5.配置：</h2><pre><code>## /etc/init.d/oracledb_ORCLCDB-18c configure\n执行脚本之后将创建一个容器数据库(ORCLCDB)和一个可插拔数据库(ORCLPDB1),并且配置的默认监听端口是1521.\n\n--详细信息：\nConfiguring Oracle Database ORCLCDB.\nPrepare for db operation\n8% complete\nCopying database files\n31% complete\nCreating and starting Oracle instance\n32% complete\n36% complete\n40% complete\n43% complete\n46% complete\nCompleting Database Creation\n51% complete\n54% complete\nCreating Pluggable Databases\n58% complete\n77% complete\nExecuting Post Configuration Actions\n100% complete\nDatabase creation complete. For details check the logfiles at:\n /opt/oracle/cfgtoollogs/dbca/ORCLCDB.\nDatabase Information:\nGlobal Database Name:ORCLCDB\nSystem Identifier(SID):ORCLCDB\nLook at the log file &quot;/opt/oracle/cfgtoollogs/dbca/ORCLCDB/ORCLCDB.log&quot; for further details.\nDatabase configuration completed successfully. The passwords were auto generated, you must change them by connecting to the database using &#39;sqlplus / as sysdba&#39; as the oracle user.\n--参考时间：\nreal 10m52.464s\nuser 0m49.829s\nsys 0m4.022s\n</code></pre><h2 id=\"h2-6-\"><a name=\"6.进程和端口查看：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6.进程和端口查看：</h2><pre><code>#端口查看\n# netstat -nultp  | grep -E &#39;1521|5500&#39;\ntcp6       0      0 :::1521                 :::*                    LISTEN      590400/tnslsnr      \ntcp6       0      0 :::5500                 :::*                    LISTEN      590400/tnslsnr \n# ps -ef | grep -i orcl | grep -v grep\noracle   604203      1  0 00:08 ?00:00:00 ora_pmon_ORCLCDB\noracle   604205      1  0 00:08 ?00:00:00 ora_clmn_ORCLCDB\noracle   604207      1  0 00:08 ?00:00:00 ora_psp0_ORCLCDB\noracle   604210      1  0 00:08 ?00:00:00 ora_vktm_ORCLCDB\noracle   604214      1  0 00:08 ?00:00:00 ora_gen0_ORCLCDB\noracle   604216      1  2 00:08 ?00:00:04 ora_mman_ORCLCDB\noracle   604220      1  0 00:08 ?00:00:00 ora_gen1_ORCLCDB\noracle   604223      1  0 00:08 ?00:00:00 ora_diag_ORCLCDB\noracle   604225      1  0 00:08 ?00:00:00 ora_ofsd_ORCLCDB\noracle   604228      1  0 00:08 ?00:00:00 ora_dbrm_ORCLCDB\noracle   604230      1  0 00:08 ?00:00:00 ora_vkrm_ORCLCDB\noracle   604232      1  0 00:08 ?00:00:00 ora_svcb_ORCLCDB\noracle   604234      1  0 00:08 ?00:00:00 ora_pman_ORCLCDB\noracle   604236      1  0 00:08 ?00:00:01 ora_dia0_ORCLCDB\noracle   604238      1  0 00:08 ?00:00:00 ora_dbw0_ORCLCDB\noracle   604240      1  0 00:08 ?00:00:00 ora_dbw1_ORCLCDB\noracle   604242      1  0 00:08 ?00:00:00 ora_dbw2_ORCLCDB\noracle   604244      1  0 00:08 ?00:00:00 ora_dbw3_ORCLCDB\noracle   604246      1  0 00:08 ?00:00:00 ora_dbw4_ORCLCDB\noracle   604248      1  0 00:08 ?00:00:00 ora_dbw5_ORCLCDB\noracle   604250      1  0 00:08 ?00:00:00 ora_lgwr_ORCLCDB\noracle   604252      1  0 00:08 ?00:00:00 ora_ckpt_ORCLCDB\noracle   604254      1  0 00:08 ?00:00:00 ora_lg00_ORCLCDB\noracle   604256      1  0 00:08 ?00:00:00 ora_smon_ORCLCDB\noracle   604258      1  0 00:08 ?00:00:00 ora_lg01_ORCLCDB\noracle   604260      1  0 00:08 ?00:00:00 ora_smco_ORCLCDB\noracle   604262      1  0 00:08 ?00:00:00 ora_reco_ORCLCDB\noracle   604264      1  0 00:08 ?00:00:00 ora_w000_ORCLCDB\noracle   604266      1  0 00:08 ?00:00:00 ora_lreg_ORCLCDB\noracle   604268      1  0 00:08 ?00:00:00 ora_w001_ORCLCDB\noracle   604270      1  0 00:08 ?00:00:00 ora_pxmn_ORCLCDB\noracle   604274      1  0 00:08 ?00:00:01 ora_mmon_ORCLCDB\noracle   604276      1  0 00:08 ?00:00:00 ora_mmnl_ORCLCDB\noracle   604278      1  0 00:08 ?00:00:00 ora_d000_ORCLCDB\noracle   604280      1  0 00:08 ?00:00:00 ora_s000_ORCLCDB\noracle   604282      1  0 00:08 ?00:00:00 ora_tmon_ORCLCDB\noracle   604304      1  0 00:08 ?00:00:00 ora_m000_ORCLCDB\noracle   604306      1  0 00:08 ?00:00:00 ora_m001_ORCLCDB\noracle   604321      1  0 00:08 ?00:00:00 ora_tt00_ORCLCDB\noracle   604323      1  0 00:08 ?00:00:00 ora_tt01_ORCLCDB\noracle   604325      1  0 00:08 ?00:00:00 ora_tt02_ORCLCDB\n......\n</code></pre><h2 id=\"h2-7-\"><a name=\"7.切换账号登录系统：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>7.切换账号登录系统：</h2><pre><code># su - oracle\nERROR:\nORA-12162: TNS:net service name is incorrectly specified\n原因：\n$ echo $ORACLE_HOME\n/opt/oracle/product/18c/dbhome_1\n$ echo $ORACLE_SID\n$\n解决办法：\n$ export ORACLE_SID=ORCLCDB\n$ ./sqlplus / as sysdba\nSQL*Plus: Release 18.0.0.0.0 - Production on Sat Oct 20 00:30:17 2018\nVersion 18.3.0.0.0\n\nCopyright (c) 1982, 2018, Oracle.  All rights reserved.\n\n\nConnected to:\nOracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production\nVersion 18.3.0.0.0\n\n--版本查询：\nSQL&gt; select banner from sys.v_$version;\n\nBANNER\n--------------------------------------------------------------------------------\nOracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production\n\nSQL&gt; select * from v$version;\n\nBANNER\n--------------------------------------------------------------------------------\nBANNER_FULL\n------------------------------------------------------------------------------------------------------------------------------------------------------\nBANNER_LEGACY     CON_ID\n-------------------------------------------------------------------------------- ----------\nOracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production\nOracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production\nVersion 18.3.0.0.0\nOracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production  0\n</code></pre><h2 id=\"h2-8-\"><a name=\"8.若需要正常使用还需要配置环境变量：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>8.若需要正常使用还需要配置环境变量：</h2><pre><code># cat /etc/profile.d/oracle.sh \n#/bin/bash\nexport ORACLE_HOME=/opt/oracle/product/18c/dbhome_1\nexport PATH=$PATH:$ORACLE_HOME/bin\nexport ORACLE_SID=ORCLCDB\n# source  /etc/profile.d/oracle.sh \n$ sqlplus / as sysdba\n</code></pre><h2 id=\"h2-9-rpm-oracle-\"><a name=\"9.若在虚拟机中安装体验rpm包的oracle：\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>9.若在虚拟机中安装体验rpm包的oracle：</h2><pre><code>$ du -sh /opt/\n12G /opt/\n/opt 目录至少需要12G，此外还需要考虑RPM的oracle安装文件。\n\n\n--删除oracle实例：\n以oracle的账号登录删除实例，删除监听，再以root的账号删除软件。\n$ cd $ORACLE_HOME/bin \n$ ./dbca\n$ cd $ORACLE_HOME/bin \n$ ./netca\n# yum -y remove oracle-database-ee-18c\n参考文档：\nhttps://docs.oracle.com/en/database/oracle/oracle-database/18/ladbi/running-rpm-packages-to-install-oracle-database.html#GUID-BB7C11E3-D385-4A2F-9EAF-75F4F0AACF02\n</code></pre><hr>\n<h2 id=\"h2-10-tns-lost-contact-\"><a name=\"10.TNS:lost contact 错误\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>10.TNS:lost contact 错误</h2><pre><code>[oracle@cloud02 bin]$ $ORACLE_HOME/bin/sqlplus / as sysdba\nSQL*Plus: Release 18.0.0.0.0 - Production on Sat Jan 12 21:19:04 2019\nVersion 18.3.0.0.0\nCopyright (c) 1982, 2018, Oracle.  All rights reserved.\nERROR:\nORA-12547: TNS:lost contact\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('74', '0', 'Moonbox是一个DAAS（Data Virtualization as a Service）平台解决方案', '8', '2019-01-09 22:53:26', 'Moonbox是一个DAAS（Data Virtualization as a Service）平台解决方案。Moonbox基于数据虚拟化设计思想，致力于提供批量计算服务解决方案。Moonbox为用户带来虚拟数据库般使用体验，用户只需通过统一SQL语言，即可透明实现跨异构数据系统混算和写出。此外Moonbox还提供数据服务、数据管理、数据工具、数据开发等基础支持，可支撑更加敏捷和灵活的数据应用架构和逻辑数仓实践。', null, '0', '77', null, null, '2019-01-09 22:53:26', '2019-01-24 17:52:13', null, null, '0', '0', '0', '0', 'Moonbox\n--------\nMoonbox是一个DAAS（Data Virtualization as a Service）平台解决方案。Moonbox基于数据虚拟化设计思想，致力于提供批量计算服务解决方案。Moonbox为用户带来虚拟数据库般使用体验，用户只需通过统一SQL语言，即可透明实现跨异构数据系统混算和写出。此外Moonbox还提供数据服务、数据管理、数据工具、数据开发等基础支持，可支撑更加敏捷和灵活的数据应用架构和逻辑数仓实践。\n\nDeploying Spark Local\n\n    环境准备\n    部署配置\n    启动与停止\n\n环境准备\n\n    JDK 1.8\n    Redis 3.x.x\n    配置执行启动脚本的机器到其他所有机器SSH免密码登录\n\n部署配置\n\n下载 moonbox-0.2.0-dist.tar.gz 包，或者使用如下命令自行编译\n\ngit clone -b 0.2 https://github.com/edp963/moonbox.git\ncd moonbox\ngit checkout tags/0.2.0\nsh dev/build.sh\n\n使用dev/build.sh脚本编译,默认会添加所有数据源支持,具体有哪些数据源请参考Integration DataSource章节。如果想按需添加数据源支持,请使用如下指令编译,其中[]内为可选项。\n\ngit clone -b 0.2 https://github.com/edp963/moonbox.git\ncd moonbox\ngit checkout tags/0.2.0\nmvn package -DskipTests -Pdist [-Pmysql -Poracle -Pes -Phive]\n\n解压moonbox-0.2.0-dist.tar.gz\n\ntar -zxvf moonbox-0.2.0-dist.tar.gz\n\n解压完成之后目录结构应当如下:\n\nmoonbox\n  - bin # 应用脚本目录\n  - conf # 配置文件目录\n  - libs # moonbox依赖jar存放目录\n  - log  # 日志目录\n  - runtime # Spark运行时依赖jar存放目录\n  - sbin # 启动停止集群管理脚本目录\n\nmoonbox的配置分为环境变量、集群拓扑、运行参数三个部分，下面分别解释每个部分各表示什么含义以及如何配置。\n\n    环境变量\n\n    配置文件为conf/moonbox-env.sh\n\n    export MOONBOX_SSH_OPTIONS=\"-p 22\" # 用于配置ssh端口，如默认无需修改\n    export MOONBOX_HOME=/path/to/installed/dir # 配置moonbox安装目录\n\n    集群拓扑\n\n    用于描述集群拓扑，配置文件为$MOONBOX_HOME/conf/nodes。moonbox以master-slave集群模式运行，支持配置多个master用于主备。示例如下，请按照实际情况配置。\n\n    moonbox.gird.master.1   grid://host1:2551\n    moonbox.gird.master.2   grid://host2:2551\n    moonbox.gird.worker.1   host3\n    moonbox.gird.worker.2   host4\n\n    运行参数\n\n    用于配置运行时参数，配置文件为$MOONBOX_HOME/conf/moonbox-defaults.conf。以下为moonbox最简配置，请根据实际情况修改，更多配置请参考Configuration章节。\n\n    moonbox {\n        rest.server {\n            port = 8080\n        }\n        tcp.server {\n            port = 10010\n        }\n        catalog {\n        	  implementation = \"h2\"\n        	  url = \"jdbc:h2:mem:testdb0;DB_CLOSE_DELAY=-1\"\n        	  user = \"testUser\"\n        	  password = \"testPass\"\n        	  driver = \"org.h2.Driver\"\n        }\n        cache {\n        	  implementation = \"redis\"\n        	  redis.servers = \"host:port\"\n        }\n        mixcal {\n            implementation = \"spark\"\n        	  spark.master = \"local[*]\"\n        	  spark.loglevel = \"INFO\"\n        	  spark.app.name = \"test1\"\n        	  pushdown.enable = true\n        	  column.permission.enable = false\n        }\n    }\n\n将moonbox文件夹分发到conf/nodes中所配置的所有机器上,其所处目录应当与当前机器$MOONBOX_HOME一致。\n启动与停止\n\n我们为用户提供了一键启动与停止集群的脚本,位于$MOONBOX_HOME/sbin目录下。\n\n    启动集群 在任意节点执行\n\n      cd $MOONBOX_HOME\n      sbin/start-all.sh\n\n    停止集群 在任意节点执行\n\n      cd $MOONBOX_HOME\n      sbin/stop-all.sh\n\n    备注:\n    执行启动和停止脚本的机器需要配置到其他机器的ssh免密码登录。\n\n    如catalog配置修改为其他数据库,请将对应的驱动jar包拷贝到每台机器的$MOONBOX_HOME/libs目录下。\n	\n	\n\nUser Guide\nQuick Start\n\nMoonbox服务启动之后,系统管理人员使用ROOT用户连接Moonbox,输入SQL语句,以分号结束。\n\ncd $MOONBOX_HOME/bin\n./cli.sh -m rest -u ROOT -p 123456 -h localhost -P 18090\n\n其中:\n\n    -m 连接Moonbox的方式, 选项为rest和jdbc\n    -u 用户名\n    -p 密码,ROOT初始密码为123456\n    -h Moonbox rest server服务地址\n    -P Moonbox rest server 服务端口\n\n创建Organization,假设名为testOrg\n\nCREATE ORG/ORGANIZATION testOrg;\n\n在该Organization中创建Sa,假设名为sally\n\nCREATE SA sally IN ORG testOrg IDENTIFIED BY 123456;\n\n至此,用户空间已经创建完毕,更多命令请参考Indexing部分。\n\n应用管理人员使用Sa用户登录\n\ncd $MOONBOX_HOME/bin\n./cli.sh -m rest -u sally -p 123456 -h localhost -P 18090\n\n当Sa初始登录之后,Sa所属的Organization中只有一个默认的名为default的数据库,可以在该数据库下挂载虚拟表。例如挂载MySQL类型数据库test中的booklist表。\n\nMOUNT TABLE mysql_test OPTIONS(\n    type \'mysql\',\n    url \'jdbc:mysql://localhost:3306/test\',\n    user \'root\',\n    password \'password\',\n    driver \'com.mysql.jdbc.Driver\',\n    dbtable \'booklist\'\n);\n\n当执行挂载表指令的时候,系统会检查连接参数的正确性,所以要确保参数正确。需要注意,在发行包中并没有包含MySQL的jdbc驱动,所以需要自行将对应的驱动包拷贝到$MOONBOX_HOME/libs和$MOONBOX_HOME/runtime中。\n\n列出所有表\n\nSHOW TABLES;\n\n查看表详情\n\nDESCRIBE TABLE mysql_test;\n\n对表内容做查询\n\nSELECT * FROM mysql_test;\n\nSa还可以创建新用户\n\n    CREATE USER username IDENTIFIED BY password; # 创建用户\n    GRANT ACCOUNT, DDL, DCL TO USER username; # 给用户授权, ACCOUNT、DDL、DCL按需选择\n\n如果不给新创建的用户进行授权,那么该用户就只有DML权限,即只能执行SELECT, SHOW ,DESCRIBE等操作。 至此,Sa即可将新创建的账号分配给用户使用了。以上只是一个简短快速的体验,更多内容请阅读接下来的部分。\n客户端使用\n\nMoonbox内置http server和tcp server,支持通过rest和jdbc方式接入。\n使用命令行\n\ncd $MOONBOX_HOME/bin\n./cli.sh -m rest -u username -p password -h localhost -P 18090\n\n其中:\n\n    -m 连接Moonbox的方式, 选项为rest和jdbc\n    -u 用户名\n    -p 密码,ROOT初始密码为123456\n    -h Moonbox rest server服务地址\n    -P Moonbox rest server 服务端口\n\n使用rest\n\nrest方式支持batch和adhoc两种方式。batch是两批作业之间无上下文关联,可能对调度到不同的机器上的runner执行,adhoc是上下文相关的,有session的概念,会调度到同一个runner中执行。其中batch又分为异步和同步模式,adhoc只支持同步。\n系统登录\n\n# request 示例\ncurl -XPOST http://host:port/login -d \'{\n    \"username\": \"sally\",\n    \"password\": \"123456\"\n}\'\n# response 示例,该token内容作为该用户今后登录凭证\n{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjVhMjNiMDczLWE4NzctNGRmZC1hYjkyLWY2ZGI0YjNmNzVlYyJ9._jIe1cgbc9d9JMW6g6D6KA\"\n}\n\n查询提交\n\nadhoc方式\n\n# 开启session,request示例\ncurl -XPOST http://host:port/openSession -d \'{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjVhMjNiMDczLWE4NzctNGRmZC1hYjkyLWY2ZGI0YjNmNzVlYyJ9._jIe1cgbc9d9JMW6g6D6KA\"\n}\'\n# 开启session,response示例,该sessionId用于session标识\n{\n  \"sessionId\" : \"3ddec591-16db-4a7c-93a7-c6df54763ad0\"\n}\n\n# 提交查询,request示例\ncurl -XPOST http://host:port/query -d \'{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA\",\n    \"sessionId\" : \"3ddec591-16db-4a7c-93a7-c6df54763ad0\",\n    \"sqls\":[\"use default\", \"show tables\"]\n}\'\n# 提交查询,response示例\n{\n\"jobId\" : \"job-20180730150004-00001\",\n\"data\" : [[\"mysql_test\"], [\"oracle_test\"]]\n}\n\n# 关闭session,request示例\ncurl -XPOST http://host:port/closeSession -d \'{\n{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA\",\n    \"sessionId\" : \"3ddec591-16db-4a7c-93a7-c6df54763ad0\",\n}\'\n# 关闭session,response示例\n{}\n\nbatch同步方式\n\n# 同步提交查询,request示例\ncurl -XPOST http://host:port/submit -d \'{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA\",\n    \"mode\" : \"sync\",\n    \"sqls\":[\"use default\", \"show tables\"]\n}\'\n# 同步提交查询,response示例\n{\n\"jobId\" : \"job-20180730150004-00001\",\n\"data\" : [[\"mysql_test\"], [\"oracle_test\"]]\n}\n\nbatch异步方式\n\n异步提交作业,会将select类型作业结果保存到缓存,等待用户查询结果。对于insert类型作业会将结果保存到对应的外部存储。所以使用异步方式提交查询时,请注意create、alter、drop、show或者desc等指令,结果会丢失,因为这类指令的返回结果为direct类型,不会存储到缓存。\n\n# 异步提交查询,request示例\ncurl -XPOST http://host:port/submit -d \'{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA\",\n    \"mode\" : \"async\",\n    \"sqls\":[\"use default\", \"select * from mysql_test\"]\n}\'\n# 异步提交查询,response示例\n{\n  \"jobId\" : \"job-20180730192553-00000\"\n}\n\n# 查询异步作业状态, request示例\ncurl -XPOST http://host:port/progress -d \'{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA\",\n    \"jobId\" : \"job-20180730192553-00000\"\n}\'\n# 查询异步作业状态,response示例\n{\n    \"jobId\" : \"job-20180730192553-00000\",\n    \"status\" : \"SUCCESS\"\n}\n\n# 获取异步作业结果,request示例\ncurl -XPOST http://host:port/result -d \'{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA\",\n    \"jobId\" : \"job-20180730192553-00000\",\n    \"offset\" : 0,\n    \"size\" : 2\n}\'\n# 获取异步作业结果,response示例\n{\n  \"jobId\" : \"job-20180730192553-00000\",\n  \"schema\" : \"{\\\"type\\\":\\\"struct\\\",\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{\\\"name\\\":\\\"id\\\",\\\"scale\\\":0}},{\\\"name\\\":\\\"bname\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{\\\"name\\\":\\\"bname\\\",\\\"scale\\\":0}},{\\\"name\\\":\\\"male\\\",\\\"type\\\":\\\"boolean\\\",\\\"nullable\\\":true,\\\"metadata\\\":{\\\"name\\\":\\\"male\\\",\\\"scale\\\":0}},{\\\"name\\\":\\\"outer_key\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{\\\"name\\\":\\\"outer_key\\\",\\\"scale\\\":0}},{\\\"name\\\":\\\"china_key\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{\\\"name\\\":\\\"china_key\\\",\\\"scale\\\":0}},{\\\"name\\\":\\\"china_name\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{\\\"name\\\":\\\"china_name\\\",\\\"scale\\\":0}}]}\",\n  \"data\" : [ [ 1, \"name1\", false, 1, \"xx科技\", \"刘明\" ], [ 8, \"bbbb\", true, 2, \"xx科技\", \"李军\" ]]\n}\n\n# 取消正在运行的作业, request示例\ncurl -XPOST http://host:port/cancel -d \'{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA\",\n    \"jobId\" : \"job-20180730192553-00000\"\n}\'\n\n# 取消正在运行的作业, response示例\n{\n    \"jobId\" : \"job-20180730203509-00010\"\n}\n\n系统登出\n\n# 系统登出,request示例\ncurl -XPOST http://host:port/logout -d \'{\n    \"token\" : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA\",\n}\'\n# 系统登出,response示例\n{\n    \"message\" : \"Logout successfully.\"\n}\n\n使用jdbc编程\n\nMoonbox提供了jdbc驱动,请自行下载。以下为Scala示例:\n\nClass.forName(\"moonbox.jdbc.MbDriver\")\nval url = s\"jdbc:moonbox://host:port/database\"\nval username = \"username\"\nval password = \"password\"\nval connection = DriverManager.getConnection(url, username, password)\nval statement = connection.createStatement()\nstatement.setQueryTimeout(60*10)\nstatement.setFetchSize(200)\nval rs = statement.executeQuery(\"select * from mysql_test\")\nwhile (rs.next) {\n    println(rs.getString(1))\n}\n\n使用命令\nROOT用户\n\nROOT用户作为系统管理员,推荐仅用作创建管理Organization和Sa。ROOT可以执行的指令有:\n\n# 修改自己的用户名\nALTER USER root IDENTIFIED BY newPassword\n\n# 创建Organization\nCREATE ORG orgname\n# 重命名Organization\nRENAME ORG orgname TO newname\nALTER ORG orgname RENAME TO newname\n# 删除Organization\nDROP ORG orgname\n\n# 在Organization中创建Sa用户\nCREATE SA saname IN ORG orgname\n# 给Sa修改密码\nRENAME SA saname IN ORG orgname TO newpassword\nALTER SA saname IN ORG orgname RENAME TO newpassword\n# 删除SA\nDROP SA saname IN ORG orgname\n\nSa用户\n\nBasic Concept章节已经介绍过User的六大属性,只要拥有某个属性即有权限执行对应的一类指令。Sa是由ROOT创建,拥有全部权限。以下仅列出Sa的特殊命令,其余命令将合并到普通用户节讲解。\n\n# 给用户授权, 类似于角色类授权。Moonbox为简单起见,目前以下指令限定只能Sa执行,也即角色类权限不能传递授权。\nGRANT GRANT OPTION ACCOUNT, DDL, DCL TO USER username\n# 取消用户授权\nREVOKE GRANT OPTION ACCOUNT, DDL, DCL FROM USER username\n\nSa用户和普通用户\n\n我们将根据用户拥有的权限来分类进行指令的介绍\n\n    DML\n\n    默认所有的用户都拥有DML权限,可以执行SHOW、DESC、SELECT、INSERT类指令。\n\n      SHOW DATABASES\n      SHOW TABLES\n      SHOW USERS\n      SHOW FUNTIONS\n      SHOW PROCEDURES\n      SHOW EVENTS\n      DESC DATABASE dbname\n      DESC TABLE tbname\n      DESC USER username\n      DESC FUNTION funcname\n      DESC EVENT eventname\n      USER dbname\n      SELECT ...\n      CREATE TEMP VIEW viewname AS SELECT ...\n      INSERT INTO/OVERWRITE tbname AS SELECT ...\n\n    Account\n\n    拥有Account权限的用户,可以执行账号相关指令。\n\n      CREATE USER username IDENTIFIED BY password # 创建用户\n      RENAME USER username TO newname # 修改用户名\n      ALTER USER username RENAME TO newname # 修改用户名\n      ALTER USER username IDENTIFIED BY newpassword\n      DROP USER username\n\n    DDL\n\n    系统初始化之后,Organization中只有一个名为default的TYPE 1数据库。拥有DDL权限的用户可以进行以下一些操作: 创建、删除TYPE 1 数据库\n\n      CREATE DATABASE dbname\n      DROP DATABASE dbname\n\n    在TYPE 1 数据库中挂载、卸载虚拟表\n\n      USE dbname\n      MOUNT TABLE tbname OPTIONS(key \'value\', key \'value\')\n      RENAME TABLE tbname TO newname\n      ALTER TABLE tbname RENAME TO newname\n      ALTER TABLE tbname SET OPTIONS(key \'newvalue\')\n      UNMOUT TABLE tbname\n\n    挂载、卸载TYPE 2 数据库\n\n      MOUNT DATABASE dbname OPTIONS(key \'value\', key \'value\')\n      RENAME DATABASE dbname TO newname\n      ALTER DATABASE dbname RENAME TO newname\n      ALTER DATABASE dbname SET OPTIONS(key \'newvalue\')\n      UNMOUNT DATABASE dbname\n\n    创建、修改、删除procedure,procedure为一系列SQL的封装,主要用于定时任务。\n\n      CREATE PROC procname AS (USE default; INSERT INTO oracle_external AS SELECT * FROM mysql_test)\n      RENAME PROC procname TO newname\n      ALTER PROC procname RENAME TO newname\n      ALTER PROC procname AS (USE default; INSERT INTO oracle_external AS SELECT * FROM mysql_test LIMIT 100)\n      DROP PROC procname\n\n    创建、修改、开启、停止、删除定时任务,event需要和一个procedure进行关联,执行的即为procedure。调度表达式为crontab格式。\n\n      CREATE EVENT eventname ON SCHEDULE AT \'0/50 * * * * ?\' DO CALL procname\n      RENAME EVENT eventname TO newname\n      ALTER EVENT eventname RENAME TO newname\n      ALTER EVENT eventname ON SCHEDULE AT \'0/40 * * * * ?\'\n      ALTER EVENT eventname ENABLE\n      ALTER EVENT eventname DISABLE\n      DROP EVENT eventname\n\n    创建、删除function。Moonbox除了支持jar形式的UDF,还支持在线源代码的形式,包括Java和Scala。也可以将多个函数写在一个类中,但是在注册的时候需要制定函数名。\n\n      # 使用Scala源代码创建function\n      CREATE FUNCTION funcname AS \'PersonData\' \'mutiply1\' USING scala \'(\n          class PersonData {\n              val field = 16\n              def mutiply1(i: Int): Int = i * field\n          }\n      )\'\n      # 使用jar包创建function,多个函数写在一个类中\n      CREATE FUNCTION funcname AS \'zoo.Panda\' \'multiply\' USING jar \'hdfs://host:8020/tmp/tortoise-1.0-SNAPSHOT.jar\'\n      # 使用jar包创建function,集成Scala FunctionN接口或者Java UDFN接口\n      CREATE FUNCTION funcname AS \'zoo.Single\' USING jar \'hdfs://host:8020/tmp/single-1.0-SNAPSHOT.jar\'\n      DROP FUNCITON funcname\n\n    DCL\n\n    拥有DCL权限的用户,可以执行将某些资源授权给用户访问的指令。\n\n      GRANT SELECT ON dbname.* TO USER username\n      REVOKE SELECT ON dbname.* FROM USER username\n      GRANT SELECT ON dbname.tbname TO USER username\n      REVOKE SELECT ON dbname.tbname FROM USER username\n      GRANT SELECT(col1,col2...) ON dbname.tbname TO USER username\n      REVOKE SELECT(col1) ON dbname.tbname FROM USER username\n      GRANT UPDATE ON dbname.* TO USER username\n      REVOKE UPDATE ON dbname.* FROM USER username\n      GRANT UPDATE ON dbname.tbname TO USER username\n      REVOKE UPDATE ON dbname.tbname FROM USER username\n      GRANT UPDATE(col1,col2...) ON dbname.tbname TO USER username\n      REVOKE UPDATE(col1) ON dbname.tbname FROM USER username\n\n    GrantAccount\n\n    拥有GrantAccount权限的用户,可以执行将Account权限授予其他用户的指令。\n\n      GRANT ACCOUNT TO USER username\n      REVOKE ACCOUNT FROM USER username\n\n    GrantDDL\n\n    拥有GrantDDL权限的用户,可以执行将DDL权限授予其他用户的指令。\n\n      GRANT DDL TO USER username\n      REVOKE DDL FROM USER username\n\n    GrantDCL\n\n    拥有GrantDCL权限的用户,可以执行将DCL权限授予其他用户的指令。\n\n      GRANT DCL TO USER username\n      REVOKE DCL FROM USER username\n\n以上属性看起来很复杂,可以把理解ACCOUNT、DDL、DCL为一阶权力,GrantAccount、GrantDDL、GrantDCL为二阶权力,二阶权力掌管一阶权力的授予和撤销。SA掌管二阶权力的授予和撤销。理论上通过属性的自由组合可以根据需求构建出”集权”和”三权分立”的用户体系。\n', '1', '<h2 id=\"h2-moonbox\"><a name=\"Moonbox\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Moonbox</h2><p>Moonbox是一个DAAS（Data Virtualization as a Service）平台解决方案。Moonbox基于数据虚拟化设计思想，致力于提供批量计算服务解决方案。Moonbox为用户带来虚拟数据库般使用体验，用户只需通过统一SQL语言，即可透明实现跨异构数据系统混算和写出。此外Moonbox还提供数据服务、数据管理、数据工具、数据开发等基础支持，可支撑更加敏捷和灵活的数据应用架构和逻辑数仓实践。</p>\n<p>Deploying Spark Local</p>\n<pre><code>环境准备\n部署配置\n启动与停止\n</code></pre><p>环境准备</p>\n<pre><code>JDK 1.8\nRedis 3.x.x\n配置执行启动脚本的机器到其他所有机器SSH免密码登录\n</code></pre><p>部署配置</p>\n<p>下载 moonbox-0.2.0-dist.tar.gz 包，或者使用如下命令自行编译</p>\n<p>git clone -b 0.2 <a href=\"https://github.com/edp963/moonbox.git\">https://github.com/edp963/moonbox.git</a><br>cd moonbox<br>git checkout tags/0.2.0<br>sh dev/build.sh</p>\n<p>使用dev/build.sh脚本编译,默认会添加所有数据源支持,具体有哪些数据源请参考Integration DataSource章节。如果想按需添加数据源支持,请使用如下指令编译,其中[]内为可选项。</p>\n<p>git clone -b 0.2 <a href=\"https://github.com/edp963/moonbox.git\">https://github.com/edp963/moonbox.git</a><br>cd moonbox<br>git checkout tags/0.2.0<br>mvn package -DskipTests -Pdist [-Pmysql -Poracle -Pes -Phive]</p>\n<p>解压moonbox-0.2.0-dist.tar.gz</p>\n<p>tar -zxvf moonbox-0.2.0-dist.tar.gz</p>\n<p>解压完成之后目录结构应当如下:</p>\n<p>moonbox</p>\n<ul>\n<li>bin # 应用脚本目录</li><li>conf # 配置文件目录</li><li>libs # moonbox依赖jar存放目录</li><li>log  # 日志目录</li><li>runtime # Spark运行时依赖jar存放目录</li><li>sbin # 启动停止集群管理脚本目录</li></ul>\n<p>moonbox的配置分为环境变量、集群拓扑、运行参数三个部分，下面分别解释每个部分各表示什么含义以及如何配置。</p>\n<pre><code>环境变量\n\n配置文件为conf/moonbox-env.sh\n\nexport MOONBOX_SSH_OPTIONS=&quot;-p 22&quot; # 用于配置ssh端口，如默认无需修改\nexport MOONBOX_HOME=/path/to/installed/dir # 配置moonbox安装目录\n\n集群拓扑\n\n用于描述集群拓扑，配置文件为$MOONBOX_HOME/conf/nodes。moonbox以master-slave集群模式运行，支持配置多个master用于主备。示例如下，请按照实际情况配置。\n\nmoonbox.gird.master.1   grid://host1:2551\nmoonbox.gird.master.2   grid://host2:2551\nmoonbox.gird.worker.1   host3\nmoonbox.gird.worker.2   host4\n\n运行参数\n\n用于配置运行时参数，配置文件为$MOONBOX_HOME/conf/moonbox-defaults.conf。以下为moonbox最简配置，请根据实际情况修改，更多配置请参考Configuration章节。\n\nmoonbox {\n    rest.server {\n        port = 8080\n    }\n    tcp.server {\n        port = 10010\n    }\n    catalog {\n          implementation = &quot;h2&quot;\n          url = &quot;jdbc:h2:mem:testdb0;DB_CLOSE_DELAY=-1&quot;\n          user = &quot;testUser&quot;\n          password = &quot;testPass&quot;\n          driver = &quot;org.h2.Driver&quot;\n    }\n    cache {\n          implementation = &quot;redis&quot;\n          redis.servers = &quot;host:port&quot;\n    }\n    mixcal {\n        implementation = &quot;spark&quot;\n          spark.master = &quot;local[*]&quot;\n          spark.loglevel = &quot;INFO&quot;\n          spark.app.name = &quot;test1&quot;\n          pushdown.enable = true\n          column.permission.enable = false\n    }\n}\n</code></pre><p>将moonbox文件夹分发到conf/nodes中所配置的所有机器上,其所处目录应当与当前机器$MOONBOX_HOME一致。<br>启动与停止</p>\n<p>我们为用户提供了一键启动与停止集群的脚本,位于$MOONBOX_HOME/sbin目录下。</p>\n<pre><code>启动集群 在任意节点执行\n\n  cd $MOONBOX_HOME\n  sbin/start-all.sh\n\n停止集群 在任意节点执行\n\n  cd $MOONBOX_HOME\n  sbin/stop-all.sh\n\n备注:\n执行启动和停止脚本的机器需要配置到其他机器的ssh免密码登录。\n\n如catalog配置修改为其他数据库,请将对应的驱动jar包拷贝到每台机器的$MOONBOX_HOME/libs目录下。\n</code></pre><p>User Guide<br>Quick Start</p>\n<p>Moonbox服务启动之后,系统管理人员使用ROOT用户连接Moonbox,输入SQL语句,以分号结束。</p>\n<p>cd $MOONBOX_HOME/bin<br>./cli.sh -m rest -u ROOT -p 123456 -h localhost -P 18090</p>\n<p>其中:</p>\n<pre><code>-m 连接Moonbox的方式, 选项为rest和jdbc\n-u 用户名\n-p 密码,ROOT初始密码为123456\n-h Moonbox rest server服务地址\n-P Moonbox rest server 服务端口\n</code></pre><p>创建Organization,假设名为testOrg</p>\n<p>CREATE ORG/ORGANIZATION testOrg;</p>\n<p>在该Organization中创建Sa,假设名为sally</p>\n<p>CREATE SA sally IN ORG testOrg IDENTIFIED BY 123456;</p>\n<p>至此,用户空间已经创建完毕,更多命令请参考Indexing部分。</p>\n<p>应用管理人员使用Sa用户登录</p>\n<p>cd $MOONBOX_HOME/bin<br>./cli.sh -m rest -u sally -p 123456 -h localhost -P 18090</p>\n<p>当Sa初始登录之后,Sa所属的Organization中只有一个默认的名为default的数据库,可以在该数据库下挂载虚拟表。例如挂载MySQL类型数据库test中的booklist表。</p>\n<p>MOUNT TABLE mysql_test OPTIONS(<br>    type ‘mysql’,<br>    url ‘jdbc<img src=\"../plugins/emoji-dialog/emoji/mysql.png\" class=\"emoji\" title=\"&#58;mysql&#58;\" alt=\"&#58;mysql&#58;\" />//localhost:3306/test’,<br>    user ‘root’,<br>    password ‘password’,<br>    driver ‘com.mysql.jdbc.Driver’,<br>    dbtable ‘booklist’<br>);</p>\n<p>当执行挂载表指令的时候,系统会检查连接参数的正确性,所以要确保参数正确。需要注意,在发行包中并没有包含MySQL的jdbc驱动,所以需要自行将对应的驱动包拷贝到$MOONBOX_HOME/libs和$MOONBOX_HOME/runtime中。</p>\n<p>列出所有表</p>\n<p>SHOW TABLES;</p>\n<p>查看表详情</p>\n<p>DESCRIBE TABLE mysql_test;</p>\n<p>对表内容做查询</p>\n<p>SELECT * FROM mysql_test;</p>\n<p>Sa还可以创建新用户</p>\n<pre><code>CREATE USER username IDENTIFIED BY password; # 创建用户\nGRANT ACCOUNT, DDL, DCL TO USER username; # 给用户授权, ACCOUNT、DDL、DCL按需选择\n</code></pre><p>如果不给新创建的用户进行授权,那么该用户就只有DML权限,即只能执行SELECT, SHOW ,DESCRIBE等操作。 至此,Sa即可将新创建的账号分配给用户使用了。以上只是一个简短快速的体验,更多内容请阅读接下来的部分。<br>客户端使用</p>\n<p>Moonbox内置http server和tcp server,支持通过rest和jdbc方式接入。<br>使用命令行</p>\n<p>cd $MOONBOX_HOME/bin<br>./cli.sh -m rest -u username -p password -h localhost -P 18090</p>\n<p>其中:</p>\n<pre><code>-m 连接Moonbox的方式, 选项为rest和jdbc\n-u 用户名\n-p 密码,ROOT初始密码为123456\n-h Moonbox rest server服务地址\n-P Moonbox rest server 服务端口\n</code></pre><p>使用rest</p>\n<p>rest方式支持batch和adhoc两种方式。batch是两批作业之间无上下文关联,可能对调度到不同的机器上的runner执行,adhoc是上下文相关的,有session的概念,会调度到同一个runner中执行。其中batch又分为异步和同步模式,adhoc只支持同步。<br>系统登录</p>\n<h1 id=\"h1-request-\"><a name=\"request 示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>request 示例</h1><p>curl -XPOST <a href=\"http://host:port/login\">http://host:port/login</a> -d ‘{<br>    “username”: “sally”,<br>    “password”: “123456”<br>}’</p>\n<h1 id=\"h1-response-token-\"><a name=\"response 示例,该token内容作为该用户今后登录凭证\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>response 示例,该token内容作为该用户今后登录凭证</h1><p>{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjVhMjNiMDczLWE4NzctNGRmZC1hYjkyLWY2ZGI0YjNmNzVlYyJ9._jIe1cgbc9d9JMW6g6D6KA”<br>}</p>\n<p>查询提交</p>\n<p>adhoc方式</p>\n<h1 id=\"h1--session-request-\"><a name=\"开启session,request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>开启session,request示例</h1><p>curl -XPOST <a href=\"http://host:port/openSession\">http://host:port/openSession</a> -d ‘{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjVhMjNiMDczLWE4NzctNGRmZC1hYjkyLWY2ZGI0YjNmNzVlYyJ9._jIe1cgbc9d9JMW6g6D6KA”<br>}’</p>\n<h1 id=\"h1--session-response-sessionid-session-\"><a name=\"开启session,response示例,该sessionId用于session标识\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>开启session,response示例,该sessionId用于session标识</h1><p>{<br>  “sessionId” : “3ddec591-16db-4a7c-93a7-c6df54763ad0”<br>}</p>\n<h1 id=\"h1--request-\"><a name=\"提交查询,request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>提交查询,request示例</h1><p>curl -XPOST <a href=\"http://host:port/query\">http://host:port/query</a> -d ‘{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA”,<br>    “sessionId” : “3ddec591-16db-4a7c-93a7-c6df54763ad0”,<br>    “sqls”:[“use default”, “show tables”]<br>}’</p>\n<h1 id=\"h1--response-\"><a name=\"提交查询,response示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>提交查询,response示例</h1><p>{<br>“jobId” : “job-20180730150004-00001”,<br>“data” : [[“mysql_test”], [“oracle_test”]]<br>}</p>\n<h1 id=\"h1--session-request-\"><a name=\"关闭session,request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭session,request示例</h1><p>curl -XPOST <a href=\"http://host:port/closeSession\">http://host:port/closeSession</a> -d ‘{<br>{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA”,<br>    “sessionId” : “3ddec591-16db-4a7c-93a7-c6df54763ad0”,<br>}’</p>\n<h1 id=\"h1--session-response-\"><a name=\"关闭session,response示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>关闭session,response示例</h1><p>{}</p>\n<p>batch同步方式</p>\n<h1 id=\"h1--request-\"><a name=\"同步提交查询,request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>同步提交查询,request示例</h1><p>curl -XPOST <a href=\"http://host:port/submit\">http://host:port/submit</a> -d ‘{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA”,<br>    “mode” : “sync”,<br>    “sqls”:[“use default”, “show tables”]<br>}’</p>\n<h1 id=\"h1--response-\"><a name=\"同步提交查询,response示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>同步提交查询,response示例</h1><p>{<br>“jobId” : “job-20180730150004-00001”,<br>“data” : [[“mysql_test”], [“oracle_test”]]<br>}</p>\n<p>batch异步方式</p>\n<p>异步提交作业,会将select类型作业结果保存到缓存,等待用户查询结果。对于insert类型作业会将结果保存到对应的外部存储。所以使用异步方式提交查询时,请注意create、alter、drop、show或者desc等指令,结果会丢失,因为这类指令的返回结果为direct类型,不会存储到缓存。</p>\n<h1 id=\"h1--request-\"><a name=\"异步提交查询,request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>异步提交查询,request示例</h1><p>curl -XPOST <a href=\"http://host:port/submit\">http://host:port/submit</a> -d ‘{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA”,<br>    “mode” : “async”,<br>    “sqls”:[“use default”, “select * from mysql_test”]<br>}’</p>\n<h1 id=\"h1--response-\"><a name=\"异步提交查询,response示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>异步提交查询,response示例</h1><p>{<br>  “jobId” : “job-20180730192553-00000”<br>}</p>\n<h1 id=\"h1--request-\"><a name=\"查询异步作业状态, request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>查询异步作业状态, request示例</h1><p>curl -XPOST <a href=\"http://host:port/progress\">http://host:port/progress</a> -d ‘{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA”,<br>    “jobId” : “job-20180730192553-00000”<br>}’</p>\n<h1 id=\"h1--response-\"><a name=\"查询异步作业状态,response示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>查询异步作业状态,response示例</h1><p>{<br>    “jobId” : “job-20180730192553-00000”,<br>    “status” : “SUCCESS”<br>}</p>\n<h1 id=\"h1--request-\"><a name=\"获取异步作业结果,request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>获取异步作业结果,request示例</h1><p>curl -XPOST <a href=\"http://host:port/result\">http://host:port/result</a> -d ‘{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA”,<br>    “jobId” : “job-20180730192553-00000”,<br>    “offset” : 0,<br>    “size” : 2<br>}’</p>\n<h1 id=\"h1--response-\"><a name=\"获取异步作业结果,response示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>获取异步作业结果,response示例</h1><p>{<br>  “jobId” : “job-20180730192553-00000”,<br>  “schema” : “{\\”type\\”:\\”struct\\”,\\”fields\\”:[{\\”name\\”:\\”id\\”,\\”type\\”:\\”long\\”,\\”nullable\\”:true,\\”metadata\\”:{\\”name\\”:\\”id\\”,\\”scale\\”:0}},{\\”name\\”:\\”bname\\”,\\”type\\”:\\”string\\”,\\”nullable\\”:true,\\”metadata\\”:{\\”name\\”:\\”bname\\”,\\”scale\\”:0}},{\\”name\\”:\\”male\\”,\\”type\\”:\\”boolean\\”,\\”nullable\\”:true,\\”metadata\\”:{\\”name\\”:\\”male\\”,\\”scale\\”:0}},{\\”name\\”:\\”outer_key\\”,\\”type\\”:\\”long\\”,\\”nullable\\”:true,\\”metadata\\”:{\\”name\\”:\\”outer_key\\”,\\”scale\\”:0}},{\\”name\\”:\\”china_key\\”,\\”type\\”:\\”string\\”,\\”nullable\\”:true,\\”metadata\\”:{\\”name\\”:\\”china_key\\”,\\”scale\\”:0}},{\\”name\\”:\\”china_name\\”,\\”type\\”:\\”string\\”,\\”nullable\\”:true,\\”metadata\\”:{\\”name\\”:\\”china_name\\”,\\”scale\\”:0}}]}”,<br>  “data” : [ [ 1, “name1”, false, 1, “xx科技”, “刘明” ], [ 8, “bbbb”, true, 2, “xx科技”, “李军” ]]<br>}</p>\n<h1 id=\"h1--request-\"><a name=\"取消正在运行的作业, request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>取消正在运行的作业, request示例</h1><p>curl -XPOST <a href=\"http://host:port/cancel\">http://host:port/cancel</a> -d ‘{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA”,<br>    “jobId” : “job-20180730192553-00000”<br>}’</p>\n<h1 id=\"h1--response-\"><a name=\"取消正在运行的作业, response示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>取消正在运行的作业, response示例</h1><p>{<br>    “jobId” : “job-20180730203509-00010”<br>}</p>\n<p>系统登出</p>\n<h1 id=\"h1--request-\"><a name=\"系统登出,request示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>系统登出,request示例</h1><p>curl -XPOST <a href=\"http://host:port/logout\">http://host:port/logout</a> -d ‘{<br>    “token” : “eyJ0eXAiOiJKV1QiLCJhbGciOiJITUQ1In0.eyJ1c2VybmFtZSI6InNhbGx5Iiwic2VlZCI6IjI1MzYyNmU0LWNkMzMtNDc1ZC04NTFhLWEzYTMzZTY1NGVhMSJ9.L6t_WRLTuyXuub_i46ZAhA”,<br>}’</p>\n<h1 id=\"h1--response-\"><a name=\"系统登出,response示例\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>系统登出,response示例</h1><p>{<br>    “message” : “Logout successfully.”<br>}</p>\n<p>使用jdbc编程</p>\n<p>Moonbox提供了jdbc驱动,请自行下载。以下为Scala示例:</p>\n<p>Class.forName(“moonbox.jdbc.MbDriver”)<br>val url = s”jdbc<img src=\"../plugins/emoji-dialog/emoji/moonbox.png\" class=\"emoji\" title=\"&#58;moonbox&#58;\" alt=\"&#58;moonbox&#58;\" />//host:port/database”<br>val username = “username”<br>val password = “password”<br>val connection = DriverManager.getConnection(url, username, password)<br>val statement = connection.createStatement()<br>statement.setQueryTimeout(60<em>10)<br>statement.setFetchSize(200)<br>val rs = statement.executeQuery(“select </em> from mysql_test”)<br>while (rs.next) {<br>    println(rs.getString(1))<br>}</p>\n<p>使用命令<br>ROOT用户</p>\n<p>ROOT用户作为系统管理员,推荐仅用作创建管理Organization和Sa。ROOT可以执行的指令有:</p>\n<h1 id=\"h1-u4FEEu6539u81EAu5DF1u7684u7528u6237u540D\"><a name=\"修改自己的用户名\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>修改自己的用户名</h1><p>ALTER USER root IDENTIFIED BY newPassword</p>\n<h1 id=\"h1--organization\"><a name=\"创建Organization\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>创建Organization</h1><p>CREATE ORG orgname</p>\n<h1 id=\"h1--organization\"><a name=\"重命名Organization\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>重命名Organization</h1><p>RENAME ORG orgname TO newname<br>ALTER ORG orgname RENAME TO newname</p>\n<h1 id=\"h1--organization\"><a name=\"删除Organization\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>删除Organization</h1><p>DROP ORG orgname</p>\n<h1 id=\"h1--organization-sa-\"><a name=\"在Organization中创建Sa用户\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在Organization中创建Sa用户</h1><p>CREATE SA saname IN ORG orgname</p>\n<h1 id=\"h1--sa-\"><a name=\"给Sa修改密码\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>给Sa修改密码</h1><p>RENAME SA saname IN ORG orgname TO newpassword<br>ALTER SA saname IN ORG orgname RENAME TO newpassword</p>\n<h1 id=\"h1--sa\"><a name=\"删除SA\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>删除SA</h1><p>DROP SA saname IN ORG orgname</p>\n<p>Sa用户</p>\n<p>Basic Concept章节已经介绍过User的六大属性,只要拥有某个属性即有权限执行对应的一类指令。Sa是由ROOT创建,拥有全部权限。以下仅列出Sa的特殊命令,其余命令将合并到普通用户节讲解。</p>\n<h1 id=\"h1--moonbox-sa-\"><a name=\"给用户授权, 类似于角色类授权。Moonbox为简单起见,目前以下指令限定只能Sa执行,也即角色类权限不能传递授权。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>给用户授权, 类似于角色类授权。Moonbox为简单起见,目前以下指令限定只能Sa执行,也即角色类权限不能传递授权。</h1><p>GRANT GRANT OPTION ACCOUNT, DDL, DCL TO USER username</p>\n<h1 id=\"h1-u53D6u6D88u7528u6237u6388u6743\"><a name=\"取消用户授权\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>取消用户授权</h1><p>REVOKE GRANT OPTION ACCOUNT, DDL, DCL FROM USER username</p>\n<p>Sa用户和普通用户</p>\n<p>我们将根据用户拥有的权限来分类进行指令的介绍</p>\n<pre><code>DML\n\n默认所有的用户都拥有DML权限,可以执行SHOW、DESC、SELECT、INSERT类指令。\n\n  SHOW DATABASES\n  SHOW TABLES\n  SHOW USERS\n  SHOW FUNTIONS\n  SHOW PROCEDURES\n  SHOW EVENTS\n  DESC DATABASE dbname\n  DESC TABLE tbname\n  DESC USER username\n  DESC FUNTION funcname\n  DESC EVENT eventname\n  USER dbname\n  SELECT ...\n  CREATE TEMP VIEW viewname AS SELECT ...\n  INSERT INTO/OVERWRITE tbname AS SELECT ...\n\nAccount\n\n拥有Account权限的用户,可以执行账号相关指令。\n\n  CREATE USER username IDENTIFIED BY password # 创建用户\n  RENAME USER username TO newname # 修改用户名\n  ALTER USER username RENAME TO newname # 修改用户名\n  ALTER USER username IDENTIFIED BY newpassword\n  DROP USER username\n\nDDL\n\n系统初始化之后,Organization中只有一个名为default的TYPE 1数据库。拥有DDL权限的用户可以进行以下一些操作: 创建、删除TYPE 1 数据库\n\n  CREATE DATABASE dbname\n  DROP DATABASE dbname\n\n在TYPE 1 数据库中挂载、卸载虚拟表\n\n  USE dbname\n  MOUNT TABLE tbname OPTIONS(key &#39;value&#39;, key &#39;value&#39;)\n  RENAME TABLE tbname TO newname\n  ALTER TABLE tbname RENAME TO newname\n  ALTER TABLE tbname SET OPTIONS(key &#39;newvalue&#39;)\n  UNMOUT TABLE tbname\n\n挂载、卸载TYPE 2 数据库\n\n  MOUNT DATABASE dbname OPTIONS(key &#39;value&#39;, key &#39;value&#39;)\n  RENAME DATABASE dbname TO newname\n  ALTER DATABASE dbname RENAME TO newname\n  ALTER DATABASE dbname SET OPTIONS(key &#39;newvalue&#39;)\n  UNMOUNT DATABASE dbname\n\n创建、修改、删除procedure,procedure为一系列SQL的封装,主要用于定时任务。\n\n  CREATE PROC procname AS (USE default; INSERT INTO oracle_external AS SELECT * FROM mysql_test)\n  RENAME PROC procname TO newname\n  ALTER PROC procname RENAME TO newname\n  ALTER PROC procname AS (USE default; INSERT INTO oracle_external AS SELECT * FROM mysql_test LIMIT 100)\n  DROP PROC procname\n\n创建、修改、开启、停止、删除定时任务,event需要和一个procedure进行关联,执行的即为procedure。调度表达式为crontab格式。\n\n  CREATE EVENT eventname ON SCHEDULE AT &#39;0/50 * * * * ?&#39; DO CALL procname\n  RENAME EVENT eventname TO newname\n  ALTER EVENT eventname RENAME TO newname\n  ALTER EVENT eventname ON SCHEDULE AT &#39;0/40 * * * * ?&#39;\n  ALTER EVENT eventname ENABLE\n  ALTER EVENT eventname DISABLE\n  DROP EVENT eventname\n\n创建、删除function。Moonbox除了支持jar形式的UDF,还支持在线源代码的形式,包括Java和Scala。也可以将多个函数写在一个类中,但是在注册的时候需要制定函数名。\n\n  # 使用Scala源代码创建function\n  CREATE FUNCTION funcname AS &#39;PersonData&#39; &#39;mutiply1&#39; USING scala &#39;(\n      class PersonData {\n          val field = 16\n          def mutiply1(i: Int): Int = i * field\n      }\n  )&#39;\n  # 使用jar包创建function,多个函数写在一个类中\n  CREATE FUNCTION funcname AS &#39;zoo.Panda&#39; &#39;multiply&#39; USING jar &#39;hdfs://host:8020/tmp/tortoise-1.0-SNAPSHOT.jar&#39;\n  # 使用jar包创建function,集成Scala FunctionN接口或者Java UDFN接口\n  CREATE FUNCTION funcname AS &#39;zoo.Single&#39; USING jar &#39;hdfs://host:8020/tmp/single-1.0-SNAPSHOT.jar&#39;\n  DROP FUNCITON funcname\n\nDCL\n\n拥有DCL权限的用户,可以执行将某些资源授权给用户访问的指令。\n\n  GRANT SELECT ON dbname.* TO USER username\n  REVOKE SELECT ON dbname.* FROM USER username\n  GRANT SELECT ON dbname.tbname TO USER username\n  REVOKE SELECT ON dbname.tbname FROM USER username\n  GRANT SELECT(col1,col2...) ON dbname.tbname TO USER username\n  REVOKE SELECT(col1) ON dbname.tbname FROM USER username\n  GRANT UPDATE ON dbname.* TO USER username\n  REVOKE UPDATE ON dbname.* FROM USER username\n  GRANT UPDATE ON dbname.tbname TO USER username\n  REVOKE UPDATE ON dbname.tbname FROM USER username\n  GRANT UPDATE(col1,col2...) ON dbname.tbname TO USER username\n  REVOKE UPDATE(col1) ON dbname.tbname FROM USER username\n\nGrantAccount\n\n拥有GrantAccount权限的用户,可以执行将Account权限授予其他用户的指令。\n\n  GRANT ACCOUNT TO USER username\n  REVOKE ACCOUNT FROM USER username\n\nGrantDDL\n\n拥有GrantDDL权限的用户,可以执行将DDL权限授予其他用户的指令。\n\n  GRANT DDL TO USER username\n  REVOKE DDL FROM USER username\n\nGrantDCL\n\n拥有GrantDCL权限的用户,可以执行将DCL权限授予其他用户的指令。\n\n  GRANT DCL TO USER username\n  REVOKE DCL FROM USER username\n</code></pre><p>以上属性看起来很复杂,可以把理解ACCOUNT、DDL、DCL为一阶权力,GrantAccount、GrantDDL、GrantDCL为二阶权力,二阶权力掌管一阶权力的授予和撤销。SA掌管二阶权力的授予和撤销。理论上通过属性的自由组合可以根据需求构建出”集权”和”三权分立”的用户体系。</p>\n');
INSERT INTO `tbl_archive` VALUES ('75', '0', 'ambari集成kylin（离线部署） ', '8', '2019-01-10 04:30:51', '修改自cas-bigdatalab地址https://github.com/cas-bigdatalab/ambari-kylin-service.git主要是支持离线部署以及修正部分bugTodownloadtheKylinservicefolder,runbelowhttps://github.com/TiestoRay/ambari-kylinVERSION=`hdp-selectstatu', null, '0', '64', null, null, '2019-01-10 04:30:51', '2019-01-10 04:32:02', null, null, '0', '0', '0', '0', '代码地址:\nhttps://github.com/TiestoRay/ambari-kylin\n\n修改自 cas-bigdatalab\n地址 https://github.com/cas-bigdatalab/ambari-kylin-service.git\n主要是支持离线部署以及修正部分bug\n\nTo download the Kylin service folder, run below\n\nVERSION=`crh-select status hadoop-client | sed \'s/hadoop-client - \\([0-9]\\.[0-9]\\).*/\\1/\'`\nsudo git clone https://github.com/TiestoRay/ambari-kylin.git /var/lib/ambari-server/resources/stacks/CRH/$VERSION/services/KYLIN\n\nRestart Ambari\n\nservice ambari restart', '0', '<p>代码地址:<br><a href=\"https://github.com/TiestoRay/ambari-kylin\">https://github.com/TiestoRay/ambari-kylin</a></p>\n<p>修改自 cas-bigdatalab<br>地址 <a href=\"https://github.com/cas-bigdatalab/ambari-kylin-service.git\">https://github.com/cas-bigdatalab/ambari-kylin-service.git</a><br>主要是支持离线部署以及修正部分bug</p>\n<p>To download the Kylin service folder, run below</p>\n<p>VERSION=<code>crh-select status hadoop-client | sed &#39;s/hadoop-client - \\([0-9]\\.[0-9]\\).*/\\1/&#39;</code><br>sudo git clone <a href=\"https://github.com/TiestoRay/ambari-kylin.git\">https://github.com/TiestoRay/ambari-kylin.git</a> /var/lib/ambari-server/resources/stacks/CRH/$VERSION/services/KYLIN</p>\n<p>Restart Ambari</p>\n<p>service ambari restart</p>\n');
INSERT INTO `tbl_archive` VALUES ('76', '0', '安装 R 语言环境 on RedHat ', '8', '2019-01-19 15:51:30', 'RRPMSforFedora,RedHatEnterpriseLinuxandDerivatives===========================================================MartynPlummer2014-07-22Contents1)Fedora2)EPELforRedHatEnterpriseLinuxandOthers3)RPMSforRPac', null, '0', '59', null, null, '2019-01-19 15:51:30', '2019-01-19 17:39:45', null, null, '0', '0', '0', '0', 'R RPMS for Fedora, Red Hat Enterprise Linux and Derivatives\n===========================================================\nMartyn Plummer\n2014-07-22\n\nContents\n1) Fedora\n2) EPEL for Red Hat Enterprise Linux and Others\n3) RPMS for R Packages\n4) Creating your own R package RPMS\n\n1) Fedora\n=========\n\nR packages for Fedora Linux are maintained and distributed by Red Hat\nSoftware. Fedora users can install R with yum from the standard Fedora\nrepository using\n\nsudo yum install R\n\nThe RPM \'R\' is a meta package. It has no content but ensures that the\nfollowing components are installed\n\nR-core	       User RPM\nR-core-devel   Developer RPM containing header files\nR-java	       RPM to ensure that R is configured for use with Java\nlibRmath       Standalone R math library\nlibRmath-devel Header file for the standalone R math library\n\nIt is standard practice to divide RPMs into \"user\" and \"developer\"\nversions. In the case of R on Fedora, these are provided by the\n\'R-core\' and \'R-core-devel\' RPMs. However, almost all R users on\nFedora will need \'R-core-devel\' in order to install R packages from\nsource. Therefore it is recommended to install the meta-package \'R\'.\n\n2) Red Hat Enterprise Linux (RHEL)\n   CentOS\n   Scientific Linux\n   Oracle Linux\n==================================\n\nThe Fedora RPMs for R have been ported to RHEL by the project Extra\nPackages for Enterprise Linux (EPEL).\n\nhttp://fedoraproject.org/wiki/EPEL \n\nThese RPMs are also compatible with distributions derived from RHEL.\n\nTo use the EPEL repository, it is sufficient to download and install\nthe appropriate \"epel-release\" RPM, as described in the EPEL FAQ:\n\nhttps://fedoraproject.org/wiki/EPEL/FAQ#How_can_I_install_the_packages_from_the_EPEL_software_repository.3F\n\nThen R can be installed as described above in the section on Fedora.\n\n	For EL6:\n	su -c \'rpm -Uvh https://download.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm\'\n	su -c \'yum install foo\'\n\n	For EL7:\n	su -c \'rpm -Uvh https://download.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\'\n	su -c \'yum install foo\'\n\n\n3) R packages\n=============\n\nFedora provies a selection of R packages as RPMs. A more limited\nselection of these packages has been ported to EPEL. The RPM name is\nderived from the R package name by adding the prefix \"R-\". Hence all\nR-related RPMS can be listed with the yum command\n\nyum list R-\\*\n\nThe listing below shows all RPMS available for R packages on Fedora\n20, classified by the R repository that would normally be used to\ninstall the package from within R (See the help page ?chooseRepositories).\n\n$CRAN\n [1] \"R-abind\"      \"R-acepack\"    \"R-biglm\"      \"R-bigmemory\"  \"R-bitops\"    \n [6] \"R-car\"        \"R-caTools\"    \"R-combinat\"   \"R-DBI\"        \"R-lmtest\"    \n[11] \"R-mAr\"        \"R-msm\"        \"R-multcomp\"   \"R-mvtnorm\"    \"R-nws\"       \n[16] \"R-pls\"        \"R-qcc\"        \"R-qtl\"        \"R-RCurl\"      \"R-rlecuyer\"  \n[21] \"R-RM2\"        \"R-RODBC\"      \"R-RSQLite\"    \"R-RUnit\"      \"R-sandwich\"  \n[26] \"R-sciplot\"    \"R-statmod\"    \"R-systemfit\"  \"R-timeDate\"   \"R-waveslim\"  \n[31] \"R-wavethresh\" \"R-XML\"        \"R-xtable\"     \"R-zoo\"       \n\n$`BioC software`\n [1] \"R-affy\"                  \"R-affyio\"               \n [3] \"R-AnnotationDbi\"         \"R-Biobase\"              \n [5] \"R-BiocGenerics\"          \"R-biomaRt\"              \n [7] \"R-Biostrings\"            \"R-BSgenome\"             \n [9] \"R-BufferedMatrix\"        \"R-BufferedMatrixMethods\"\n[11] \"R-DynDoc\"                \"R-GenomicFeatures\"      \n[13] \"R-GenomicRanges\"         \"R-IRanges\"              \n[15] \"R-maanova\"               \"R-multtest\"             \n[17] \"R-preprocessCore\"        \"R-qvalue\"               \n[19] \"R-ROC\"                   \"R-Rsamtools\"            \n[21] \"R-rtracklayer\"           \"R-tkWidgets\"            \n[23] \"R-widgetTools\"          \n\n$`BioC annotation`\n[1] \"R-hgu133acdf\"    \"R-hgu95av2cdf\"   \"R-hgu95av2probe\"\n\n$`BioC experiment`\n[1] \"R-affydata\"  \"R-ALL\"       \"R-fibroEset\"\n\n$`BioC extra`\n[1] \"R-RCurl\"\n\n$Omegahat\n[1] \"R-Rcompression\" \"R-RCurl\"        \"R-XML\"         \n\n$`R-Forge`\n[1] \"R-abind\"     \"R-bigmemory\" \"R-car\"       \"R-msm\"       \"R-multcomp\" \n[6] \"R-mvtnorm\"   \"R-timeDate\"  \"R-waveslim\"  \"R-xtable\"   \n\n$Other\n[1] \"R-GeneR\"      \"R-RScaLAPACK\" \"R-Rsolid\"     \"R-hdf5\"      \n\nNote that the classification is not mutually exclusive (e.g. R-RCurl\nappears several times) and that Fedora provides RPMs that are not\navailable from any standard R repository. These are listed under\n\"Other\".\n\nThe above listing is created by the following utility function, which\nmay be freely used, redistributed and modified without restriction.\n\nclassify.rpms <- function()\n{\n    ## Get a list of R packages available via yum\n    pkg <- system(\"yum list -q R-\\\\*\", intern=TRUE)\n    pkg <- sub(pattern=\"\\\\..+$\", replacement=\"\", pkg)\n    pkg <- pkg[grep(\"-devel$\", pkg, invert=TRUE)] #no devel packages\n    pkg <- pkg[grep(\"-debuginfo$\", pkg, invert=TRUE)] #no debug packages\n    pkg <- setdiff(pkg, c(\"R\", \"R-core\", \"R-java\",\n                          \"Installed Packages\",\n                          \"Available Packages\"))\n    pkg <- unique(pkg)\n\n    ## Get the database of standard repositories\n    p <- file.path(R.home(\"etc\"), \"repositories\")\n    reps <- read.table(p, header=TRUE, sep=\"\\t\")\n    out <- vector(\"list\", nrow(reps))\n    names(out) <- reps$menu_name\n    for (i in seq_along(out)) {\n        ## Match repositories to available yum packages\n        setRepositories(ind=i)\n        av <- paste(\"R\", available.packages()[,\"Package\"], sep=\"-\")\n        out[[i]] <- intersect(av, pkg)\n    }\n    setRepositories(ind=1) #Set default repository to CRAN\n    out$Other <- setdiff(pkg, unlist(out)) #unclassified packages\n    out[sapply(out, length) > 0] #remove empty categories\n}\n\n4) Creating your own R package RPMs\n===================================\n\nBoth Fedora and EPEL provide the R2spec package, which may be used\nto create your own R package RPMs. See https://fedorahosted.org/r2spec/\n\n\n5)安装R \n===================================\n\nCentOS7安装大部分软件的方法\n\n	sudo yum install R\n\n6)安装R Studio Server\n===================================\n\nR Studio Server 安装官方文档 [ Download RStudio Server ]\n\n64Bit\n\n	wget https://download2.rstudio.org/rstudio-server-rhel-1.1.383-x86_64.rpm\n	sudo yum install --nogpgcheck rstudio-server-rhel-1.1.383-x86_64.rpm\n\nR Studio Server就安装好了。访问服务器地址：http://<server-ip>:8787 \n新建用户 root用户无法登陆，新建一个用户进行登陆\n\n	useradd -d /home/R -m R，创建用户的同时指定主目录\n	passwd R，设置密码\n	\n	R中实现脚本调用，以及函数调用\n\n6)运行R测试\n===================================\n\n安装依赖环境\n	\n	yum install mariadb-connector-c-devel  mariadb-devel \n安装数据库连接\n	\n	install.packages(\'DBI\')\n	install.packages(\'RMySQL\')\n\n这里的列子是test.R调用mysql_con.R中的函数\n\nmysql_con.R\n复制代码\n\n	# 使用RMySQL操作数据库\n	# 载入DBI和RMySQL包\n	library(\'DBI\')\n	library(\'RMySQL\')\n\n	mysql_con <- function(sql){\n\n	  # 创建数据库连接\n	  con <- dbConnect(MySQL(),host =\"localhost\",port=3307,dbname=\"cars\",user=\"root\",password=\"123456\")\n	  #说明用什么字符集来获取数据库字段\n	  dbGetQuery(con, \"SET NAMES gbk\")\n	  #dbSendQuery(con, \"SET NAMES gbk\"); \n\n	  # 验证连接\n	  #print(summary(con)) \n\n	  # SQL查询\n	  results <- dbGetQuery(con,sql)\n	  \n	  #断开连接\n	  dbDisconnect(con) \n	  return(results)\n	}\n复制代码\n\ntest.R\n\n# 引入脚本文件\n	source(\'E:/workspace/RStudio/codeSpace/cars/Helper/mysql_con.R\', encoding = \'UTF-8\')\n	print(mysql_con(\"select count(*) from discretized_data\"))\n	\n整合到XXL-JOBS中\n===========================\n	#!/bin/bash\n	echo \"xxl-job: hello shell\"\n\n	echo \"脚本位置：$0\"\n	echo \"任务参数：$1\"\n	echo \"分片序号 = $2\"\n	echo \"分片总数 = $3\"\n\n	echo \"\"\"\n	library(\'DBI\')\n	library(\'RMySQL\')\n\n	mysql_con <- function(sql){\n	  con <- dbConnect(MySQL(),host =\\\"192.168.0.83\\\",port =3307,dbname=\\\"test\\\",user=\\\"root\\\",password=\\\"\\\")\n	  dbGetQuery(con, \\\"SET NAMES utf8\\\")\n	  print(summary(con))\n	  results <- dbGetQuery(con,sql)\n	  dbDisconnect(con)\n	  return(results)\n	}\n\n	print(mysql_con(\\\"SELECT * FROM test.tob_count02\\\"))\n\n	\"\"\" > /opt/sql.r\n\n	R --save < /opt/sql.r > /opt/sql.log\n	\n	echo \"Good bye!\"\n	exit 0\n\n', '0', '<h1 id=\"h1-r-rpms-for-fedora-red-hat-enterprise-linux-and-derivatives\"><a name=\"R RPMS for Fedora, Red Hat Enterprise Linux and Derivatives\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>R RPMS for Fedora, Red Hat Enterprise Linux and Derivatives</h1><p>Martyn Plummer<br>2014-07-22</p>\n<p>Contents<br>1) Fedora<br>2) EPEL for Red Hat Enterprise Linux and Others<br>3) RPMS for R Packages<br>4) Creating your own R package RPMS</p>\n<h1 id=\"h1-1-fedora\"><a name=\"1) Fedora\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1) Fedora</h1><p>R packages for Fedora Linux are maintained and distributed by Red Hat<br>Software. Fedora users can install R with yum from the standard Fedora<br>repository using</p>\n<p>sudo yum install R</p>\n<p>The RPM ‘R’ is a meta package. It has no content but ensures that the<br>following components are installed</p>\n<p>R-core           User RPM<br>R-core-devel   Developer RPM containing header files<br>R-java           RPM to ensure that R is configured for use with Java<br>libRmath       Standalone R math library<br>libRmath-devel Header file for the standalone R math library</p>\n<p>It is standard practice to divide RPMs into “user” and “developer”<br>versions. In the case of R on Fedora, these are provided by the<br>‘R-core’ and ‘R-core-devel’ RPMs. However, almost all R users on<br>Fedora will need ‘R-core-devel’ in order to install R packages from<br>source. Therefore it is recommended to install the meta-package ‘R’.</p>\n<p>2) Red Hat Enterprise Linux (RHEL)<br>   CentOS<br>   Scientific Linux</p>\n<h1 id=\"h1-oracle-linux\"><a name=\"Oracle Linux\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>   Oracle Linux</h1><p>The Fedora RPMs for R have been ported to RHEL by the project Extra<br>Packages for Enterprise Linux (EPEL).</p>\n<p><a href=\"http://fedoraproject.org/wiki/EPEL\">http://fedoraproject.org/wiki/EPEL</a> </p>\n<p>These RPMs are also compatible with distributions derived from RHEL.</p>\n<p>To use the EPEL repository, it is sufficient to download and install<br>the appropriate “epel-release” RPM, as described in the EPEL FAQ:</p>\n<p><a href=\"https://fedoraproject.org/wiki/EPEL/FAQ#How_can_I_install_the_packages_from_the_EPEL_software_repository.3F\">https://fedoraproject.org/wiki/EPEL/FAQ#How_can_I_install_the_packages_from_the_EPEL_software_repository.3F</a></p>\n<p>Then R can be installed as described above in the section on Fedora.</p>\n<pre><code>For EL6:\nsu -c &#39;rpm -Uvh https://download.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm&#39;\nsu -c &#39;yum install foo&#39;\n\nFor EL7:\nsu -c &#39;rpm -Uvh https://download.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm&#39;\nsu -c &#39;yum install foo&#39;\n</code></pre><h1 id=\"h1-3-r-packages\"><a name=\"3) R packages\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3) R packages</h1><p>Fedora provies a selection of R packages as RPMs. A more limited<br>selection of these packages has been ported to EPEL. The RPM name is<br>derived from the R package name by adding the prefix “R-“. Hence all<br>R-related RPMS can be listed with the yum command</p>\n<p>yum list R-*</p>\n<p>The listing below shows all RPMS available for R packages on Fedora<br>20, classified by the R repository that would normally be used to<br>install the package from within R (See the help page ?chooseRepositories).</p>\n<p>$CRAN<br> [1] “R-abind”      “R-acepack”    “R-biglm”      “R-bigmemory”  “R-bitops”<br> [6] “R-car”        “R-caTools”    “R-combinat”   “R-DBI”        “R-lmtest”<br>[11] “R-mAr”        “R-msm”        “R-multcomp”   “R-mvtnorm”    “R-nws”<br>[16] “R-pls”        “R-qcc”        “R-qtl”        “R-RCurl”      “R-rlecuyer”<br>[21] “R-RM2”        “R-RODBC”      “R-RSQLite”    “R-RUnit”      “R-sandwich”<br>[26] “R-sciplot”    “R-statmod”    “R-systemfit”  “R-timeDate”   “R-waveslim”<br>[31] “R-wavethresh” “R-XML”        “R-xtable”     “R-zoo”       </p>\n<p>$<code>BioC software</code><br> [1] “R-affy”                  “R-affyio”<br> [3] “R-AnnotationDbi”         “R-Biobase”<br> [5] “R-BiocGenerics”          “R-biomaRt”<br> [7] “R-Biostrings”            “R-BSgenome”<br> [9] “R-BufferedMatrix”        “R-BufferedMatrixMethods”<br>[11] “R-DynDoc”                “R-GenomicFeatures”<br>[13] “R-GenomicRanges”         “R-IRanges”<br>[15] “R-maanova”               “R-multtest”<br>[17] “R-preprocessCore”        “R-qvalue”<br>[19] “R-ROC”                   “R-Rsamtools”<br>[21] “R-rtracklayer”           “R-tkWidgets”<br>[23] “R-widgetTools”          </p>\n<p>$<code>BioC annotation</code><br>[1] “R-hgu133acdf”    “R-hgu95av2cdf”   “R-hgu95av2probe”</p>\n<p>$<code>BioC experiment</code><br>[1] “R-affydata”  “R-ALL”       “R-fibroEset”</p>\n<p>$<code>BioC extra</code><br>[1] “R-RCurl”</p>\n<p>$Omegahat<br>[1] “R-Rcompression” “R-RCurl”        “R-XML”         </p>\n<p>$<code>R-Forge</code><br>[1] “R-abind”     “R-bigmemory” “R-car”       “R-msm”       “R-multcomp”<br>[6] “R-mvtnorm”   “R-timeDate”  “R-waveslim”  “R-xtable”   </p>\n<p>$Other<br>[1] “R-GeneR”      “R-RScaLAPACK” “R-Rsolid”     “R-hdf5”      </p>\n<p>Note that the classification is not mutually exclusive (e.g. R-RCurl<br>appears several times) and that Fedora provides RPMs that are not<br>available from any standard R repository. These are listed under<br>“Other”.</p>\n<p>The above listing is created by the following utility function, which<br>may be freely used, redistributed and modified without restriction.</p>\n<p>classify.rpms &lt;- function()<br>{</p>\n<pre><code>## Get a list of R packages available via yum\npkg &lt;- system(&quot;yum list -q R-\\\\*&quot;, intern=TRUE)\npkg &lt;- sub(pattern=&quot;\\\\..+$&quot;, replacement=&quot;&quot;, pkg)\npkg &lt;- pkg[grep(&quot;-devel$&quot;, pkg, invert=TRUE)] #no devel packages\npkg &lt;- pkg[grep(&quot;-debuginfo$&quot;, pkg, invert=TRUE)] #no debug packages\npkg &lt;- setdiff(pkg, c(&quot;R&quot;, &quot;R-core&quot;, &quot;R-java&quot;,\n                      &quot;Installed Packages&quot;,\n                      &quot;Available Packages&quot;))\npkg &lt;- unique(pkg)\n\n## Get the database of standard repositories\np &lt;- file.path(R.home(&quot;etc&quot;), &quot;repositories&quot;)\nreps &lt;- read.table(p, header=TRUE, sep=&quot;\\t&quot;)\nout &lt;- vector(&quot;list&quot;, nrow(reps))\nnames(out) &lt;- reps$menu_name\nfor (i in seq_along(out)) {\n    ## Match repositories to available yum packages\n    setRepositories(ind=i)\n    av &lt;- paste(&quot;R&quot;, available.packages()[,&quot;Package&quot;], sep=&quot;-&quot;)\n    out[[i]] &lt;- intersect(av, pkg)\n}\nsetRepositories(ind=1) #Set default repository to CRAN\nout$Other &lt;- setdiff(pkg, unlist(out)) #unclassified packages\nout[sapply(out, length) &gt; 0] #remove empty categories\n</code></pre><p>}</p>\n<h1 id=\"h1-4-creating-your-own-r-package-rpms\"><a name=\"4) Creating your own R package RPMs\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4) Creating your own R package RPMs</h1><p>Both Fedora and EPEL provide the R2spec package, which may be used<br>to create your own R package RPMs. See <a href=\"https://fedorahosted.org/r2spec/\">https://fedorahosted.org/r2spec/</a></p>\n<h1 id=\"h1-5-r\"><a name=\"5)安装R\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5)安装R </h1><p>CentOS7安装大部分软件的方法</p>\n<pre><code>sudo yum install R\n</code></pre><h1 id=\"h1-6-r-studio-server\"><a name=\"6)安装R Studio Server\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6)安装R Studio Server</h1><p>R Studio Server 安装官方文档 [ Download RStudio Server ]</p>\n<p>64Bit</p>\n<pre><code>wget https://download2.rstudio.org/rstudio-server-rhel-1.1.383-x86_64.rpm\nsudo yum install --nogpgcheck rstudio-server-rhel-1.1.383-x86_64.rpm\n</code></pre><p>R Studio Server就安装好了。访问服务器地址：http://&lt;server-ip&gt;:8787<br>新建用户 root用户无法登陆，新建一个用户进行登陆</p>\n<pre><code>useradd -d /home/R -m R，创建用户的同时指定主目录\npasswd R，设置密码\n\nR中实现脚本调用，以及函数调用\n</code></pre><h1 id=\"h1-6-r-\"><a name=\"6)运行R测试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6)运行R测试</h1><p>安装依赖环境</p>\n<pre><code>yum install mariadb-connector-c-devel  mariadb-devel \n</code></pre><p>安装数据库连接</p>\n<pre><code>install.packages(&#39;DBI&#39;)\ninstall.packages(&#39;RMySQL&#39;)\n</code></pre><p>这里的列子是test.R调用mysql_con.R中的函数</p>\n<p>mysql_con.R<br>复制代码</p>\n<pre><code># 使用RMySQL操作数据库\n# 载入DBI和RMySQL包\nlibrary(&#39;DBI&#39;)\nlibrary(&#39;RMySQL&#39;)\n\nmysql_con &lt;- function(sql){\n\n  # 创建数据库连接\n  con &lt;- dbConnect(MySQL(),host =&quot;localhost&quot;,port=3307,dbname=&quot;cars&quot;,user=&quot;root&quot;,password=&quot;123456&quot;)\n  #说明用什么字符集来获取数据库字段\n  dbGetQuery(con, &quot;SET NAMES gbk&quot;)\n  #dbSendQuery(con, &quot;SET NAMES gbk&quot;); \n\n  # 验证连接\n  #print(summary(con)) \n\n  # SQL查询\n  results &lt;- dbGetQuery(con,sql)\n\n  #断开连接\n  dbDisconnect(con) \n  return(results)\n}\n</code></pre><p>复制代码</p>\n<p>test.R</p>\n<h1 id=\"h1-u5F15u5165u811Au672Cu6587u4EF6\"><a name=\"引入脚本文件\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>引入脚本文件</h1><pre><code>source(&#39;E:/workspace/RStudio/codeSpace/cars/Helper/mysql_con.R&#39;, encoding = &#39;UTF-8&#39;)\nprint(mysql_con(&quot;select count(*) from discretized_data&quot;))\n</code></pre><h1 id=\"h1--xxl-jobs-\"><a name=\"整合到XXL-JOBS中\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>整合到XXL-JOBS中</h1><pre><code>#!/bin/bash\necho &quot;xxl-job: hello shell&quot;\n\necho &quot;脚本位置：$0&quot;\necho &quot;任务参数：$1&quot;\necho &quot;分片序号 = $2&quot;\necho &quot;分片总数 = $3&quot;\n\necho &quot;&quot;&quot;\nlibrary(&#39;DBI&#39;)\nlibrary(&#39;RMySQL&#39;)\n\nmysql_con &lt;- function(sql){\n  con &lt;- dbConnect(MySQL(),host =\\&quot;192.168.0.83\\&quot;,port =3307,dbname=\\&quot;test\\&quot;,user=\\&quot;root\\&quot;,password=\\&quot;\\&quot;)\n  dbGetQuery(con, \\&quot;SET NAMES utf8\\&quot;)\n  print(summary(con))\n  results &lt;- dbGetQuery(con,sql)\n  dbDisconnect(con)\n  return(results)\n}\n\nprint(mysql_con(\\&quot;SELECT * FROM test.tob_count02\\&quot;))\n\n&quot;&quot;&quot; &gt; /opt/sql.r\n\nR --save &lt; /opt/sql.r &gt; /opt/sql.log\n\necho &quot;Good bye!&quot;\nexit 0\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('77', '0', 'Davinci 是一个 DVAAS（Data Visualization as a Service）平台解决方案', '8', '2019-01-24 13:54:58', '1平台介绍Davinci是一个DVAAS（DataVisualizationasaService）平台解决方案，面向业务人员/数据工程师/数据分析师/数据科学家，致力于提供一站式数据可视化解决方案。既可作为公有云/私有云独立部署使用，也可作为可视化插件集成到三方系统。用户只需在可视化UI上简单配置即可服务多种数据可视化应用，并支持高级交互/行业分析/模式探索/社交智能等可视化功能。2模块架构ove', null, '0', '51', null, null, '2019-01-24 13:54:58', '2019-01-24 16:05:38', null, null, '0', '0', '0', '0', '1 平台介绍\n=======================\nDavinci 是一个 DVAAS（Data Visualization as a Service）平台解决方案，面向业务人员/数据工程师/数据分析师/数据科学家，致力于提供一站式数据可视化解决方案。既可作为公有云/私有云独立部署使用，也可作为可视化插件集成到三方系统。用户只需在可视化 UI 上简单配置即可服务多种数据可视化应用，并支持高级交互/行业分析/模式探索/社交智能等可视化功能。\n2 模块架构\n\noverview_architecture\n3 设计理念\n====================\n围绕 View（数据视图）与 Widget（可视组件）两个核心概念设计\nView 是数据的结构化形态，一切逻辑/权限/服务等相关都是从 View 展开。\nWidget 是数据的可视化形态，一切展示/交互/引导等都是从 Widget 展开。\n作为数据的两种不同形态，二者相辅相成，让用户拥有一致的体验和认识。\n\n强化集成定制能力和智能社交能力\n集成定制能力指无缝集成到三方系统，并提供强大的定制化能力，使其和三方系统融为一体。\n社交智能能力指共享优秀的数据可视化思想，激发用户对数据可视化表达能力和艺术美感的追求，同时也使 Davinci 更加智能的引导和提高用户的数据可视化能力。\n在数据可视化领域里，Davinci 重视基础的交互能力和多种多样的图表选择能力，同时更加重视集成定制能力和社交智能能力。\n\n4 功能特点\n==================\n    数据源\n        支持多种 JDBC 数据源\n        支持 CSV 数据文件上传\n\n    数据模型\n        支持友好 SQL 编辑器进行数据处理和转换\n        支持自动和自定义数据模型设计和共享\n\n    可视化组件\n        支持基于数据模型拖拽智能生成可视化组件\n        支持各种可视化组件样式配置\n        支持自由分析能力\n\n    数据门户\n        支持基于可视化组件创建可视化仪表板\n        支持可视化组件自动布局\n        支持可视化组件全屏显示、本地控制器、高级过滤器、组件间联动、群控控制器可视组件\n        支持可视化组件大数据量展示分页和滑块\n        支持可视化组件 CSV 数据下载、公共分享授权分享以及可视化仪表板的公共分享和授权分享\n        支持基于可视化仪表板创建数据门户\n\n    数据大屏\n        支持可视化组件自由布局\n        支持图层、透明度设置、边框、背景色、对齐、标签等更丰富大屏美化功能\n        支持多种屏幕自适应方式\n\n    用户体系\n        支持多租户用户体系\n        支持每个用户自建一整套组织架构层级结构\n        支持浅社交能力\n\n    安全权限\n        支持 LDAP 登录认证\n        支持动态 Token 鉴权\n        支持细粒度操作权限矩阵配置\n        支持数据列权限、行权限\n\n    集成能力\n        支持安全 URL 嵌入式集成\n        支持 JS 融入式集成\n\n    多屏适应\n        支持大屏、PC、Pad、手机移动端等多屏自适应\n\n5 场景支持\n---------------\n    安全多样自助交互式报表\n\n    一次配置即可实现可视组件高级过滤、高级控制、联动、钻取、下载、分享等，帮助业务人员快速完成对比、地理分析、分布、趋势以及聚类等分析和决策。\n\n    自动布局的 Dashboard（仪表板），适用于大多数通过快速配置即可查看和分享的可视化报表。\n\n    自由布局的 Display（大屏），适用于一些特定的、需要添加额外修饰元素的、长时间查看的场景，通常配置这类场景需要花一定的时间和精力，如“双11”大屏。\n\n    实时运营监控\n\n    实时观察运营状态，衔接各个环节流程，对比检测异常情况，处理关键环节问题。\n\n    透视驱动与图表驱动两种图表配置模式，满足不同的应用场景需求。\n\n    快速集成\n\n    分享链接、IFRAME 或调用开发接口，方便快捷地集成到三方系统，并能够支撑二次开发与功能拓展，充分适应不同业务人员的个性化需求，快速打造属于自己的数据可视化平台。\n\n6 Davinci 0.3 与 0.2 的区别\n====================\n五个重大变化\n----------\n    打通了数据可视化全流程协作模式\n    打通了用户体系和权限体系\n    打通了数据模型和自由分析\n    打通了透视驱动模式和图表驱动模式配置可视化组件\n    打通了自动布局和自由布局支持各种可视化应用\n\n在功能上具体的变化\n====================\n    全新协作流程\n\n    多出“项目”的概念，Davinci 0.2 的 Source、View、Widget、Dashboard、Schedule 都从属于一个“项目”，Dashboard 这一层命名为“数据应用”，Dashboard 属于“数据应用”里其中的一种。\n\n    全新用户系统\n\n    在 Davinci 0.2 中，用户权限围绕超级管理员和普通用户展开。Davinci 0.3 里用户角色不再分管理员和普通用户，每个用户都是平级的，都可以创建组织和团队，组织和团队拥有对项目进行浏览、添加、修改、删除、点赞以及收藏等操作权限，组织可以转交拥有者，团队可以转交维护者。通过这个系统既能完全实现用户权限控制，同时又拥有了社交化。\n\n    数据模型与自由分析\n\n    对于用户配置好的数据视图，Davinci 0.3 可以为其自动生成数据模型，数据模型里将字段分作“维度”和“指标”两种类型，用户也可以手动指定维度和指标。在 Widget 内支持用户对指定的维度进行自由钻取，方便用户进行数据探索分析工作。\n\n    全新 Widget 编辑器\n\n    在 Davinci 0.3 中，用户通过预先配置好的数据模型，在 Widget 编辑器中可以选择想要显示的维度和指标，编辑器自动推荐出适合用来可视化的图形。可以通过颜色对字段进行分组编码。\n\n    全新数据应用 Display\n\n    在 Davinci 0.3 中，数据应用里除了包含之前的 Dashboard 外，还多了 Display。Display 支持用户将 Widget 以自定义布局和背景的方式放置到画布中，同时 Display 本身也支持自定义尺寸和背景，在多种搭配之下用户可以自己打造多样化的可视化应用。\n	\n文档地址\n--------------------\nhttps://legacy.gitbook.com/download/pdf/book/edp-davinci/davinci-user-guide-cn\n', '1', '<h1 id=\"h1-1-\"><a name=\"1 平台介绍\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1 平台介绍</h1><p>Davinci 是一个 DVAAS（Data Visualization as a Service）平台解决方案，面向业务人员/数据工程师/数据分析师/数据科学家，致力于提供一站式数据可视化解决方案。既可作为公有云/私有云独立部署使用，也可作为可视化插件集成到三方系统。用户只需在可视化 UI 上简单配置即可服务多种数据可视化应用，并支持高级交互/行业分析/模式探索/社交智能等可视化功能。<br>2 模块架构</p>\n<p>overview_architecture</p>\n<h1 id=\"h1-3-\"><a name=\"3 设计理念\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3 设计理念</h1><p>围绕 View（数据视图）与 Widget（可视组件）两个核心概念设计<br>View 是数据的结构化形态，一切逻辑/权限/服务等相关都是从 View 展开。<br>Widget 是数据的可视化形态，一切展示/交互/引导等都是从 Widget 展开。<br>作为数据的两种不同形态，二者相辅相成，让用户拥有一致的体验和认识。</p>\n<p>强化集成定制能力和智能社交能力<br>集成定制能力指无缝集成到三方系统，并提供强大的定制化能力，使其和三方系统融为一体。<br>社交智能能力指共享优秀的数据可视化思想，激发用户对数据可视化表达能力和艺术美感的追求，同时也使 Davinci 更加智能的引导和提高用户的数据可视化能力。<br>在数据可视化领域里，Davinci 重视基础的交互能力和多种多样的图表选择能力，同时更加重视集成定制能力和社交智能能力。</p>\n<h1 id=\"h1-4-\"><a name=\"4 功能特点\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4 功能特点</h1><pre><code>数据源\n    支持多种 JDBC 数据源\n    支持 CSV 数据文件上传\n\n数据模型\n    支持友好 SQL 编辑器进行数据处理和转换\n    支持自动和自定义数据模型设计和共享\n\n可视化组件\n    支持基于数据模型拖拽智能生成可视化组件\n    支持各种可视化组件样式配置\n    支持自由分析能力\n\n数据门户\n    支持基于可视化组件创建可视化仪表板\n    支持可视化组件自动布局\n    支持可视化组件全屏显示、本地控制器、高级过滤器、组件间联动、群控控制器可视组件\n    支持可视化组件大数据量展示分页和滑块\n    支持可视化组件 CSV 数据下载、公共分享授权分享以及可视化仪表板的公共分享和授权分享\n    支持基于可视化仪表板创建数据门户\n\n数据大屏\n    支持可视化组件自由布局\n    支持图层、透明度设置、边框、背景色、对齐、标签等更丰富大屏美化功能\n    支持多种屏幕自适应方式\n\n用户体系\n    支持多租户用户体系\n    支持每个用户自建一整套组织架构层级结构\n    支持浅社交能力\n\n安全权限\n    支持 LDAP 登录认证\n    支持动态 Token 鉴权\n    支持细粒度操作权限矩阵配置\n    支持数据列权限、行权限\n\n集成能力\n    支持安全 URL 嵌入式集成\n    支持 JS 融入式集成\n\n多屏适应\n    支持大屏、PC、Pad、手机移动端等多屏自适应\n</code></pre><h2 id=\"h2-5-\"><a name=\"5 场景支持\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5 场景支持</h2><pre><code>安全多样自助交互式报表\n\n一次配置即可实现可视组件高级过滤、高级控制、联动、钻取、下载、分享等，帮助业务人员快速完成对比、地理分析、分布、趋势以及聚类等分析和决策。\n\n自动布局的 Dashboard（仪表板），适用于大多数通过快速配置即可查看和分享的可视化报表。\n\n自由布局的 Display（大屏），适用于一些特定的、需要添加额外修饰元素的、长时间查看的场景，通常配置这类场景需要花一定的时间和精力，如“双11”大屏。\n\n实时运营监控\n\n实时观察运营状态，衔接各个环节流程，对比检测异常情况，处理关键环节问题。\n\n透视驱动与图表驱动两种图表配置模式，满足不同的应用场景需求。\n\n快速集成\n\n分享链接、IFRAME 或调用开发接口，方便快捷地集成到三方系统，并能够支撑二次开发与功能拓展，充分适应不同业务人员的个性化需求，快速打造属于自己的数据可视化平台。\n</code></pre><h1 id=\"h1-6-davinci-0-3-0-2-\"><a name=\"6 Davinci 0.3 与 0.2 的区别\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>6 Davinci 0.3 与 0.2 的区别</h1><h2 id=\"h2-u4E94u4E2Au91CDu5927u53D8u5316\"><a name=\"五个重大变化\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>五个重大变化</h2><pre><code>打通了数据可视化全流程协作模式\n打通了用户体系和权限体系\n打通了数据模型和自由分析\n打通了透视驱动模式和图表驱动模式配置可视化组件\n打通了自动布局和自由布局支持各种可视化应用\n</code></pre><h1 id=\"h1-u5728u529Fu80FDu4E0Au5177u4F53u7684u53D8u5316\"><a name=\"在功能上具体的变化\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在功能上具体的变化</h1><pre><code>全新协作流程\n\n多出“项目”的概念，Davinci 0.2 的 Source、View、Widget、Dashboard、Schedule 都从属于一个“项目”，Dashboard 这一层命名为“数据应用”，Dashboard 属于“数据应用”里其中的一种。\n\n全新用户系统\n\n在 Davinci 0.2 中，用户权限围绕超级管理员和普通用户展开。Davinci 0.3 里用户角色不再分管理员和普通用户，每个用户都是平级的，都可以创建组织和团队，组织和团队拥有对项目进行浏览、添加、修改、删除、点赞以及收藏等操作权限，组织可以转交拥有者，团队可以转交维护者。通过这个系统既能完全实现用户权限控制，同时又拥有了社交化。\n\n数据模型与自由分析\n\n对于用户配置好的数据视图，Davinci 0.3 可以为其自动生成数据模型，数据模型里将字段分作“维度”和“指标”两种类型，用户也可以手动指定维度和指标。在 Widget 内支持用户对指定的维度进行自由钻取，方便用户进行数据探索分析工作。\n\n全新 Widget 编辑器\n\n在 Davinci 0.3 中，用户通过预先配置好的数据模型，在 Widget 编辑器中可以选择想要显示的维度和指标，编辑器自动推荐出适合用来可视化的图形。可以通过颜色对字段进行分组编码。\n\n全新数据应用 Display\n\n在 Davinci 0.3 中，数据应用里除了包含之前的 Dashboard 外，还多了 Display。Display 支持用户将 Widget 以自定义布局和背景的方式放置到画布中，同时 Display 本身也支持自定义尺寸和背景，在多种搭配之下用户可以自己打造多样化的可视化应用。\n</code></pre><h2 id=\"h2-u6587u6863u5730u5740\"><a name=\"文档地址\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>文档地址</h2><p><a href=\"https://legacy.gitbook.com/download/pdf/book/edp-davinci/davinci-user-guide-cn\">https://legacy.gitbook.com/download/pdf/book/edp-davinci/davinci-user-guide-cn</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('78', '0', 'MySQL 通用命令 导入和导出', '8', '2019-01-24 16:54:57', '1.mysql命令导出-------------------导出SQL格式的数据导出SQL格式的数据到指定文件，如下所示：$mysqldump-uroot-pRUNOOBrunoob_tbl>dump.txtpassword******2、mysql命令导入--------------------------使用mysql命令导入语法格式为：mysql-u用户名-p密码<要导入的数据库数据(run', null, '0', '36', null, null, '2019-01-24 16:54:57', '2019-01-24 16:55:51', null, null, '0', '0', '0', '0', '1.mysql 命令导出\n-------------------\n导出 SQL 格式的数据\n导出 SQL 格式的数据到指定文件，如下所示：\n$ mysqldump -u root -p RUNOOB runoob_tbl > dump.txt\npassword ******\n\n2、mysql 命令导入\n--------------------------\n使用 mysql 命令导入语法格式为：\n\n	mysql -u用户名    -p密码    <  要导入的数据库数据(runoob.sql)\n	实例:\n	mysql -uroot -p123456 < runoob.sql\n\n2、source 命令导入\n\nsource 命令导入数据库需要先登录到数库终端：\n\n	mysql> create database abc;      # 创建数据库\n	mysql> use abc;                  # 使用已创建的数据库 \n	mysql> set names utf8;           # 设置编码\n	mysql> source /home/abc/abc.sql  # 导入备份数据库\n\n参考：\nhttp://www.runoob.com/mysql/mysql-database-export.html\nhttp://www.runoob.com/mysql/mysql-database-import.html\n', '0', '<h2 id=\"h2-1-mysql-\"><a name=\"1.mysql 命令导出\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.mysql 命令导出</h2><p>导出 SQL 格式的数据<br>导出 SQL 格式的数据到指定文件，如下所示：<br>$ mysqldump -u root -p RUNOOB runoob_tbl &gt; dump.txt<br>password <strong>**</strong></p>\n<h2 id=\"h2-2-mysql-\"><a name=\"2、mysql 命令导入\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2、mysql 命令导入</h2><p>使用 mysql 命令导入语法格式为：</p>\n<pre><code>mysql -u用户名    -p密码    &lt;  要导入的数据库数据(runoob.sql)\n实例:\nmysql -uroot -p123456 &lt; runoob.sql\n</code></pre><p>2、source 命令导入</p>\n<p>source 命令导入数据库需要先登录到数库终端：</p>\n<pre><code>mysql&gt; create database abc;      # 创建数据库\nmysql&gt; use abc;                  # 使用已创建的数据库 \nmysql&gt; set names utf8;           # 设置编码\nmysql&gt; source /home/abc/abc.sql  # 导入备份数据库\n</code></pre><p>参考：<br><a href=\"http://www.runoob.com/mysql/mysql-database-export.html\">http://www.runoob.com/mysql/mysql-database-export.html</a><br><a href=\"http://www.runoob.com/mysql/mysql-database-import.html\">http://www.runoob.com/mysql/mysql-database-import.html</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('79', '0', 'Wormhole 是一个一站式流式处理云平台解决方案（SPaaS - Stream Processing as a Service）', '8', '2019-01-24 17:43:46', '![](https://github.com/edp963/wormhole/raw/master/docs/img/wormhole-logo.png)[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)[', null, '0', '67', null, null, '2019-01-24 17:43:46', '2019-01-24 17:46:43', 'https://github.com/edp963/edp-resource/raw/master/WeChat.jpg', null, '0', '0', '0', '0', '![](https://github.com/edp963/wormhole/raw/master/docs/img/wormhole-logo.png)\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![Build Status](https://travis-ci.org/edp963/wormhole.svg?branch=master)](https://travis-ci.org/edp963/wormhole)\n[![Coverage Status](https://coveralls.io/repos/github/edp963/wormhole/badge.svg)](https://coveralls.io/github/edp963/wormhole)\n\n## Wormhole\n\n> 来自[宜信](https://www.creditease.cn/)[技术研发中心](http://crdc.creditease.cn/)的流式处理平台\n\n**Wormhole 是一个一站式流式处理云平台解决方案（SPaaS - Stream Processing as a Service）。**\n\nWormhole 面向大数据流式处理项目的开发管理运维人员，致力于提供统一抽象的概念体系，直观可视化的操作界面，简单流畅的配置管理流程，基于 SQL 即可完成的业务逻辑开发方式，并且屏蔽了流式处理的底层技术细节，极大的降低了数据项目管理运维门槛，使得大数据流式处理项目的开发管理运维变得更加轻量敏捷可控可靠。\n\n## Documentation\n\nPlease refer to [Wormhole用户手册](https://edp963.github.io/wormhole).\n\n\n## Architecture\n![](https://github.com/edp963/wormhole/raw/master/docs/img/wh4_pipeline_overview.png)\n\n\n### 设计理念\n\n- **统一 DAG 高阶分形抽象**\n  - 构建由 Source DataSys，Kafka Topic，Spark Stream（Flink Stream），Sink DataSys 组成的物理 DAG\n  - 每个物理 DAG 里可以并行处理多个由 Source Namespace，Flow，Sink Namespace 组成的逻辑 DAG\n  - 每个 Flow 本身是典型的 Spark RDD DAG\n- **统一通用流消息 UMS 协议抽象**\n  - UMS 是 Wormhole 定义的流消息协议规范\n  - UMS 试图抽象统一所有结构化消息\n  - UMS 自身携带结构化数据 Schema 信息\n  - Wh4 支持用户自定义半结构化 JSON 格式\n- **统一数据逻辑表命名空间 Namespace 抽象**\n  - Namespace 唯一定位所有数据存储所有结构化逻辑表\n  - [Data System].[Instance].[Database].[Table].[Table Version].[Database Partition].[Table Partition]\n\n### 主要特性\n\n- **支持可视化，配置化，SQL 化开发实施流式项目**\n- **支持指令式动态流式处理的管理，运维，诊断和监控**\n- **支持统一结构化 UMS 消息和自定义半结构化 JSON 消息**\n- **支持处理增删改三态事件消息流**\n- **支持单个物理流同时并行处理多个逻辑业务流**\n- **支持流上 Lookup Anywhere，Pushdown Anywhere**\n- **支持基于业务策略的事件时间戳流式处理**\n- **支持UDF的注册管理和动态加载**\n- **支持多目标数据系统的并发幂等入库**\n- **支持多级基于增量消息的数据质量管理**\n- **支持基于增量消息的流式处理和批量处理**\n- **支持 Lambda 架构和 Kappa 架构**\n- **支持与三方系统无缝集成，可作为三方系统的流控引擎**\n- **支持私有云部署，安全权限管控和多租户资源管理**\n\n## Experience\n\n#### Admin 可以创建 Project/Namespace/User/UDF，并且可以查看所有 Flow/Stream/Job\n![](https://github.com/edp963/wormhole/raw/master/docs/img/admin_1.png)\n\n\n#### Admin 可以为 Project 分配 Namespace 资源/User 资源/UDF 资源/计算资源，以支持多租户资源隔离\n![](https://github.com/edp963/wormhole/raw/master/docs/img/admin_2.png)\n\n\n#### User 可以对自己有权限的 Project 进行开发实施和管理运维工作\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_1_project.png)\n\n\n#### User 可以通过简单配置步骤即可搭建起一个流式作业 pipeline（Flow），只需关注数据从哪来到哪去和如何转换处理\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_2_flow_1.png)\n\n\n#### 转换支持大部分流上作业常用场景，大部分工作可以通过配置 SQL 实现流上处理逻辑\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_2_flow_2.png)\n\n#### Wormhole 有 Flow 和 Stream 的概念，支持在一个物理 Stream（对应一个 Spark Stream）里通过并行处理多个逻辑 Flow，使得 User 可以更加精细灵活的利用计算资源，User 也可以对 Stream 进行精细化参数配置调整以更好平衡需求和资源\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_3_stream.png)\n\n\n#### Wormhole 也支持批处理 Job，同样可以配置化实现处理逻辑并落到多个异构 Sink，Flow 和 Job 的配合可以很容易实现 Lambda 架构和 Kappa架构\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_4_job_1.png)\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_4_job_2.png)\n\n\n#### User 可以查看 Project 相关的 Namespace/User/UDF/Resource\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_5_ns.png)\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_5_user.png)\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_6_udf.png)\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_7_res.png)\n\n#### User还可以监控 Project 正在运行的所有 Flow/Stream 的吞吐和延迟\n![](https://github.com/edp963/wormhole/raw/master/docs/img/user_8_mon.png)\n\n#### 以上是简短的功能和用户体验预览，更多强大的细节功能请参见 Documentation\n\n## Latest Release\n\nPlease download the latest RELEASE(链接：https://pan.baidu.com/s/1JYRJoaPy6E3u8VqGas0neg 提取码：yzgc).\n\n## Get Help\n\n- **Mailing list**: edp_support@groups.163.com\n- **WeChat**: edpstack <img src=\"https://github.com/edp963/edp-resource/raw/master/WeChat.jpg\" alt=\"\" width=\"100\"/>\n\n## License\n\nWormhole is under the Apache 2.0 license. See the [LICENSE](https://github.com/edp963/wormhole/blob/master/LICENSE) file for details.\n', '1', '<p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/wormhole-logo.png\" alt=\"\"></p>\n<p><a href=\"https://www.apache.org/licenses/LICENSE-2.0.html\"><img src=\"https://img.shields.io/badge/license-Apache%202-4EB1BA.svg\" alt=\"License\"></a><br><a href=\"https://travis-ci.org/edp963/wormhole\"><img src=\"https://travis-ci.org/edp963/wormhole.svg?branch=master\" alt=\"Build Status\"></a><br><a href=\"https://coveralls.io/github/edp963/wormhole\"><img src=\"https://coveralls.io/repos/github/edp963/wormhole/badge.svg\" alt=\"Coverage Status\"></a></p>\n<h2 id=\"h2-wormhole\"><a name=\"Wormhole\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Wormhole</h2><blockquote>\n<p>来自<a href=\"https://www.creditease.cn/\">宜信</a><a href=\"http://crdc.creditease.cn/\">技术研发中心</a>的流式处理平台</p>\n</blockquote>\n<p><strong>Wormhole 是一个一站式流式处理云平台解决方案（SPaaS - Stream Processing as a Service）。</strong></p>\n<p>Wormhole 面向大数据流式处理项目的开发管理运维人员，致力于提供统一抽象的概念体系，直观可视化的操作界面，简单流畅的配置管理流程，基于 SQL 即可完成的业务逻辑开发方式，并且屏蔽了流式处理的底层技术细节，极大的降低了数据项目管理运维门槛，使得大数据流式处理项目的开发管理运维变得更加轻量敏捷可控可靠。</p>\n<h2 id=\"h2-documentation\"><a name=\"Documentation\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Documentation</h2><p>Please refer to <a href=\"https://edp963.github.io/wormhole\">Wormhole用户手册</a>.</p>\n<h2 id=\"h2-architecture\"><a name=\"Architecture\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Architecture</h2><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/wh4_pipeline_overview.png\" alt=\"\"></p>\n<h3 id=\"h3-u8BBEu8BA1u7406u5FF5\"><a name=\"设计理念\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>设计理念</h3><ul>\n<li><strong>统一 DAG 高阶分形抽象</strong><ul>\n<li>构建由 Source DataSys，Kafka Topic，Spark Stream（Flink Stream），Sink DataSys 组成的物理 DAG</li><li>每个物理 DAG 里可以并行处理多个由 Source Namespace，Flow，Sink Namespace 组成的逻辑 DAG</li><li>每个 Flow 本身是典型的 Spark RDD DAG</li></ul>\n</li><li><strong>统一通用流消息 UMS 协议抽象</strong><ul>\n<li>UMS 是 Wormhole 定义的流消息协议规范</li><li>UMS 试图抽象统一所有结构化消息</li><li>UMS 自身携带结构化数据 Schema 信息</li><li>Wh4 支持用户自定义半结构化 JSON 格式</li></ul>\n</li><li><strong>统一数据逻辑表命名空间 Namespace 抽象</strong><ul>\n<li>Namespace 唯一定位所有数据存储所有结构化逻辑表</li><li>[Data System].[Instance].[Database].[Table].[Table Version].[Database Partition].[Table Partition]</li></ul>\n</li></ul>\n<h3 id=\"h3-u4E3Bu8981u7279u6027\"><a name=\"主要特性\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>主要特性</h3><ul>\n<li><strong>支持可视化，配置化，SQL 化开发实施流式项目</strong></li><li><strong>支持指令式动态流式处理的管理，运维，诊断和监控</strong></li><li><strong>支持统一结构化 UMS 消息和自定义半结构化 JSON 消息</strong></li><li><strong>支持处理增删改三态事件消息流</strong></li><li><strong>支持单个物理流同时并行处理多个逻辑业务流</strong></li><li><strong>支持流上 Lookup Anywhere，Pushdown Anywhere</strong></li><li><strong>支持基于业务策略的事件时间戳流式处理</strong></li><li><strong>支持UDF的注册管理和动态加载</strong></li><li><strong>支持多目标数据系统的并发幂等入库</strong></li><li><strong>支持多级基于增量消息的数据质量管理</strong></li><li><strong>支持基于增量消息的流式处理和批量处理</strong></li><li><strong>支持 Lambda 架构和 Kappa 架构</strong></li><li><strong>支持与三方系统无缝集成，可作为三方系统的流控引擎</strong></li><li><strong>支持私有云部署，安全权限管控和多租户资源管理</strong></li></ul>\n<h2 id=\"h2-experience\"><a name=\"Experience\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Experience</h2><h4 id=\"h4-admin-project-namespace-user-udf-flow-stream-job\"><a name=\"Admin 可以创建 Project/Namespace/User/UDF，并且可以查看所有 Flow/Stream/Job\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Admin 可以创建 Project/Namespace/User/UDF，并且可以查看所有 Flow/Stream/Job</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/admin_1.png\" alt=\"\"></p>\n<h4 id=\"h4-admin-project-namespace-user-udf-\"><a name=\"Admin 可以为 Project 分配 Namespace 资源/User 资源/UDF 资源/计算资源，以支持多租户资源隔离\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Admin 可以为 Project 分配 Namespace 资源/User 资源/UDF 资源/计算资源，以支持多租户资源隔离</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/admin_2.png\" alt=\"\"></p>\n<h4 id=\"h4-user-project-\"><a name=\"User 可以对自己有权限的 Project 进行开发实施和管理运维工作\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>User 可以对自己有权限的 Project 进行开发实施和管理运维工作</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_1_project.png\" alt=\"\"></p>\n<h4 id=\"h4-user-pipeline-flow-\"><a name=\"User 可以通过简单配置步骤即可搭建起一个流式作业 pipeline（Flow），只需关注数据从哪来到哪去和如何转换处理\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>User 可以通过简单配置步骤即可搭建起一个流式作业 pipeline（Flow），只需关注数据从哪来到哪去和如何转换处理</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_2_flow_1.png\" alt=\"\"></p>\n<h4 id=\"h4--sql-\"><a name=\"转换支持大部分流上作业常用场景，大部分工作可以通过配置 SQL 实现流上处理逻辑\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>转换支持大部分流上作业常用场景，大部分工作可以通过配置 SQL 实现流上处理逻辑</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_2_flow_2.png\" alt=\"\"></p>\n<h4 id=\"h4-wormhole-flow-stream-stream-spark-stream-flow-user-user-stream-\"><a name=\"Wormhole 有 Flow 和 Stream 的概念，支持在一个物理 Stream（对应一个 Spark Stream）里通过并行处理多个逻辑 Flow，使得 User 可以更加精细灵活的利用计算资源，User 也可以对 Stream 进行精细化参数配置调整以更好平衡需求和资源\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Wormhole 有 Flow 和 Stream 的概念，支持在一个物理 Stream（对应一个 Spark Stream）里通过并行处理多个逻辑 Flow，使得 User 可以更加精细灵活的利用计算资源，User 也可以对 Stream 进行精细化参数配置调整以更好平衡需求和资源</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_3_stream.png\" alt=\"\"></p>\n<h4 id=\"h4-wormhole-job-sink-flow-job-lambda-kappa-\"><a name=\"Wormhole 也支持批处理 Job，同样可以配置化实现处理逻辑并落到多个异构 Sink，Flow 和 Job 的配合可以很容易实现 Lambda 架构和 Kappa架构\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Wormhole 也支持批处理 Job，同样可以配置化实现处理逻辑并落到多个异构 Sink，Flow 和 Job 的配合可以很容易实现 Lambda 架构和 Kappa架构</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_4_job_1.png\" alt=\"\"><br><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_4_job_2.png\" alt=\"\"></p>\n<h4 id=\"h4-user-project-namespace-user-udf-resource\"><a name=\"User 可以查看 Project 相关的 Namespace/User/UDF/Resource\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>User 可以查看 Project 相关的 Namespace/User/UDF/Resource</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_5_ns.png\" alt=\"\"><br><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_5_user.png\" alt=\"\"><br><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_6_udf.png\" alt=\"\"><br><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_7_res.png\" alt=\"\"></p>\n<h4 id=\"h4-user-project-flow-stream-\"><a name=\"User还可以监控 Project 正在运行的所有 Flow/Stream 的吞吐和延迟\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>User还可以监控 Project 正在运行的所有 Flow/Stream 的吞吐和延迟</h4><p><img src=\"https://github.com/edp963/wormhole/raw/master/docs/img/user_8_mon.png\" alt=\"\"></p>\n<h4 id=\"h4--documentation\"><a name=\"以上是简短的功能和用户体验预览，更多强大的细节功能请参见 Documentation\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>以上是简短的功能和用户体验预览，更多强大的细节功能请参见 Documentation</h4><h2 id=\"h2-latest-release\"><a name=\"Latest Release\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Latest Release</h2><p>Please download the latest RELEASE(链接：<a href=\"https://pan.baidu.com/s/1JYRJoaPy6E3u8VqGas0neg\">https://pan.baidu.com/s/1JYRJoaPy6E3u8VqGas0neg</a> 提取码：yzgc).</p>\n<h2 id=\"h2-get-help\"><a name=\"Get Help\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Get Help</h2><ul>\n<li><strong>Mailing list</strong>: <a href=\"mailto:edp_support@groups.163.com\">edp_support@groups.163.com</a></li><li><strong>WeChat</strong>: edpstack &lt;img src=&quot;https://github.com/edp963/edp-resource/raw/master/WeChat.jpg&quot; alt=&quot;&quot; width=&quot;100&quot;/&gt;</li></ul>\n<h2 id=\"h2-license\"><a name=\"License\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>License</h2><p>Wormhole is under the Apache 2.0 license. See the <a href=\"https://github.com/edp963/wormhole/blob/master/LICENSE\">LICENSE</a> file for details.</p>\n');
INSERT INTO `tbl_archive` VALUES ('80', '0', 'DBus（数据总线)', '8', '2019-01-24 17:53:40', 'Dbus概览--------------1背景2项目介绍3快速体验4系统架构和工作原理4.1DBUS源端数据采集4.2多租户数据分发5主要功能6其他编译代码版本相关版权声明其他相关资料交流和问题反馈欢迎来到DBus帮助文档，您可以从以下信息中找到相关说明。或者从FAQ找到解决常见问题的方案。1背景企业中大量业务数据保存在各个业务系统数据库中，过去通常的同步数据的方法有很多种，比如：各个数据使用方在', null, '0', '56', null, null, '2019-01-24 17:53:40', '2019-01-24 18:11:40', null, null, '0', '0', '0', '0', 'Dbus 概览\n--------------\n\n    1 背景\n    2 项目介绍\n    3 快速体验\n    4 系统架构和工作原理\n        4.1 DBUS源端数据采集\n        4.2 多租户数据分发\n    5 主要功能\n    6 其他\n        编译代码\n        版本相关\n        版权声明\n        其他相关资料\n        交流和问题反馈\n\n欢迎来到DBus帮助文档，您可以从以下信息中找到相关说明。或者从 FAQ找到解决常见问题的方案。\n1 背景\n-------------\n企业中大量业务数据保存在各个业务系统数据库中，过去通常的同步数据的方法有很多种，比如：\n\n    各个数据使用方在业务低峰期各种抽取所需数据（缺点是存在重复抽取而且数据不一致）\n    由统一的数仓平台通过sqoop到各个系统中抽取数据（缺点是sqoop抽取方法时效性差，一般都是T+1的时效性）\n    基于trigger或时间戳的方式获得增量的变更（缺点是对业务方侵入性大，带来性能损失等）\n\n这些方案都不能算完美，我们在了解和考虑了不同实现方式后，认为要想同时解决数据一致性和实时性，比较合理的方法应该是基于日志的解决方案，同时能够提供消息订阅的方式给下游系统使用。\n\nDBus（数据总线）项目就是应这个需求而生的， DBus专注于数据的收集及实时数据流计算，通过简单灵活的配置，无侵入的方式对源端数据进行采集，采用高可用的流式计算框架，对公司各个IT系统在业务流程中产生的数据进行汇聚，经过处理后转换成统一JSON的数据格式UMS，提供给不同下游客户订阅和消费，充当报表数据源、大数据分析数据源等。 目前DBus在公司内部广泛使用，支持oracle，mysql，log, RocketMQ等数据源，这次开源版本支持mysql数据源。\n\nDBus的主要潜在客户包括：\n\n    数仓平台和数据分析平台\n    实时营销决策\n    实时报表展示\n    异构数据实时同步\n    其他实时性要求高的系统\n\n2 项目介绍\n\n    项目名称：DBus 数据总线\n    语言：java/js\n\n专注于数据的收集及实时数据流计算，通过简单灵活的配置，以无侵入的方式对源端数据进行采集，采用高可用的流式计算框架，对公司各个IT系统在业务流程中产生的数据进行汇聚，经过转换处理后成为统一JSON的数据格式（UMS），提供给不同数据使用方订阅和消费，充当数仓平台、大数据分析平台、实时报表和实时营销等业务的数据源。支持多租户管理，提供租户级资源、数据隔离机制。\n3 快速体验\n-----------\n\n全套DBus包含诸多组件(Canal，zk，kafka，storm，mysql，influxdb，grafana)，为了简单化，我们准备了All in One 包，包含了预先安装数据和一键启动脚本， 用于快速体验。 请参考 快速体验\n4 系统架构和工作原理\n------------\n![](https://bridata.github.io/DBus/img/index/ds_and_projdispatch.png)\nDBUS主要分为两个部分：貼源数据采集和多租户数据分发。两个部分之间以Kafka为媒介进行衔接。无多租户资源、数据隔离需求的用户，可以直接消费源端数据采集这一级输出到kafka的数据，无需再配置多租户数据分发。\n\nGlobalOverview\n4.1 DBUS源端数据采集\n------------\nDBUS源端数据采集大体来说分为两部分：\n\n    读取RDBMS增量日志的方式来 实时获取增量数据日志，并支持全量拉取；\n    基于logtash，flume，filebeat等抓取工具来实时获得数据，以可视化的方式对数据进行结构化输出；\n\n以下为具体实现原理 system arch\n![](https://bridata.github.io/DBus/img/more-system-architecture.png)\n主要模块如下：\n\n    日志抓取模块：从RDBMS的备库中读取增量日志，并实时同步到kafka中；\n    增量转换模块：将增量数据实时转换为UMS数据，处理schema变更，脱敏等；\n    全量抽取程序：将全量数据从RDBMS备库拉取并转换为UMS数据；\n    日志算子处理模块：将来自不同抓取端的日志数据按照算子规则进行结构化处理；\n    心跳监控模块：对于RDMS类源，定时向源端发送心跳数据，并在末端进行监控，发送预警通知；对于日志类，直接在末端监控预警。\n    web管理模块：管理所有相关模块。\n\n4.2 多租户数据分发\n----------------\n对于不同租户对不同源端数据有不同访问权限、脱敏需求的情形，需要引入Router分发模块，将源端貼源数据，根据配置好的权限、用户有权获取的源端表、不同脱敏规则等，分发到分配给租户的Topic。这一级的引入，在DBUS管理系统中，涉及到用户管理、Sink管理、资源分配、脱敏配置等。不同项目消费分配给他的topic。\n![](https://bridata.github.io/DBus/img/index/route2Project.png)\nroute2Project\n5 主要功能\n-------------\n    无侵入方式接入多种数据源： 业务系统无需任何修改，以无侵入性读取数据库系统的日志获得增量数据实时变化。目前RDBMS支持mysql，oracle数据源（Oracle数据源请参考Oracle相关协议）， 日志方面支持基于logstash，flume和filebeat的多种数据日志抽取方案。\n    海量数据实时传输： 使用基于Storm的流式计算框架，秒级延时，整体无单点保证高可用性。\n    多租户支持： 提供用户管理、资源分配、Topology管理、租户表管理等丰富的功能，可根据需求，为不同租户分配不同的源端表数据访问权限，应用不同的脱敏规则，从而实现多租户资源隔离、差异化数据安全。\n\ngrafana\n![](https://bridata.github.io/DBus/img/index/2intr_proj_mgr.png)\n2intr_proj_table\n![](https://bridata.github.io/DBus/img/index/2intr_proj_table.png)\n2intr_router_topo\n![](https://bridata.github.io/DBus/img/index/2intr_router_topo.png)\n\n    感知源端schema变更： 当源端发生schema变更时，能自动感知schema变化，调整UMS版本号，并通过Kafka消息和邮件通知下游diff\n![](https://bridata.github.io/DBus/img/index/2intr_diff.png)\n    数据实时脱敏： 可根据需求对指定列数据进行实时脱敏。脱敏策略包括：直接替换、MD5、murmur等脱敏算法，脱敏加盐，正则表达式替换等。支持用户开发jar包实现DBUS未覆盖的个性化脱敏策略。 encode\n	\n\n![](https://bridata.github.io/DBus/img/index/2intr_encode.png)\n    初始化加载： 支持高效的初始化加载和重新加载，支持任意指定输出topic，灵活应对客户需求。 fuller\n\n    统一标准化消息传输协议： 使用统一的UMS(JSON格式)消息schema格式输出便于消费，提供数据线级ums_id保证数据顺序性,输出insert,Update(before/after),Delete event数据。 ums\n\n    可靠多路消息订阅分发： 使用Kafka存储和传递消息保证可靠性和便捷的多用户订阅\n\n    支持分区表/系列表数据汇集： 支持分区表的数据汇集到一个“逻辑表” 。也可将用户自定义的系列表数据汇集到一个“逻辑表“。例：\n\n    grafana\n\n    实时监控&预警： 可视化监控系统能随时查看各数据线实时流量和延时状况；当数据线发生异常时，根据配置策略自动发邮件或短信通知相关负责人\n\n    grafana\n\n6 其他\n编译代码\n\n关于编译代码，参考 compile\n版本相关\n\n建议版本：0.5.0\n\n下载发布包：请参考：downloads\n版权声明\n\nDBus 自身使用 Apache v2.0 协议\n\n关于DBus 自身协议，修改第三方包代码，以及三方包协议参考： License\n其他相关资料\n\n与开源项目 Wormhole 项目搭配使用将是最佳选择。\n\n参考：如何基于日志，同步实现数据的一致性和实时抽取?\n\n参考： 基于可视化配置的日志结构化转换实现\n\n参考：实时敏捷大数据在宜信的实践\n交流和问题反馈\n\n邮件交流： bridata@126.com\n\n提交issue ： issue\n', '1', '<h2 id=\"h2-dbus-\"><a name=\"Dbus 概览\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Dbus 概览</h2><pre><code>1 背景\n2 项目介绍\n3 快速体验\n4 系统架构和工作原理\n    4.1 DBUS源端数据采集\n    4.2 多租户数据分发\n5 主要功能\n6 其他\n    编译代码\n    版本相关\n    版权声明\n    其他相关资料\n    交流和问题反馈\n</code></pre><p>欢迎来到DBus帮助文档，您可以从以下信息中找到相关说明。或者从 FAQ找到解决常见问题的方案。</p>\n<h2 id=\"h2-1-\"><a name=\"1 背景\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1 背景</h2><p>企业中大量业务数据保存在各个业务系统数据库中，过去通常的同步数据的方法有很多种，比如：</p>\n<pre><code>各个数据使用方在业务低峰期各种抽取所需数据（缺点是存在重复抽取而且数据不一致）\n由统一的数仓平台通过sqoop到各个系统中抽取数据（缺点是sqoop抽取方法时效性差，一般都是T+1的时效性）\n基于trigger或时间戳的方式获得增量的变更（缺点是对业务方侵入性大，带来性能损失等）\n</code></pre><p>这些方案都不能算完美，我们在了解和考虑了不同实现方式后，认为要想同时解决数据一致性和实时性，比较合理的方法应该是基于日志的解决方案，同时能够提供消息订阅的方式给下游系统使用。</p>\n<p>DBus（数据总线）项目就是应这个需求而生的， DBus专注于数据的收集及实时数据流计算，通过简单灵活的配置，无侵入的方式对源端数据进行采集，采用高可用的流式计算框架，对公司各个IT系统在业务流程中产生的数据进行汇聚，经过处理后转换成统一JSON的数据格式UMS，提供给不同下游客户订阅和消费，充当报表数据源、大数据分析数据源等。 目前DBus在公司内部广泛使用，支持oracle，mysql，log, RocketMQ等数据源，这次开源版本支持mysql数据源。</p>\n<p>DBus的主要潜在客户包括：</p>\n<pre><code>数仓平台和数据分析平台\n实时营销决策\n实时报表展示\n异构数据实时同步\n其他实时性要求高的系统\n</code></pre><p>2 项目介绍</p>\n<pre><code>项目名称：DBus 数据总线\n语言：java/js\n</code></pre><p>专注于数据的收集及实时数据流计算，通过简单灵活的配置，以无侵入的方式对源端数据进行采集，采用高可用的流式计算框架，对公司各个IT系统在业务流程中产生的数据进行汇聚，经过转换处理后成为统一JSON的数据格式（UMS），提供给不同数据使用方订阅和消费，充当数仓平台、大数据分析平台、实时报表和实时营销等业务的数据源。支持多租户管理，提供租户级资源、数据隔离机制。</p>\n<h2 id=\"h2-3-\"><a name=\"3 快速体验\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>3 快速体验</h2><p>全套DBus包含诸多组件(Canal，zk，kafka，storm，mysql，influxdb，grafana)，为了简单化，我们准备了All in One 包，包含了预先安装数据和一键启动脚本， 用于快速体验。 请参考 快速体验</p>\n<h2 id=\"h2-4-\"><a name=\"4 系统架构和工作原理\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4 系统架构和工作原理</h2><p><img src=\"https://bridata.github.io/DBus/img/index/ds_and_projdispatch.png\" alt=\"\"><br>DBUS主要分为两个部分：貼源数据采集和多租户数据分发。两个部分之间以Kafka为媒介进行衔接。无多租户资源、数据隔离需求的用户，可以直接消费源端数据采集这一级输出到kafka的数据，无需再配置多租户数据分发。</p>\n<p>GlobalOverview</p>\n<h2 id=\"h2-4-1-dbus-\"><a name=\"4.1 DBUS源端数据采集\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.1 DBUS源端数据采集</h2><p>DBUS源端数据采集大体来说分为两部分：</p>\n<pre><code>读取RDBMS增量日志的方式来 实时获取增量数据日志，并支持全量拉取；\n基于logtash，flume，filebeat等抓取工具来实时获得数据，以可视化的方式对数据进行结构化输出；\n</code></pre><p>以下为具体实现原理 system arch<br><img src=\"https://bridata.github.io/DBus/img/more-system-architecture.png\" alt=\"\"><br>主要模块如下：</p>\n<pre><code>日志抓取模块：从RDBMS的备库中读取增量日志，并实时同步到kafka中；\n增量转换模块：将增量数据实时转换为UMS数据，处理schema变更，脱敏等；\n全量抽取程序：将全量数据从RDBMS备库拉取并转换为UMS数据；\n日志算子处理模块：将来自不同抓取端的日志数据按照算子规则进行结构化处理；\n心跳监控模块：对于RDMS类源，定时向源端发送心跳数据，并在末端进行监控，发送预警通知；对于日志类，直接在末端监控预警。\nweb管理模块：管理所有相关模块。\n</code></pre><h2 id=\"h2-4-2-\"><a name=\"4.2 多租户数据分发\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>4.2 多租户数据分发</h2><p>对于不同租户对不同源端数据有不同访问权限、脱敏需求的情形，需要引入Router分发模块，将源端貼源数据，根据配置好的权限、用户有权获取的源端表、不同脱敏规则等，分发到分配给租户的Topic。这一级的引入，在DBUS管理系统中，涉及到用户管理、Sink管理、资源分配、脱敏配置等。不同项目消费分配给他的topic。<br><img src=\"https://bridata.github.io/DBus/img/index/route2Project.png\" alt=\"\"><br>route2Project</p>\n<h2 id=\"h2-5-\"><a name=\"5 主要功能\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>5 主要功能</h2><pre><code>无侵入方式接入多种数据源： 业务系统无需任何修改，以无侵入性读取数据库系统的日志获得增量数据实时变化。目前RDBMS支持mysql，oracle数据源（Oracle数据源请参考Oracle相关协议）， 日志方面支持基于logstash，flume和filebeat的多种数据日志抽取方案。\n海量数据实时传输： 使用基于Storm的流式计算框架，秒级延时，整体无单点保证高可用性。\n多租户支持： 提供用户管理、资源分配、Topology管理、租户表管理等丰富的功能，可根据需求，为不同租户分配不同的源端表数据访问权限，应用不同的脱敏规则，从而实现多租户资源隔离、差异化数据安全。\n</code></pre><p>grafana<br><img src=\"https://bridata.github.io/DBus/img/index/2intr_proj_mgr.png\" alt=\"\"><br>2intr_proj_table<br><img src=\"https://bridata.github.io/DBus/img/index/2intr_proj_table.png\" alt=\"\"><br>2intr_router_topo<br><img src=\"https://bridata.github.io/DBus/img/index/2intr_router_topo.png\" alt=\"\"></p>\n<pre><code>感知源端schema变更： 当源端发生schema变更时，能自动感知schema变化，调整UMS版本号，并通过Kafka消息和邮件通知下游diff\n</code></pre><p><img src=\"https://bridata.github.io/DBus/img/index/2intr_diff.png\" alt=\"\"><br>    数据实时脱敏： 可根据需求对指定列数据进行实时脱敏。脱敏策略包括：直接替换、MD5、murmur等脱敏算法，脱敏加盐，正则表达式替换等。支持用户开发jar包实现DBUS未覆盖的个性化脱敏策略。 encode</p>\n<p><img src=\"https://bridata.github.io/DBus/img/index/2intr_encode.png\" alt=\"\"><br>    初始化加载： 支持高效的初始化加载和重新加载，支持任意指定输出topic，灵活应对客户需求。 fuller</p>\n<pre><code>统一标准化消息传输协议： 使用统一的UMS(JSON格式)消息schema格式输出便于消费，提供数据线级ums_id保证数据顺序性,输出insert,Update(before/after),Delete event数据。 ums\n\n可靠多路消息订阅分发： 使用Kafka存储和传递消息保证可靠性和便捷的多用户订阅\n\n支持分区表/系列表数据汇集： 支持分区表的数据汇集到一个“逻辑表” 。也可将用户自定义的系列表数据汇集到一个“逻辑表“。例：\n\ngrafana\n\n实时监控&amp;预警： 可视化监控系统能随时查看各数据线实时流量和延时状况；当数据线发生异常时，根据配置策略自动发邮件或短信通知相关负责人\n\ngrafana\n</code></pre><p>6 其他<br>编译代码</p>\n<p>关于编译代码，参考 compile<br>版本相关</p>\n<p>建议版本：0.5.0</p>\n<p>下载发布包：请参考：downloads<br>版权声明</p>\n<p>DBus 自身使用 Apache v2.0 协议</p>\n<p>关于DBus 自身协议，修改第三方包代码，以及三方包协议参考： License<br>其他相关资料</p>\n<p>与开源项目 Wormhole 项目搭配使用将是最佳选择。</p>\n<p>参考：如何基于日志，同步实现数据的一致性和实时抽取?</p>\n<p>参考： 基于可视化配置的日志结构化转换实现</p>\n<p>参考：实时敏捷大数据在宜信的实践<br>交流和问题反馈</p>\n<p>邮件交流： <a href=\"mailto:bridata@126.com\">bridata@126.com</a></p>\n<p>提交issue ： issue</p>\n');
INSERT INTO `tbl_archive` VALUES ('81', '0', '关于遥感数据的非标量化问题', '8', '2019-01-24 22:35:58', '我们最近在思考一个问题,遥感卫星的非结构化数据如何才能被绿色金融委员会在绿色金融系统的使用。因为遥感数据是\"据数\"，而金融系统需要的是\"量数\"，两者有很强的关系，但很难被引用。比如太湖环境治理，政府拨款治理太湖污染问题。遥感数据作为基础数据应该能提供宏观的检测指标，这里面就存在“非标准数据的量化问题”，简称“非标量化”。比如不同公司和组织对\"据数\"，量化出来的数值因算法不同，结果会差别很大。如何才', null, '0', '50', null, null, '2019-01-24 22:35:58', '2019-01-25 21:21:06', null, null, '0', '0', '0', '0', '我们最近在思考一个问题, 遥感卫星的非结构化数据如何才能被绿色金融委员会在绿色金融系统的使用。\n因为遥感数据是\"据数\"，而金融系统需要的是 \"量数\"，两者有很强的关系，但很难被引用。\n比如 太湖环境治理，政府拨款治理 太湖污染问题。遥感数据作为基础数据应该能提供宏观的 检测指标，这里面就存在 “非标准数据的量化问题”，简称 “非标量化”。\n比如不同公司和组织对\"据数\"，量化出来的数值因算法不同，结果会差别很大。如何才能让据数 “非标量化 ”后的量数天然更具备公信力。 有机会探讨探讨。，我们最近在研究这个课题。\n我们已经完成湖州地区的遥感数据数值量化，并提交给湖州政府，计划在湖州试点。\n\n数据版权\n', '0', '<p>我们最近在思考一个问题, 遥感卫星的非结构化数据如何才能被绿色金融委员会在绿色金融系统的使用。<br>因为遥感数据是”据数”，而金融系统需要的是 “量数”，两者有很强的关系，但很难被引用。<br>比如 太湖环境治理，政府拨款治理 太湖污染问题。遥感数据作为基础数据应该能提供宏观的 检测指标，这里面就存在 “非标准数据的量化问题”，简称 “非标量化”。<br>比如不同公司和组织对”据数”，量化出来的数值因算法不同，结果会差别很大。如何才能让据数 “非标量化 ”后的量数天然更具备公信力。 有机会探讨探讨。，我们最近在研究这个课题。<br>我们已经完成湖州地区的遥感数据数值量化，并提交给湖州政府，计划在湖州试点。</p>\n<p>数据版权</p>\n');
INSERT INTO `tbl_archive` VALUES ('82', '0', '如何批量下载卫星数据', '8', '2019-01-24 23:10:41', '##下载地址https://earthexplorer.usgs.gov/', null, '0', '53', null, null, '2019-01-24 23:10:41', '2019-01-27 13:27:17', null, null, '0', '0', '0', '0', '##Google Earth 查询名字\n##下载地址\nhttps://earthexplorer.usgs.gov/\n\nGoogle Earth 瓦片编号查询\n\n```html\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<kml xmlns=\"http://www.opengis.net/kml/2.2\" xmlns:gx=\"http://www.google.com/kml/ext/2.2\" xmlns:kml=\"http://www.opengis.net/kml/2.2\" xmlns:atom=\"http://www.w3.org/2005/Atom\">\n<Document>\n	<name>Sentinel imagery Tiles</name>\n	<Style id=\"sentinelTile\">\n		<LineStyle>\n			<color>ff0000ff</color>\n		</LineStyle>\n		<PolyStyle>\n			<fill>0</fill>\n		</PolyStyle>\n		<BalloonStyle>\n			<text><![CDATA[&lt;script src=\"https://www.gearthblog.com/js/jquery/jquery-3.1.0.min.js\">&lt;&#47;script&gt;\n&lt;script src=\"https://www.gearthblog.com/js/babel/polyfill.min.js\">&lt;&#47;script&gt;\n<div style=\"width:2000px;height:1000px\">\n<input id=\"tile\" value=\"$[name]\" type=\"hidden\"/>\n<b><font color=\"#20385e\" size=\"+3\">$[name]</font></b>\n\n<br/>\n<div id=\"output\"></div><br/>\n\n<table id=\"imageList\" ></table>\n\n<br/>\n</div>\n&lt;script&gt;\n\nvar bucketName = \"sentinel-s2-l1c\";\nvar baseUrl = \"https:\"+\"//roda.sentinel-hub.com/\"+bucketName;\nvar webBaseUrl = \"https:\"+\"//roda.sentinel-hub.com/\"+bucketName;\n\nvar maxDateCount;\nfunction start() {\n    maxDateCount = 20;\n    clearError();\n    var tile = document.getElementById(\'tile\').value;\n    showStatus(\"Finding products Count:\"+maxDateCount+\" tile:\"+tile+\"...\")\n    getList(getTileUrl(tile)).then(function(products) {\n		//appendStatus(\" ===== getList products =====:\"+products)\n        getImages(products);\n		});\n}\nfunction getTileUrl(tileId) {\n    var tileUrl = \'tiles/\'\n    if (tileId.length > 0)\n        tileUrl += (tileId[0] === \'0\') ? tileId.substr(1, 1) + \'/\' : tileId.substr(0, 2) + \'/\';\n    if (tileId.length > 2)\n        tileUrl += tileId.substr(2, 1) + \'/\';\n    if (tileId.length > 3)\n        tileUrl += tileId.substr(3, 2) + \'/\';\n	//appendStatus(\" getTileUrl tileUrl:\"+tileUrl)\n    return tileUrl;\n}\nfunction showProgress(progress) {\n    return new Promise(function(resolve, reject) {\n        document.getElementById(\'output\').innerHTML = progress;\n        setTimeout(resolve, 50, \"done\");\n    }\n    );\n}\nfunction showStatus(status) {\n    document.getElementById(\'output\').innerHTML = status;\n}\nfunction appendStatus(status) {\n    document.getElementById(\'output\').innerHTML += status;\n}\nfunction showError(error) {\n    document.getElementById(\'output\').innerHTML = error;\n    document.getElementById(\'output\').style.color = \'red\';\n}\nfunction clearError() {\n    document.getElementById(\'output\').style.color = \'black\';\n}\nfunction getList(location) {\n	//showProgress(\" getList location:\"+location);\n	//showProgress(\" getList location: \"+baseUrl+\"/\"+location);\n    return new Promise(function(resolve, reject) {\n        var data = {\n            //delimiter: \"/\"\n        };\n		\n        if (location) {\n            //data.prefix = location;\n        }\n		\n        $.ajax({\n            url: baseUrl+\"/\"+location,\n            data: data,\n            success: function(data) {\n				//showProgress(\" getList data:\"+data);\n                analyzeOuter(data, location).then(function(products) {\n					//showProgress(\" getList products:\"+products);\n					//alert(data);\n                    resolve(products);\n                })\n            }\n        });\n    }\n    );\n}\nfunction analyzeOuter(data, location) {\n    var products = [];\n    function analyze(data, location) {\n		//appendStatus(\" analyzeOuter>analyze data:\"+data+\" location:\"+location);\n        return new Promise(function(resolve, reject) {\n            var directories = Array.prototype.slice.call(data.CommonPrefixes);\n			//appendStatus(\" analyzeOuter>analyze Promise: directories:\"+directories);\n            if (directories.length === 0) {\n                return resolve(products);\n            }\n            var paths = directories.map(function(d) {\n				\n				//appendStatus(\" analyzeOuter>analyze dataCoveragePercentage:\"+tileInfo.utmZone+\" cloudyPixelPercentage:\"+tileInfo.timestamp);\n				//if (tileInfo.dataCoveragePercentage==100&tileInfo.cloudyPixelPercentage>=90){\n					return d.Prefix;\n				//}\n            });\n            paths = paths.sort(function(a, b) {\n                return parseFloat(a.split(\'/\').slice(-2, -1)[0]) - parseFloat(b.split(\'/\').slice(-2, -1)[0])\n            });\n			\n			//appendStatus(\" analyzeOuter>analyze Promise: paths:\"+paths);\n			\n            function next() {\n                var path = paths.pop();\n				//appendStatus(\"analyzeOuter:Promise:path:\"+path);\n                var depth = (path.match(/\\//g) || []).length;\n				//appendStatus(\"analyzeOuter:next:depth:\"+depth);\n                if (depth == 8) {\n					var titleInfoUrl=baseUrl+\"/\"+path+\"tileInfo.json\";\n					appendStatus(\" titleInfoUrl:\"+titleInfoUrl);\n					getTileInfo(titleInfoUrl).then(function(tileInfo) {\n							//var tileInfo = JSON.parse(tileInfoData);\n							//appendStatus(\"tileInfo:\"+tileInfo.productName);\n							if (tileInfo.dataCoveragePercentage>=50){\n								if (tileInfo.cloudyPixelPercentage<=100){\n                                    appendStatus();\n								    appendStatus(\" productName:\"+tileInfo.productName+\" [DCP:\"+tileInfo.dataCoveragePercentage+\" CPP:\"+tileInfo.cloudyPixelPercentage+\"]\");\n									//appendStatus(\" titleInfoUrl:\"+titleInfoUrl);\n									products.push(path);\n								}\n							}\n					});\n					\n					\n					//var tileInfo=getTileInfo(titleInfoUrl);\n					//appendStatus(\" tileInfo:titleInfoUrl\"+titleInfoUrl+\" tileInfo:\"+JSON.stringify(tileInfo));\n					//appendStatus(\" dataCoveragePercentage:\"+tileInfo.dataCoveragePercentage+\"cloudyPixelPercentage:\"+tileInfo.cloudyPixelPercentage);\n					\n                    //products.push(path);\n					//appendStatus(\"analyzeOuter:next:depth:5:products:\"+products);\n                    return resolve(products);\n                }\n				\n				//appendStatus(\" analyzeOuter:next:\" +products.length);\n				appendStatus(\".\");\n                if (products.length < maxDateCount) {\n                    getListPromise(path).then(function(data) {\n                        analyze(data, path).then(function() {\n                            if (paths.length !== 0) {\n                                next();\n                            } else {\n								//appendStatus(\" analyzeOuter:next:depth:6:else:products:\"+products);\n                                return resolve(products);\n                            }\n                        });\n                    });\n                } else {\n					//appendStatus(\" analyzeOuter:next:depth:6:products:\"+products);\n                    return resolve(products);\n                }\n            }\n            next();\n        }\n        );\n    }\n    return analyze(data, location);\n}\n\n\nfunction getListPromise(location) {\n    //appendStatus(\".ListPromise:location:\" +location);\n    return new Promise(function(resolve, reject) {\n        var data = {\n            //delimiter: \"/\"\n        };\n        if (location) {\n            //data.prefix = location;\n        }\n        $.ajax({\n            url: baseUrl+\"/\"+location,\n            data: data,\n            success: function(data) {\n                resolve(data);\n            },\n            failure: function(error) {\n                console.log(\"failure\" + error);\n            }\n        });\n    }\n    );\n}\n\n\nfunction getTileInfo(location) {\n    //appendStatus(\".getTileInfo:location:\" +location);\n    return new Promise(function(resolve, reject) {\n        var data = {\n            //delimiter: \"/\"\n        };\n        if (location) {\n            //data.prefix = location;\n        }\n        $.ajax({\n            url: location,\n            data: data,\n            success: function(data) {\n				data = data.replace(/\\\\/g,\"/\");\n                var result = null;\n                result = JSON.parse(data);\n                resolve(result);\n            },\n            failure: function(error) {\n                console.log(\"failure\" + error);\n            }\n        });\n    }\n    );\n}\n\n\nfunction test() {\n    products = [\"tiles/15/R/XP/2016/8/4/0/\", \"tiles/15/R/XP/2016/7/5/0/\", \"tiles/15/R/XP/2016/7/15/0/\", \"tiles/15/R/XP/2016/6/5/0/\", \"tiles/15/R/XP/2016/6/25/0/\", \"tiles/15/R/XP/2016/6/15/0/\"];\n    getImages();\n}\nfunction getImages(products) {\n    products.reverse();\n    $(\"#imageList\").empty();\n    if (products.length === 0) {\n        showError(\"No products found for this tile.\")\n        return;\n    }\n    var targetWidget = document.getElementById(\"imageList\");\n    var i = 0;\n    var row = targetWidget.insertRow();\n    function next() {\n        getListPromise(products[i]).then(function(data) {\n            var cell = row.insertCell();\n            getPreview($(cell), products[i], data);\n            if (i == 5)\n                row = targetWidget.insertRow();\n            i++;\n            if (i < products.length)\n                next();\n            else\n                showStatus(\"Done.\")\n        });\n    }\n    next();\n}\nfunction getPreview(targetWidget, currentLocation, data) {\n	\n    var files = data.Contents;\n    var lastKey;\n    for (var i = 0; i < files.length; i++) {\n        var path = files[i].Key;\n        lastKey = path;\n        var name = path.substring(currentLocation.length).replace(/\\/$/, \"\");\n        if (name === \'preview.jpg\') {\n            targetWidget.append(createImageAnchor(name, path));\n            var date = getDateFromPath(currentLocation);\n            targetWidget.append(\'<br>\');\n            targetWidget.append(createDirectoryAnchor(date, currentLocation));\n            targetWidget.append(\'<br>\');\n        }\n    }\n}\nfunction getDateFromPath(path) {\n    var locationParts = path.split(\'/\');\n    return locationParts[4] + \'-\' + locationParts[5] + \'-\' + locationParts[6];\n}\nfunction createImageAnchor(title, location) {\n    return $(\"<img>\", {\n        src: baseUrl + \"/\" + location\n    }).html(title);\n}\nfunction createDirectoryAnchor(title, location) {\n    return $(\"<a>\", {\n        target: \"_blank\",\n        href: webBaseUrl + \"/\" + location\n    }).html(title);\n}\n\njQuery(document).ready(function() { \n    start();\n });\n  \n   \n   \n   \n\n&lt;&#47;script&gt;\n<br/>\n<br/>]]></text>\n			<bgColor>ffd3dfe1</bgColor>\n		</BalloonStyle>\n	&lt;&#47;style&gt;\n	<Placemark>\n		<name>50TLK</name>\n		<description>1</description>\n		<styleUrl>#sentinelTile</styleUrl>\n		&lt;style&gt;\n			<LineStyle>\n				<color>ff00ff08</color>\n				<width>1</width>\n			</LineStyle>\n			<PolyStyle>\n				<fill>0</fill>\n			</PolyStyle>\n		&lt;&#47;style&gt;\n		<Polygon>\n			<tessellate>1</tessellate>\n			<outerBoundaryIs>\n				<LinearRing>\n					<coordinates>\n						114.669349,39.638218,0 115.948551,39.656848,0 115.933185,40.645929,0 114.635319,40.62664,0 114.669349,39.638218,0 \n					</coordinates>\n				</LinearRing>\n			</outerBoundaryIs>\n		</Polygon>\n	</Placemark>\n	<Placemark>\n		<name>49SCU</name>\n		<description>1</description>\n		<styleUrl>#sentinelTile</styleUrl>\n		&lt;style&gt;\n			<LineStyle>\n				<color>ff00ff08</color>\n				<width>1</width>\n			</LineStyle>\n			<PolyStyle>\n				<fill>0</fill>\n			</PolyStyle>\n		&lt;&#47;style&gt;\n		<Polygon>\n			<tessellate>1</tessellate>\n			<outerBoundaryIs>\n				<LinearRing>\n					<coordinates>\n						108.828503,34.233687,0 110.020408,34.249008,0 110.00865,35.239018,0 108.802458,35.223125,0 108.828503,34.233687,0 \n					</coordinates>\n				</LinearRing>\n			</outerBoundaryIs>\n		</Polygon>\n	</Placemark>\n	<Placemark>\n		<name>48MVU</name>\n		<description>10</description>\n		<styleUrl>#sentinelTile</styleUrl>\n		&lt;style&gt;\n			<LineStyle>\n				<color>ff00ff2f</color>\n				<width>1</width>\n			</LineStyle>\n			<PolyStyle>\n				<fill>0</fill>\n			</PolyStyle>\n		&lt;&#47;style&gt;\n		<Polygon>\n			<tessellate>1</tessellate>\n			<outerBoundaryIs>\n				<LinearRing>\n					<coordinates>\n						104.095366,-6.420715,0 105.088261,-6.421506,0 105.088103,-5.428219,0 104.096981,-5.427551,0 104.095366,-6.420715,0 \n					</coordinates>\n				</LinearRing>\n			</outerBoundaryIs>\n		</Polygon>\n	</Placemark>\n	<Placemark>\n		<name>43NBE</name>\n		<description>45</description>\n		<styleUrl>#sentinelTile</styleUrl>\n		&lt;style&gt;\n			<LineStyle>\n				<color>ff00ffc3</color>\n				<width>1</width>\n			</LineStyle>\n			<PolyStyle>\n				<fill>0</fill>\n			</PolyStyle>\n		&lt;&#47;style&gt;\n		<Polygon>\n			<tessellate>1</tessellate>\n			<outerBoundaryIs>\n				<LinearRing>\n					<coordinates>\n						72.29971399999999,3.526642,0 73.28757,3.528996,0 73.285493,4.521894,0 72.296443,4.518876,0 72.29971399999999,3.526642,0 \n					</coordinates>\n				</LinearRing>\n			</outerBoundaryIs>\n		</Polygon>\n	</Placemark>\n	<Placemark>\n		<name>39PZP</name>\n		<description>44</description>\n		<styleUrl>#sentinelTile</styleUrl>\n		&lt;style&gt;\n			<LineStyle>\n				<color>ff00ffbf</color>\n				<width>1</width>\n			</LineStyle>\n			<PolyStyle>\n				<fill>0</fill>\n			</PolyStyle>\n		&lt;&#47;style&gt;\n		<Polygon>\n			<tessellate>1</tessellate>\n			<outerBoundaryIs>\n				<LinearRing>\n					<coordinates>\n						53.751278,11.658428,0 54.757004,11.647043,0 54.770939,12.637842,0 53.761497,12.650225,0 53.751278,11.658428,0 \n					</coordinates>\n				</LinearRing>\n			</outerBoundaryIs>\n		</Polygon>\n	</Placemark>\n	<Placemark id=\"07B272AF3F09A58FC4E4\">\n		<name>51RTQ</name>\n		<description>25</description>\n		<styleUrl>#sentinelTile</styleUrl>\n		&lt;style&gt;\n			<LineStyle>\n				<color>ff00ff6e</color>\n				<width>1</width>\n			</LineStyle>\n			<PolyStyle>\n				<fill>0</fill>\n			</PolyStyle>\n		&lt;&#47;style&gt;\n		<Polygon>\n			<tessellate>1</tessellate>\n			<outerBoundaryIs>\n				<LinearRing>\n					<coordinates>\n						119.870825,30.607154,0 121.015281,30.629668,0 120.994556,31.619796,0 119.838188,31.596391,0 119.870825,30.607154,0 \n					</coordinates>\n				</LinearRing>\n			</outerBoundaryIs>\n		</Polygon>\n	</Placemark>\n	\n		<Placemark>\n		<name>51TWL</name>\n		<description>19</description>\n		<styleUrl>#sentinelTile</styleUrl>\n		&lt;style&gt;\n			<LineStyle>\n				<color>ff00ff55</color>\n				<width>1</width>\n			</LineStyle>\n			<PolyStyle>\n				<fill>0</fill>\n			</PolyStyle>\n		&lt;&#47;style&gt;\n		<Polygon>\n			<tessellate>1</tessellate>\n			<outerBoundaryIs>\n				<LinearRing>\n					<coordinates>\n						122.999742,46.053574,0 124.418904,46.044766,0 124.394254,45.056749,0 122.999746,45.06526000000001,0 122.999742,46.053574,0 \n					</coordinates>\n				</LinearRing>\n			</outerBoundaryIs>\n		</Polygon>\n	</Placemark>\n	\n	\n</Document>\n</kml>\n\n```', '0', '<h2 id=\"h2-google-earth-\"><a name=\"Google Earth 查询名字\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Google Earth 查询名字</h2><h2 id=\"h2-u4E0Bu8F7Du5730u5740\"><a name=\"下载地址\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>下载地址</h2><p><a href=\"https://earthexplorer.usgs.gov/\">https://earthexplorer.usgs.gov/</a></p>\n<p>Google Earth 瓦片编号查询</p>\n<pre><code class=\"lang-html\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;kml xmlns=&quot;http://www.opengis.net/kml/2.2&quot; xmlns:gx=&quot;http://www.google.com/kml/ext/2.2&quot; xmlns:kml=&quot;http://www.opengis.net/kml/2.2&quot; xmlns:atom=&quot;http://www.w3.org/2005/Atom&quot;&gt;\n&lt;Document&gt;\n    &lt;name&gt;Sentinel imagery Tiles&lt;/name&gt;\n    &lt;Style id=&quot;sentinelTile&quot;&gt;\n        &lt;LineStyle&gt;\n            &lt;color&gt;ff0000ff&lt;/color&gt;\n        &lt;/LineStyle&gt;\n        &lt;PolyStyle&gt;\n            &lt;fill&gt;0&lt;/fill&gt;\n        &lt;/PolyStyle&gt;\n        &lt;BalloonStyle&gt;\n            &lt;text&gt;&lt;![CDATA[&lt;script src=&quot;https://www.gearthblog.com/js/jquery/jquery-3.1.0.min.js&quot;&gt;&lt;/script&gt;\n&lt;script src=&quot;https://www.gearthblog.com/js/babel/polyfill.min.js&quot;&gt;&lt;/script&gt;\n&lt;div style=&quot;width:2000px;height:1000px&quot;&gt;\n&lt;input id=&quot;tile&quot; value=&quot;$[name]&quot; type=&quot;hidden&quot;/&gt;\n&lt;b&gt;&lt;font color=&quot;#20385e&quot; size=&quot;+3&quot;&gt;$[name]&lt;/font&gt;&lt;/b&gt;\n\n&lt;br/&gt;\n&lt;div id=&quot;output&quot;&gt;&lt;/div&gt;&lt;br/&gt;\n\n&lt;table id=&quot;imageList&quot; &gt;&lt;/table&gt;\n\n&lt;br/&gt;\n&lt;/div&gt;\n&lt;script&gt;\n\nvar bucketName = &quot;sentinel-s2-l1c&quot;;\nvar baseUrl = &quot;https:&quot;+&quot;//roda.sentinel-hub.com/&quot;+bucketName;\nvar webBaseUrl = &quot;https:&quot;+&quot;//roda.sentinel-hub.com/&quot;+bucketName;\n\nvar maxDateCount;\nfunction start() {\n    maxDateCount = 20;\n    clearError();\n    var tile = document.getElementById(&#39;tile&#39;).value;\n    showStatus(&quot;Finding products Count:&quot;+maxDateCount+&quot; tile:&quot;+tile+&quot;...&quot;)\n    getList(getTileUrl(tile)).then(function(products) {\n        //appendStatus(&quot; ===== getList products =====:&quot;+products)\n        getImages(products);\n        });\n}\nfunction getTileUrl(tileId) {\n    var tileUrl = &#39;tiles/&#39;\n    if (tileId.length &gt; 0)\n        tileUrl += (tileId[0] === &#39;0&#39;) ? tileId.substr(1, 1) + &#39;/&#39; : tileId.substr(0, 2) + &#39;/&#39;;\n    if (tileId.length &gt; 2)\n        tileUrl += tileId.substr(2, 1) + &#39;/&#39;;\n    if (tileId.length &gt; 3)\n        tileUrl += tileId.substr(3, 2) + &#39;/&#39;;\n    //appendStatus(&quot; getTileUrl tileUrl:&quot;+tileUrl)\n    return tileUrl;\n}\nfunction showProgress(progress) {\n    return new Promise(function(resolve, reject) {\n        document.getElementById(&#39;output&#39;).innerHTML = progress;\n        setTimeout(resolve, 50, &quot;done&quot;);\n    }\n    );\n}\nfunction showStatus(status) {\n    document.getElementById(&#39;output&#39;).innerHTML = status;\n}\nfunction appendStatus(status) {\n    document.getElementById(&#39;output&#39;).innerHTML += status;\n}\nfunction showError(error) {\n    document.getElementById(&#39;output&#39;).innerHTML = error;\n    document.getElementById(&#39;output&#39;).style.color = &#39;red&#39;;\n}\nfunction clearError() {\n    document.getElementById(&#39;output&#39;).style.color = &#39;black&#39;;\n}\nfunction getList(location) {\n    //showProgress(&quot; getList location:&quot;+location);\n    //showProgress(&quot; getList location: &quot;+baseUrl+&quot;/&quot;+location);\n    return new Promise(function(resolve, reject) {\n        var data = {\n            //delimiter: &quot;/&quot;\n        };\n\n        if (location) {\n            //data.prefix = location;\n        }\n\n        $.ajax({\n            url: baseUrl+&quot;/&quot;+location,\n            data: data,\n            success: function(data) {\n                //showProgress(&quot; getList data:&quot;+data);\n                analyzeOuter(data, location).then(function(products) {\n                    //showProgress(&quot; getList products:&quot;+products);\n                    //alert(data);\n                    resolve(products);\n                })\n            }\n        });\n    }\n    );\n}\nfunction analyzeOuter(data, location) {\n    var products = [];\n    function analyze(data, location) {\n        //appendStatus(&quot; analyzeOuter&gt;analyze data:&quot;+data+&quot; location:&quot;+location);\n        return new Promise(function(resolve, reject) {\n            var directories = Array.prototype.slice.call(data.CommonPrefixes);\n            //appendStatus(&quot; analyzeOuter&gt;analyze Promise: directories:&quot;+directories);\n            if (directories.length === 0) {\n                return resolve(products);\n            }\n            var paths = directories.map(function(d) {\n\n                //appendStatus(&quot; analyzeOuter&gt;analyze dataCoveragePercentage:&quot;+tileInfo.utmZone+&quot; cloudyPixelPercentage:&quot;+tileInfo.timestamp);\n                //if (tileInfo.dataCoveragePercentage==100&amp;tileInfo.cloudyPixelPercentage&gt;=90){\n                    return d.Prefix;\n                //}\n            });\n            paths = paths.sort(function(a, b) {\n                return parseFloat(a.split(&#39;/&#39;).slice(-2, -1)[0]) - parseFloat(b.split(&#39;/&#39;).slice(-2, -1)[0])\n            });\n\n            //appendStatus(&quot; analyzeOuter&gt;analyze Promise: paths:&quot;+paths);\n\n            function next() {\n                var path = paths.pop();\n                //appendStatus(&quot;analyzeOuter:Promise:path:&quot;+path);\n                var depth = (path.match(/\\//g) || []).length;\n                //appendStatus(&quot;analyzeOuter:next:depth:&quot;+depth);\n                if (depth == 8) {\n                    var titleInfoUrl=baseUrl+&quot;/&quot;+path+&quot;tileInfo.json&quot;;\n                    appendStatus(&quot; titleInfoUrl:&quot;+titleInfoUrl);\n                    getTileInfo(titleInfoUrl).then(function(tileInfo) {\n                            //var tileInfo = JSON.parse(tileInfoData);\n                            //appendStatus(&quot;tileInfo:&quot;+tileInfo.productName);\n                            if (tileInfo.dataCoveragePercentage&gt;=50){\n                                if (tileInfo.cloudyPixelPercentage&lt;=100){\n                                    appendStatus();\n                                    appendStatus(&quot; productName:&quot;+tileInfo.productName+&quot; [DCP:&quot;+tileInfo.dataCoveragePercentage+&quot; CPP:&quot;+tileInfo.cloudyPixelPercentage+&quot;]&quot;);\n                                    //appendStatus(&quot; titleInfoUrl:&quot;+titleInfoUrl);\n                                    products.push(path);\n                                }\n                            }\n                    });\n\n\n                    //var tileInfo=getTileInfo(titleInfoUrl);\n                    //appendStatus(&quot; tileInfo:titleInfoUrl&quot;+titleInfoUrl+&quot; tileInfo:&quot;+JSON.stringify(tileInfo));\n                    //appendStatus(&quot; dataCoveragePercentage:&quot;+tileInfo.dataCoveragePercentage+&quot;cloudyPixelPercentage:&quot;+tileInfo.cloudyPixelPercentage);\n\n                    //products.push(path);\n                    //appendStatus(&quot;analyzeOuter:next:depth:5:products:&quot;+products);\n                    return resolve(products);\n                }\n\n                //appendStatus(&quot; analyzeOuter:next:&quot; +products.length);\n                appendStatus(&quot;.&quot;);\n                if (products.length &lt; maxDateCount) {\n                    getListPromise(path).then(function(data) {\n                        analyze(data, path).then(function() {\n                            if (paths.length !== 0) {\n                                next();\n                            } else {\n                                //appendStatus(&quot; analyzeOuter:next:depth:6:else:products:&quot;+products);\n                                return resolve(products);\n                            }\n                        });\n                    });\n                } else {\n                    //appendStatus(&quot; analyzeOuter:next:depth:6:products:&quot;+products);\n                    return resolve(products);\n                }\n            }\n            next();\n        }\n        );\n    }\n    return analyze(data, location);\n}\n\n\nfunction getListPromise(location) {\n    //appendStatus(&quot;.ListPromise:location:&quot; +location);\n    return new Promise(function(resolve, reject) {\n        var data = {\n            //delimiter: &quot;/&quot;\n        };\n        if (location) {\n            //data.prefix = location;\n        }\n        $.ajax({\n            url: baseUrl+&quot;/&quot;+location,\n            data: data,\n            success: function(data) {\n                resolve(data);\n            },\n            failure: function(error) {\n                console.log(&quot;failure&quot; + error);\n            }\n        });\n    }\n    );\n}\n\n\nfunction getTileInfo(location) {\n    //appendStatus(&quot;.getTileInfo:location:&quot; +location);\n    return new Promise(function(resolve, reject) {\n        var data = {\n            //delimiter: &quot;/&quot;\n        };\n        if (location) {\n            //data.prefix = location;\n        }\n        $.ajax({\n            url: location,\n            data: data,\n            success: function(data) {\n                data = data.replace(/\\\\/g,&quot;/&quot;);\n                var result = null;\n                result = JSON.parse(data);\n                resolve(result);\n            },\n            failure: function(error) {\n                console.log(&quot;failure&quot; + error);\n            }\n        });\n    }\n    );\n}\n\n\nfunction test() {\n    products = [&quot;tiles/15/R/XP/2016/8/4/0/&quot;, &quot;tiles/15/R/XP/2016/7/5/0/&quot;, &quot;tiles/15/R/XP/2016/7/15/0/&quot;, &quot;tiles/15/R/XP/2016/6/5/0/&quot;, &quot;tiles/15/R/XP/2016/6/25/0/&quot;, &quot;tiles/15/R/XP/2016/6/15/0/&quot;];\n    getImages();\n}\nfunction getImages(products) {\n    products.reverse();\n    $(&quot;#imageList&quot;).empty();\n    if (products.length === 0) {\n        showError(&quot;No products found for this tile.&quot;)\n        return;\n    }\n    var targetWidget = document.getElementById(&quot;imageList&quot;);\n    var i = 0;\n    var row = targetWidget.insertRow();\n    function next() {\n        getListPromise(products[i]).then(function(data) {\n            var cell = row.insertCell();\n            getPreview($(cell), products[i], data);\n            if (i == 5)\n                row = targetWidget.insertRow();\n            i++;\n            if (i &lt; products.length)\n                next();\n            else\n                showStatus(&quot;Done.&quot;)\n        });\n    }\n    next();\n}\nfunction getPreview(targetWidget, currentLocation, data) {\n\n    var files = data.Contents;\n    var lastKey;\n    for (var i = 0; i &lt; files.length; i++) {\n        var path = files[i].Key;\n        lastKey = path;\n        var name = path.substring(currentLocation.length).replace(/\\/$/, &quot;&quot;);\n        if (name === &#39;preview.jpg&#39;) {\n            targetWidget.append(createImageAnchor(name, path));\n            var date = getDateFromPath(currentLocation);\n            targetWidget.append(&#39;&lt;br&gt;&#39;);\n            targetWidget.append(createDirectoryAnchor(date, currentLocation));\n            targetWidget.append(&#39;&lt;br&gt;&#39;);\n        }\n    }\n}\nfunction getDateFromPath(path) {\n    var locationParts = path.split(&#39;/&#39;);\n    return locationParts[4] + &#39;-&#39; + locationParts[5] + &#39;-&#39; + locationParts[6];\n}\nfunction createImageAnchor(title, location) {\n    return $(&quot;&lt;img&gt;&quot;, {\n        src: baseUrl + &quot;/&quot; + location\n    }).html(title);\n}\nfunction createDirectoryAnchor(title, location) {\n    return $(&quot;&lt;a&gt;&quot;, {\n        target: &quot;_blank&quot;,\n        href: webBaseUrl + &quot;/&quot; + location\n    }).html(title);\n}\n\njQuery(document).ready(function() { \n    start();\n });\n\n\n\n\n\n&lt;/script&gt;\n&lt;br/&gt;\n&lt;br/&gt;]]&gt;&lt;/text&gt;\n            &lt;bgColor&gt;ffd3dfe1&lt;/bgColor&gt;\n        &lt;/BalloonStyle&gt;\n    &lt;/Style&gt;\n    &lt;Placemark&gt;\n        &lt;name&gt;50TLK&lt;/name&gt;\n        &lt;description&gt;1&lt;/description&gt;\n        &lt;styleUrl&gt;#sentinelTile&lt;/styleUrl&gt;\n        &lt;Style&gt;\n            &lt;LineStyle&gt;\n                &lt;color&gt;ff00ff08&lt;/color&gt;\n                &lt;width&gt;1&lt;/width&gt;\n            &lt;/LineStyle&gt;\n            &lt;PolyStyle&gt;\n                &lt;fill&gt;0&lt;/fill&gt;\n            &lt;/PolyStyle&gt;\n        &lt;/Style&gt;\n        &lt;Polygon&gt;\n            &lt;tessellate&gt;1&lt;/tessellate&gt;\n            &lt;outerBoundaryIs&gt;\n                &lt;LinearRing&gt;\n                    &lt;coordinates&gt;\n                        114.669349,39.638218,0 115.948551,39.656848,0 115.933185,40.645929,0 114.635319,40.62664,0 114.669349,39.638218,0 \n                    &lt;/coordinates&gt;\n                &lt;/LinearRing&gt;\n            &lt;/outerBoundaryIs&gt;\n        &lt;/Polygon&gt;\n    &lt;/Placemark&gt;\n    &lt;Placemark&gt;\n        &lt;name&gt;49SCU&lt;/name&gt;\n        &lt;description&gt;1&lt;/description&gt;\n        &lt;styleUrl&gt;#sentinelTile&lt;/styleUrl&gt;\n        &lt;Style&gt;\n            &lt;LineStyle&gt;\n                &lt;color&gt;ff00ff08&lt;/color&gt;\n                &lt;width&gt;1&lt;/width&gt;\n            &lt;/LineStyle&gt;\n            &lt;PolyStyle&gt;\n                &lt;fill&gt;0&lt;/fill&gt;\n            &lt;/PolyStyle&gt;\n        &lt;/Style&gt;\n        &lt;Polygon&gt;\n            &lt;tessellate&gt;1&lt;/tessellate&gt;\n            &lt;outerBoundaryIs&gt;\n                &lt;LinearRing&gt;\n                    &lt;coordinates&gt;\n                        108.828503,34.233687,0 110.020408,34.249008,0 110.00865,35.239018,0 108.802458,35.223125,0 108.828503,34.233687,0 \n                    &lt;/coordinates&gt;\n                &lt;/LinearRing&gt;\n            &lt;/outerBoundaryIs&gt;\n        &lt;/Polygon&gt;\n    &lt;/Placemark&gt;\n    &lt;Placemark&gt;\n        &lt;name&gt;48MVU&lt;/name&gt;\n        &lt;description&gt;10&lt;/description&gt;\n        &lt;styleUrl&gt;#sentinelTile&lt;/styleUrl&gt;\n        &lt;Style&gt;\n            &lt;LineStyle&gt;\n                &lt;color&gt;ff00ff2f&lt;/color&gt;\n                &lt;width&gt;1&lt;/width&gt;\n            &lt;/LineStyle&gt;\n            &lt;PolyStyle&gt;\n                &lt;fill&gt;0&lt;/fill&gt;\n            &lt;/PolyStyle&gt;\n        &lt;/Style&gt;\n        &lt;Polygon&gt;\n            &lt;tessellate&gt;1&lt;/tessellate&gt;\n            &lt;outerBoundaryIs&gt;\n                &lt;LinearRing&gt;\n                    &lt;coordinates&gt;\n                        104.095366,-6.420715,0 105.088261,-6.421506,0 105.088103,-5.428219,0 104.096981,-5.427551,0 104.095366,-6.420715,0 \n                    &lt;/coordinates&gt;\n                &lt;/LinearRing&gt;\n            &lt;/outerBoundaryIs&gt;\n        &lt;/Polygon&gt;\n    &lt;/Placemark&gt;\n    &lt;Placemark&gt;\n        &lt;name&gt;43NBE&lt;/name&gt;\n        &lt;description&gt;45&lt;/description&gt;\n        &lt;styleUrl&gt;#sentinelTile&lt;/styleUrl&gt;\n        &lt;Style&gt;\n            &lt;LineStyle&gt;\n                &lt;color&gt;ff00ffc3&lt;/color&gt;\n                &lt;width&gt;1&lt;/width&gt;\n            &lt;/LineStyle&gt;\n            &lt;PolyStyle&gt;\n                &lt;fill&gt;0&lt;/fill&gt;\n            &lt;/PolyStyle&gt;\n        &lt;/Style&gt;\n        &lt;Polygon&gt;\n            &lt;tessellate&gt;1&lt;/tessellate&gt;\n            &lt;outerBoundaryIs&gt;\n                &lt;LinearRing&gt;\n                    &lt;coordinates&gt;\n                        72.29971399999999,3.526642,0 73.28757,3.528996,0 73.285493,4.521894,0 72.296443,4.518876,0 72.29971399999999,3.526642,0 \n                    &lt;/coordinates&gt;\n                &lt;/LinearRing&gt;\n            &lt;/outerBoundaryIs&gt;\n        &lt;/Polygon&gt;\n    &lt;/Placemark&gt;\n    &lt;Placemark&gt;\n        &lt;name&gt;39PZP&lt;/name&gt;\n        &lt;description&gt;44&lt;/description&gt;\n        &lt;styleUrl&gt;#sentinelTile&lt;/styleUrl&gt;\n        &lt;Style&gt;\n            &lt;LineStyle&gt;\n                &lt;color&gt;ff00ffbf&lt;/color&gt;\n                &lt;width&gt;1&lt;/width&gt;\n            &lt;/LineStyle&gt;\n            &lt;PolyStyle&gt;\n                &lt;fill&gt;0&lt;/fill&gt;\n            &lt;/PolyStyle&gt;\n        &lt;/Style&gt;\n        &lt;Polygon&gt;\n            &lt;tessellate&gt;1&lt;/tessellate&gt;\n            &lt;outerBoundaryIs&gt;\n                &lt;LinearRing&gt;\n                    &lt;coordinates&gt;\n                        53.751278,11.658428,0 54.757004,11.647043,0 54.770939,12.637842,0 53.761497,12.650225,0 53.751278,11.658428,0 \n                    &lt;/coordinates&gt;\n                &lt;/LinearRing&gt;\n            &lt;/outerBoundaryIs&gt;\n        &lt;/Polygon&gt;\n    &lt;/Placemark&gt;\n    &lt;Placemark id=&quot;07B272AF3F09A58FC4E4&quot;&gt;\n        &lt;name&gt;51RTQ&lt;/name&gt;\n        &lt;description&gt;25&lt;/description&gt;\n        &lt;styleUrl&gt;#sentinelTile&lt;/styleUrl&gt;\n        &lt;Style&gt;\n            &lt;LineStyle&gt;\n                &lt;color&gt;ff00ff6e&lt;/color&gt;\n                &lt;width&gt;1&lt;/width&gt;\n            &lt;/LineStyle&gt;\n            &lt;PolyStyle&gt;\n                &lt;fill&gt;0&lt;/fill&gt;\n            &lt;/PolyStyle&gt;\n        &lt;/Style&gt;\n        &lt;Polygon&gt;\n            &lt;tessellate&gt;1&lt;/tessellate&gt;\n            &lt;outerBoundaryIs&gt;\n                &lt;LinearRing&gt;\n                    &lt;coordinates&gt;\n                        119.870825,30.607154,0 121.015281,30.629668,0 120.994556,31.619796,0 119.838188,31.596391,0 119.870825,30.607154,0 \n                    &lt;/coordinates&gt;\n                &lt;/LinearRing&gt;\n            &lt;/outerBoundaryIs&gt;\n        &lt;/Polygon&gt;\n    &lt;/Placemark&gt;\n\n        &lt;Placemark&gt;\n        &lt;name&gt;51TWL&lt;/name&gt;\n        &lt;description&gt;19&lt;/description&gt;\n        &lt;styleUrl&gt;#sentinelTile&lt;/styleUrl&gt;\n        &lt;Style&gt;\n            &lt;LineStyle&gt;\n                &lt;color&gt;ff00ff55&lt;/color&gt;\n                &lt;width&gt;1&lt;/width&gt;\n            &lt;/LineStyle&gt;\n            &lt;PolyStyle&gt;\n                &lt;fill&gt;0&lt;/fill&gt;\n            &lt;/PolyStyle&gt;\n        &lt;/Style&gt;\n        &lt;Polygon&gt;\n            &lt;tessellate&gt;1&lt;/tessellate&gt;\n            &lt;outerBoundaryIs&gt;\n                &lt;LinearRing&gt;\n                    &lt;coordinates&gt;\n                        122.999742,46.053574,0 124.418904,46.044766,0 124.394254,45.056749,0 122.999746,45.06526000000001,0 122.999742,46.053574,0 \n                    &lt;/coordinates&gt;\n                &lt;/LinearRing&gt;\n            &lt;/outerBoundaryIs&gt;\n        &lt;/Polygon&gt;\n    &lt;/Placemark&gt;\n\n\n&lt;/Document&gt;\n&lt;/kml&gt;\n</code></pre>\n');
INSERT INTO `tbl_archive` VALUES ('83', '0', 'centos6.5系统下kdump工具的安装和使用', '8', '2019-02-11 19:38:05', 'https://blog.csdn.net/Tostick/article/details/783571171安装kdump1.1安装kdump工具yuminstallkexec-tools1.2配置grubvi/boot/grub/grub.conf在quiet后面添加crashkernel=256M，如下图所示1.3重启系统reboot1.4查看kdump服务1）查看服务状态servicekd', null, '0', '33', null, null, '2019-02-11 19:38:05', '2019-02-11 19:39:24', null, null, '0', '0', '0', '0', 'https://blog.csdn.net/Tostick/article/details/78357117\n\n1 安装kdump\n-----\n1.1 安装kdump工具\n-------\nyum install kexec-tools\n\n \n1.2 配置grub\n------\nvi /boot/grub/grub.conf\n\n在quiet后面添加 crashkernel=256M，如下图所示\n\n\n1.3重启系统\n------\nreboot\n1.4 查看kdump服务\n----\n1）查看服务状态 service kdump status\n\n如果没启动，则启动service kdump start\n\n2）查看是否开机自启动 chkconfig --list | grep kdump\n\n如果没加入启动项则加入启动项，chkconfig kdump on\n1.5 强制挂死linux系统\n\necho c > /proc/sysrq-trigger\n1.6 查看是否生成core文件（默认文件目录为/var/crash）\n----\n2 crash调试\n-----\n2.1 安装crash工具\n-----\nyum -y install crash\n\n2.2 安装kernel-debuginfo包\n---\n下面的包可在10.18.*.*服务器中获取（\\\\10.18.*.*\\software\\其他\\内核debug包\\centos6.5 x64）或者网上下载\n\n\n2.3 执行crash命令\n----\ncrash /usr/lib/debug/lib/modules/2.6.32-431.el6.x86_64/vmlinux /var/crash/127.0.0.1-2016-07-22-10\\:03\\:46/vmcore\n\n2.4查看堆栈\n----\n', '0', '<p><a href=\"https://blog.csdn.net/Tostick/article/details/78357117\">https://blog.csdn.net/Tostick/article/details/78357117</a></p>\n<h2 id=\"h2-1-kdump\"><a name=\"1 安装kdump\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1 安装kdump</h2><h2 id=\"h2-1-1-kdump-\"><a name=\"1.1 安装kdump工具\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.1 安装kdump工具</h2><p>yum install kexec-tools</p>\n<h2 id=\"h2-1-2-grub\"><a name=\"1.2 配置grub\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.2 配置grub</h2><p>vi /boot/grub/grub.conf</p>\n<p>在quiet后面添加 crashkernel=256M，如下图所示</p>\n<h2 id=\"h2-1-3-\"><a name=\"1.3重启系统\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.3重启系统</h2><p>reboot</p>\n<h2 id=\"h2-1-4-kdump-\"><a name=\"1.4 查看kdump服务\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.4 查看kdump服务</h2><p>1）查看服务状态 service kdump status</p>\n<p>如果没启动，则启动service kdump start</p>\n<p>2）查看是否开机自启动 chkconfig —list | grep kdump</p>\n<p>如果没加入启动项则加入启动项，chkconfig kdump on<br>1.5 强制挂死linux系统</p>\n<p>echo c &gt; /proc/sysrq-trigger</p>\n<h2 id=\"h2-1-6-core-var-crash-\"><a name=\"1.6 查看是否生成core文件（默认文件目录为/var/crash）\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.6 查看是否生成core文件（默认文件目录为/var/crash）</h2><h2 id=\"h2-2-crash-\"><a name=\"2 crash调试\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2 crash调试</h2><h2 id=\"h2-2-1-crash-\"><a name=\"2.1 安装crash工具\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.1 安装crash工具</h2><p>yum -y install crash</p>\n<h2 id=\"h2-2-2-kernel-debuginfo-\"><a name=\"2.2 安装kernel-debuginfo包\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.2 安装kernel-debuginfo包</h2><p>下面的包可在10.18.<em>.</em>服务器中获取（\\10.18.<em>.</em>\\software\\其他\\内核debug包\\centos6.5 x64）或者网上下载</p>\n<h2 id=\"h2-2-3-crash-\"><a name=\"2.3 执行crash命令\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.3 执行crash命令</h2><p>crash /usr/lib/debug/lib/modules/2.6.32-431.el6.x86_64/vmlinux /var/crash/127.0.0.1-2016-07-22-10\\:03\\:46/vmcore</p>\n<h2 id=\"h2-2-4-\"><a name=\"2.4查看堆栈\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.4查看堆栈</h2>');
INSERT INTO `tbl_archive` VALUES ('84', '0', '配置flutter 遇到的问题及解决办法', '8', '2019-02-12 18:47:23', 'https://blog.csdn.net/liy010/article/details/82078484我是在windows环境下安装的。1.从官网下载压缩包  https://flutter.io/sdk-archive/#windows解压放在你某一个目录下（我的是C:\\aplication\\，目录建的时候名字写错了），这个目录就相当于flutter的安装目录。然后配置环境变量。2.安装An', null, '0', '37', null, null, '2019-02-12 18:47:23', null, null, null, '0', '0', '0', '0', 'https://blog.csdn.net/liy010/article/details/82078484\n我是在windows环境下安装的。\n\n1. 从官网下载压缩包  https://flutter.io/sdk-archive/#windows\n\n解压放在你某一个目录下（我的是C:\\aplication\\， 目录建的时候名字写错了）， 这个目录就相当于flutter的安装目录。然后配置环境变量。\n\n2.安装 AndroidStutio https://developer.android.com/studio/  我在安装完成之后没有SDK， 导致接下来有很多问题。\n\n3. 在cmd下  执行\n\n> flutter doctor\n  （这是花了最长时间的）；\n\n\n\n首先解决第一个  X Android license status unknown.\n\nhttps://www.liangzl.com/get-article-detail-1443.html     在这个链接下找到了解决办法，执行\n\n> flutter doctor --android-licenses\n但是则需要翻墙。接下来我们来配置代理。我用的 shadowsocks 已经实现了翻墙， 执行\n\n> set http_proxy=http://127.0.0.1:1080\n> set https_proxy=http://127.0.0.1:1080\n配置cmd的代理。执行\n\n> flutter doctor --android-licenses\n 出现了下面的问题\n\n \n\nWarning: An error occurred during installation: Failed to move away or delete existing target file: C:\\aplication\\SDK\\tools \n\n 我在   https://stackoverflow.com/questions/49306527/failed-to-move-away-or-delete-existing-target-c-androidsdk-sdk-tools\n\n下面，找到了解决办法， 首先进入SDK的安装目录， 我的是C:\\aplication\\SDK（有些人可能没有， 比如我就是， 文章下面有解决办法）；\n\n找到tools文件夹， 把他重命名成tool， cmd下执行\n\nC:\\aplication\\SDK\\tool\\bin\\sdkmanager --update\n\n\n 上面两个Warning不要管他。 执行结束后会有done。 此时SDK目录会新增一个tools，把tools里的所有文件移到tool里， 有重复， 全部选替换， 接着把tools改为tools。\n\n现在解决没有SDK的问题\n\n（这个会在flutter doctor时 提示： 如 （这两个是网上的错误信息， 我的当时没截图）\n\n[X] Android toolchain - develop for Android devices\n    X ANDROID_HOME = C:\\Users\\Name\\AppData\\Local\\Android\\sdk\\Android\n      but Android SDK not found at this location.\n或    有 SDK tools directory is missing  ）。\n\n在   http://www.androiddevtools.cn/  下载SDK tools\n\n\n\n 之后安装，上面会有默认的选项，就直接点安装，可以配置代理， 下载更快。 之后就是配置环境变量。\n\n\n\n \n\n 这样就完成了。\n\n接下来解决这个：\n\n X Flutter plugin not installed; this adds Flutter specific functionality.\n X Dart plugin not installed; this adds Dart specific functionality.\n\n打开AndroidStudio 在主界面， 也就是下面这个， 点击configure\n\n\n\n \n\n \n\n 搜索， Dart，flutter， 安装\n\n\n\n 成功。No  devices available  是我还没连接设备。\n--------------------- \n作者：liy010 \n来源：CSDN \n原文：https://blog.csdn.net/liy010/article/details/82078484 \n版权声明：本文为博主原创文章，转载请附上博文链接！', '0', '<p><a href=\"https://blog.csdn.net/liy010/article/details/82078484\">https://blog.csdn.net/liy010/article/details/82078484</a><br>我是在windows环境下安装的。</p>\n<ol>\n<li>从官网下载压缩包  <a href=\"https://flutter.io/sdk-archive/#windows\">https://flutter.io/sdk-archive/#windows</a></li></ol>\n<p>解压放在你某一个目录下（我的是C:\\aplication\\， 目录建的时候名字写错了）， 这个目录就相当于flutter的安装目录。然后配置环境变量。</p>\n<p>2.安装 AndroidStutio <a href=\"https://developer.android.com/studio/\">https://developer.android.com/studio/</a>  我在安装完成之后没有SDK， 导致接下来有很多问题。</p>\n<ol>\n<li>在cmd下  执行</li></ol>\n<blockquote>\n<p>flutter doctor<br>  （这是花了最长时间的）；</p>\n</blockquote>\n<p>首先解决第一个  X Android license status unknown.</p>\n<p><a href=\"https://www.liangzl.com/get-article-detail-1443.html\">https://www.liangzl.com/get-article-detail-1443.html</a>     在这个链接下找到了解决办法，执行</p>\n<blockquote>\n<p>flutter doctor —android-licenses<br>但是则需要翻墙。接下来我们来配置代理。我用的 shadowsocks 已经实现了翻墙， 执行</p>\n<p>set http_proxy=<a href=\"http://127.0.0.1:1080\">http://127.0.0.1:1080</a><br>set https_proxy=<a href=\"http://127.0.0.1:1080\">http://127.0.0.1:1080</a><br>配置cmd的代理。执行</p>\n<p>flutter doctor —android-licenses<br> 出现了下面的问题</p>\n</blockquote>\n<p>Warning: An error occurred during installation: Failed to move away or delete existing target file: C:\\aplication\\SDK\\tools </p>\n<p> 我在   <a href=\"https://stackoverflow.com/questions/49306527/failed-to-move-away-or-delete-existing-target-c-androidsdk-sdk-tools\">https://stackoverflow.com/questions/49306527/failed-to-move-away-or-delete-existing-target-c-androidsdk-sdk-tools</a></p>\n<p>下面，找到了解决办法， 首先进入SDK的安装目录， 我的是C:\\aplication\\SDK（有些人可能没有， 比如我就是， 文章下面有解决办法）；</p>\n<p>找到tools文件夹， 把他重命名成tool， cmd下执行</p>\n<p>C:\\aplication\\SDK\\tool\\bin\\sdkmanager —update</p>\n<p> 上面两个Warning不要管他。 执行结束后会有done。 此时SDK目录会新增一个tools，把tools里的所有文件移到tool里， 有重复， 全部选替换， 接着把tools改为tools。</p>\n<p>现在解决没有SDK的问题</p>\n<p>（这个会在flutter doctor时 提示： 如 （这两个是网上的错误信息， 我的当时没截图）</p>\n<p>[X] Android toolchain - develop for Android devices<br>    X ANDROID_HOME = C:\\Users\\Name\\AppData\\Local\\Android\\sdk\\Android<br>      but Android SDK not found at this location.<br>或    有 SDK tools directory is missing  ）。</p>\n<p>在   <a href=\"http://www.androiddevtools.cn/\">http://www.androiddevtools.cn/</a>  下载SDK tools</p>\n<p> 之后安装，上面会有默认的选项，就直接点安装，可以配置代理， 下载更快。 之后就是配置环境变量。</p>\n<p> 这样就完成了。</p>\n<p>接下来解决这个：</p>\n<p> X Flutter plugin not installed; this adds Flutter specific functionality.<br> X Dart plugin not installed; this adds Dart specific functionality.</p>\n<p>打开AndroidStudio 在主界面， 也就是下面这个， 点击configure</p>\n<p> 搜索， Dart，flutter， 安装</p>\n<h2 id=\"h2--no-devices-available-\"><a name=\"成功。No  devices available  是我还没连接设备。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span> 成功。No  devices available  是我还没连接设备。</h2><p>作者：liy010<br>来源：CSDN<br>原文：<a href=\"https://blog.csdn.net/liy010/article/details/82078484\">https://blog.csdn.net/liy010/article/details/82078484</a><br>版权声明：本文为博主原创文章，转载请附上博文链接！</p>\n');
INSERT INTO `tbl_archive` VALUES ('85', '0', 'Hadoop NameNode HA 节点故障恢复', '8', '2019-02-19 18:04:17', '1.关闭cloud01的NameNode节点，ActiveNameNode切换到cloud02--------------2.后台停止并卸载cloud01的NameNode和zkFailover组件。--------------curl-uadmin:admin-H\"X-Requested-By:ambari\"-XDELETEhttp://cloud01:8080/api/v1/clusters/', null, '0', '51', null, null, '2019-02-19 18:04:17', '2019-02-20 13:03:07', null, null, '0', '0', '0', '0', '# Hadoop NameNode HA 节点故障恢复流程\n1.备份namenode1上的配置文件和元数据。\n2.重装namenode1操作系统,配置主机名，时间，IP，防火墙，JDK，Repo 源\n3.安装Ambari-Agent 并注册到 Ambari-Server 中。\n4.在Ambari命令中卸载namenode1的 NameNode,zkFailover,Journalnode组件。\n5.在Ambari命令中安装namenode1的 NameNode,zkFailover,Journalnode组件。\n6.在Ambari命令中启动namenode1的 zkFailover,Journalnode组件。\n7.集群进入安全模式，在namenode2生成 checkpoint，同步到namenode1 目录.\n8.初始化namenode1 上的 SharedEdits 和 bootstrapStandby。\n9.在Ambari命令中启动namenode1的 namenode 组件并保持在备用状态。\n10.检查namenode 1 组件状态并检查和 namenode2 元数据是否保持一致。\n推出集群安全模式，确认恢复成功。\n\n执行细节\n1.关闭cloud01 的  NameNode 节点，Active NameNode 切换到 cloud02\n--------------\n2.后台停止并卸载cloud01 的 NameNode 和  zkFailover 组件。\n--------------\ncurl -u admin:admin -H \"X-Requested-By: ambari\" -X DELETE  http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/ZKFC\ncurl -u admin:admin -H \"X-Requested-By: ambari\" -X DELETE  http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/NAMENODE\ncurl -u admin:admin -H \"X-Requested-By: ambari\" -X DELETE  http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/JOURNALNODE\n\n在重装机器的节点上恢复步骤\n---------------\n3.后台安装 cloud01 的 NameNode 和 zkFailover 组件。\n主要是先安装 Journalnode、zkFailover、Namenode，安装完之后，可以先启动 zkFailover，其它两个可以先不启动。\n下面的步骤主要是为了同步 Journalnode 和 Additional Namenode 的数据。\n---------------\ncurl -u admin:admin -H \"X-Requested-By: ambari\" -i -X POST -d \'{\"host_components\" : [{\"HostRoles\":{\"component_name\":\"JOURNALNODE\"}}] }\' http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01\n\ncurl -u admin:admin -H \"X-Requested-By: ambari\" -i -X POST -d \'{\"host_components\" : [{\"HostRoles\":{\"component_name\":\"ZKFC\"}}] }\' http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01\n\ncurl -u admin:admin -H \"X-Requested-By: ambari\" -i -X POST -d \'{\"host_components\" : [{\"HostRoles\":{\"component_name\":\"NAMENODE\"}}] }\' http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01\n\n\n4.重新启用 cloud01 的 NameNode 和 zkFailover 组件。\n生成 checkpoint:\n\n# 在 cloud02 开启只读模式\nhdfs dfsadmin -safemode enter\nhdfs dfsadmin -fs cloud02:8020 -safemode enter\n\n# 在 cloud02 生成 checkpoint\nhdfs dfsadmin -saveNamespace\nhdfs dfsadmin -fs cloud02:8020 -saveNamespace\n \n然后停止 Namenode（2、3 步主要是为了同步新添加回去的 Journalnode 跟其它 Journalnode 状态一致）\n\nreformat jonuralnode\n请确保两个前提：（1）Namenode 已经停止掉；（2）所有的 Journalnode 一定启动\n\n# 在 cloud01 Namenode 的机器上\n将当前 cloud02 Namenode 的所有文件，scp 至新的 Additional Namenode 的对应目录\n\nscp -r /hadoop/hdfs/namenode cloud01:/hadoop/hdfs/\nscp -r /disk/sda/hadoop/hdfs/namenode cloud01:/disk/sda/hadoop/hdfs/\nscp -r /disk/sdb/hadoop/hdfs/namenode cloud01:/disk/sdb/hadoop/hdfs/\nscp -r /disk/sdc/hadoop/hdfs/namenode cloud01:/disk/sdc/hadoop/hdfs/\nscp -r /disk/sdd/hadoop/hdfs/namenode cloud01:/disk/sdd/hadoop/hdfs/\n\nchown -R hdfs:hadoop /hadoop/hdfs/namenode\nchown -R hdfs:hadoop /disk/sda/hadoop/hdfs/namenode\nchown -R hdfs:hadoop /disk/sdb/hadoop/hdfs/namenode\nchown -R hdfs:hadoop /disk/sdc/hadoop/hdfs/namenode\nchown -R hdfs:hadoop /disk/sdd/hadoop/hdfs/namenode\n\n然后启动 Additional Namenode\n在 ActiveNamenode 上执行下面的命令\nhdfs namenode -initializeSharedEdits\nhdfs namenode -bootstrapStandby\n\n在Ambari 中重新启动\n由于操作中涉及了 Namenode 的启停，所以最好操作前将 HBase 服务下线掉，操作完成之后再重新上线\n\n作者：zczhuohuo\n链接：https://www.jianshu.com/p/f273c6e01a04\n來源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n\n参考文档\n----------------\n[Namenode HA恢复](https://www.jianshu.com/p/f273c6e01a04 \"Namenode HA恢复\")\n[记录一次namenode ha中一个namenode失效处理过程](https://blog.csdn.net/BrotherDong90/article/details/80571655 \"记录一次namenode ha中一个namenode失效处理过程\")\n[HDFS 相关命令](https://www.cnblogs.com/zwgblog/p/6490988.html \"HDFS 相关命令\")\n\n---- bug \nhdfs dfsadmin -safemode 命令在 HA 节点下面无法使用。\n[hdfs@cloud02 root]$ hdfs dfsadmin -safemode \nUsage: hdfs dfsadmin [-safemode enter | leave | get | wait]\n[hdfs@cloud02 root]$ hdfs dfsadmin -safemode get \nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/crh/6.1.2.6-1457/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/crh/6.1.2.6-1457/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nsafemode: Call From cloud02/192.168.0.83 to cloud01:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused', '0', '<h1 id=\"h1-hadoop-namenode-ha-\"><a name=\"Hadoop NameNode HA 节点故障恢复流程\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Hadoop NameNode HA 节点故障恢复流程</h1><p>1.备份namenode1上的配置文件和元数据。<br>2.重装namenode1操作系统,配置主机名，时间，IP，防火墙，JDK，Repo 源<br>3.安装Ambari-Agent 并注册到 Ambari-Server 中。<br>4.在Ambari命令中卸载namenode1的 NameNode,zkFailover,Journalnode组件。<br>5.在Ambari命令中安装namenode1的 NameNode,zkFailover,Journalnode组件。<br>6.在Ambari命令中启动namenode1的 zkFailover,Journalnode组件。<br>7.集群进入安全模式，在namenode2生成 checkpoint，同步到namenode1 目录.<br>8.初始化namenode1 上的 SharedEdits 和 bootstrapStandby。<br>9.在Ambari命令中启动namenode1的 namenode 组件并保持在备用状态。<br>10.检查namenode 1 组件状态并检查和 namenode2 元数据是否保持一致。<br>推出集群安全模式，确认恢复成功。</p>\n<p>执行细节</p>\n<h2 id=\"h2-1-cloud01-namenode-active-namenode-cloud02\"><a name=\"1.关闭cloud01 的  NameNode 节点，Active NameNode 切换到 cloud02\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>1.关闭cloud01 的  NameNode 节点，Active NameNode 切换到 cloud02</h2><h2 id=\"h2-2-cloud01-namenode-zkfailover-\"><a name=\"2.后台停止并卸载cloud01 的 NameNode 和  zkFailover 组件。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>2.后台停止并卸载cloud01 的 NameNode 和  zkFailover 组件。</h2><p>curl -u admin:admin -H “X-Requested-By: ambari” -X DELETE  <a href=\"http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/ZKFC\">http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/ZKFC</a><br>curl -u admin:admin -H “X-Requested-By: ambari” -X DELETE  <a href=\"http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/NAMENODE\">http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/NAMENODE</a><br>curl -u admin:admin -H “X-Requested-By: ambari” -X DELETE  <a href=\"http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/JOURNALNODE\">http://cloud01:8080/api/v1/clusters/redoop/hosts/cloud01/host_components/JOURNALNODE</a></p>\n<h2 id=\"h2-u5728u91CDu88C5u673Au5668u7684u8282u70B9u4E0Au6062u590Du6B65u9AA4\"><a name=\"在重装机器的节点上恢复步骤\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在重装机器的节点上恢复步骤</h2><p>3.后台安装 cloud01 的 NameNode 和 zkFailover 组件。<br>主要是先安装 Journalnode、zkFailover、Namenode，安装完之后，可以先启动 zkFailover，其它两个可以先不启动。</p>\n<h2 id=\"h2--journalnode-additional-namenode-\"><a name=\"下面的步骤主要是为了同步 Journalnode 和 Additional Namenode 的数据。\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>下面的步骤主要是为了同步 Journalnode 和 Additional Namenode 的数据。</h2><p>curl -u admin:admin -H “X-Requested-By: ambari” -i -X POST -d ‘{“host_components” : [{“HostRoles”:{“component_name”:”JOURNALNODE”}}] }’ <a href=\"http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01\">http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01</a></p>\n<p>curl -u admin:admin -H “X-Requested-By: ambari” -i -X POST -d ‘{“host_components” : [{“HostRoles”:{“component_name”:”ZKFC”}}] }’ <a href=\"http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01\">http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01</a></p>\n<p>curl -u admin:admin -H “X-Requested-By: ambari” -i -X POST -d ‘{“host_components” : [{“HostRoles”:{“component_name”:”NAMENODE”}}] }’ <a href=\"http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01\">http://cloud01:8080/api/v1/clusters/redoop/hosts?Hosts/host_name=cloud01</a></p>\n<p>4.重新启用 cloud01 的 NameNode 和 zkFailover 组件。<br>生成 checkpoint:</p>\n<h1 id=\"h1--cloud02-\"><a name=\"在 cloud02 开启只读模式\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在 cloud02 开启只读模式</h1><p>hdfs dfsadmin -safemode enter<br>hdfs dfsadmin -fs cloud02:8020 -safemode enter</p>\n<h1 id=\"h1--cloud02-checkpoint\"><a name=\"在 cloud02 生成 checkpoint\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在 cloud02 生成 checkpoint</h1><p>hdfs dfsadmin -saveNamespace<br>hdfs dfsadmin -fs cloud02:8020 -saveNamespace</p>\n<p>然后停止 Namenode（2、3 步主要是为了同步新添加回去的 Journalnode 跟其它 Journalnode 状态一致）</p>\n<p>reformat jonuralnode<br>请确保两个前提：（1）Namenode 已经停止掉；（2）所有的 Journalnode 一定启动</p>\n<h1 id=\"h1--cloud01-namenode-\"><a name=\"在 cloud01 Namenode 的机器上\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>在 cloud01 Namenode 的机器上</h1><p>将当前 cloud02 Namenode 的所有文件，scp 至新的 Additional Namenode 的对应目录</p>\n<p>scp -r /hadoop/hdfs/namenode cloud01:/hadoop/hdfs/<br>scp -r /disk/sda/hadoop/hdfs/namenode cloud01:/disk/sda/hadoop/hdfs/<br>scp -r /disk/sdb/hadoop/hdfs/namenode cloud01:/disk/sdb/hadoop/hdfs/<br>scp -r /disk/sdc/hadoop/hdfs/namenode cloud01:/disk/sdc/hadoop/hdfs/<br>scp -r /disk/sdd/hadoop/hdfs/namenode cloud01:/disk/sdd/hadoop/hdfs/</p>\n<p>chown -R hdfs:hadoop /hadoop/hdfs/namenode<br>chown -R hdfs:hadoop /disk/sda/hadoop/hdfs/namenode<br>chown -R hdfs:hadoop /disk/sdb/hadoop/hdfs/namenode<br>chown -R hdfs:hadoop /disk/sdc/hadoop/hdfs/namenode<br>chown -R hdfs:hadoop /disk/sdd/hadoop/hdfs/namenode</p>\n<p>然后启动 Additional Namenode<br>在 ActiveNamenode 上执行下面的命令<br>hdfs namenode -initializeSharedEdits<br>hdfs namenode -bootstrapStandby</p>\n<p>在Ambari 中重新启动<br>由于操作中涉及了 Namenode 的启停，所以最好操作前将 HBase 服务下线掉，操作完成之后再重新上线</p>\n<p>作者：zczhuohuo<br>链接：<a href=\"https://www.jianshu.com/p/f273c6e01a04\">https://www.jianshu.com/p/f273c6e01a04</a><br>來源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n<h2 id=\"h2-u53C2u8003u6587u6863\"><a name=\"参考文档\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>参考文档</h2><p><a href=\"https://www.jianshu.com/p/f273c6e01a04\" title=\"Namenode HA恢复\">Namenode HA恢复</a><br><a href=\"https://blog.csdn.net/BrotherDong90/article/details/80571655\" title=\"记录一次namenode ha中一个namenode失效处理过程\">记录一次namenode ha中一个namenode失效处理过程</a><br><a href=\"https://www.cnblogs.com/zwgblog/p/6490988.html\" title=\"HDFS 相关命令\">HDFS 相关命令</a></p>\n<p>—— bug<br>hdfs dfsadmin -safemode 命令在 HA 节点下面无法使用。<br>[hdfs<a href=\"https://github.com/cloud02\" title=\"&#64;cloud02\" class=\"at-link\">@cloud02</a> root]$ hdfs dfsadmin -safemode<br>Usage: hdfs dfsadmin [-safemode enter | leave | get | wait]<br>[hdfs<a href=\"https://github.com/cloud02\" title=\"&#64;cloud02\" class=\"at-link\">@cloud02</a> root]$ hdfs dfsadmin -safemode get<br>SLF4J: Class path contains multiple SLF4J bindings.<br>SLF4J: Found binding in [jar<img src=\"../plugins/emoji-dialog/emoji/file.png\" class=\"emoji\" title=\"&#58;file&#58;\" alt=\"&#58;file&#58;\" />/usr/crh/6.1.2.6-1457/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]<br>SLF4J: Found binding in [jar<img src=\"../plugins/emoji-dialog/emoji/file.png\" class=\"emoji\" title=\"&#58;file&#58;\" alt=\"&#58;file&#58;\" />/usr/crh/6.1.2.6-1457/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]<br>SLF4J: See <a href=\"http://www.slf4j.org/codes.html#multiple_bindings\">http://www.slf4j.org/codes.html#multiple_bindings</a> for an explanation.<br>SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]<br>safemode: Call From cloud02/192.168.0.83 to cloud01:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  <a href=\"http://wiki.apache.org/hadoop/ConnectionRefused\">http://wiki.apache.org/hadoop/ConnectionRefused</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('86', '0', '差分吸收光谱（differential optical absorption spectroscopy ，DOAS ）技术', '8', '2019-02-20 01:01:46', '差分吸收光谱（differentialopticalabsorptionspectroscopy，DOAS）技术是由德国海德堡大学PLATT和PERNER教授于２０世纪７０年代提出，并将其成功应用于大气痕量气体监测http://www.iup.uni-heidelberg.de/institut/forschung/groups/atmosphere/software', null, '0', '36', null, null, '2019-02-20 01:01:46', '2019-02-22 00:02:16', null, null, '0', '0', '0', '0', '差分吸收光谱（differential optical absorption spectroscopy ，DOAS ）技术是由德国海德堡大学PLATT 和PERNER 教授于２０世纪７０年代提出，并将其成功应用于大气痕量气体监测\n\n\n参考:\n下载地址:\nhttps://doasis.iup.uni-heidelberg.de/bugtracker/projects/doasis/download.php\nhttp://www.iup.uni-heidelberg.de/institut/forschung/groups/atmosphere/software\n\nhttp://www.cas.cn/hzjl/gjjl/hzdt/200602/t20060213_1713597.shtml\n\nhttp://www.doas-bremen.de/air_idoas.htm\n\n[Mobile MAX-DOAS observations of tropospheric trace gases](https://www.atmos-meas-tech.net/3/129/2010/amt-3-129-2010.pdf \"Mobile MAX-DOAS observations of tropospheric trace gases\")\n\nhttp://www.doas-bremen.de/index.html\n\nhttp://www.bic.cas.cn/gjkjxw/201709/t20170915_4614499.html\n', '0', '<p>差分吸收光谱（differential optical absorption spectroscopy ，DOAS ）技术是由德国海德堡大学PLATT 和PERNER 教授于２０世纪７０年代提出，并将其成功应用于大气痕量气体监测</p>\n<p>参考:<br>下载地址:<br><a href=\"https://doasis.iup.uni-heidelberg.de/bugtracker/projects/doasis/download.php\">https://doasis.iup.uni-heidelberg.de/bugtracker/projects/doasis/download.php</a><br><a href=\"http://www.iup.uni-heidelberg.de/institut/forschung/groups/atmosphere/software\">http://www.iup.uni-heidelberg.de/institut/forschung/groups/atmosphere/software</a></p>\n<p><a href=\"http://www.cas.cn/hzjl/gjjl/hzdt/200602/t20060213_1713597.shtml\">http://www.cas.cn/hzjl/gjjl/hzdt/200602/t20060213_1713597.shtml</a></p>\n<p><a href=\"http://www.doas-bremen.de/air_idoas.htm\">http://www.doas-bremen.de/air_idoas.htm</a></p>\n<p><a href=\"https://www.atmos-meas-tech.net/3/129/2010/amt-3-129-2010.pdf\" title=\"Mobile MAX-DOAS observations of tropospheric trace gases\">Mobile MAX-DOAS observations of tropospheric trace gases</a></p>\n<p><a href=\"http://www.doas-bremen.de/index.html\">http://www.doas-bremen.de/index.html</a></p>\n<p><a href=\"http://www.bic.cas.cn/gjkjxw/201709/t20170915_4614499.html\">http://www.bic.cas.cn/gjkjxw/201709/t20170915_4614499.html</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('87', '0', '高分五号载荷介绍', '8', '2019-02-22 00:01:56', '大气痕量气体差分吸收光谱仪(EMI)大气主要温室气体监测仪(GMI)大气气溶胶多角度偏振探测仪(DPC)参考:https://wenku.baidu.com/view/898469f26429647d27284b73f242336c1fb93059.html', null, '0', '18', null, null, '2019-02-22 00:01:56', '2019-02-22 00:02:06', null, null, '0', '0', '0', '0', '大气痕量气体差分吸收光谱仪(EMI)\n大气主要温室气体监测仪(GMI)\n大气气溶胶多角度偏振探测仪(DPC)\n\n参考:\nhttps://wenku.baidu.com/view/898469f26429647d27284b73f242336c1fb93059.html', '0', '<p>大气痕量气体差分吸收光谱仪(EMI)<br>大气主要温室气体监测仪(GMI)<br>大气气溶胶多角度偏振探测仪(DPC)</p>\n<p>参考:<br><a href=\"https://wenku.baidu.com/view/898469f26429647d27284b73f242336c1fb93059.html\">https://wenku.baidu.com/view/898469f26429647d27284b73f242336c1fb93059.html</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('88', '0', ' RasterFrames Computing NDVI', '8', '2019-02-22 00:29:35', 'http://rasterframes.io/apps/ndvi.htmlComputingNDVIHere’sanexampleofcomputingtheNormalizedDifferentialVegetationIndex(NDVI)isastandardizedvegetationindexwhichallowsustogenerateanimagehighlightingdiffer', null, '0', '30', null, null, '2019-02-22 00:29:35', '2019-02-22 00:58:52', null, null, '0', '0', '0', '0', 'http://rasterframes.io/apps/ndvi.html\nComputing NDVI\n![](http://rasterframes.io/images/RasterFramesLogo.png)\nHere’s an example of computing the Normalized Differential Vegetation Index (NDVI) is a standardized vegetation index which allows us to generate an image highlighting differences in relative biomass.\n\n    “An NDVI is often used worldwide to monitor drought, monitor and predict agricultural production, assist in predicting hazardous fire zones, and map desert encroachment. The NDVI is preferred for global vegetation monitoring because it helps to compensate for changing illumination conditions, surface slope, aspect, and other extraneous factors” (Lillesand. Remote sensing and image interpretation. 2004).\n	\n“全球范围内，NDVI通常用于监测干旱、监测和预测农业生产、协助预测危险的火灾区域以及绘制沙漠入侵地图。NDVI是全球植被监测的首选，因为它有助于补偿不断变化的照明条件、地表坡度、坡向和其他外来因素”（Lillesand）。遥感和图像解释。2004）。 \n\n\n```scala\ndef redBand = SinglebandGeoTiff(\"../core/src/test/resources/L8-B4-Elkton-VA.tiff\").projectedRaster.toRF(\"red_band\")\ndef nirBand = SinglebandGeoTiff(\"../core/src/test/resources/L8-B5-Elkton-VA.tiff\").projectedRaster.toRF(\"nir_band\")\n\n// We use `asRF` to indicate we know the structure still conforms to RasterFrame constraints\nval rf = redBand.spatialJoin(nirBand).withColumn(\"ndvi\", normalized_difference($\"red_band\", $\"nir_band\")).asRF\n\nval pr = rf.toRaster($\"ndvi\", 466, 428)\n\nval brownToGreen = ColorRamp(\n  RGBA(166,97,26,255),\n  RGBA(223,194,125,255),\n  RGBA(245,245,245,255),\n  RGBA(128,205,193,255),\n  RGBA(1,133,113,255)\n).stops(128)\n\nval colors = ColorMap.fromQuantileBreaks(pr.tile.histogramDouble(), brownToGreen)\npr.tile.color(colors).renderPng().write(\"target/scala-2.11/tut/apps/rf-ndvi.png\")\n\nFor a georefrenced singleband greyscale image, we could have done this instead:\n\nGeoTiff(pr).write(\"ndvi.tiff\")\n```\n\n\n![](http://rasterframes.io/apps/rf-ndvi.png)', '0', '<p><a href=\"http://rasterframes.io/apps/ndvi.html\">http://rasterframes.io/apps/ndvi.html</a><br>Computing NDVI<br><img src=\"http://rasterframes.io/images/RasterFramesLogo.png\" alt=\"\"><br>Here’s an example of computing the Normalized Differential Vegetation Index (NDVI) is a standardized vegetation index which allows us to generate an image highlighting differences in relative biomass.</p>\n<pre><code>“An NDVI is often used worldwide to monitor drought, monitor and predict agricultural production, assist in predicting hazardous fire zones, and map desert encroachment. The NDVI is preferred for global vegetation monitoring because it helps to compensate for changing illumination conditions, surface slope, aspect, and other extraneous factors” (Lillesand. Remote sensing and image interpretation. 2004).\n</code></pre><p>“全球范围内，NDVI通常用于监测干旱、监测和预测农业生产、协助预测危险的火灾区域以及绘制沙漠入侵地图。NDVI是全球植被监测的首选，因为它有助于补偿不断变化的照明条件、地表坡度、坡向和其他外来因素”（Lillesand）。遥感和图像解释。2004）。 </p>\n<pre><code class=\"lang-scala\">def redBand = SinglebandGeoTiff(&quot;../core/src/test/resources/L8-B4-Elkton-VA.tiff&quot;).projectedRaster.toRF(&quot;red_band&quot;)\ndef nirBand = SinglebandGeoTiff(&quot;../core/src/test/resources/L8-B5-Elkton-VA.tiff&quot;).projectedRaster.toRF(&quot;nir_band&quot;)\n\n// We use `asRF` to indicate we know the structure still conforms to RasterFrame constraints\nval rf = redBand.spatialJoin(nirBand).withColumn(&quot;ndvi&quot;, normalized_difference($&quot;red_band&quot;, $&quot;nir_band&quot;)).asRF\n\nval pr = rf.toRaster($&quot;ndvi&quot;, 466, 428)\n\nval brownToGreen = ColorRamp(\n  RGBA(166,97,26,255),\n  RGBA(223,194,125,255),\n  RGBA(245,245,245,255),\n  RGBA(128,205,193,255),\n  RGBA(1,133,113,255)\n).stops(128)\n\nval colors = ColorMap.fromQuantileBreaks(pr.tile.histogramDouble(), brownToGreen)\npr.tile.color(colors).renderPng().write(&quot;target/scala-2.11/tut/apps/rf-ndvi.png&quot;)\n\nFor a georefrenced singleband greyscale image, we could have done this instead:\n\nGeoTiff(pr).write(&quot;ndvi.tiff&quot;)\n</code></pre>\n<p><img src=\"http://rasterframes.io/apps/rf-ndvi.png\" alt=\"\"></p>\n');
INSERT INTO `tbl_archive` VALUES ('89', '0', 'GeoMesa is a suite of tools for working with big geo-spatial data in a distributed fashion.', '8', '2019-02-22 00:33:37', 'http://geomesa.github.io![](https://raw.githubusercontent.com/geomesa/geomesa.github.io/master/img/geomesa-2x.png)GeoMesaisanopensourcesuiteoftoolsthatenableslarge-scalegeospatialqueryingandanalyticso', null, '0', '21', null, null, '2019-02-22 00:33:37', null, 'https://badges.gitter.im/Join%20Chat.svg', null, '0', '0', '0', '0', 'http://geomesa.github.io\n![](https://raw.githubusercontent.com/geomesa/geomesa.github.io/master/img/geomesa-2x.png)\n\nGeoMesa is an open source suite of tools that enables large-scale geospatial querying and analytics on distributed\ncomputing systems. GeoMesa provides spatio-temporal indexing on top of the Accumulo, HBase, Google Bigtable and\nCassandra databases for massive storage of point, line, and polygon data. GeoMesa also provides near real time\nstream processing of spatio-temporal data by layering spatial semantics on top of Apache Kafka. Through GeoServer,\nGeoMesa facilitates integration with a wide range of existing mapping clients over standard OGC (Open Geospatial\nConsortium) APIs and protocols such as WFS and WMS. GeoMesa supports Apache Spark for custom distributed\ngeospatial analytics.\n\n![](http://www.geomesa.org/img/geomesa-overview-848x250.png)\n\n#### ![LocationTech](https://pbs.twimg.com/profile_images/2552421256/hv2oas84tv7n3maianiq_normal.png) GeoMesa is a member of the [LocationTech](http://www.locationtech.org) working group of the Eclipse Foundation.\n\n## Join the Community\n\n* <a href=\"https://gitter.im/locationtech/geomesa?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\" target=\"_blank\"><img src=\"https://badges.gitter.im/Join%20Chat.svg\" alt=\"Join the chat at https://gitter.im/locationtech/geomesa\"></img></a>\n* GeoMesa [Users](https://locationtech.org/mhonarc/lists/geomesa-users/) and [Dev](https://locationtech.org/mhonarc/lists/geomesa-dev/) mailing lists\n* GeoMesa [JIRA](https://geomesa.atlassian.net/issues/?jql=order+by+created+DESC) for issue tracking\n\n## Documentation\n\n* [Main documentation](http://www.geomesa.org/documentation/)\n* Quick Starts:\n  [HBase](http://www.geomesa.org/documentation/tutorials/geomesa-quickstart-hbase.html) |\n  [Accumulo](http://www.geomesa.org/documentation/tutorials/geomesa-quickstart-accumulo.html) |\n  [Cassandra](http://www.geomesa.org/documentation/tutorials/geomesa-quickstart-cassandra.html) |\n  [Kafka](http://www.geomesa.org/documentation/tutorials/geomesa-quickstart-kafka.html) |\n  [FileSystem](http://www.geomesa.org/documentation/current/tutorials/geomesa-quickstart-fsds.html)\n \n* [Tutorials](http://www.geomesa.org/tutorials/)\n\n## Downloads\n\n**Current release: 2.2.1**\n\n  &nbsp;&nbsp;&nbsp;&nbsp;\n  [**HBase**](https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-hbase_2.11-2.2.1-bin.tar.gz) |\n  [**Accumulo**](https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-accumulo_2.11-2.2.1-bin.tar.gz) |\n  [**Cassandra**](https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-cassandra_2.11-2.2.1-bin.tar.gz) |\n  [**Kafka**](https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-kafka_2.11-2.2.1-bin.tar.gz) |\n  [**FileSystem**](https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-fs_2.11-2.2.1-bin.tar.gz) |\n  [**Bigtable**](https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-bigtable_2.11-2.2.1-bin.tar.gz) |\n  [**Source**](https://github.com/locationtech/geomesa/archive/geomesa_2.11-2.2.1.tar.gz) |\n  [**CheckSums**](https://github.com/locationtech/geomesa/releases/geomesa_2.11-2.2.1)\n\n**Development version: 2.3.0-SNAPSHOT** &nbsp;\n  [![Build Status](https://api.travis-ci.org/locationtech/geomesa.svg?branch=master)](https://travis-ci.org/locationtech/geomesa)\n\n### Verifying Downloads\n\nDownloads hosted on GitHub include SHA-256 hashes and gpg signatures (.asc files). To verify a download using gpg,\nimport the appropriate key:\n\n```bash\n$ gpg2 --keyserver hkp://pool.sks-keyservers.net --recv-keys CD24F317\n```\n\nThen verify the file:\n\n```bash\n$ gpg2 --verify geomesa-accumulo_2.11-2.2.1-bin.tar.gz.asc geomesa-accumulo_2.11-2.2.1-bin.tar.gz\n```\n\nThe keys currently used for signing are:\n\n| Key ID | Name |\n| ------ | ---- |\n| `CD24F317` | Emilio Lahr-Vivaz &lt;elahrvivaz(-at-)ccri.com&gt; |\n| `1E679A56` | James Hughes &lt;jnh5y(-at-)ccri.com&gt; |\n\n### Upgrading\n\nTo upgrade between minor releases of GeoMesa, the versions of all GeoMesa components **must** match. \n\nThis means that the version of the `geomesa-accumulo-distributed-runtime` JAR installed on Accumulo\ntablet servers **must** match the version of the `geomesa-accumulo-gs-plugin` JAR installed in the `WEB-INF/lib`\ndirectory of GeoServer.\n\nSee the [Upgrade Guide](http://www.geomesa.org/documentation/user/upgrade.html) for information on specific version updates.\n\n## Maven Integration\n\nGeoMesa is now hosted on Maven Central. However, it still depends on several third-party libraries only available\nin other repositories. To include GeoMesa in your project, add the following repositories to your pom:\n\n```xml\n<repositories>\n  <repository>\n    <id>boundlessgeo</id>\n    <url>https://repo.boundlessgeo.com/main</url>\n  </repository>\n  <repository>\n    <id>osgeo</id>\n    <url>http://download.osgeo.org/webdav/geotools</url>\n  </repository>\n  <repository>\n    <id>conjars.org</id>\n    <url>http://conjars.org/repo</url>\n  </repository>\n</repositories>\n```\n\nand then include the desired `geomesa-*` dependencies:\n\n```xml\n<dependency>\n  <groupId>org.locationtech.geomesa</groupId>\n  <artifactId>geomesa-utils_2.11</artifactId>\n  <version>2.2.1</version>\n</dependency>\n  ...\n```\n\nTo download from the LocationTech Maven repository (required for older versions), add:\n\n```xml\n<repository>\n  <id>locationtech-releases</id>\n  <url>https://repo.locationtech.org/content/groups/releases</url>\n  <snapshots>\n    <enabled>false</enabled>\n  </snapshots>\n</repository>\n```\n\nFor snapshot integration, add:\n\n```xml\n<repository>\n  <id>geomesa-snapshots</id>\n  <url>https://repo.locationtech.org/content/repositories/geomesa-snapshots</url>\n  <releases>\n    <enabled>false</enabled>\n  </releases>\n  <snapshots>\n    <enabled>true</enabled>\n  </snapshots>\n</repository>\n```\n\n## `sbt` Integration\n\nSimilarly, integration with `sbt` is straightforward:\n\n```scala\n// Add necessary resolvers\nresolvers ++= Seq(\n  \"locationtech-releases\" at \"https://repo.locationtech.org/content/groups/releases\",\n  \"boundlessgeo\" at \"https://repo.boundlessgeo.com/main\",\n  \"osgeo\" at \"http://download.osgeo.org/webdav/geotools\",\n  \"conjars.org\" at \"http://conjars.org/repo\"\n)\n\n// Select desired modules\nlibraryDependencies ++= Seq(\n  \"org.locationtech.geomesa\" %% \"geomesa-utils\" % \"2.2.1\",\n  ...\n)\n```\n\n## Building from Source\n\nRequirements:\n\n* [Git](http://git-scm.com/)\n* [Java JDK 8](http://www.oracle.com/technetwork/java/javase/downloads/index.html)\n* [Apache Maven](http://maven.apache.org/) 3.3.9 or later\n\nUse Git to download the source code. Navigate to the destination directory, then run:\n\n    git clone git@github.com:locationtech/geomesa.git\n    cd geomesa\n\nThe project is managed by Maven. To build, run:\n\n    mvn clean install\n\nThe full build takes quite a while. To speed it up, you may skip tests and use multiple threads. GeoMesa also\nprovides the script `build/mvn`, which is a wrapper around Maven that downloads and runs\n[Zinc](https://github.com/typesafehub/zinc), a fast incremental compiler:\n\n    build/mvn clean install -T8 -DskipTests\n\nIf the Zinc build fails with an error finding \"javac\", try setting the JAVA_HOME\nenvironment variable to point to the root of your JDK.  Example from a Mac:\n\n    JAVA_HOME=\"/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home\" build/mvn clean install\n', '0', '<p><a href=\"http://geomesa.github.io\">http://geomesa.github.io</a><br><img src=\"https://raw.githubusercontent.com/geomesa/geomesa.github.io/master/img/geomesa-2x.png\" alt=\"\"></p>\n<p>GeoMesa is an open source suite of tools that enables large-scale geospatial querying and analytics on distributed<br>computing systems. GeoMesa provides spatio-temporal indexing on top of the Accumulo, HBase, Google Bigtable and<br>Cassandra databases for massive storage of point, line, and polygon data. GeoMesa also provides near real time<br>stream processing of spatio-temporal data by layering spatial semantics on top of Apache Kafka. Through GeoServer,<br>GeoMesa facilitates integration with a wide range of existing mapping clients over standard OGC (Open Geospatial<br>Consortium) APIs and protocols such as WFS and WMS. GeoMesa supports Apache Spark for custom distributed<br>geospatial analytics.</p>\n<p><img src=\"http://www.geomesa.org/img/geomesa-overview-848x250.png\" alt=\"\"></p>\n<h4 id=\"h4--img-src-https-pbs-twimg-com-profile_images-2552421256-hv2oas84tv7n3maianiq_normal-png-alt-locationtech-geomesa-is-a-member-of-the-locationtech-working-group-of-the-eclipse-foundation-\"><a name=\"<img src=\"https://pbs.twimg.com/profile_images/2552421256/hv2oas84tv7n3maianiq_normal.png\" alt=\"LocationTech\"> GeoMesa is a member of the   LocationTech  working group of the Eclipse Foundation.\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><img src=\"https://pbs.twimg.com/profile_images/2552421256/hv2oas84tv7n3maianiq_normal.png\" alt=\"LocationTech\"> GeoMesa is a member of the <a href=\"http://www.locationtech.org\">LocationTech</a> working group of the Eclipse Foundation.</h4><h2 id=\"h2-join-the-community\"><a name=\"Join the Community\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Join the Community</h2><ul>\n<li>&lt;a href=&quot;https://gitter.im/locationtech/geomesa?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://badges.gitter.im/Join%20Chat.svg&quot; alt=&quot;Join the chat at https://gitter.im/locationtech/geomesa&quot;&gt;&lt;/img&gt;&lt;/a&gt;</li><li>GeoMesa <a href=\"https://locationtech.org/mhonarc/lists/geomesa-users/\">Users</a> and <a href=\"https://locationtech.org/mhonarc/lists/geomesa-dev/\">Dev</a> mailing lists</li><li>GeoMesa <a href=\"https://geomesa.atlassian.net/issues/?jql=order+by+created+DESC\">JIRA</a> for issue tracking</li></ul>\n<h2 id=\"h2-documentation\"><a name=\"Documentation\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Documentation</h2><ul>\n<li><a href=\"http://www.geomesa.org/documentation/\">Main documentation</a></li><li><p>Quick Starts:<br><a href=\"http://www.geomesa.org/documentation/tutorials/geomesa-quickstart-hbase.html\">HBase</a> |<br><a href=\"http://www.geomesa.org/documentation/tutorials/geomesa-quickstart-accumulo.html\">Accumulo</a> |<br><a href=\"http://www.geomesa.org/documentation/tutorials/geomesa-quickstart-cassandra.html\">Cassandra</a> |<br><a href=\"http://www.geomesa.org/documentation/tutorials/geomesa-quickstart-kafka.html\">Kafka</a> |<br><a href=\"http://www.geomesa.org/documentation/current/tutorials/geomesa-quickstart-fsds.html\">FileSystem</a></p>\n</li><li><p><a href=\"http://www.geomesa.org/tutorials/\">Tutorials</a></p>\n</li></ul>\n<h2 id=\"h2-downloads\"><a name=\"Downloads\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Downloads</h2><p><strong>Current release: 2.2.1</strong></p>\n<p>  &nbsp;&nbsp;&nbsp;&nbsp;<br>  <a href=\"https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-hbase_2.11-2.2.1-bin.tar.gz\"><strong>HBase</strong></a> |<br>  <a href=\"https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-accumulo_2.11-2.2.1-bin.tar.gz\"><strong>Accumulo</strong></a> |<br>  <a href=\"https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-cassandra_2.11-2.2.1-bin.tar.gz\"><strong>Cassandra</strong></a> |<br>  <a href=\"https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-kafka_2.11-2.2.1-bin.tar.gz\"><strong>Kafka</strong></a> |<br>  <a href=\"https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-fs_2.11-2.2.1-bin.tar.gz\"><strong>FileSystem</strong></a> |<br>  <a href=\"https://github.com/locationtech/geomesa/releases/download/geomesa_2.11-2.2.1/geomesa-bigtable_2.11-2.2.1-bin.tar.gz\"><strong>Bigtable</strong></a> |<br>  <a href=\"https://github.com/locationtech/geomesa/archive/geomesa_2.11-2.2.1.tar.gz\"><strong>Source</strong></a> |<br>  <a href=\"https://github.com/locationtech/geomesa/releases/geomesa_2.11-2.2.1\"><strong>CheckSums</strong></a></p>\n<p><strong>Development version: 2.3.0-SNAPSHOT</strong> &nbsp;<br>  <a href=\"https://travis-ci.org/locationtech/geomesa\"><img src=\"https://api.travis-ci.org/locationtech/geomesa.svg?branch=master\" alt=\"Build Status\"></a></p>\n<h3 id=\"h3-verifying-downloads\"><a name=\"Verifying Downloads\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Verifying Downloads</h3><p>Downloads hosted on GitHub include SHA-256 hashes and gpg signatures (.asc files). To verify a download using gpg,<br>import the appropriate key:</p>\n<pre><code class=\"lang-bash\">$ gpg2 --keyserver hkp://pool.sks-keyservers.net --recv-keys CD24F317\n</code></pre>\n<p>Then verify the file:</p>\n<pre><code class=\"lang-bash\">$ gpg2 --verify geomesa-accumulo_2.11-2.2.1-bin.tar.gz.asc geomesa-accumulo_2.11-2.2.1-bin.tar.gz\n</code></pre>\n<p>The keys currently used for signing are:</p>\n<table>\n<thead>\n<tr>\n<th>Key ID</th>\n<th>Name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>CD24F317</code></td>\n<td>Emilio Lahr-Vivaz &lt;elahrvivaz(-at-)ccri.com&gt;</td>\n</tr>\n<tr>\n<td><code>1E679A56</code></td>\n<td>James Hughes &lt;jnh5y(-at-)ccri.com&gt;</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"h3-upgrading\"><a name=\"Upgrading\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Upgrading</h3><p>To upgrade between minor releases of GeoMesa, the versions of all GeoMesa components <strong>must</strong> match. </p>\n<p>This means that the version of the <code>geomesa-accumulo-distributed-runtime</code> JAR installed on Accumulo<br>tablet servers <strong>must</strong> match the version of the <code>geomesa-accumulo-gs-plugin</code> JAR installed in the <code>WEB-INF/lib</code><br>directory of GeoServer.</p>\n<p>See the <a href=\"http://www.geomesa.org/documentation/user/upgrade.html\">Upgrade Guide</a> for information on specific version updates.</p>\n<h2 id=\"h2-maven-integration\"><a name=\"Maven Integration\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Maven Integration</h2><p>GeoMesa is now hosted on Maven Central. However, it still depends on several third-party libraries only available<br>in other repositories. To include GeoMesa in your project, add the following repositories to your pom:</p>\n<pre><code class=\"lang-xml\">&lt;repositories&gt;\n  &lt;repository&gt;\n    &lt;id&gt;boundlessgeo&lt;/id&gt;\n    &lt;url&gt;https://repo.boundlessgeo.com/main&lt;/url&gt;\n  &lt;/repository&gt;\n  &lt;repository&gt;\n    &lt;id&gt;osgeo&lt;/id&gt;\n    &lt;url&gt;http://download.osgeo.org/webdav/geotools&lt;/url&gt;\n  &lt;/repository&gt;\n  &lt;repository&gt;\n    &lt;id&gt;conjars.org&lt;/id&gt;\n    &lt;url&gt;http://conjars.org/repo&lt;/url&gt;\n  &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre>\n<p>and then include the desired <code>geomesa-*</code> dependencies:</p>\n<pre><code class=\"lang-xml\">&lt;dependency&gt;\n  &lt;groupId&gt;org.locationtech.geomesa&lt;/groupId&gt;\n  &lt;artifactId&gt;geomesa-utils_2.11&lt;/artifactId&gt;\n  &lt;version&gt;2.2.1&lt;/version&gt;\n&lt;/dependency&gt;\n  ...\n</code></pre>\n<p>To download from the LocationTech Maven repository (required for older versions), add:</p>\n<pre><code class=\"lang-xml\">&lt;repository&gt;\n  &lt;id&gt;locationtech-releases&lt;/id&gt;\n  &lt;url&gt;https://repo.locationtech.org/content/groups/releases&lt;/url&gt;\n  &lt;snapshots&gt;\n    &lt;enabled&gt;false&lt;/enabled&gt;\n  &lt;/snapshots&gt;\n&lt;/repository&gt;\n</code></pre>\n<p>For snapshot integration, add:</p>\n<pre><code class=\"lang-xml\">&lt;repository&gt;\n  &lt;id&gt;geomesa-snapshots&lt;/id&gt;\n  &lt;url&gt;https://repo.locationtech.org/content/repositories/geomesa-snapshots&lt;/url&gt;\n  &lt;releases&gt;\n    &lt;enabled&gt;false&lt;/enabled&gt;\n  &lt;/releases&gt;\n  &lt;snapshots&gt;\n    &lt;enabled&gt;true&lt;/enabled&gt;\n  &lt;/snapshots&gt;\n&lt;/repository&gt;\n</code></pre>\n<h2 id=\"h2--code-sbt-code-integration\"><a name=\"<code>sbt</code> Integration\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><code>sbt</code> Integration</h2><p>Similarly, integration with <code>sbt</code> is straightforward:</p>\n<pre><code class=\"lang-scala\">// Add necessary resolvers\nresolvers ++= Seq(\n  &quot;locationtech-releases&quot; at &quot;https://repo.locationtech.org/content/groups/releases&quot;,\n  &quot;boundlessgeo&quot; at &quot;https://repo.boundlessgeo.com/main&quot;,\n  &quot;osgeo&quot; at &quot;http://download.osgeo.org/webdav/geotools&quot;,\n  &quot;conjars.org&quot; at &quot;http://conjars.org/repo&quot;\n)\n\n// Select desired modules\nlibraryDependencies ++= Seq(\n  &quot;org.locationtech.geomesa&quot; %% &quot;geomesa-utils&quot; % &quot;2.2.1&quot;,\n  ...\n)\n</code></pre>\n<h2 id=\"h2-building-from-source\"><a name=\"Building from Source\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Building from Source</h2><p>Requirements:</p>\n<ul>\n<li><a href=\"http://git-scm.com/\">Git</a></li><li><a href=\"http://www.oracle.com/technetwork/java/javase/downloads/index.html\">Java JDK 8</a></li><li><a href=\"http://maven.apache.org/\">Apache Maven</a> 3.3.9 or later</li></ul>\n<p>Use Git to download the source code. Navigate to the destination directory, then run:</p>\n<pre><code>git clone git@github.com:locationtech/geomesa.git\ncd geomesa\n</code></pre><p>The project is managed by Maven. To build, run:</p>\n<pre><code>mvn clean install\n</code></pre><p>The full build takes quite a while. To speed it up, you may skip tests and use multiple threads. GeoMesa also<br>provides the script <code>build/mvn</code>, which is a wrapper around Maven that downloads and runs<br><a href=\"https://github.com/typesafehub/zinc\">Zinc</a>, a fast incremental compiler:</p>\n<pre><code>build/mvn clean install -T8 -DskipTests\n</code></pre><p>If the Zinc build fails with an error finding “javac”, try setting the JAVA_HOME<br>environment variable to point to the root of your JDK.  Example from a Mac:</p>\n<pre><code>JAVA_HOME=&quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home&quot; build/mvn clean install\n</code></pre>');
INSERT INTO `tbl_archive` VALUES ('90', '0', 'GeoWave provides geospatial and temporal indexing on top of Accumulo, HBase, BigTable, Cassandra, and DynamoDB', '8', '2019-02-22 00:35:42', 'http://locationtech.github.io/geowave/![](https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/geowave-index/images/geowave-logo-transluscent.png)##About|ContinuousIntegration|Li', null, '0', '19', null, null, '2019-02-22 00:35:42', '2019-02-22 00:39:34', 'https://travis-ci.org/locationtech/geowave.svg?branch=master', null, '0', '0', '0', '0', 'http://locationtech.github.io/geowave/\n\n![](https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/geowave-index/images/geowave-logo-transluscent.png)\n\n\n## About  \n\n| Continuous Integration | License | Chat |            \n|:------------------:|:-------:|:----:| \n| <a href=\"https://travis-ci.org/locationtech/geowave/branches\"><img alt=\"Travis-CI test status\" src=\"https://travis-ci.org/locationtech/geowave.svg?branch=master\"/></a> | [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0) | [![Join the chat at https://gitter.im/locationtech/geowave](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/locationtech/geowave?utm_source=badge&utm_medium=badge&utm_content=badge) |  \n\nGeoWave is an open source set of software that:\n\n* Capabilities\n  * Adds multi-dimensional indexing capability to key-value stores (currently [Apache Accumulo](https://accumulo.apache.org), [Apache HBase](https://hbase.apache.org), [Apache Cassandra](http://cassandra.apache.org/), [AmazonDynamoDB](https://aws.amazon.com/dynamodb/), [Cloud BigTable](https://cloud.google.com/bigtable/), [Redis](https://redis.io/), and [RocksDB](https://rocksdb.org/))\n  * Adds support for geographic objects and geospatial operators to these stores\n  * Provides Map-Reduce input and output formats for distributed processing and analysis of geospatial data\n* Geospatial software plugins\n  * [GeoServer](http://geoserver.org/) plugin to allow geospatial data in various key-value stores to be shared and visualized via OGC standard services\n  * [PDAL](http://www.pdal.io/) plugin for working with point cloud data\n  * [Mapnik](http://mapnik.org/) plugin for generating map tiles and generally making good looking maps. \n  \nBasically, GeoWave is working to bridge geospatial software with modern key-value stores and distributed compute systems.\n\n## The Docs\n* Check out our [GeoWave io page](http://locationtech.github.io/geowave/) page for detailed documentation.\n* A [changelog is available](http://locationtech.github.io/geowave/changelog.html) which details the changes and features for each of our [github releases](https://github.com/locationtech/geowave/releases)\n* The underlying principles employed in GeoWave are outlined in recent academic publications to include largely the background theory in [Advances in Spatial and Temporal Databases 2017](https://link.springer.com/chapter/10.1007/978-3-319-64367-0_6) and a derivative, more applied paper in [FOSS4G Conference Proceedings 2017](http://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1027&context=foss4g).\n\n## The Software\n* We have a [RPM repository](http://locationtech.github.io/geowave/packages.html)\n  * See [Documentation: Installation from RPM](http://locationtech.github.io/geowave/devguide.html#installation-from-rpm) for more info.\n  * Deb packages if enough people request them\n* We have [Maven artifact repositories](http://locationtech.github.io/geowave/devguide.html#maven-pom-fragments) (indexes not enabled, but it works in a maven repo fragment)\n  * Releases: http://geowave-maven.s3-website-us-east-1.amazonaws.com/release\n  * Snapshots: http://geowave-maven.s3-website-us-east-1.amazonaws.com/snapshot (nightly)\n* And you can always [build from source](http://locationtech.github.io/geowave/devguide.html#development-setup)\n\n## Community\n\n* Community support is available on [chat](https://gitter.im/locationtech/geowave) and on [our mailing list](mailto:geowave-dev@locationtech.org).\n\n## Getting Started\n### Programmatic Access\nYou can use maven to reference pre-built GeoWave artifacts with the following pom.xml snippet (replacing `${keyvalue-datastore}` with your datastore of choice and `${geowave.version}` with the geowave version you\'d like to use):\n```\n	<dependencies>\n		<dependency>\n			<groupId>org.locationtech.geowave</groupId>\n			<artifactId>geowave-datastore-${keyvalue-datastore}</artifactId>\n			<version>${geowave.version}</version>\n		</dependency>\n		<dependency>\n			<groupId>org.locationtech.geowave</groupId>\n			<artifactId>geowave-adapter-vector</artifactId>\n			<version>${geowave.version}</version>\n		</dependency>\n		<dependency>\n			<groupId>org.locationtech.geowave</groupId>\n			<artifactId>geowave-adapter-raster</artifactId>\n			<version>${geowave.version}</version>\n		</dependency>\n	</dependencies>\n    <repositories>\n		<repository>\n			<id>geowave-maven-snapshots</id>\n			<name>GeoWave AWS Snapshots Repository</name>\n			<url>http://geowave-maven.s3-website-us-east-1.amazonaws.com/snapshot</url>\n			<releases>\n				<enabled>false</enabled>\n			</releases>\n			<snapshots>\n				<enabled>true</enabled>\n			</snapshots>\n		</repository>\n		<repository>\n			<id>geowave-maven-releases</id>\n			<name>GeoWave AWS Release Repository</name>\n			<url>http://geowave-maven.s3-website-us-east-1.amazonaws.com/release</url>\n			<releases>\n				<enabled>true</enabled>\n			</releases>\n			<snapshots>\n				<enabled>false</enabled>\n			</snapshots>\n		</repository>\n	</repositories>\n```\n\nUse the libraries available in the `api` package to leverage GeoWave\'s capabilities (where `<data store options>` might be `AccumuloRequiredOptions` or `HBaseRequiredOptions` and simple examples of creating the data type and index can be found in `SimpleIngest` within the `examples` directory):\n```java\nDataStore store = DataStoreFactory.createDataStore(<data store options>);\nstore.addType(<my data type>, <my index>);\ntry(Writer writer = store.createWriter()){\n  //write data\n  writer.writer(<data);\n}\n \n//this just queries everything\ntry(CloseableIterator it = store.query(QueryBuilder.newBuilder().build())){\n  while(it.hasNext()){\n    //retrieve results matching query criteria and do something\n    it.next();\n  }\n}\n```\n### Commandline Access\nAlternatively, you can always use the GeoWave commandline to access the same capabilities. Install the `geowave-$VERSION-apache-tools` RPM as instructed [here](http://locationtech.github.io/geowave/packages.html).  Then `geowave config addstore ...` and `geowave config addindex ...` are used to create named configurations for connecting to a key-value store (addstore) and describing how you want the data indexed (addindex).  You can use `--help` at any time such as `geowave config addstore --help` or furthermore get additional help after specifying the type with `-t` such as `geowave config addstore -t accumulo --help` to understand accumulo specific parameters. Once you have the indexing and store specified you can use `geowave ingest localtogw <file or directory> <store name> <index name(s)>` to ingest data into the key-value store. For the most basic walkthrough with minimal setup, run through the [quickstart guide](http://locationtech.github.io/geowave/quickstart.html) locally using RocksDB.\n\n![](http://locationtech.github.io/geowave/images/operational_overview.png)\n\n## Some GeoWave rendered eye candy\n\n\n![](https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/userguide/images/geolife-density-13-thumb.jpg)\n\n![](https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/userguide/images/geolife-density-17-thumb.jpg)\n\n![](https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/userguide/images/osmgpx-thumb.jpg)\n\nSee [Screenshots](http://locationtech.github.io/geowave/userguide.html#example-screenshots) in the documentation for more information.\n\n## Supported versions of core libraries\n\nWe work to maintain a N and N-1 tested and supported version pace for the following core libraries.\n\n| Geoserver | Geotools | Accumulo | HBase | Hadoop | PDAL | Mapnik | Java |\n|:---------:|:--------:|:--------:|:-----:|:------:|:----:|:------:|:----:|\n| 2.14.x | 20.x | [1.7.x,1.9.x] | [1.1.x,1.4.x] | 2.x | 0.9.9 |  3.x | Java8 |\n\n* [Apache Maven](http://maven.apache.org/) 3.x or greater is required for building\n* [Java Advanced Imaging](http://download.java.net/media/jai/builds/release/1_1_3/INSTALL.html) and [Java Image I/O](http://download.java.net/media/jai-imageio/builds/release/1.1/INSTALL-jai_imageio.html) should both be installed on Geoserver for GeoWave versions 0.9.2.1 and below (licensing prohibits us redistributing)\n   * At the time of writing, Oracle is migrating Java projects around and these links are subject to change.  Read the INSTALL files to determine the download file name for different operating systems and architectures.  They are stored in the same directory as the INSTALL file.  Here are some common download locations.\n   * Java Advanced Imaging\n      * Linux ([32-bit](http://download.java.net/media/jai/builds/release/1_1_3/jai-1_1_3-lib-linux-i586.tar.gz) and [64-bit](http://download.java.net/media/jai/builds/release/1_1_3/jai-1_1_3-lib-linux-amd64.tar.gz))\n      * Windows ([32-bit](http://download.java.net/media/jai/builds/release/1_1_3/jai-1_1_3-lib-windows-i586.exe))\n   * Java Image I/O\n      * Linux ([32-bit](http://download.java.net/media/jai-imageio/builds/release/1.1/jai_imageio-1_1-lib-linux-i586.tar.gz) and [64-bit](http://download.java.net/media/jai-imageio/builds/release/1.1/jai_imageio-1_1-lib-linux-amd64.tar.gz))\n      * Windows ([32-bit](http://download.java.net/media/jai-imageio/builds/release/1.1/jai_imageio-1_1-lib-windows-i586.exe))\n* See our [.travis.yml](https://github.com/locationtech/geowave/blob/master/.travis.yml) file for the currently tested build matrix. \n\n\n\n## Origin\n\nGeoWave was developed at the National Geospatial-Intelligence Agency (NGA) in collaboration with [RadiantBlue Technologies](http://www.radiantblue.com/) (Now DigitalGlobe) and [Booz Allen Hamilton](http://www.boozallen.com/).  The government has [\"unlimited rights\"](https://github.com/locationtech/geowave/blob/master/NOTICE) and is releasing this software to increase the impact of government investments by providing developers with the opportunity to take things in new directions. The software use, modification, and distribution rights are stipulated within the [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0.html) license.  \n\n\n## Contributing\n\nAll pull request contributions to this project will be released under the Apache 2.0 or compatible license.\nSoftware source code previously released under an open source license and then modified by NGA staff is considered a \"joint work\" (see 17 USC § 101); it is partially copyrighted, partially public domain, and as a whole is protected by the copyrights of the non-government authors and must be released according to the terms of the original open source license.\n\nDid I mention our [documentation!](http://locationtech.github.io/geowave/)\n', '0', '<p><a href=\"http://locationtech.github.io/geowave/\">http://locationtech.github.io/geowave/</a></p>\n<p><img src=\"https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/geowave-index/images/geowave-logo-transluscent.png\" alt=\"\"></p>\n<h2 id=\"h2-about\"><a name=\"About\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>About</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Continuous Integration</th>\n<th style=\"text-align:center\">License</th>\n<th style=\"text-align:center\">Chat</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">&lt;a href=&quot;https://travis-ci.org/locationtech/geowave/branches&quot;&gt;&lt;img alt=&quot;Travis-CI test status&quot; src=&quot;https://travis-ci.org/locationtech/geowave.svg?branch=master&quot;/&gt;&lt;/a&gt;</td>\n<td style=\"text-align:center\"><a href=\"https://opensource.org/licenses/Apache-2.0\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License\"></a></td>\n<td style=\"text-align:center\"><a href=\"https://gitter.im/locationtech/geowave?utm_source=badge&amp;utm_medium=badge&amp;utm_content=badge\"><img src=\"https://badges.gitter.im/Join%20Chat.svg\" alt=\"Join the chat at https://gitter.im/locationtech/geowave\"></a></td>\n</tr>\n</tbody>\n</table>\n<p>GeoWave is an open source set of software that:</p>\n<ul>\n<li>Capabilities<ul>\n<li>Adds multi-dimensional indexing capability to key-value stores (currently <a href=\"https://accumulo.apache.org\">Apache Accumulo</a>, <a href=\"https://hbase.apache.org\">Apache HBase</a>, <a href=\"http://cassandra.apache.org/\">Apache Cassandra</a>, <a href=\"https://aws.amazon.com/dynamodb/\">AmazonDynamoDB</a>, <a href=\"https://cloud.google.com/bigtable/\">Cloud BigTable</a>, <a href=\"https://redis.io/\">Redis</a>, and <a href=\"https://rocksdb.org/\">RocksDB</a>)</li><li>Adds support for geographic objects and geospatial operators to these stores</li><li>Provides Map-Reduce input and output formats for distributed processing and analysis of geospatial data</li></ul>\n</li><li>Geospatial software plugins<ul>\n<li><a href=\"http://geoserver.org/\">GeoServer</a> plugin to allow geospatial data in various key-value stores to be shared and visualized via OGC standard services</li><li><a href=\"http://www.pdal.io/\">PDAL</a> plugin for working with point cloud data</li><li><a href=\"http://mapnik.org/\">Mapnik</a> plugin for generating map tiles and generally making good looking maps. </li></ul>\n</li></ul>\n<p>Basically, GeoWave is working to bridge geospatial software with modern key-value stores and distributed compute systems.</p>\n<h2 id=\"h2-the-docs\"><a name=\"The Docs\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>The Docs</h2><ul>\n<li>Check out our <a href=\"http://locationtech.github.io/geowave/\">GeoWave io page</a> page for detailed documentation.</li><li>A <a href=\"http://locationtech.github.io/geowave/changelog.html\">changelog is available</a> which details the changes and features for each of our <a href=\"https://github.com/locationtech/geowave/releases\">github releases</a></li><li>The underlying principles employed in GeoWave are outlined in recent academic publications to include largely the background theory in <a href=\"https://link.springer.com/chapter/10.1007/978-3-319-64367-0_6\">Advances in Spatial and Temporal Databases 2017</a> and a derivative, more applied paper in <a href=\"http://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1027&amp;context=foss4g\">FOSS4G Conference Proceedings 2017</a>.</li></ul>\n<h2 id=\"h2-the-software\"><a name=\"The Software\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>The Software</h2><ul>\n<li>We have a <a href=\"http://locationtech.github.io/geowave/packages.html\">RPM repository</a><ul>\n<li>See <a href=\"http://locationtech.github.io/geowave/devguide.html#installation-from-rpm\">Documentation: Installation from RPM</a> for more info.</li><li>Deb packages if enough people request them</li></ul>\n</li><li>We have <a href=\"http://locationtech.github.io/geowave/devguide.html#maven-pom-fragments\">Maven artifact repositories</a> (indexes not enabled, but it works in a maven repo fragment)<ul>\n<li>Releases: <a href=\"http://geowave-maven.s3-website-us-east-1.amazonaws.com/release\">http://geowave-maven.s3-website-us-east-1.amazonaws.com/release</a></li><li>Snapshots: <a href=\"http://geowave-maven.s3-website-us-east-1.amazonaws.com/snapshot\">http://geowave-maven.s3-website-us-east-1.amazonaws.com/snapshot</a> (nightly)</li></ul>\n</li><li>And you can always <a href=\"http://locationtech.github.io/geowave/devguide.html#development-setup\">build from source</a></li></ul>\n<h2 id=\"h2-community\"><a name=\"Community\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Community</h2><ul>\n<li>Community support is available on <a href=\"https://gitter.im/locationtech/geowave\">chat</a> and on <a href=\"mailto:geowave-<a href=\"mailto:dev@locationtech.org\">dev@locationtech.org</a>\">our mailing list</a>.</li></ul>\n<h2 id=\"h2-getting-started\"><a name=\"Getting Started\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Getting Started</h2><h3 id=\"h3-programmatic-access\"><a name=\"Programmatic Access\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Programmatic Access</h3><p>You can use maven to reference pre-built GeoWave artifacts with the following pom.xml snippet (replacing <code>${keyvalue-datastore}</code> with your datastore of choice and <code>${geowave.version}</code> with the geowave version you’d like to use):</p>\n<pre><code>    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.locationtech.geowave&lt;/groupId&gt;\n            &lt;artifactId&gt;geowave-datastore-${keyvalue-datastore}&lt;/artifactId&gt;\n            &lt;version&gt;${geowave.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.locationtech.geowave&lt;/groupId&gt;\n            &lt;artifactId&gt;geowave-adapter-vector&lt;/artifactId&gt;\n            &lt;version&gt;${geowave.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.locationtech.geowave&lt;/groupId&gt;\n            &lt;artifactId&gt;geowave-adapter-raster&lt;/artifactId&gt;\n            &lt;version&gt;${geowave.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n    &lt;repositories&gt;\n        &lt;repository&gt;\n            &lt;id&gt;geowave-maven-snapshots&lt;/id&gt;\n            &lt;name&gt;GeoWave AWS Snapshots Repository&lt;/name&gt;\n            &lt;url&gt;http://geowave-maven.s3-website-us-east-1.amazonaws.com/snapshot&lt;/url&gt;\n            &lt;releases&gt;\n                &lt;enabled&gt;false&lt;/enabled&gt;\n            &lt;/releases&gt;\n            &lt;snapshots&gt;\n                &lt;enabled&gt;true&lt;/enabled&gt;\n            &lt;/snapshots&gt;\n        &lt;/repository&gt;\n        &lt;repository&gt;\n            &lt;id&gt;geowave-maven-releases&lt;/id&gt;\n            &lt;name&gt;GeoWave AWS Release Repository&lt;/name&gt;\n            &lt;url&gt;http://geowave-maven.s3-website-us-east-1.amazonaws.com/release&lt;/url&gt;\n            &lt;releases&gt;\n                &lt;enabled&gt;true&lt;/enabled&gt;\n            &lt;/releases&gt;\n            &lt;snapshots&gt;\n                &lt;enabled&gt;false&lt;/enabled&gt;\n            &lt;/snapshots&gt;\n        &lt;/repository&gt;\n    &lt;/repositories&gt;\n</code></pre><p>Use the libraries available in the <code>api</code> package to leverage GeoWave’s capabilities (where <code>&lt;data store options&gt;</code> might be <code>AccumuloRequiredOptions</code> or <code>HBaseRequiredOptions</code> and simple examples of creating the data type and index can be found in <code>SimpleIngest</code> within the <code>examples</code> directory):</p>\n<pre><code class=\"lang-java\">DataStore store = DataStoreFactory.createDataStore(&lt;data store options&gt;);\nstore.addType(&lt;my data type&gt;, &lt;my index&gt;);\ntry(Writer writer = store.createWriter()){\n  //write data\n  writer.writer(&lt;data);\n}\n\n//this just queries everything\ntry(CloseableIterator it = store.query(QueryBuilder.newBuilder().build())){\n  while(it.hasNext()){\n    //retrieve results matching query criteria and do something\n    it.next();\n  }\n}\n</code></pre>\n<h3 id=\"h3-commandline-access\"><a name=\"Commandline Access\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Commandline Access</h3><p>Alternatively, you can always use the GeoWave commandline to access the same capabilities. Install the <code>geowave-$VERSION-apache-tools</code> RPM as instructed <a href=\"http://locationtech.github.io/geowave/packages.html\">here</a>.  Then <code>geowave config addstore ...</code> and <code>geowave config addindex ...</code> are used to create named configurations for connecting to a key-value store (addstore) and describing how you want the data indexed (addindex).  You can use <code>--help</code> at any time such as <code>geowave config addstore --help</code> or furthermore get additional help after specifying the type with <code>-t</code> such as <code>geowave config addstore -t accumulo --help</code> to understand accumulo specific parameters. Once you have the indexing and store specified you can use <code>geowave ingest localtogw &lt;file or directory&gt; &lt;store name&gt; &lt;index name(s)&gt;</code> to ingest data into the key-value store. For the most basic walkthrough with minimal setup, run through the <a href=\"http://locationtech.github.io/geowave/quickstart.html\">quickstart guide</a> locally using RocksDB.</p>\n<p><img src=\"http://locationtech.github.io/geowave/images/operational_overview.png\" alt=\"\"></p>\n<h2 id=\"h2-some-geowave-rendered-eye-candy\"><a name=\"Some GeoWave rendered eye candy\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Some GeoWave rendered eye candy</h2><p><img src=\"https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/userguide/images/geolife-density-13-thumb.jpg\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/userguide/images/geolife-density-17-thumb.jpg\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/locationtech/geowave/master/docs/content/userguide/images/osmgpx-thumb.jpg\" alt=\"\"></p>\n<p>See <a href=\"http://locationtech.github.io/geowave/userguide.html#example-screenshots\">Screenshots</a> in the documentation for more information.</p>\n<h2 id=\"h2-supported-versions-of-core-libraries\"><a name=\"Supported versions of core libraries\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Supported versions of core libraries</h2><p>We work to maintain a N and N-1 tested and supported version pace for the following core libraries.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Geoserver</th>\n<th style=\"text-align:center\">Geotools</th>\n<th style=\"text-align:center\">Accumulo</th>\n<th style=\"text-align:center\">HBase</th>\n<th style=\"text-align:center\">Hadoop</th>\n<th style=\"text-align:center\">PDAL</th>\n<th style=\"text-align:center\">Mapnik</th>\n<th style=\"text-align:center\">Java</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">2.14.x</td>\n<td style=\"text-align:center\">20.x</td>\n<td style=\"text-align:center\">[1.7.x,1.9.x]</td>\n<td style=\"text-align:center\">[1.1.x,1.4.x]</td>\n<td style=\"text-align:center\">2.x</td>\n<td style=\"text-align:center\">0.9.9</td>\n<td style=\"text-align:center\">3.x</td>\n<td style=\"text-align:center\">Java8</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><a href=\"http://maven.apache.org/\">Apache Maven</a> 3.x or greater is required for building</li><li><a href=\"http://download.java.net/media/jai/builds/release/1_1_3/INSTALL.html\">Java Advanced Imaging</a> and <a href=\"http://download.java.net/media/jai-imageio/builds/release/1.1/INSTALL-jai_imageio.html\">Java Image I/O</a> should both be installed on Geoserver for GeoWave versions 0.9.2.1 and below (licensing prohibits us redistributing)<ul>\n<li>At the time of writing, Oracle is migrating Java projects around and these links are subject to change.  Read the INSTALL files to determine the download file name for different operating systems and architectures.  They are stored in the same directory as the INSTALL file.  Here are some common download locations.</li><li>Java Advanced Imaging<ul>\n<li>Linux (<a href=\"http://download.java.net/media/jai/builds/release/1_1_3/jai-1_1_3-lib-linux-i586.tar.gz\">32-bit</a> and <a href=\"http://download.java.net/media/jai/builds/release/1_1_3/jai-1_1_3-lib-linux-amd64.tar.gz\">64-bit</a>)</li><li>Windows (<a href=\"http://download.java.net/media/jai/builds/release/1_1_3/jai-1_1_3-lib-windows-i586.exe\">32-bit</a>)</li></ul>\n</li><li>Java Image I/O<ul>\n<li>Linux (<a href=\"http://download.java.net/media/jai-imageio/builds/release/1.1/jai_imageio-1_1-lib-linux-i586.tar.gz\">32-bit</a> and <a href=\"http://download.java.net/media/jai-imageio/builds/release/1.1/jai_imageio-1_1-lib-linux-amd64.tar.gz\">64-bit</a>)</li><li>Windows (<a href=\"http://download.java.net/media/jai-imageio/builds/release/1.1/jai_imageio-1_1-lib-windows-i586.exe\">32-bit</a>)</li></ul>\n</li></ul>\n</li><li>See our <a href=\"https://github.com/locationtech/geowave/blob/master/.travis.yml\">.travis.yml</a> file for the currently tested build matrix. </li></ul>\n<h2 id=\"h2-origin\"><a name=\"Origin\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Origin</h2><p>GeoWave was developed at the National Geospatial-Intelligence Agency (NGA) in collaboration with <a href=\"http://www.radiantblue.com/\">RadiantBlue Technologies</a> (Now DigitalGlobe) and <a href=\"http://www.boozallen.com/\">Booz Allen Hamilton</a>.  The government has <a href=\"https://github.com/locationtech/geowave/blob/master/NOTICE\">“unlimited rights”</a> and is releasing this software to increase the impact of government investments by providing developers with the opportunity to take things in new directions. The software use, modification, and distribution rights are stipulated within the <a href=\"http://www.apache.org/licenses/LICENSE-2.0.html\">Apache 2.0</a> license.  </p>\n<h2 id=\"h2-contributing\"><a name=\"Contributing\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Contributing</h2><p>All pull request contributions to this project will be released under the Apache 2.0 or compatible license.<br>Software source code previously released under an open source license and then modified by NGA staff is considered a “joint work” (see 17 USC § 101); it is partially copyrighted, partially public domain, and as a whole is protected by the copyrights of the non-government authors and must be released according to the terms of the original open source license.</p>\n<p>Did I mention our <a href=\"http://locationtech.github.io/geowave/\">documentation!</a></p>\n');
INSERT INTO `tbl_archive` VALUES ('91', '0', 'GeoTrellis is a geographic data processing engine for high performance applications. ', '8', '2019-02-22 00:41:35', '#GeoTrellis[![BuildStatus](https://api.travis-ci.org/locationtech/geotrellis.svg?branch=master)](http://travis-ci.org/locationtech/geotrellis)[![Jointhechatathttps://gitter.im/geotrellis/geotrellis](h', null, '0', '32', null, null, '2019-02-22 00:41:35', '2019-02-22 00:48:22', null, null, '0', '0', '0', '0', '# [GeoTrellis](http://geotrellis.io \"GeoTrellis\")\n\n[![Build Status](https://api.travis-ci.org/locationtech/geotrellis.svg?branch=master)](http://travis-ci.org/locationtech/geotrellis) [![Join the chat at https://gitter.im/geotrellis/geotrellis](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/geotrellis/geotrellis?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Maven Central](https://img.shields.io/maven-metadata/v/http/central.maven.org/maven2/org/locationtech/geotrellis/geotrellis-spark_2.11/maven-metadata.xml.svg)](http://search.maven.org/#search%7Cga%7C1%7Corg.locationtech.geotrellis)\n[![ReadTheDocs](https://readthedocs.org/projects/geotrellis/badge/?version=latest)](http://geotrellis.readthedocs.io/en/latest/)\n[![Changelog](https://img.shields.io/badge/changelog-v1.2.0-brightgreen.svg)](https://geotrellis.readthedocs.io/en/latest/CHANGELOG.html)\n[![Contributing](https://img.shields.io/badge/contributing-see%20conditions-brightgreen.svg)](https://github.com/locationtech/geotrellis/blob/master/docs/CONTRIBUTING.rst)\n\n![](https://geotrellis.io/img/setup_01.jpg)\n\n*GeoTrellis* is a Scala library and framework that uses\nSpark to work with raster data.  It is released under\nthe Apache 2 License.\n\nGeoTrellis reads, writes, and operates on raster data\nas fast as possible. It implements many\n[Map Algebra](http://en.wikipedia.org/wiki/Map_algebra)\noperations as well as vector to raster or raster to\nvector operations.\n\nGeoTrellis also provides tools to render rasters into\nPNGs or to store metadata about raster files as JSON.\nIt aims to provide raster processing at web speeds (sub-second\nor less) with RESTful endpoints as well as provide\nfast batch processing of large raster data sets.\n\nPlease visit the **[project site](http://geotrellis.io)**\nfor more information as well as some interactive demos.\n\nDEMO\n----\n[![](https://geotrellis.io/img/demo_02.jpg)](http://demo.geotrellis.com/chatta/)    [![](https://geotrellis.io/img/case_study_03.png)](https://wikiwatershed.org/)\n\n#### GeoTrellis with Python\n\nGeoTrellis has Python bindings through a project called [GeoPySpark](http://github.com/locationtech-labs/geopyspark).\nGeoPySpark is a Python bindings library for GeoTrellis and can do many\n(but not all) of the operations present in GeoTrellis. GeoPySpark can\nbe integrated with other tools in the Python ecosystem, such as NumPy,\nscikit-learn, and Jupyter notebooks. Several GeoPySpark tutorials have\nbeen developed that leverage the visualization capability of [GeoNotebook](https://github.com/OpenGeoscience/geonotebook),\nan open-source Jupyter extension that provides interactive map displays.\n\n## Contact and Support\n\nYou can find more information and talk to developers\n(let us know what you\'re working on!) at:\n\n  - [Gitter](https://gitter.im/geotrellis/geotrellis)\n  - [GeoTrellis mailing list](https://locationtech.org/mailman/listinfo/geotrellis-user)\n\n\n## Getting Started\n\nGeoTrellis is currently available for Scala 2.11 and Spark 2.0+.\n\nTo get started with SBT, simply add the following to your build.sbt file:\n\n```scala\nlibraryDependencies += \"org.locationtech.geotrellis\" %% \"geotrellis-raster\" % \"1.1.0\"\n```\n\nTo grab the latest `SNAPSHOT`, `RC` or milestone build, add these resolvers:\n```scala\nresolvers ++= Seq(\n  \"locationtech-releases\" at \"https://repo.locationtech.org/content/groups/releases\",\n  \"locationtech-snapshots\" at \"https://repo.locationtech.org/content/groups/snapshots\"\n)\n```\n\n`geotrellis-raster` is just one submodule that you can depend on. Here are a list of our published submodules:\n\n- `geotrellis-proj4`: Coordinate Reference systems and reproject (Scala wrapper around Proj4j)\n- `geotrellis-vector`: Vector data types and operations (Scala wrapper around JTS)\n- `geotrellis-raster`: Raster data types and operations\n- `geotrellis-spark`: Geospatially enables Spark; save to and from HDFS\n- `geotrellis-s3`: S3 backend for geotrellis-spark\n- `geotrellis-accumulo`: Accumulo backend for geotrellis-spark\n- `geotrellis-cassandra`: Cassandra backend for geotrellis-spark\n- `geotrellis-hbase`: HBase backend for geotrellis-spark\n- `geotrellis-spark-etl`: Utilities for writing ETL (Extract-Transform-Load), or \"ingest\" applications for geotrellis-spark\n- `geotrellis-geotools`: Conversions to and from GeoTools Vector and Raster data\n- `geotrellis-geomesa`: Experimental GeoMesa integration\n- `geotrellis-geowave`: Experimental GeoWave integration\n- `geotrellis-shapefile`: Read shapefiles into GeoTrellis data types via GeoTools\n- `geotrellis-slick`: Read vector data out of PostGIS via [LightBend Slick](http://slick.lightbend.com/)\n- `geotrellis-vectortile`: Experimental vector tile support, including reading and writing\n- `geotrellis-raster-testkit`: Testkit for testing geotrellis-raster types\n- `geotrellis-vector-testkit`: Testkit for testing geotrellis-vector types\n- `geotrellis-spark-testkit`: Testkit for testing geotrellis-spark code\n\nA more complete feature list can be found below.\n\n## Where is our commit history and contributor list?\n\nIn November 2016, GeoTrellis moved it\'s repository from the\n[GeoTrellis GitHub Organization](https://github.com/geotrellis) to it\'s current\nhome in the LocationTech GitHub organization.\nIn the process of moving our repository, we went through an IP review process.\nBecause the Eclipse foundation only reviews a snapshot of the repository, and\nnot all of history, we had to start from a clean `master` branch. The entire\nold history is available in the `_old/master` branch. You can also tie\nyour local clone\'s master history to the old history by running\n\n```console\n> git fetch origin refs/replace/*:refs/replace/*\n```\n\nif `origin` points to https://github.com/locationtech/geotrellis.\nThis will allow you to see the old history for commands like `git log`.\n\nUnfortunately, we lost our commit and contributor count in the move.\nThese are significant statistics for a repository,\nand our current counts make us look younger than we are.\nGeoTrellis has been an open source project since 2011.\nThis is what our contributor and commit count looked like\nbefore the move to LocationTech:\n\n![Commit and contributor count before LocationTech move](docs/img/contributor-and-commit-count-pre-locationtech.png)\n\nAlong with counts, we want to make sure that all the awesome people\nwho contributed to GeoTrellis before the LocationTech move can\nstill be credited on a contributors page. For posterity, I will\nleave the following contributors page to what it was before the move:\n\nhttps://github.com/lossyrob/geotrellis-before-locationtech/graphs/contributors\n\n## Hello Raster\n\n```scala\nscala> import geotrellis.raster._\nimport geotrellis.raster._\n\nscala> import geotrellis.raster.render.ascii._\nimport geotrellis.raster.render.ascii._\n\nscala> import geotrellis.raster.mapalgebra.focal._\nimport geotrellis.raster.mapalgebra.focal._\n\nscala> val nd = NODATA\nnd: Int = -2147483648\n\nscala> val input = Array[Int](\n     nd, 7, 1, 1,  3, 5, 9, 8, 2,\n      9, 1, 1, 2,  2, 2, 4, 3, 5,\n      3, 8, 1, 3,  3, 3, 1, 2, 2,\n      2, 4, 7, 1, nd, 1, 8, 4, 3)\ninput: Array[Int] = Array(-2147483648, 7, 1, 1, 3, 5, 9, 8, 2, 9, 1, 1, 2,\n2, 2, 4, 3, 5, 3, 8, 1, 3, 3, 3, 1, 2, 2, 2, 4, 7, 1, -2147483648, 1, 8, 4, 3)\n\nscala> val iat = IntArrayTile(input, 9, 4)  // 9 and 4 here specify columns and rows\niat: geotrellis.raster.IntArrayTile = IntArrayTile([I@278434d0,9,4)\n\n// The renderAscii method is mostly useful when you\'re working with small tiles\n// which can be taken in at a glance.\nscala> iat.renderAscii(AsciiArtEncoder.Palette.STIPLED)\nres0: String =\n∘█  ▚▜██▖\n█  ▖▖▖▜▚▜\n▚█ ▚▚▚ ▖▖\n▖▜█ ∘ █▜▚\n\nscala> val focalNeighborhood = Square(1)  // a 3x3 square neighborhood\nfocalNeighborhood: geotrellis.raster.op.focal.Square =\n O  O  O\n O  O  O\n O  O  O\n\nscala> val meanTile = iat.focalMean(focalNeighborhood)\nmeanTile: geotrellis.raster.Tile = DoubleArrayTile([D@7e31c125,9,4)\n\nscala> meanTile.getDouble(0, 0)  // Should equal (1 + 7 + 9) / 3\nres1: Double = 5.666666666666667\n```\n\n## GeoTrellis Features\n\nThis is a list of features contained in the GeoTrellis library. It is broken up by the subproject that contains the features.\n\n#### geotrellis-proj4\n\n- Represent a Coordinate Reference System (CRS) based on Ellipsoid, Datum, and Projection.\n- Translate CRSs to and from proj4 string representations.\n- Lookup CRS\'s based on EPSG and other codes.\n- Transform `(x, y)` coordinates from one CRS to another.\n\n#### geotrellis-vector\n\n- Provides a scala idiomatic wrapper around JTS types: Point, Line (LineString in JTS), Polygon, MultiPoint, MultiLine (MultiLineString in JTS), MultiPolygon, GeometryCollection\n- Methods for geometric operations supported in JTS, with results that provide a type-safe way to match over possible results of geometries.\n- Provides a Feature type that is the composition of a geometry and a generic data type.\n- Read and write geometries and features to and from GeoJSON.\n- Read and write geometries to and from WKT and WKB.\n- Reproject geometries between two CRSs.\n- Geometric operations: Convex Hull, Densification, Simplification\n- Perform Kriging interpolation on point values.\n- Perform affine transformations of geometries\n\n#### geotrellis-vector-testkit\n\n- GeometryBuilder for building test geometries\n- GeometryMatcher for scalatest unit tests, which aides in testing equality in geometries with an optional threshold.\n\n#### geotrellis-raster\n\n- Provides types to represent single- and multi-band rasters, supporting Bit, Byte, UByte, Short, UShort, Int, Float, and Double data, with either a constant NoData value (which improves performance) or a user defined NoData value.\n- Treat a tile as a collection of values, by calling \"map\" and \"foreach\", along with floating point valued versions of those methods (separated out for performance).\n- Combine raster data in generic ways.\n- Render rasters via color ramps and color maps to PNG and JPG images.\n- Read GeoTiffs with DEFLATE, LZW, and PackBits compression, including horizontal and floating point prediction for LZW and DEFLATE.\n- Write GeoTiffs with DEFLATE or no compression.\n- Reproject rasters from one CRS to another.\n- Resample of raster data.\n- Mask and Crop rasters.\n- Split rasters into smaller tiles, and stitch tiles into larger rasters.\n- Derive histograms from rasters in order to represent the distribution of values and create quantile breaks.\n- Local Map Algebra operations: Abs, Acos, Add, And, Asin, Atan, Atan2, Ceil, Cos, Cosh, Defined, Divide, Equal, Floor, Greater, GreaterOrEqual, InverseMask, Less, LessOrEqual, Log, Majority, Mask, Max, MaxN, Mean, Min, MinN, Minority, Multiply, Negate, Not, Or, Pow, Round, Sin, Sinh, Sqrt, Subtract, Tan, Tanh, Undefined, Unequal, Variance, Variety, Xor, If\n- Focal Map Algebra operations: Hillshade, Aspect, Slope, Convolve, Conway\'s Game of Life, Max, Mean, Median, Mode, Min, MoransI, StandardDeviation, Sum\n- Zonal Map Algebra operations: ZonalHistogram, ZonalPercentage\n- Operations that summarize raster data intersecting polygons: Min, Mean, Max, Sum.\n- Cost distance operation based on a set of starting points and a friction raster.\n- Hydrology operations: Accumulation, Fill, and FlowDirection.\n- Rasterization of geometries and the ability to iterate over cell values covered by geometries.\n- Vectorization of raster data.\n- Kriging Interpolation of point data into rasters.\n- Viewshed operation.\n- RegionGroup operation.\n\n#### geotrellis-raster-testkit\n\n- Build test raster data.\n- Assert raster data matches Array data or other rasters in scalatest.\n\n#### geotrellis-spark\n\n- Generic way to represent key value RDDs as layers, where the key represents a coordinate in space based on some uniform grid layout, optionally with a temporal component.\n- Represent spatial or spatiotemporal raster data as an RDD of raster tiles.\n- Generic architecture for saving/loading layers RDD data and metadata to/from various backends, using Spark\'s IO API with Space Filling Curve indexing to optimize storage retrieval (support for Hilbert curve and Z order curve SFCs). HDFS and local file system are supported backends by default, S3 and Accumulo are supported backends by the `geotrellis-s3` and `geotrellis-accumulo` projects, respectively.\n- Query architecture that allows for simple querying of layer data by spatial or spatiotemporal bounds.\n- Perform map algebra operations on layers of raster data, including all supported Map Algebra operations mentioned in the geotrellis-raster feature list.\n- Perform seamless reprojection on raster layers, using neighboring tile information in the reprojection to avoid unwanted NoData cells.\n- Pyramid up layers through zoom levels using various resampling methods.\n- Types to reason about tiled raster layouts in various CRS\'s and schemes.\n- Perform operations on raster RDD layers: crop, filter, join, mask, merge, partition, pyramid, render, resample, split, stitch, and tile.\n- Polygonal summary over raster layers: Min, Mean, Max, Sum.\n- Save spatially keyed RDDs of byte arrays to z/x/y files into HDFS or the local file system. Useful for saving PNGs off for use as map layers in web maps or for accessing GeoTiffs through z/x/y tile coordinates.\n- Utilities around creating spark contexts for applications using GeoTrellis, including a Kryo registrator that registers most types.\n\n#### geotrellis-spark-testkit\n\n- Utility code to create test RDDs of raster data.\n- Matching methods to test equality of RDDs of raster data in scalatest unit tests.\n\n#### geotrellis-accumulo\n\n- Save and load layers to and from Accumulo. Query large layers efficiently using the layer query API.\n\n#### geotrellis-cassandra\n\n- Save and load layers to and from Casandra. Query large layers efficiently using the layer query API.\n\n#### geotrellis-hbase\n\n- Save and load layers to and from HBase. Query large layers efficiently using the layer query API.\n\n#### geotrellis-s3\n\n- Save/load raster layers to/from the local filesystem or HDFS using Spark\'s IO API.\n- Save spatially keyed RDDs of byte arrays to z/x/y files in S3. Useful for saving PNGs off for use as map layers in web maps.\n\n#### geotrellis-etl\n\n- Parse command line options for input and output of ETL (Extract, Transform, and Load) applications\n- Utility methods that make ETL applications easier for the user to build.\n- Work with input rasters from the local file system, HDFS, or S3\n- Reproject input rasters using a per-tile reproject or a seamless reprojection that takes into account neighboring tiles.\n- Transform input rasters into layers based on a ZXY layout scheme\n- Save layers into Accumulo, S3, HDFS or the local file system.\n\n#### geotrellis-shapefile\n\n- Read geometry and feature data from shapefiles into GeoTrellis types using GeoTools.\n\n#### geotrellis-slick\n\n- Save and load geometry and feature data to and from PostGIS using the slick scala database library.\n- Perform PostGIS `ST_` operations in PostGIS through scala.\n\n## Documentation\n\n- Further examples and documentation of GeoTrellis use-cases can be found in the [docs/](./docs) folder\n- *Scaladocs* for the latest version of the project can be found here:\n\n[http://geotrellis.github.com/scaladocs/latest/#geotrellis.package](http://geotrellis.github.com/scaladocs/latest/#geotrellis.package)\n\n## Contributing\n\nFeedback and contributions to the project, no matter what kind, are always\nvery welcome. A CLA is required for contribution, see\n[Contributing](http://geotrellis.readthedocs.io/en/latest/CONTRIBUTING.html)\nfor more information. Please refer to the [Scala style\nguide](http://docs.scala-lang.org/style/) for formatting patches to the\ncodebase.\n', '0', '<h1 id=\"h1-geotrellis\"><a name=\"GeoTrellis\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span><a href=\"http://geotrellis.io\" title=\"GeoTrellis\">GeoTrellis</a></h1><p><a href=\"http://travis-ci.org/locationtech/geotrellis\"><img src=\"https://api.travis-ci.org/locationtech/geotrellis.svg?branch=master\" alt=\"Build Status\"></a> <a href=\"https://gitter.im/geotrellis/geotrellis?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge\"><img src=\"https://badges.gitter.im/Join%20Chat.svg\" alt=\"Join the chat at https://gitter.im/geotrellis/geotrellis\"></a><br><a href=\"http://search.maven.org/#search%7Cga%7C1%7Corg.locationtech.geotrellis\"><img src=\"https://img.shields.io/maven-metadata/v/http/central.maven.org/maven2/org/locationtech/geotrellis/geotrellis-spark_2.11/maven-metadata.xml.svg\" alt=\"Maven Central\"></a><br><a href=\"http://geotrellis.readthedocs.io/en/latest/\"><img src=\"https://readthedocs.org/projects/geotrellis/badge/?version=latest\" alt=\"ReadTheDocs\"></a><br><a href=\"https://geotrellis.readthedocs.io/en/latest/CHANGELOG.html\"><img src=\"https://img.shields.io/badge/changelog-v1.2.0-brightgreen.svg\" alt=\"Changelog\"></a><br><a href=\"https://github.com/locationtech/geotrellis/blob/master/docs/CONTRIBUTING.rst\"><img src=\"https://img.shields.io/badge/contributing-see%20conditions-brightgreen.svg\" alt=\"Contributing\"></a></p>\n<p><img src=\"https://geotrellis.io/img/setup_01.jpg\" alt=\"\"></p>\n<p><em>GeoTrellis</em> is a Scala library and framework that uses<br>Spark to work with raster data.  It is released under<br>the Apache 2 License.</p>\n<p>GeoTrellis reads, writes, and operates on raster data<br>as fast as possible. It implements many<br><a href=\"http://en.wikipedia.org/wiki/Map_algebra\">Map Algebra</a><br>operations as well as vector to raster or raster to<br>vector operations.</p>\n<p>GeoTrellis also provides tools to render rasters into<br>PNGs or to store metadata about raster files as JSON.<br>It aims to provide raster processing at web speeds (sub-second<br>or less) with RESTful endpoints as well as provide<br>fast batch processing of large raster data sets.</p>\n<p>Please visit the <strong><a href=\"http://geotrellis.io\">project site</a></strong><br>for more information as well as some interactive demos.</p>\n<h2 id=\"h2-demo\"><a name=\"DEMO\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>DEMO</h2><p><a href=\"http://demo.geotrellis.com/chatta/\"><img src=\"https://geotrellis.io/img/demo_02.jpg\" alt=\"\"></a>    <a href=\"https://wikiwatershed.org/\"><img src=\"https://geotrellis.io/img/case_study_03.png\" alt=\"\"></a></p>\n<h4 id=\"h4-geotrellis-with-python\"><a name=\"GeoTrellis with Python\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>GeoTrellis with Python</h4><p>GeoTrellis has Python bindings through a project called <a href=\"http://github.com/locationtech-labs/geopyspark\">GeoPySpark</a>.<br>GeoPySpark is a Python bindings library for GeoTrellis and can do many<br>(but not all) of the operations present in GeoTrellis. GeoPySpark can<br>be integrated with other tools in the Python ecosystem, such as NumPy,<br>scikit-learn, and Jupyter notebooks. Several GeoPySpark tutorials have<br>been developed that leverage the visualization capability of <a href=\"https://github.com/OpenGeoscience/geonotebook\">GeoNotebook</a>,<br>an open-source Jupyter extension that provides interactive map displays.</p>\n<h2 id=\"h2-contact-and-support\"><a name=\"Contact and Support\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Contact and Support</h2><p>You can find more information and talk to developers<br>(let us know what you’re working on!) at:</p>\n<ul>\n<li><a href=\"https://gitter.im/geotrellis/geotrellis\">Gitter</a></li><li><a href=\"https://locationtech.org/mailman/listinfo/geotrellis-user\">GeoTrellis mailing list</a></li></ul>\n<h2 id=\"h2-getting-started\"><a name=\"Getting Started\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Getting Started</h2><p>GeoTrellis is currently available for Scala 2.11 and Spark 2.0+.</p>\n<p>To get started with SBT, simply add the following to your build.sbt file:</p>\n<pre><code class=\"lang-scala\">libraryDependencies += &quot;org.locationtech.geotrellis&quot; %% &quot;geotrellis-raster&quot; % &quot;1.1.0&quot;\n</code></pre>\n<p>To grab the latest <code>SNAPSHOT</code>, <code>RC</code> or milestone build, add these resolvers:</p>\n<pre><code class=\"lang-scala\">resolvers ++= Seq(\n  &quot;locationtech-releases&quot; at &quot;https://repo.locationtech.org/content/groups/releases&quot;,\n  &quot;locationtech-snapshots&quot; at &quot;https://repo.locationtech.org/content/groups/snapshots&quot;\n)\n</code></pre>\n<p><code>geotrellis-raster</code> is just one submodule that you can depend on. Here are a list of our published submodules:</p>\n<ul>\n<li><code>geotrellis-proj4</code>: Coordinate Reference systems and reproject (Scala wrapper around Proj4j)</li><li><code>geotrellis-vector</code>: Vector data types and operations (Scala wrapper around JTS)</li><li><code>geotrellis-raster</code>: Raster data types and operations</li><li><code>geotrellis-spark</code>: Geospatially enables Spark; save to and from HDFS</li><li><code>geotrellis-s3</code>: S3 backend for geotrellis-spark</li><li><code>geotrellis-accumulo</code>: Accumulo backend for geotrellis-spark</li><li><code>geotrellis-cassandra</code>: Cassandra backend for geotrellis-spark</li><li><code>geotrellis-hbase</code>: HBase backend for geotrellis-spark</li><li><code>geotrellis-spark-etl</code>: Utilities for writing ETL (Extract-Transform-Load), or “ingest” applications for geotrellis-spark</li><li><code>geotrellis-geotools</code>: Conversions to and from GeoTools Vector and Raster data</li><li><code>geotrellis-geomesa</code>: Experimental GeoMesa integration</li><li><code>geotrellis-geowave</code>: Experimental GeoWave integration</li><li><code>geotrellis-shapefile</code>: Read shapefiles into GeoTrellis data types via GeoTools</li><li><code>geotrellis-slick</code>: Read vector data out of PostGIS via <a href=\"http://slick.lightbend.com/\">LightBend Slick</a></li><li><code>geotrellis-vectortile</code>: Experimental vector tile support, including reading and writing</li><li><code>geotrellis-raster-testkit</code>: Testkit for testing geotrellis-raster types</li><li><code>geotrellis-vector-testkit</code>: Testkit for testing geotrellis-vector types</li><li><code>geotrellis-spark-testkit</code>: Testkit for testing geotrellis-spark code</li></ul>\n<p>A more complete feature list can be found below.</p>\n<h2 id=\"h2-where-is-our-commit-history-and-contributor-list-\"><a name=\"Where is our commit history and contributor list?\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Where is our commit history and contributor list?</h2><p>In November 2016, GeoTrellis moved it’s repository from the<br><a href=\"https://github.com/geotrellis\">GeoTrellis GitHub Organization</a> to it’s current<br>home in the LocationTech GitHub organization.<br>In the process of moving our repository, we went through an IP review process.<br>Because the Eclipse foundation only reviews a snapshot of the repository, and<br>not all of history, we had to start from a clean <code>master</code> branch. The entire<br>old history is available in the <code>_old/master</code> branch. You can also tie<br>your local clone’s master history to the old history by running</p>\n<pre><code class=\"lang-console\">&gt; git fetch origin refs/replace/*:refs/replace/*\n</code></pre>\n<p>if <code>origin</code> points to <a href=\"https://github.com/locationtech/geotrellis\">https://github.com/locationtech/geotrellis</a>.<br>This will allow you to see the old history for commands like <code>git log</code>.</p>\n<p>Unfortunately, we lost our commit and contributor count in the move.<br>These are significant statistics for a repository,<br>and our current counts make us look younger than we are.<br>GeoTrellis has been an open source project since 2011.<br>This is what our contributor and commit count looked like<br>before the move to LocationTech:</p>\n<p><img src=\"docs/img/contributor-and-commit-count-pre-locationtech.png\" alt=\"Commit and contributor count before LocationTech move\"></p>\n<p>Along with counts, we want to make sure that all the awesome people<br>who contributed to GeoTrellis before the LocationTech move can<br>still be credited on a contributors page. For posterity, I will<br>leave the following contributors page to what it was before the move:</p>\n<p><a href=\"https://github.com/lossyrob/geotrellis-before-locationtech/graphs/contributors\">https://github.com/lossyrob/geotrellis-before-locationtech/graphs/contributors</a></p>\n<h2 id=\"h2-hello-raster\"><a name=\"Hello Raster\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Hello Raster</h2><pre><code class=\"lang-scala\">scala&gt; import geotrellis.raster._\nimport geotrellis.raster._\n\nscala&gt; import geotrellis.raster.render.ascii._\nimport geotrellis.raster.render.ascii._\n\nscala&gt; import geotrellis.raster.mapalgebra.focal._\nimport geotrellis.raster.mapalgebra.focal._\n\nscala&gt; val nd = NODATA\nnd: Int = -2147483648\n\nscala&gt; val input = Array[Int](\n     nd, 7, 1, 1,  3, 5, 9, 8, 2,\n      9, 1, 1, 2,  2, 2, 4, 3, 5,\n      3, 8, 1, 3,  3, 3, 1, 2, 2,\n      2, 4, 7, 1, nd, 1, 8, 4, 3)\ninput: Array[Int] = Array(-2147483648, 7, 1, 1, 3, 5, 9, 8, 2, 9, 1, 1, 2,\n2, 2, 4, 3, 5, 3, 8, 1, 3, 3, 3, 1, 2, 2, 2, 4, 7, 1, -2147483648, 1, 8, 4, 3)\n\nscala&gt; val iat = IntArrayTile(input, 9, 4)  // 9 and 4 here specify columns and rows\niat: geotrellis.raster.IntArrayTile = IntArrayTile([I@278434d0,9,4)\n\n// The renderAscii method is mostly useful when you&#39;re working with small tiles\n// which can be taken in at a glance.\nscala&gt; iat.renderAscii(AsciiArtEncoder.Palette.STIPLED)\nres0: String =\n∘█  ▚▜██▖\n█  ▖▖▖▜▚▜\n▚█ ▚▚▚ ▖▖\n▖▜█ ∘ █▜▚\n\nscala&gt; val focalNeighborhood = Square(1)  // a 3x3 square neighborhood\nfocalNeighborhood: geotrellis.raster.op.focal.Square =\n O  O  O\n O  O  O\n O  O  O\n\nscala&gt; val meanTile = iat.focalMean(focalNeighborhood)\nmeanTile: geotrellis.raster.Tile = DoubleArrayTile([D@7e31c125,9,4)\n\nscala&gt; meanTile.getDouble(0, 0)  // Should equal (1 + 7 + 9) / 3\nres1: Double = 5.666666666666667\n</code></pre>\n<h2 id=\"h2-geotrellis-features\"><a name=\"GeoTrellis Features\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>GeoTrellis Features</h2><p>This is a list of features contained in the GeoTrellis library. It is broken up by the subproject that contains the features.</p>\n<h4 id=\"h4-geotrellis-proj4\"><a name=\"geotrellis-proj4\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-proj4</h4><ul>\n<li>Represent a Coordinate Reference System (CRS) based on Ellipsoid, Datum, and Projection.</li><li>Translate CRSs to and from proj4 string representations.</li><li>Lookup CRS’s based on EPSG and other codes.</li><li>Transform <code>(x, y)</code> coordinates from one CRS to another.</li></ul>\n<h4 id=\"h4-geotrellis-vector\"><a name=\"geotrellis-vector\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-vector</h4><ul>\n<li>Provides a scala idiomatic wrapper around JTS types: Point, Line (LineString in JTS), Polygon, MultiPoint, MultiLine (MultiLineString in JTS), MultiPolygon, GeometryCollection</li><li>Methods for geometric operations supported in JTS, with results that provide a type-safe way to match over possible results of geometries.</li><li>Provides a Feature type that is the composition of a geometry and a generic data type.</li><li>Read and write geometries and features to and from GeoJSON.</li><li>Read and write geometries to and from WKT and WKB.</li><li>Reproject geometries between two CRSs.</li><li>Geometric operations: Convex Hull, Densification, Simplification</li><li>Perform Kriging interpolation on point values.</li><li>Perform affine transformations of geometries</li></ul>\n<h4 id=\"h4-geotrellis-vector-testkit\"><a name=\"geotrellis-vector-testkit\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-vector-testkit</h4><ul>\n<li>GeometryBuilder for building test geometries</li><li>GeometryMatcher for scalatest unit tests, which aides in testing equality in geometries with an optional threshold.</li></ul>\n<h4 id=\"h4-geotrellis-raster\"><a name=\"geotrellis-raster\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-raster</h4><ul>\n<li>Provides types to represent single- and multi-band rasters, supporting Bit, Byte, UByte, Short, UShort, Int, Float, and Double data, with either a constant NoData value (which improves performance) or a user defined NoData value.</li><li>Treat a tile as a collection of values, by calling “map” and “foreach”, along with floating point valued versions of those methods (separated out for performance).</li><li>Combine raster data in generic ways.</li><li>Render rasters via color ramps and color maps to PNG and JPG images.</li><li>Read GeoTiffs with DEFLATE, LZW, and PackBits compression, including horizontal and floating point prediction for LZW and DEFLATE.</li><li>Write GeoTiffs with DEFLATE or no compression.</li><li>Reproject rasters from one CRS to another.</li><li>Resample of raster data.</li><li>Mask and Crop rasters.</li><li>Split rasters into smaller tiles, and stitch tiles into larger rasters.</li><li>Derive histograms from rasters in order to represent the distribution of values and create quantile breaks.</li><li>Local Map Algebra operations: Abs, Acos, Add, And, Asin, Atan, Atan2, Ceil, Cos, Cosh, Defined, Divide, Equal, Floor, Greater, GreaterOrEqual, InverseMask, Less, LessOrEqual, Log, Majority, Mask, Max, MaxN, Mean, Min, MinN, Minority, Multiply, Negate, Not, Or, Pow, Round, Sin, Sinh, Sqrt, Subtract, Tan, Tanh, Undefined, Unequal, Variance, Variety, Xor, If</li><li>Focal Map Algebra operations: Hillshade, Aspect, Slope, Convolve, Conway’s Game of Life, Max, Mean, Median, Mode, Min, MoransI, StandardDeviation, Sum</li><li>Zonal Map Algebra operations: ZonalHistogram, ZonalPercentage</li><li>Operations that summarize raster data intersecting polygons: Min, Mean, Max, Sum.</li><li>Cost distance operation based on a set of starting points and a friction raster.</li><li>Hydrology operations: Accumulation, Fill, and FlowDirection.</li><li>Rasterization of geometries and the ability to iterate over cell values covered by geometries.</li><li>Vectorization of raster data.</li><li>Kriging Interpolation of point data into rasters.</li><li>Viewshed operation.</li><li>RegionGroup operation.</li></ul>\n<h4 id=\"h4-geotrellis-raster-testkit\"><a name=\"geotrellis-raster-testkit\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-raster-testkit</h4><ul>\n<li>Build test raster data.</li><li>Assert raster data matches Array data or other rasters in scalatest.</li></ul>\n<h4 id=\"h4-geotrellis-spark\"><a name=\"geotrellis-spark\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-spark</h4><ul>\n<li>Generic way to represent key value RDDs as layers, where the key represents a coordinate in space based on some uniform grid layout, optionally with a temporal component.</li><li>Represent spatial or spatiotemporal raster data as an RDD of raster tiles.</li><li>Generic architecture for saving/loading layers RDD data and metadata to/from various backends, using Spark’s IO API with Space Filling Curve indexing to optimize storage retrieval (support for Hilbert curve and Z order curve SFCs). HDFS and local file system are supported backends by default, S3 and Accumulo are supported backends by the <code>geotrellis-s3</code> and <code>geotrellis-accumulo</code> projects, respectively.</li><li>Query architecture that allows for simple querying of layer data by spatial or spatiotemporal bounds.</li><li>Perform map algebra operations on layers of raster data, including all supported Map Algebra operations mentioned in the geotrellis-raster feature list.</li><li>Perform seamless reprojection on raster layers, using neighboring tile information in the reprojection to avoid unwanted NoData cells.</li><li>Pyramid up layers through zoom levels using various resampling methods.</li><li>Types to reason about tiled raster layouts in various CRS’s and schemes.</li><li>Perform operations on raster RDD layers: crop, filter, join, mask, merge, partition, pyramid, render, resample, split, stitch, and tile.</li><li>Polygonal summary over raster layers: Min, Mean, Max, Sum.</li><li>Save spatially keyed RDDs of byte arrays to z/x/y files into HDFS or the local file system. Useful for saving PNGs off for use as map layers in web maps or for accessing GeoTiffs through z/x/y tile coordinates.</li><li>Utilities around creating spark contexts for applications using GeoTrellis, including a Kryo registrator that registers most types.</li></ul>\n<h4 id=\"h4-geotrellis-spark-testkit\"><a name=\"geotrellis-spark-testkit\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-spark-testkit</h4><ul>\n<li>Utility code to create test RDDs of raster data.</li><li>Matching methods to test equality of RDDs of raster data in scalatest unit tests.</li></ul>\n<h4 id=\"h4-geotrellis-accumulo\"><a name=\"geotrellis-accumulo\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-accumulo</h4><ul>\n<li>Save and load layers to and from Accumulo. Query large layers efficiently using the layer query API.</li></ul>\n<h4 id=\"h4-geotrellis-cassandra\"><a name=\"geotrellis-cassandra\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-cassandra</h4><ul>\n<li>Save and load layers to and from Casandra. Query large layers efficiently using the layer query API.</li></ul>\n<h4 id=\"h4-geotrellis-hbase\"><a name=\"geotrellis-hbase\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-hbase</h4><ul>\n<li>Save and load layers to and from HBase. Query large layers efficiently using the layer query API.</li></ul>\n<h4 id=\"h4-geotrellis-s3\"><a name=\"geotrellis-s3\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-s3</h4><ul>\n<li>Save/load raster layers to/from the local filesystem or HDFS using Spark’s IO API.</li><li>Save spatially keyed RDDs of byte arrays to z/x/y files in S3. Useful for saving PNGs off for use as map layers in web maps.</li></ul>\n<h4 id=\"h4-geotrellis-etl\"><a name=\"geotrellis-etl\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-etl</h4><ul>\n<li>Parse command line options for input and output of ETL (Extract, Transform, and Load) applications</li><li>Utility methods that make ETL applications easier for the user to build.</li><li>Work with input rasters from the local file system, HDFS, or S3</li><li>Reproject input rasters using a per-tile reproject or a seamless reprojection that takes into account neighboring tiles.</li><li>Transform input rasters into layers based on a ZXY layout scheme</li><li>Save layers into Accumulo, S3, HDFS or the local file system.</li></ul>\n<h4 id=\"h4-geotrellis-shapefile\"><a name=\"geotrellis-shapefile\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-shapefile</h4><ul>\n<li>Read geometry and feature data from shapefiles into GeoTrellis types using GeoTools.</li></ul>\n<h4 id=\"h4-geotrellis-slick\"><a name=\"geotrellis-slick\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>geotrellis-slick</h4><ul>\n<li>Save and load geometry and feature data to and from PostGIS using the slick scala database library.</li><li>Perform PostGIS <code>ST_</code> operations in PostGIS through scala.</li></ul>\n<h2 id=\"h2-documentation\"><a name=\"Documentation\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Documentation</h2><ul>\n<li>Further examples and documentation of GeoTrellis use-cases can be found in the <a href=\"./docs\">docs/</a> folder</li><li><em>Scaladocs</em> for the latest version of the project can be found here:</li></ul>\n<p><a href=\"http://geotrellis.github.com/scaladocs/latest/#geotrellis.package\">http://geotrellis.github.com/scaladocs/latest/#geotrellis.package</a></p>\n<h2 id=\"h2-contributing\"><a name=\"Contributing\" class=\"reference-link\"></a><span class=\"header-link octicon octicon-link\"></span>Contributing</h2><p>Feedback and contributions to the project, no matter what kind, are always<br>very welcome. A CLA is required for contribution, see<br><a href=\"http://geotrellis.readthedocs.io/en/latest/CONTRIBUTING.html\">Contributing</a><br>for more information. Please refer to the <a href=\"http://docs.scala-lang.org/style/\">Scala style<br>guide</a> for formatting patches to the<br>codebase.</p>\n');

-- ----------------------------
-- Table structure for tbl_archive_favor
-- ----------------------------
DROP TABLE IF EXISTS `tbl_archive_favor`;
CREATE TABLE `tbl_archive_favor` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `archive_id` int(11) DEFAULT '0',
  `member_id` int(11) DEFAULT '0',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_archive_id_member_id` (`archive_id`,`member_id`) USING BTREE,
  KEY `fk_archive_favor_member` (`member_id`) USING BTREE,
  CONSTRAINT `tbl_archive_favor_ibfk_1` FOREIGN KEY (`archive_id`) REFERENCES `tbl_archive` (`archive_id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_archive_favor_ibfk_2` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=37 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_archive_favor
-- ----------------------------
INSERT INTO `tbl_archive_favor` VALUES ('2', '2018-01-22 20:33:04', '4', '8');
INSERT INTO `tbl_archive_favor` VALUES ('5', '2018-01-26 11:12:10', '13', '13');
INSERT INTO `tbl_archive_favor` VALUES ('6', '2018-01-26 11:13:43', '13', '18');
INSERT INTO `tbl_archive_favor` VALUES ('8', '2018-01-26 11:20:22', '10', '1');
INSERT INTO `tbl_archive_favor` VALUES ('11', '2018-02-09 19:42:37', '19', '8');
INSERT INTO `tbl_archive_favor` VALUES ('13', '2018-02-26 14:26:02', '19', '15');
INSERT INTO `tbl_archive_favor` VALUES ('14', '2018-02-26 14:26:20', '17', '15');
INSERT INTO `tbl_archive_favor` VALUES ('15', '2018-02-27 11:27:17', '20', '15');
INSERT INTO `tbl_archive_favor` VALUES ('16', '2018-02-28 15:25:35', '28', '1');
INSERT INTO `tbl_archive_favor` VALUES ('17', '2018-02-28 15:25:41', '26', '1');
INSERT INTO `tbl_archive_favor` VALUES ('18', '2018-02-28 15:30:50', '23', '1');
INSERT INTO `tbl_archive_favor` VALUES ('20', '2018-02-28 15:31:00', '25', '1');
INSERT INTO `tbl_archive_favor` VALUES ('21', '2018-02-28 15:31:30', '21', '1');
INSERT INTO `tbl_archive_favor` VALUES ('23', '2018-03-02 16:12:12', '23', '19');
INSERT INTO `tbl_archive_favor` VALUES ('24', '2018-03-05 18:31:15', '32', '1');
INSERT INTO `tbl_archive_favor` VALUES ('26', '2018-03-09 18:04:25', '29', '24');
INSERT INTO `tbl_archive_favor` VALUES ('27', '2018-03-23 17:01:18', '17', '25');
INSERT INTO `tbl_archive_favor` VALUES ('28', '2018-03-26 08:56:58', '39', '26');
INSERT INTO `tbl_archive_favor` VALUES ('29', '2018-04-09 11:38:49', '17', '22');
INSERT INTO `tbl_archive_favor` VALUES ('30', '2018-06-10 22:17:59', '63', '8');
INSERT INTO `tbl_archive_favor` VALUES ('32', '2019-01-09 15:10:50', '18', '8');
INSERT INTO `tbl_archive_favor` VALUES ('33', '2019-01-24 18:08:56', '80', '8');
INSERT INTO `tbl_archive_favor` VALUES ('34', '2019-01-24 18:09:37', '79', '8');
INSERT INTO `tbl_archive_favor` VALUES ('35', '2019-01-24 18:09:43', '77', '8');
INSERT INTO `tbl_archive_favor` VALUES ('36', '2019-01-24 18:09:48', '74', '8');

-- ----------------------------
-- Table structure for tbl_article
-- ----------------------------
DROP TABLE IF EXISTS `tbl_article`;
CREATE TABLE `tbl_article` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `collect_time` datetime DEFAULT NULL,
  `cate_id` int(11) DEFAULT NULL COMMENT '栏目ID',
  `archive_id` int(11) DEFAULT NULL COMMENT '文章ID',
  `status` int(11) DEFAULT '0' COMMENT '状态，0未审核，1已审核',
  PRIMARY KEY (`id`),
  KEY `fk_article_archive` (`archive_id`) USING BTREE,
  KEY `fk_article_cate` (`cate_id`) USING BTREE,
  CONSTRAINT `tbl_article_ibfk_1` FOREIGN KEY (`archive_id`) REFERENCES `tbl_archive` (`archive_id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_article_ibfk_2` FOREIGN KEY (`cate_id`) REFERENCES `tbl_article_cate` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_article
-- ----------------------------
INSERT INTO `tbl_article` VALUES ('3', '2018-04-27 15:50:29', '7', '56', '1');
INSERT INTO `tbl_article` VALUES ('4', '2018-04-28 16:24:11', '6', '58', '1');
INSERT INTO `tbl_article` VALUES ('5', '2018-04-28 17:15:41', '6', '59', '1');

-- ----------------------------
-- Table structure for tbl_article_cate
-- ----------------------------
DROP TABLE IF EXISTS `tbl_article_cate`;
CREATE TABLE `tbl_article_cate` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `fid` int(11) DEFAULT '0' COMMENT '上级类目ID，顶级栏目为0',
  `name` varchar(30) DEFAULT NULL COMMENT '栏目名称',
  `status` int(1) DEFAULT '0' COMMENT '0正常，1隐藏',
  `sort` int(11) DEFAULT '50' COMMENT '排序，越大越靠前',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_article_cate
-- ----------------------------
INSERT INTO `tbl_article_cate` VALUES ('6', '0', 'CRH', '0', '52');
INSERT INTO `tbl_article_cate` VALUES ('7', '0', 'CRF', '0', '53');
INSERT INTO `tbl_article_cate` VALUES ('8', '0', 'CRS', '0', '51');

-- ----------------------------
-- Table structure for tbl_article_comment
-- ----------------------------
DROP TABLE IF EXISTS `tbl_article_comment`;
CREATE TABLE `tbl_article_comment` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `article_id` int(11) DEFAULT NULL,
  `member_id` int(11) DEFAULT NULL,
  `content` text,
  PRIMARY KEY (`id`),
  KEY `fk_article_comment_member` (`member_id`) USING BTREE,
  KEY `fk_article_comment_article` (`article_id`) USING BTREE,
  CONSTRAINT `tbl_article_comment_ibfk_1` FOREIGN KEY (`article_id`) REFERENCES `tbl_article` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_article_comment_ibfk_2` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_article_comment
-- ----------------------------

-- ----------------------------
-- Table structure for tbl_config
-- ----------------------------
DROP TABLE IF EXISTS `tbl_config`;
CREATE TABLE `tbl_config` (
  `jkey` varchar(100) NOT NULL DEFAULT '',
  `jvalue` varchar(500) DEFAULT '',
  `description` varchar(255) DEFAULT '',
  PRIMARY KEY (`jkey`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_config
-- ----------------------------
INSERT INTO `tbl_config` VALUES ('cms_post', '1', 'cms会员文章投稿，0关闭，1开启');
INSERT INTO `tbl_config` VALUES ('cms_post_review', '1', 'cms投稿审核，0需要审核，1不需要审核');
INSERT INTO `tbl_config` VALUES ('group_alias', '群组', '群组别名');
INSERT INTO `tbl_config` VALUES ('group_apply', '1', '群组是否可以申请，0不可以，1可以');
INSERT INTO `tbl_config` VALUES ('group_apply_review', '1', '群组申请是否需要审核，0需要审核，1不需要审核');
INSERT INTO `tbl_config` VALUES ('member_email_valid', '1', '邮箱验证，0不需要验证，1需要验证');
INSERT INTO `tbl_config` VALUES ('member_login_open', '1', '会员登录开关，0关闭，1开启');
INSERT INTO `tbl_config` VALUES ('member_register_open', '1', '会员注册开关，0关闭，1开启');
INSERT INTO `tbl_config` VALUES ('site_copyright', 'Copyright © 2013 - 2017.', '版权说明');
INSERT INTO `tbl_config` VALUES ('site_description', '红象大数据社区(Redoop Community)', '网站描述');
INSERT INTO `tbl_config` VALUES ('site_domain', 'www.redoop.com', '网站域名');
INSERT INTO `tbl_config` VALUES ('site_icp', '京ICP备17046370号', '备案号');
INSERT INTO `tbl_config` VALUES ('site_keys', 'Redoop,HDFS,MapReduce,HBase,Hive,Zookeeper,Pig,Ambari,Sqoop,java,Hadoop,CRH,CRF,SPACEP,Cloud,BigData|CASES,CRS,OpenStack,Storm,OpenPower,ARM,Rasie', '网站关键词');
INSERT INTO `tbl_config` VALUES ('site_logo', '/res/common/images/RedoopLogo.png', '网站LOGO');
INSERT INTO `tbl_config` VALUES ('site_name', 'Redoop', '网站名称');
INSERT INTO `tbl_config` VALUES ('site_send_email_account', 'huangtianhao@redoop.com', '发送邮箱账号');
INSERT INTO `tbl_config` VALUES ('site_send_email_password', 'RedOop123', '发送邮箱密码');
INSERT INTO `tbl_config` VALUES ('site_send_email_smtp', 'smtp.exmail.qq.com', '发送邮箱SMTP服务器地址');
INSERT INTO `tbl_config` VALUES ('site_seo_title', '红象大数据社区', 'SEO标题');
INSERT INTO `tbl_config` VALUES ('site_tongji', '<script>var _hmt = _hmt || [];(function() {var hm = document.createElement(\"script\");hm.src = \"https://hm.baidu.com/hm.js?6e79d941db914e4195f4a839b06f2567\";var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s);})();</script>', '统计代码');
INSERT INTO `tbl_config` VALUES ('weibo_alias', '微博', '微博别名');
INSERT INTO `tbl_config` VALUES ('weibo_post', '0', '微博发布，0不可以发布，1可以发布');
INSERT INTO `tbl_config` VALUES ('weibo_post_maxcontent', '140', '微博内容字数');

-- ----------------------------
-- Table structure for tbl_group
-- ----------------------------
DROP TABLE IF EXISTS `tbl_group`;
CREATE TABLE `tbl_group` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `name` varchar(50) DEFAULT NULL COMMENT '群组名字',
  `logo` varchar(255) DEFAULT NULL COMMENT '群组logo',
  `creator` int(11) DEFAULT NULL COMMENT '创建人',
  `managers` varchar(200) DEFAULT NULL COMMENT '管理员',
  `tags` varchar(100) DEFAULT NULL COMMENT '标签',
  `introduce` varchar(255) DEFAULT NULL COMMENT '介绍',
  `can_post` int(11) DEFAULT '0' COMMENT '是否能发帖，0不可以，1可以',
  `topic_review` int(11) DEFAULT '0' COMMENT '帖子是否需要审核，0不需要，1需要',
  `status` int(11) DEFAULT '0' COMMENT '0未审核，1已审核，-1审核不通过',
  PRIMARY KEY (`id`),
  KEY `fk_group_member` (`creator`) USING BTREE,
  CONSTRAINT `tbl_group_ibfk_1` FOREIGN KEY (`creator`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_group
-- ----------------------------
INSERT INTO `tbl_group` VALUES ('1', '2017-12-08 15:13:03', 'Redoop', '/upload/images/20171214/9a08f321-29b3-42ed-a7f0-6f8ca6873529.jpg', '1', '1', 'hadoop,hbase', '红象云腾论坛群组', '1', '0', '1');
INSERT INTO `tbl_group` VALUES ('2', '2018-01-08 17:23:44', 'CRH', '/upload/images/20180404//dcff6584-7c45-48b7-9106-2cb560706913.jpg', '8', '8', '', '', '1', '0', '1');
INSERT INTO `tbl_group` VALUES ('3', '2018-01-10 09:38:47', 'BigData', '/upload/images/20180110/32ee7c0a-392a-4767-8149-f3bca1fcac3b.jpg', '21', '21', '', '基于红象CRH，领域的应用场景实现。', '1', '0', '1');
INSERT INTO `tbl_group` VALUES ('4', '2018-01-24 15:00:28', 'CRS', '/upload/images/20180404//d38ed4fd-eb2b-4550-8902-b2d34b039905.jpg', '1', '1', 'AI', 'Redoop Data Science', '1', '0', '1');
INSERT INTO `tbl_group` VALUES ('5', '2018-01-26 10:16:53', 'CRF', '/upload/images/20180404//a0ffc4d0-a10e-4c2f-98fe-2f8fe563b907.jpg', '1', '1', 'CRF', 'CRF', '1', '0', '1');
INSERT INTO `tbl_group` VALUES ('7', '2018-03-10 18:43:07', 'SPACEP', '/upload/images/20180310/be8b370c-375a-452c-b2a0-2a65ab5a1e32.png', '8', '8', '', 'SPACEP\r\nwww.spacep.org', '1', '0', '1');
INSERT INTO `tbl_group` VALUES ('8', '2018-04-06 14:08:20', 'Cloud', '/upload/images/20180406/967d7bed-e407-4750-8b59-1cf3aa0dd01f.jpg', '8', '8', '', 'Cloud', '1', '0', '1');
INSERT INTO `tbl_group` VALUES ('10', '2019-02-12 18:46:25', 'Mobile', '/upload/images/20190212/4af39422-e750-47b4-b896-e74f5c7390e2.jpg', '8', '8', '', '', '1', '0', '1');

-- ----------------------------
-- Table structure for tbl_group_fans
-- ----------------------------
DROP TABLE IF EXISTS `tbl_group_fans`;
CREATE TABLE `tbl_group_fans` (
  `create_time` datetime DEFAULT NULL,
  `group_id` int(11) DEFAULT NULL,
  `member_id` int(11) DEFAULT NULL,
  UNIQUE KEY `uk_group_id_member_id` (`group_id`,`member_id`) USING BTREE,
  KEY `fk_group_fans_member` (`member_id`) USING BTREE,
  CONSTRAINT `tbl_group_fans_ibfk_1` FOREIGN KEY (`group_id`) REFERENCES `tbl_group` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_group_fans_ibfk_2` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_group_fans
-- ----------------------------
INSERT INTO `tbl_group_fans` VALUES ('2017-12-08 15:13:03', '1', '1');
INSERT INTO `tbl_group_fans` VALUES ('2017-12-08 15:47:58', '1', '7');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-05 16:53:11', '1', '10');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-08 10:13:50', '1', '12');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-08 17:23:44', '2', '8');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-10 08:41:32', '1', '20');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-10 09:38:47', '3', '21');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-12 10:17:59', '1', '15');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-13 23:44:39', '1', '8');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-16 16:19:21', '1', '22');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-22 11:06:01', '2', '13');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-22 11:07:53', '2', '14');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-24 15:00:28', '4', '1');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-25 10:21:48', '2', '23');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-25 10:26:06', '4', '24');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-25 10:44:25', '2', '10');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-25 13:49:15', '2', '19');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-25 14:45:51', '2', '18');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-26 10:16:53', '5', '1');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-26 11:37:32', '3', '12');
INSERT INTO `tbl_group_fans` VALUES ('2018-01-26 13:08:00', '5', '12');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-02 15:48:39', '5', '8');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-02 16:33:25', '5', '25');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-03 10:17:44', '2', '22');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-14 18:23:10', '3', '8');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-25 14:22:27', '2', '11');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-27 09:10:11', '3', '16');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-27 09:28:46', '1', '11');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-27 11:22:12', '4', '26');
INSERT INTO `tbl_group_fans` VALUES ('2018-02-27 16:58:56', '3', '26');
INSERT INTO `tbl_group_fans` VALUES ('2018-03-10 18:43:07', '7', '8');
INSERT INTO `tbl_group_fans` VALUES ('2018-03-14 16:29:40', '7', '31');
INSERT INTO `tbl_group_fans` VALUES ('2018-03-30 15:56:19', '5', '16');
INSERT INTO `tbl_group_fans` VALUES ('2018-04-03 09:31:13', '1', '16');
INSERT INTO `tbl_group_fans` VALUES ('2018-04-03 09:31:19', '2', '16');
INSERT INTO `tbl_group_fans` VALUES ('2018-04-06 14:08:20', '8', '8');
INSERT INTO `tbl_group_fans` VALUES ('2018-04-08 10:58:05', '8', '25');
INSERT INTO `tbl_group_fans` VALUES ('2018-09-20 13:47:47', '4', '8');
INSERT INTO `tbl_group_fans` VALUES ('2018-09-28 10:24:45', '2', '25');
INSERT INTO `tbl_group_fans` VALUES ('2019-01-09 15:12:54', '4', '22');
INSERT INTO `tbl_group_fans` VALUES ('2019-01-15 17:14:51', '8', '22');
INSERT INTO `tbl_group_fans` VALUES ('2019-02-12 18:46:25', '10', '8');

-- ----------------------------
-- Table structure for tbl_group_topic
-- ----------------------------
DROP TABLE IF EXISTS `tbl_group_topic`;
CREATE TABLE `tbl_group_topic` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `collect_time` datetime DEFAULT NULL,
  `group_id` int(11) DEFAULT NULL,
  `archive_id` int(11) DEFAULT NULL,
  `status` int(11) DEFAULT '0' COMMENT '状态，0未审核，1已审核',
  `is_essence` int(11) DEFAULT '0' COMMENT '精华，0不加精，1加精',
  `is_top` int(11) DEFAULT '0' COMMENT '置顶，0不置顶，1置顶，2超级置顶',
  `groupstatus` int(11) DEFAULT NULL COMMENT 'GroupStatus',
  PRIMARY KEY (`id`),
  KEY `fk_group_topic_group` (`group_id`) USING BTREE,
  KEY `fk_group_topic_archive` (`archive_id`) USING BTREE,
  CONSTRAINT `tbl_group_topic_ibfk_1` FOREIGN KEY (`archive_id`) REFERENCES `tbl_archive` (`archive_id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_group_topic_ibfk_2` FOREIGN KEY (`group_id`) REFERENCES `tbl_group` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=85 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_group_topic
-- ----------------------------
INSERT INTO `tbl_group_topic` VALUES ('3', '2018-01-22 11:14:40', '2', '3', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('4', '2018-01-22 18:31:25', '7', '4', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('5', '2018-01-23 16:12:29', '2', '5', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('6', '2018-01-23 17:17:18', '2', '6', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('8', '2018-01-25 10:56:39', '4', '8', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('9', '2018-01-25 11:00:12', '2', '9', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('10', '2018-01-25 13:55:27', '2', '10', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('11', '2018-01-25 14:25:22', '2', '11', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('12', '2018-01-25 14:49:30', '2', '12', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('13', '2018-01-26 10:06:19', '2', '13', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('14', '2018-01-26 11:29:49', '3', '14', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('17', '2018-02-03 17:04:09', '5', '17', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('18', '2018-02-05 17:19:27', '8', '18', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('19', '2018-02-09 16:48:08', '8', '19', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('20', '2018-02-27 10:37:40', '3', '20', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('21', '2018-02-27 10:38:12', '1', '21', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('22', '2018-02-27 10:45:21', '1', '22', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('23', '2018-02-27 15:37:12', '2', '23', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('24', '2018-02-27 15:53:14', '2', '24', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('25', '2018-02-27 16:00:11', '4', '25', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('26', '2018-02-27 16:52:03', '2', '26', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('28', '2018-02-27 17:36:15', '4', '28', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('29', '2018-02-28 17:17:17', '2', '29', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('30', '2018-03-01 14:26:00', '2', '30', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('31', '2018-03-02 16:11:44', '2', '31', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('32', '2018-03-02 16:22:38', '4', '32', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('33', '2018-03-07 11:49:28', '2', '33', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('34', '2018-03-07 15:27:10', '2', '34', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('35', '2018-03-08 09:16:30', '2', '35', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('36', '2018-03-09 09:31:24', '8', '36', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('37', '2018-03-09 15:27:31', '4', '37', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('38', '2018-03-14 17:06:13', '7', '38', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('39', '2018-03-21 19:11:26', '5', '39', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('40', '2018-03-22 16:23:59', '8', '40', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('41', '2018-03-23 08:39:34', '2', '41', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('42', '2018-03-26 18:48:23', '1', '42', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('43', '2018-03-27 10:05:08', '2', '43', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('44', '2018-03-29 10:54:51', '4', '44', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('45', '2018-03-29 11:32:14', '4', '45', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('46', '2018-03-30 16:00:22', '5', '46', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('47', '2018-04-03 10:02:13', '1', '47', '0', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('48', '2018-04-16 14:45:24', '8', '50', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('49', '2018-04-24 11:33:46', '8', '51', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('50', '2018-04-24 13:16:00', '2', '52', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('51', '2018-04-25 13:56:03', '5', '53', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('52', '2018-04-28 15:34:03', '5', '57', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('53', '2018-05-09 14:18:49', '2', '60', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('54', '2018-06-05 15:09:55', '4', '61', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('55', '2018-06-09 18:23:50', '7', '62', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('56', '2018-06-10 16:24:42', '7', '63', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('57', '2018-06-13 18:06:31', '7', '64', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('58', '2018-09-13 19:36:07', '7', '65', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('59', '2018-09-20 13:49:16', '4', '66', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('60', '2018-09-28 10:30:04', '2', '67', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('61', '2018-11-30 18:41:16', '2', '68', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('62', '2019-01-03 13:58:34', '5', '69', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('63', '2019-01-05 19:34:25', '8', '70', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('64', '2019-01-05 21:18:16', '2', '71', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('66', '2019-01-09 22:20:33', '3', '73', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('67', '2019-01-09 22:53:26', '4', '74', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('68', '2019-01-10 04:30:51', '3', '75', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('69', '2019-01-19 15:51:30', '3', '76', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('70', '2019-01-24 13:54:58', '3', '77', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('71', '2019-01-24 16:54:57', '1', '78', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('72', '2019-01-24 17:43:46', '3', '79', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('73', '2019-01-24 17:53:40', '3', '80', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('74', '2019-01-24 22:35:58', '3', '81', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('75', '2019-01-24 23:10:41', '7', '82', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('76', '2019-02-11 19:38:05', '8', '83', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('77', '2019-02-12 18:47:23', '10', '84', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('78', '2019-02-19 18:04:17', '2', '85', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('79', '2019-02-20 01:01:46', '1', '86', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('80', '2019-02-22 00:01:56', '7', '87', '1', '0', '0', '1');
INSERT INTO `tbl_group_topic` VALUES ('81', '2019-02-22 00:29:35', '7', '88', '1', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('82', '2019-02-22 00:33:37', '7', '89', '0', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('83', '2019-02-22 00:35:42', '7', '90', '0', '0', '0', '0');
INSERT INTO `tbl_group_topic` VALUES ('84', '2019-02-22 00:41:35', '7', '91', '0', '0', '0', '0');

-- ----------------------------
-- Table structure for tbl_group_topic_comment
-- ----------------------------
DROP TABLE IF EXISTS `tbl_group_topic_comment`;
CREATE TABLE `tbl_group_topic_comment` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `group_topic_id` int(11) DEFAULT NULL,
  `member_id` int(11) DEFAULT NULL,
  `comment_id` int(11) DEFAULT NULL,
  `content` text,
  PRIMARY KEY (`id`),
  KEY `fk_group_topic_comment_member` (`member_id`) USING BTREE,
  KEY `fk_group_topic_comment_group_topic` (`group_topic_id`) USING BTREE,
  CONSTRAINT `tbl_group_topic_comment_ibfk_1` FOREIGN KEY (`group_topic_id`) REFERENCES `tbl_group_topic` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_group_topic_comment_ibfk_2` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_group_topic_comment
-- ----------------------------
INSERT INTO `tbl_group_topic_comment` VALUES ('1', '2018-01-22 11:33:19', '3', '13', null, 'markdown解释器是不是需要调整，这和其他markdown解释器显示效果区别太大');
INSERT INTO `tbl_group_topic_comment` VALUES ('2', '2018-01-22 13:50:33', '3', '1', '1', '正在调试中');
INSERT INTO `tbl_group_topic_comment` VALUES ('3', '2018-02-03 21:05:19', '4', '8', null, '矿物光谱\nhttps://crustal.usgs.gov/speclab/QueryAll07a.php');
INSERT INTO `tbl_group_topic_comment` VALUES ('4', '2018-02-04 19:47:38', '4', '1', null, '开源GIS工具链：\nGeoServer（应用服务）  + PostGis(数据库) + OpenStreetMap(矢量数据) + 	OpenLayers(展现)\n参考文档:https://www.cnblogs.com/think8848/p/6016984.html');
INSERT INTO `tbl_group_topic_comment` VALUES ('5', '2018-02-04 23:30:40', '4', '1', null, 'System for Automated Geoscientific Analyses\nhttp://www.saga-gis.org/en/index.html');
INSERT INTO `tbl_group_topic_comment` VALUES ('6', '2018-03-04 05:32:54', '3', '28', null, 'crh所需要的repo文件 官网的下载地址失效了 能不能重新发一个');
INSERT INTO `tbl_group_topic_comment` VALUES ('7', '2018-03-07 19:18:53', '33', '1', null, '这个是在主版本中嘛？记得IBM系统优化部提供过一个Path，可以讨论一下。');
INSERT INTO `tbl_group_topic_comment` VALUES ('8', '2018-03-10 18:45:50', '4', '8', null, 'Python 多光谱处理:http://blog.csdn.net/mrlevo520/article/details/78512066?locationnum=9&fps=1');
INSERT INTO `tbl_group_topic_comment` VALUES ('9', '2018-03-14 19:55:02', '38', '8', null, '不错。');
INSERT INTO `tbl_group_topic_comment` VALUES ('10', '2018-03-30 17:09:16', '46', '8', null, '如果和TIDB结合，就可以完成　MySQL和TIDB  同步了。');
INSERT INTO `tbl_group_topic_comment` VALUES ('11', '2018-04-29 22:15:16', '4', '1', null, 'http://gea.esac.esa.int/archive/');
INSERT INTO `tbl_group_topic_comment` VALUES ('12', '2018-06-13 22:46:30', '4', '8', null, 'https://planet.openstreetmap.org/ ');
INSERT INTO `tbl_group_topic_comment` VALUES ('13', '2019-02-19 14:04:06', '17', '25', null, 'https://www.osyunwei.com/archives/7174.html');

-- ----------------------------
-- Table structure for tbl_link
-- ----------------------------
DROP TABLE IF EXISTS `tbl_link`;
CREATE TABLE `tbl_link` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `name` varchar(100) DEFAULT NULL COMMENT '网站名称',
  `url` varchar(255) DEFAULT NULL COMMENT '网址',
  `sort` int(11) NOT NULL DEFAULT '0' COMMENT '排序，越大越靠前',
  `recomment` int(11) NOT NULL DEFAULT '0' COMMENT '推荐，0不推荐，1推荐',
  `status` int(1) DEFAULT '0' COMMENT '状态，0禁用，1启用',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_link
-- ----------------------------

-- ----------------------------
-- Table structure for tbl_member
-- ----------------------------
DROP TABLE IF EXISTS `tbl_member`;
CREATE TABLE `tbl_member` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `group_id` int(11) DEFAULT '0' COMMENT '分组ID',
  `name` varchar(50) DEFAULT NULL COMMENT '会员名称',
  `email` varchar(50) DEFAULT '' COMMENT '邮箱',
  `phone` varchar(11) DEFAULT '' COMMENT '手机号码',
  `password` varchar(32) DEFAULT '' COMMENT '密码',
  `sex` varchar(2) DEFAULT NULL COMMENT '性别',
  `avatar` varchar(255) DEFAULT NULL COMMENT '头像',
  `create_time` datetime DEFAULT NULL COMMENT '注册时间',
  `regip` varchar(15) DEFAULT '' COMMENT '注册IP',
  `login_count` int(11) DEFAULT '0' COMMENT '登录次数',
  `curr_login_time` datetime DEFAULT NULL COMMENT '本次登录时间',
  `curr_login_ip` varchar(15) DEFAULT NULL COMMENT '本次登录IP',
  `last_login_time` datetime DEFAULT NULL COMMENT '上次登录时间',
  `last_login_ip` varchar(15) DEFAULT NULL COMMENT '上次登录IP',
  `update_time` datetime DEFAULT NULL COMMENT '更新资料时间',
  `money` double(11,2) DEFAULT '0.00' COMMENT '金额',
  `score` int(11) DEFAULT '0' COMMENT '积分',
  `is_active` int(1) DEFAULT '0' COMMENT '是否已激活，0未激活，1已激活',
  `status` int(2) DEFAULT '0' COMMENT '-1禁用，0启用',
  `birthday` varchar(10) DEFAULT NULL COMMENT '生日',
  `addprovince` varchar(20) DEFAULT '' COMMENT '居住省份',
  `addcity` varchar(20) DEFAULT '' COMMENT '居住城市',
  `addarea` varchar(20) DEFAULT '' COMMENT '居住地区',
  `address` varchar(50) DEFAULT '' COMMENT '居住地址',
  `qq` varchar(15) DEFAULT '' COMMENT 'QQ',
  `wechat` varchar(20) DEFAULT '' COMMENT '微信',
  `contact_phone` varchar(11) DEFAULT '' COMMENT '联系手机号',
  `contact_email` varchar(32) DEFAULT '' COMMENT '联系邮箱',
  `website` varchar(50) DEFAULT '' COMMENT '个人网站',
  `introduce` varchar(255) DEFAULT '' COMMENT '个人介绍',
  `is_admin` int(11) DEFAULT '0' COMMENT '是否管理员，0不是，1是普通管理员，2是超级管理员',
  `follows` int(11) DEFAULT '0' COMMENT '关注会员数量',
  `fans` int(11) DEFAULT '0' COMMENT '粉丝数量',
  PRIMARY KEY (`id`),
  UNIQUE KEY `name` (`name`) USING BTREE,
  UNIQUE KEY `email` (`email`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=35 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_member
-- ----------------------------
INSERT INTO `tbl_member` VALUES ('1', '0', 'admin', 'huangtianhao@redoop.com', '18515670511', 'e10adc3949ba59abbe56e057f20f883e', '男', '/res/common/images/default-avatar.png', '2017-11-27 17:24:32', '', '304', '2019-02-26 16:56:45', '0:0:0:0:0:0:0:1', '2019-02-26 16:17:41', '0:0:0:0:0:0:0:1', null, '0.00', '100104', '1', '0', '1971-12-20', '', '', '', '', '8888888', 'admin', '18515670511', 'redoop@redoop.com', 'www.redoop.com', '', '2', '0', '1');
INSERT INTO `tbl_member` VALUES ('7', '0', 'haowenju', 'haowenju@redoop.com', '', 'e0612e032457c89bf3b7b425436eeeeb', null, '/res/common/images/default-avatar.png', '2017-12-08 15:20:55', '223.223.188.66', '11', '2018-04-25 08:50:57', '127.0.0.1', '2018-01-30 11:24:48', '223.223.188.66', null, '0.00', '115', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '1', '0', '0');
INSERT INTO `tbl_member` VALUES ('8', '0', 'tongxiaojun', 'tongxiaojun@redoop.com', '', '36b1185b9cf2f423e0c56c2af8550f0f', null, '/res/common/images/default-avatar.png', '2017-12-25 22:59:31', '223.223.188.66', '60', '2019-02-21 23:45:53', '192.168.0.155', '2019-02-20 13:01:54', '192.168.0.155', null, '0.00', '135', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '1', '0', '0');
INSERT INTO `tbl_member` VALUES ('9', '0', '闲庭信步', 'pangxinyou@redoop.com', '', '0434f5e537545071e1c8920621c85a57', '男', '/upload/avatar/201801/fa332d9f-8401-4963-9870-b2120ec111f2.jpg', '2018-01-05 15:47:26', '223.223.188.66', '2', '2018-02-28 13:24:01', '127.0.0.1', '2018-01-05 15:47:43', '223.223.188.66', null, '0.00', '103', '1', '0', null, '', '', '', '', '', '', '', '', '', '大红象', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('10', '0', 'niuhaisheng', 'niuhaisheng@redoop.com', '', '0d0cdf5dc98d730114d6e990940655a4', null, '/res/common/images/default-avatar.png', '2018-01-05 16:49:12', '223.223.188.66', '4', '2018-02-27 16:33:21', '127.0.0.1', '2018-01-25 10:42:00', '114.242.250.209', null, '0.00', '105', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('11', '0', 'zhangxing', 'zhangxing@redoop.com', '', '833ef5c74990d278641c5a5ba5a29371', '男', '/res/common/images/default-avatar.png', '2018-01-05 17:00:09', '223.223.188.66', '15', '2018-03-26 18:41:04', '127.0.0.1', '2018-03-25 21:32:30', '127.0.0.1', null, '0.00', '112', '1', '0', null, '', '', '', '', '', '', '', '', '', 'a boy love coding and baseball.', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('12', '0', 'sundafei', 'sundafei@redoop.com', '', '69e4a0df53c64ac5c2c072299c21774e', null, '/res/common/images/default-avatar.png', '2018-01-08 10:11:54', '223.223.188.66', '6', '2018-01-26 11:18:07', '223.223.188.66', '2018-01-17 10:46:14', '223.223.188.66', null, '0.00', '110', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '1');
INSERT INTO `tbl_member` VALUES ('13', '0', 'xingweidong', 'xingweidong@redoop.com', '', '7e94bb7c3f0fc2950cd38687981bc7c8', null, '/res/common/images/default-avatar.png', '2018-01-08 10:15:24', '223.223.188.66', '10', '2018-05-09 14:15:56', '127.0.0.1', '2018-05-08 10:08:04', '127.0.0.1', null, '0.00', '115', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('14', '0', 'niuxin', 'niuxin@redoop.com', '', 'e10adc3949ba59abbe56e057f20f883e', null, '/res/common/images/default-avatar.png', '2018-01-08 10:16:14', '223.223.188.66', '10', '2018-04-28 16:19:42', '127.0.0.1', '2018-03-08 09:15:52', '127.0.0.1', null, '0.00', '112', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('15', '0', 'wangchunli', 'wangchunli@redoop.com', '', '1dd6d808807a4255bc836b402bbad74b', null, '/upload/avatar/201801/c8e58443-23bb-48d2-a68c-cc22c00ab955.jpg', '2018-01-08 10:59:41', '223.223.188.66', '40', '2018-04-04 09:09:18', '127.0.0.1', '2018-04-03 09:54:24', '127.0.0.1', null, '0.00', '141', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '1', '0');
INSERT INTO `tbl_member` VALUES ('16', '0', 'sunweijian', 'sunweijian@redoop.com', '', '2c61b05639efa7c6054b72000523b791', null, '/res/common/images/default-avatar.png', '2018-01-08 11:21:39', '223.223.188.66', '7', '2018-04-08 15:17:00', '127.0.0.1', '2018-04-03 16:58:36', '127.0.0.1', null, '0.00', '107', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('17', '0', 'nick-123456', 'xuening@redoop.com', '', 'e807f1fcf82d132f9bb018ca6738a19f', null, '/res/common/images/default-avatar.png', '2018-01-08 11:49:19', '223.223.188.66', '1', '2018-01-08 11:49:40', '223.223.188.66', '2018-01-08 11:49:19', '223.223.188.66', null, '0.00', '101', '0', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('18', '0', 'zhaoshuai', 'zhaoshuai@redoop.com', '', '82d7a302c815c3246cf63bc6a987452f', null, '/res/common/images/default-avatar.png', '2018-01-08 16:20:43', '223.223.188.66', '10', '2018-10-17 11:49:50', '192.168.0.155', '2018-07-11 15:45:07', '127.0.0.1', null, '0.00', '111', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('19', '0', 'sulongfei', 'sulongfei@redoop.com', '', 'b740d33c9758bc572edda085068d1416', null, '/res/common/images/default-avatar.png', '2018-01-09 16:13:00', '223.223.188.66', '13', '2018-07-04 14:12:00', '127.0.0.1', '2018-04-08 10:38:22', '127.0.0.1', null, '0.00', '113', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('20', '0', 'xamlay', 'liuxin@redoop.com', '', 'bbee81971886a52592fb84ba4ea27f83', null, '/res/common/images/default-avatar.png', '2018-01-10 08:40:03', '223.223.188.66', '1', '2018-01-10 08:40:12', '223.223.188.66', '2018-01-10 08:40:03', '223.223.188.66', null, '0.00', '102', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('21', '0', 'min120', 'panbo@redoop.com', '', '3ce25a66d5b3a8cd661024fea6c79388', '男', '/upload/avatar/201801/18b7fc1a-364a-4ead-a3c0-d3ca8691107b.jpg', '2018-01-10 09:28:22', '223.223.188.66', '2', '2018-01-26 11:21:23', '223.223.188.66', '2018-01-10 09:28:32', '223.223.188.66', null, '0.00', '93', '1', '0', null, '', '', '', '', '', '', '', '', '', '欢天喜地当禽兽', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('22', '0', 'huangtianhao', 'HTH_SWP@163.com', '', '46600abaec8f726c05a2c023c7e114d2', null, '/res/common/images/default-avatar.png', '2018-01-11 11:29:00', '223.223.188.69', '32', '2019-02-28 09:22:05', '0:0:0:0:0:0:0:1', '2019-02-26 16:18:01', '0:0:0:0:0:0:0:1', null, '0.00', '116', '1', '0', '2019-01-09', '', '', '', '', 'asd', 'qw', '111111', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('23', '0', 'houjinxia', 'houjinxia@redoop.com', '', '005c5f70e070eb7002496086e8458a45', null, '/res/common/images/default-avatar.png', '2018-01-25 10:18:15', '223.223.188.66', '3', '2018-03-07 14:32:38', '127.0.0.1', '2018-02-28 16:49:14', '127.0.0.1', null, '0.00', '104', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('24', '0', 'songxiaolei', 'songxiaolei@redoop.com', '', 'e10adc3949ba59abbe56e057f20f883e', null, '/res/common/images/default-avatar.png', '2018-01-25 10:23:20', '223.223.188.66', '11', '2018-06-12 10:43:44', '127.0.0.1', '2018-06-05 14:41:39', '127.0.0.1', null, '0.00', '113', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('25', '0', 'mazeteng', 'mazeteng@redoop.com', '', '194083cb26dcfd535d438c32d8acb505', null, '/res/common/images/default-avatar.png', '2018-01-26 10:16:18', '223.223.188.66', '42', '2019-02-19 14:03:38', '192.168.0.155', '2019-01-03 13:37:49', '192.168.0.155', null, '0.00', '143', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('26', '0', 'wangyabin', 'wangyabin@redoop.com', '', 'e10adc3949ba59abbe56e057f20f883e', null, '/res/common/images/default-avatar.png', '2018-02-26 08:55:19', '223.223.188.69', '8', '2018-03-29 09:51:31', '127.0.0.1', '2018-03-26 08:56:49', '127.0.0.1', null, '0.00', '105', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('28', '0', '翠竹随锋血墨', '747146282@qq.com', '', '428618ecda6b48a0132fe1f7dec66a02', null, '/res/common/images/default-avatar.png', '2018-03-04 05:29:02', '127.0.0.1', '1', '2018-03-04 05:30:30', '127.0.0.1', '2018-03-04 05:29:02', '127.0.0.1', null, '0.00', '103', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('29', '0', 'leixianp', 'leixianp@163.com', '', '376c43878878ac04e05946ec1dd7a55f', null, '/res/common/images/default-avatar.png', '2018-03-06 14:49:33', '127.0.0.1', '1', '2018-03-06 14:49:45', '127.0.0.1', '2018-03-06 14:49:33', '127.0.0.1', null, '0.00', '102', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('30', '0', 'nsnzdw', '2993001710@qq.com', '', 'e61eb0b66fcca00a61da9e0f6a81129a', null, '/res/common/images/default-avatar.png', '2018-03-07 15:45:48', '127.0.0.1', '1', '2018-03-07 15:45:57', '127.0.0.1', '2018-03-07 15:45:48', '127.0.0.1', null, '0.00', '102', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('31', '0', 'guoxiaopei', 'guoxiaopei@redoop.com', '', 'ce1ea20f49e5e075ed4676dbd46de4df', null, '/res/common/images/default-avatar.png', '2018-03-14 16:20:02', '127.0.0.1', '1', '2018-03-14 16:20:10', '127.0.0.1', '2018-03-14 16:20:02', '127.0.0.1', null, '0.00', '102', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('32', '0', 'haonit', 'silver@163.com', '', '59e5cdce3e05204d70864b7a757098e6', null, '/res/common/images/default-avatar.png', '2018-03-16 13:50:00', '127.0.0.1', '1', '2018-03-16 13:50:10', '127.0.0.1', '2018-03-16 13:50:00', '127.0.0.1', null, '0.00', '101', '0', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('33', '0', 'hua6884858', '303064157@qq.com', '', '27fdd371d13fec7ed2d206950fac03e2', null, '/res/common/images/default-avatar.png', '2018-09-26 18:31:23', '192.168.0.155', '1', '2018-09-26 18:31:29', '192.168.0.155', '2018-09-26 18:31:23', '192.168.0.155', null, '0.00', '102', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');
INSERT INTO `tbl_member` VALUES ('34', '0', 'binaryshuai', '526107212@qq.com', '', '3293a84f9e9e10ba2519f3021e475d9b', null, '/res/common/images/default-avatar.png', '2018-11-02 11:11:09', '192.168.0.155', '1', '2018-11-02 11:11:19', '192.168.0.155', '2018-11-02 11:11:09', '192.168.0.155', null, '0.00', '102', '1', '0', null, '', '', '', '', '', '', '', '', '', '', '0', '0', '0');

-- ----------------------------
-- Table structure for tbl_member_fans
-- ----------------------------
DROP TABLE IF EXISTS `tbl_member_fans`;
CREATE TABLE `tbl_member_fans` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `follow_who` int(11) DEFAULT '0',
  `who_follow` int(11) DEFAULT '0',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_follow_who_who_follow` (`follow_who`,`who_follow`) USING BTREE,
  KEY `fk_member_fans_who_follow` (`who_follow`) USING BTREE,
  CONSTRAINT `tbl_member_fans_ibfk_1` FOREIGN KEY (`follow_who`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_member_fans_ibfk_2` FOREIGN KEY (`who_follow`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_member_fans
-- ----------------------------
INSERT INTO `tbl_member_fans` VALUES ('1', '2018-01-12 10:15:47', '12', '15');

-- ----------------------------
-- Table structure for tbl_member_token
-- ----------------------------
DROP TABLE IF EXISTS `tbl_member_token`;
CREATE TABLE `tbl_member_token` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `member_id` int(11) DEFAULT '0' COMMENT '会员ID',
  `token` varchar(32) DEFAULT '',
  `expire_time` datetime DEFAULT NULL,
  `status` int(11) DEFAULT '0' COMMENT '状态，0是正常，1是失效',
  PRIMARY KEY (`id`),
  KEY `fk_member_token_member` (`member_id`) USING BTREE,
  CONSTRAINT `tbl_member_token_ibfk_1` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_member_token
-- ----------------------------

-- ----------------------------
-- Table structure for tbl_memgroup
-- ----------------------------
DROP TABLE IF EXISTS `tbl_memgroup`;
CREATE TABLE `tbl_memgroup` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `isadmin` int(1) DEFAULT '0' COMMENT '是否是管理组，0不是，1是',
  `name` varchar(50) DEFAULT '' COMMENT '分组名称',
  `fid` int(11) DEFAULT '0' COMMENT '上级分组ID，默认0，0是顶级分组',
  `rankid` int(11) DEFAULT '0' COMMENT '权限ID，0-99是会员权限，100以上是管理员权限',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_memgroup
-- ----------------------------

-- ----------------------------
-- Table structure for tbl_message
-- ----------------------------
DROP TABLE IF EXISTS `tbl_message`;
CREATE TABLE `tbl_message` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `from_member_id` int(11) DEFAULT '0',
  `to_member_id` int(11) DEFAULT '0',
  `content` text,
  `url` varchar(255) DEFAULT NULL,
  `app_tag` int(11) DEFAULT NULL,
  `type` int(11) DEFAULT NULL,
  `relate_key_id` int(11) DEFAULT NULL,
  `member_id` int(11) DEFAULT NULL,
  `description` varchar(500) DEFAULT NULL,
  `isread` int(1) DEFAULT '0' COMMENT '是否已读，0未读，1已读',
  PRIMARY KEY (`id`),
  KEY `fk_message_from_member` (`from_member_id`) USING BTREE,
  KEY `fk_message_to_member` (`to_member_id`) USING BTREE,
  KEY `fk_message_member` (`member_id`) USING BTREE,
  CONSTRAINT `tbl_message_ibfk_1` FOREIGN KEY (`from_member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_message_ibfk_2` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_message_ibfk_3` FOREIGN KEY (`to_member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=45 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_message
-- ----------------------------
INSERT INTO `tbl_message` VALUES ('1', '2018-01-12 10:16:39', null, '12', null, null, '3', '31003', '9', '15', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('2', '2018-01-12 10:17:09', null, '12', null, null, '3', '31003', '8', '15', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('3', '2018-01-16 11:27:48', null, '12', '不错', null, '3', '32001', '8', '22', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('4', '2018-01-16 11:39:56', null, '12', null, null, '3', '31003', '8', '22', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('5', '2018-01-16 11:41:49', null, '12', null, null, '3', '31003', '8', '22', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('6', '2018-01-16 11:43:03', null, '12', null, null, '3', '31003', '8', '22', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('7', '2018-01-16 12:28:25', null, '12', '很好，喜欢这文章', null, '3', '32001', '8', '22', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('8', '2018-01-16 13:07:15', null, '12', null, null, '3', '31003', '8', '22', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('9', '2018-01-16 13:07:21', null, '12', null, null, '3', '31003', '8', '22', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('10', '2018-01-22 11:33:19', null, '14', 'markdown解释器是不是需要调整，这和其他markdown解释器显示效果区别太大', null, '3', '32001', '3', '13', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('11', '2018-01-22 13:50:33', null, '14', '正在调试中', null, '3', '32001', '3', '1', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('12', '2018-01-22 13:50:33', null, '13', '正在调试中', null, '3', '33001', '1', '1', '回复了你的群组帖子评论。', '0');
INSERT INTO `tbl_message` VALUES ('13', '2018-01-22 19:19:00', null, '14', null, null, '3', '31003', '3', '8', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('14', '2018-01-22 20:33:04', null, '1', null, null, '3', '31003', '4', '8', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('15', '2018-01-26 11:01:00', null, '13', null, null, '3', '31003', '13', '18', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('16', '2018-01-26 11:13:43', null, '13', null, null, '3', '31003', '13', '18', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('17', '2018-01-26 11:19:15', null, '19', null, null, '3', '31003', '10', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('18', '2018-01-26 11:20:22', null, '19', null, null, '3', '31003', '10', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('19', '2018-02-03 21:05:19', null, '1', '矿物光谱\nhttps://crustal.usgs.gov/speclab/QueryAll07a.php', null, '3', '32001', '4', '8', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('20', '2018-02-05 16:40:28', null, '25', null, null, '3', '31003', '17', '22', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('21', '2018-02-09 19:42:37', null, '25', null, null, '3', '31003', '19', '8', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('22', '2018-02-26 14:25:59', null, '25', null, null, '3', '31003', '19', '15', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('23', '2018-02-26 14:26:02', null, '25', null, null, '3', '31003', '19', '15', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('24', '2018-02-26 14:26:20', null, '25', null, null, '3', '31003', '17', '15', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('25', '2018-02-27 11:27:17', null, '16', null, null, '3', '31003', '20', '15', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('26', '2018-02-28 15:25:35', null, '26', null, null, '3', '31003', '28', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('27', '2018-02-28 15:25:41', null, '10', null, null, '3', '31003', '26', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('28', '2018-02-28 15:30:50', null, '19', null, null, '3', '31003', '23', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('29', '2018-02-28 15:30:57', null, '24', null, null, '3', '31003', '25', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('30', '2018-02-28 15:31:00', null, '24', null, null, '3', '31003', '25', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('31', '2018-02-28 15:31:30', null, '11', null, null, '3', '31003', '21', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('32', '2018-03-04 05:32:54', null, '14', 'crh所需要的repo文件 官网的下载地址失效了 能不能重新发一个', null, '3', '32001', '3', '28', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('33', '2018-03-05 18:31:15', null, '24', null, null, '3', '31003', '32', '1', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('34', '2018-03-07 19:18:53', null, '13', '这个是在主版本中嘛？记得IBM系统优化部提供过一个Path，可以讨论一下。', null, '3', '32001', '33', '1', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('35', '2018-03-09 18:04:23', null, '23', null, null, '3', '31003', '29', '24', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('36', '2018-03-09 18:04:25', null, '23', null, null, '3', '31003', '29', '24', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('37', '2018-03-10 18:45:50', null, '1', 'Python 多光谱处理:http://blog.csdn.net/mrlevo520/article/details/78512066?locationnum=9&fps=1', null, '3', '32001', '4', '8', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('38', '2018-03-14 19:55:02', null, '31', '不错。', null, '3', '32001', '38', '8', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('39', '2018-03-26 08:56:58', null, '11', null, null, '3', '31003', '39', '26', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('40', '2018-03-30 17:09:16', null, '16', '如果和TIDB结合，就可以完成　MySQL和TIDB  同步了。', null, '3', '32001', '46', '8', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('41', '2018-04-09 11:38:49', null, '25', null, null, '3', '31003', '17', '22', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('42', '2018-06-13 22:46:30', null, '1', 'https://planet.openstreetmap.org/ ', null, '3', '32001', '4', '8', '回复了你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('43', '2019-01-09 15:10:45', null, '25', null, null, '3', '31003', '18', '8', '喜欢你的群组帖子。', '0');
INSERT INTO `tbl_message` VALUES ('44', '2019-01-09 15:10:50', null, '25', null, null, '3', '31003', '18', '8', '喜欢你的群组帖子。', '0');

-- ----------------------------
-- Table structure for tbl_picture
-- ----------------------------
DROP TABLE IF EXISTS `tbl_picture`;
CREATE TABLE `tbl_picture` (
  `picture_id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `member_id` int(11) DEFAULT NULL,
  `type` int(11) NOT NULL COMMENT '1是文章图片，2是群组帖子图片，3是微博图片',
  `foreign_id` int(11) DEFAULT NULL COMMENT '外键ID',
  `path` varchar(255) NOT NULL COMMENT '图片路径',
  `thumbnail_path` varchar(255) DEFAULT NULL COMMENT '缩小的图片路径',
  `md5` varchar(32) NOT NULL,
  `width` int(11) DEFAULT '0',
  `height` int(11) DEFAULT '0',
  `description` varchar(1000) DEFAULT NULL,
  PRIMARY KEY (`picture_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_picture
-- ----------------------------

-- ----------------------------
-- Table structure for tbl_score_detail
-- ----------------------------
DROP TABLE IF EXISTS `tbl_score_detail`;
CREATE TABLE `tbl_score_detail` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `member_id` int(11) DEFAULT '0' COMMENT '会员ID',
  `type` int(11) DEFAULT '0' COMMENT '类型，0是普通积分增加，1是奖励，2是撤销奖励',
  `score` int(11) DEFAULT '0' COMMENT '变化积分',
  `balance` int(11) DEFAULT '0' COMMENT '账户剩余积分',
  `remark` varchar(255) DEFAULT NULL COMMENT '说明',
  `foreign_id` int(11) DEFAULT '0' COMMENT '外键ID',
  `score_rule_id` int(11) DEFAULT '0' COMMENT '积分规则ID',
  `status` int(11) DEFAULT '1' COMMENT '状态，1是成功，0是取消',
  PRIMARY KEY (`id`),
  KEY `fk_score_detail_member` (`member_id`) USING BTREE,
  KEY `fk_score_detail_score_rule` (`score_rule_id`) USING BTREE,
  CONSTRAINT `tbl_score_detail_ibfk_1` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_score_detail_ibfk_2` FOREIGN KEY (`score_rule_id`) REFERENCES `tbl_score_rule` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=623 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_score_detail
-- ----------------------------
INSERT INTO `tbl_score_detail` VALUES ('41', '2017-11-30 16:29:02', '1', '1', '1', '100001', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('44', '2017-12-01 17:11:40', '1', '1', '1', '100002', '文章投稿 #4', '4', '4', '0');
INSERT INTO `tbl_score_detail` VALUES ('48', '2017-12-01 19:50:19', '1', '1', '1', '100003', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('49', '2017-12-01 21:43:25', '1', '2', '-1', '100002', '撤销积分奖励 #44', '4', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('50', '2017-12-01 21:47:07', '1', '1', '1', '100003', '文章投稿 #5', '5', '4', '0');
INSERT INTO `tbl_score_detail` VALUES ('51', '2017-12-01 21:47:22', '1', '1', '1', '100004', '文章收到喜欢 #5', '5', '6', '1');
INSERT INTO `tbl_score_detail` VALUES ('56', '2017-12-05 14:58:15', '1', '1', '1', '100005', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('59', '2017-12-08 09:37:16', '1', '1', '1', '100006', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('60', '2017-12-08 15:08:58', '1', '2', '-1', '100005', '撤销积分奖励 #50', '5', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('61', '2017-12-08 15:11:35', '1', '1', '1', '100006', '文章投稿 #6', '6', '4', '0');
INSERT INTO `tbl_score_detail` VALUES ('62', '2017-12-08 15:12:02', '1', '1', '1', '100007', '文章投稿 #7', '7', '4', '0');
INSERT INTO `tbl_score_detail` VALUES ('63', '2017-12-08 15:13:03', '1', '1', '-10', '99997', '申请群组 #1', '1', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('64', '2017-12-08 15:13:37', '1', '1', '1', '99998', '群组发帖 #1', '1', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('65', '2017-12-08 15:14:00', '1', '1', '1', '99999', '群组发帖 #2', '2', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('66', '2017-12-08 15:20:55', '7', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('67', '2017-12-08 15:21:12', '7', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('70', '2017-12-08 15:25:57', '7', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('72', '2017-12-08 15:48:23', '7', '1', '1', '103', '群组发帖 #3', '3', '11', '0');
INSERT INTO `tbl_score_detail` VALUES ('73', '2017-12-08 15:49:09', '7', '1', '1', '104', '群组帖子收到喜欢 #3', '3', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('74', '2017-12-08 15:49:11', '7', '2', '-1', '103', '撤销积分奖励 #73', '3', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('75', '2017-12-08 15:49:11', '7', '1', '1', '104', '群组帖子收到喜欢 #3', '3', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('76', '2017-12-08 15:49:12', '7', '2', '-1', '103', '撤销积分奖励 #75', '3', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('77', '2017-12-08 16:50:16', '1', '1', '1', '100000', '文章投稿 #8', '8', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('78', '2017-12-08 17:00:52', '1', '1', '1', '100001', '文章投稿 #9', '9', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('79', '2017-12-08 17:50:48', '1', '1', '1', '100002', '文章评论 #3', '3', '5', '1');
INSERT INTO `tbl_score_detail` VALUES ('80', '2017-12-08 17:51:52', '1', '2', '-1', '100001', '撤销积分奖励 #61', '6', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('81', '2017-12-11 08:29:51', '1', '1', '1', '100002', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('82', '2017-12-11 08:42:17', '1', '1', '1', '100003', '文章投稿 #10', '10', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('83', '2017-12-11 10:30:37', '1', '2', '-1', '100002', '撤销积分奖励 #62', '7', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('84', '2017-12-11 16:55:59', '1', '1', '1', '100003', '文章投稿 #11', '11', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('85', '2017-12-12 08:40:23', '1', '1', '1', '100004', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('86', '2017-12-12 10:12:34', '1', '1', '1', '100005', '文章投稿 #12', '12', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('87', '2017-12-12 13:37:12', '7', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('88', '2017-12-12 14:08:24', '7', '2', '-1', '103', '撤销积分奖励 #72', '3', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('89', '2017-12-12 15:18:08', '7', '1', '1', '104', '群组发帖 #4', '4', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('90', '2017-12-14 10:33:09', '1', '1', '1', '100006', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('91', '2017-12-14 14:20:00', '1', '1', '1', '100007', '群组帖子收到喜欢 #4', '4', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('92', '2017-12-14 14:21:31', '7', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('93', '2017-12-14 15:31:03', '1', '1', '1', '100008', '文章投稿 #13', '13', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('94', '2017-12-14 15:50:30', '1', '1', '1', '100009', '文章投稿 #14', '14', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('95', '2017-12-15 10:35:11', '1', '1', '1', '100010', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('96', '2017-12-15 11:25:22', '1', '1', '1', '100011', '文章投稿 #15', '15', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('97', '2017-12-15 16:06:57', '7', '1', '1', '106', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('98', '2017-12-15 16:11:48', '7', '1', '1', '107', '群组发帖 #5', '5', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('99', '2017-12-15 16:13:27', '7', '1', '1', '108', '群组帖子评论 #1', '1', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('100', '2017-12-18 09:16:27', '1', '1', '1', '100012', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('101', '2017-12-18 10:02:35', '1', '1', '1', '100013', '文章投稿 #16', '16', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('102', '2017-12-18 15:58:35', '1', '1', '1', '100014', '文章收到喜欢 #16', '16', '6', '1');
INSERT INTO `tbl_score_detail` VALUES ('103', '2017-12-25 22:59:31', '8', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('104', '2017-12-25 22:59:38', '8', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('105', '2017-12-25 23:00:16', '8', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('106', '2017-12-25 23:03:04', '8', '1', '1', '103', '文章收到喜欢 #10', '10', '6', '1');
INSERT INTO `tbl_score_detail` VALUES ('107', '2017-12-27 11:08:23', '1', '1', '1', '100015', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('108', '2017-12-27 20:54:35', '8', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('109', '2018-01-02 14:40:11', '1', '1', '1', '100016', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('110', '2018-01-02 15:39:40', '8', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('111', '2018-01-02 15:57:35', '8', '1', '1', '106', '群组发帖 #6', '6', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('112', '2018-01-04 14:56:36', '1', '1', '1', '100017', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('113', '2018-01-05 09:45:56', '1', '1', '1', '100018', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('114', '2018-01-05 09:46:11', '7', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('115', '2018-01-05 15:47:26', '9', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('116', '2018-01-05 15:47:43', '9', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('117', '2018-01-05 15:48:03', '9', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('118', '2018-01-05 16:49:12', '10', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('119', '2018-01-05 16:49:25', '10', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('120', '2018-01-05 16:51:02', '10', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('121', '2018-01-05 17:00:09', '11', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('122', '2018-01-05 17:00:19', '11', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('123', '2018-01-05 17:00:54', '11', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('124', '2018-01-06 11:55:33', '1', '1', '1', '100019', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('125', '2018-01-06 11:55:58', '1', '1', '1', '100020', '文章投稿 #17', '17', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('126', '2018-01-06 11:56:05', '1', '1', '1', '100021', '文章投稿 #18', '18', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('127', '2018-01-06 15:13:47', '1', '1', '1', '100022', '群组发帖 #7', '7', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('128', '2018-01-06 15:27:34', '7', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('129', '2018-01-06 15:28:36', '7', '1', '1', '111', '群组发帖 #8', '8', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('130', '2018-01-06 15:43:53', '1', '1', '1', '100023', '群组发帖 #9', '9', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('131', '2018-01-06 16:42:02', '1', '1', '1', '100024', '群组发帖 #10', '10', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('132', '2018-01-06 16:43:04', '1', '1', '1', '100025', '群组发帖 #11', '11', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('133', '2018-01-06 16:48:22', '1', '1', '1', '100026', '群组发帖 #12', '12', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('134', '2018-01-06 16:49:07', '1', '1', '1', '100027', '群组发帖 #13', '13', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('135', '2018-01-06 17:05:18', '1', '1', '1', '100028', '群组发帖 #14', '14', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('136', '2018-01-06 17:10:03', '1', '1', '1', '100029', '群组发帖 #15', '15', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('137', '2018-01-06 17:14:27', '1', '1', '1', '100030', '群组发帖 #16', '16', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('138', '2018-01-06 17:17:04', '1', '1', '1', '100031', '群组发帖 #17', '17', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('139', '2018-01-06 17:29:55', '1', '1', '1', '100032', '群组发帖 #18', '18', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('140', '2018-01-06 19:14:16', '1', '1', '1', '100033', '群组发帖 #19', '19', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('141', '2018-01-06 19:27:20', '1', '1', '1', '100034', '群组发帖 #20', '20', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('142', '2018-01-07 15:19:36', '1', '1', '1', '100035', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('143', '2018-01-07 15:19:47', '1', '1', '1', '100036', '群组发帖 #21', '21', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('144', '2018-01-07 16:08:38', '1', '1', '1', '100037', '群组发帖 #22', '22', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('145', '2018-01-07 16:15:47', '1', '1', '1', '100038', '群组发帖 #23', '23', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('146', '2018-01-07 16:31:49', '7', '1', '1', '112', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('147', '2018-01-07 16:31:57', '7', '1', '1', '113', '群组发帖 #24', '24', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('148', '2018-01-07 16:40:06', '1', '1', '1', '100039', '群组发帖 #25', '25', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('149', '2018-01-07 16:57:09', '1', '1', '1', '100040', '群组发帖 #26', '26', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('150', '2018-01-07 17:06:38', '1', '1', '1', '100041', '群组发帖 #27', '27', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('151', '2018-01-07 17:47:01', '1', '1', '1', '100042', '群组发帖 #28', '28', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('152', '2018-01-07 18:12:32', '1', '1', '1', '100043', '群组发帖 #29', '29', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('153', '2018-01-08 08:31:46', '1', '1', '1', '100044', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('154', '2018-01-08 10:11:54', '12', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('155', '2018-01-08 10:12:07', '12', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('156', '2018-01-08 10:12:39', '12', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('157', '2018-01-08 10:14:02', '12', '1', '1', '103', '群组发帖 #3', '3', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('158', '2018-01-08 10:15:24', '13', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('159', '2018-01-08 10:15:37', '13', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('160', '2018-01-08 10:16:03', '13', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('161', '2018-01-08 10:16:14', '14', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('162', '2018-01-08 10:16:34', '14', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('163', '2018-01-08 10:17:26', '14', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('164', '2018-01-08 10:59:41', '15', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('165', '2018-01-08 10:59:56', '15', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('166', '2018-01-08 11:00:23', '15', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('167', '2018-01-08 11:21:39', '16', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('168', '2018-01-08 11:21:52', '16', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('169', '2018-01-08 11:23:44', '16', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('170', '2018-01-08 11:28:56', '8', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('171', '2018-01-08 11:49:19', '17', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('172', '2018-01-08 11:49:40', '17', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('173', '2018-01-08 13:14:33', '1', '1', '1', '100045', '群组发帖 #4', '4', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('174', '2018-01-08 13:17:55', '1', '1', '1', '100046', '群组发帖 #5', '5', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('175', '2018-01-08 14:00:20', '1', '1', '1', '100047', '群组发帖 #6', '6', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('176', '2018-01-08 16:05:40', '10', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('177', '2018-01-08 16:20:43', '18', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('178', '2018-01-08 16:20:58', '18', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('179', '2018-01-08 16:21:52', '18', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('180', '2018-01-08 17:23:44', '8', '1', '-10', '97', '申请群组 #2', '2', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('181', '2018-01-09 09:12:41', '15', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('182', '2018-01-09 16:13:00', '19', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('183', '2018-01-09 16:13:12', '19', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('184', '2018-01-09 16:14:14', '19', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('185', '2018-01-10 08:40:03', '20', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('186', '2018-01-10 08:40:12', '20', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('187', '2018-01-10 08:40:39', '20', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('188', '2018-01-10 09:28:22', '21', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('189', '2018-01-10 09:28:32', '21', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('190', '2018-01-10 09:34:49', '21', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('191', '2018-01-10 09:38:47', '21', '1', '-10', '92', '申请群组 #3', '3', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('192', '2018-01-11 11:20:21', '1', '1', '1', '100048', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('193', '2018-01-11 11:29:00', '22', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('194', '2018-01-11 11:29:11', '22', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('195', '2018-01-11 11:29:53', '22', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('196', '2018-01-11 11:30:19', '22', '1', '-10', '92', '申请群组 #4', '4', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('197', '2018-01-11 21:19:11', '12', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('198', '2018-01-11 21:27:32', '12', '1', '1', '105', '群组发帖 #7', '7', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('199', '2018-01-11 21:35:24', '12', '1', '1', '106', '群组发帖 #8', '8', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('200', '2018-01-11 21:37:29', '12', '1', '1', '107', '群组发帖 #9', '9', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('201', '2018-01-12 08:45:05', '1', '1', '1', '100049', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('202', '2018-01-12 10:15:34', '15', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('203', '2018-01-12 10:16:39', '15', '1', '1', '105', '群组帖子收到喜欢 #9', '9', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('204', '2018-01-12 10:17:09', '15', '1', '1', '106', '群组帖子收到喜欢 #8', '8', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('205', '2018-01-13 11:56:15', '1', '1', '1', '100050', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('206', '2018-01-13 23:44:12', '8', '1', '1', '98', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('207', '2018-01-15 08:51:07', '1', '1', '1', '100051', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('208', '2018-01-16 11:27:38', '22', '1', '1', '93', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('209', '2018-01-16 11:27:48', '22', '1', '1', '94', '群组帖子评论 #1', '1', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('210', '2018-01-16 11:39:56', '22', '1', '1', '95', '群组帖子收到喜欢 #8', '8', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('211', '2018-01-16 11:41:48', '22', '2', '-1', '94', '撤销积分奖励 #210', '8', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('212', '2018-01-16 11:41:49', '22', '1', '1', '95', '群组帖子收到喜欢 #8', '8', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('213', '2018-01-16 11:41:54', '22', '2', '-1', '94', '撤销积分奖励 #212', '8', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('214', '2018-01-16 11:43:03', '22', '1', '1', '95', '群组帖子收到喜欢 #8', '8', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('215', '2018-01-16 11:43:05', '22', '2', '-1', '94', '撤销积分奖励 #214', '8', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('216', '2018-01-16 12:28:25', '22', '1', '1', '95', '群组帖子评论 #2', '2', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('217', '2018-01-16 13:07:15', '22', '1', '1', '96', '群组帖子收到喜欢 #8', '8', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('218', '2018-01-16 13:07:18', '22', '2', '-1', '95', '撤销积分奖励 #217', '8', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('219', '2018-01-16 13:07:21', '22', '1', '1', '96', '群组帖子收到喜欢 #8', '8', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('220', '2018-01-16 17:34:58', '1', '1', '1', '100052', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('221', '2018-01-16 17:35:28', '12', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('222', '2018-01-17 09:36:10', '8', '1', '1', '99', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('223', '2018-01-17 10:43:30', '15', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('224', '2018-01-17 10:46:14', '12', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('225', '2018-01-17 20:28:56', '8', '1', '1', '100', '群组帖子评论 #1', '1', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('226', '2018-01-17 20:35:54', '1', '1', '1', '100053', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('227', '2018-01-18 08:27:59', '18', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('228', '2018-01-18 11:09:32', '8', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('229', '2018-01-19 16:19:20', '14', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('230', '2018-01-21 13:12:25', '8', '1', '1', '102', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('231', '2018-01-21 13:12:40', '1', '1', '1', '100054', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('232', '2018-01-22 08:40:52', '1', '1', '1', '100055', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('233', '2018-01-22 11:05:03', '13', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('234', '2018-01-22 11:07:26', '14', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('235', '2018-01-22 11:27:16', '22', '1', '1', '97', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('236', '2018-01-22 11:33:19', '13', '1', '1', '104', '群组帖子评论 #1', '1', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('237', '2018-01-22 13:50:33', '1', '1', '1', '100056', '群组帖子评论 #2', '2', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('238', '2018-01-22 18:33:16', '8', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('239', '2018-01-22 19:19:00', '8', '1', '1', '104', '群组帖子收到喜欢 #3', '3', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('240', '2018-01-22 19:19:02', '8', '2', '-1', '103', '撤销积分奖励 #239', '3', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('241', '2018-01-22 20:33:04', '8', '1', '1', '104', '群组帖子收到喜欢 #4', '4', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('242', '2018-01-23 16:08:57', '13', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('243', '2018-01-23 17:16:04', '14', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('244', '2018-01-24 08:22:45', '14', '1', '1', '106', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('245', '2018-01-24 15:00:28', '1', '1', '-10', '100046', '申请群组 #4', '4', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('246', '2018-01-24 15:04:02', '8', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('247', '2018-01-24 15:10:01', '1', '1', '1', '100047', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('248', '2018-01-25 08:43:04', '22', '1', '1', '98', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('249', '2018-01-25 08:44:17', '1', '1', '1', '100048', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('250', '2018-01-25 10:18:15', '23', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('251', '2018-01-25 10:18:34', '23', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('252', '2018-01-25 10:19:26', '23', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('253', '2018-01-25 10:23:20', '24', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('254', '2018-01-25 10:23:36', '24', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('255', '2018-01-25 10:24:02', '24', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('256', '2018-01-25 10:42:00', '10', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('257', '2018-01-25 13:21:25', '18', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('258', '2018-01-25 13:48:27', '19', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('259', '2018-01-26 09:54:45', '1', '1', '1', '100049', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('260', '2018-01-26 10:16:18', '25', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('261', '2018-01-26 10:16:33', '25', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('262', '2018-01-26 10:16:53', '1', '1', '-10', '100039', '申请群组 #5', '5', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('263', '2018-01-26 10:16:57', '25', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('264', '2018-01-26 11:00:34', '18', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('265', '2018-01-26 11:01:00', '18', '1', '1', '106', '群组帖子收到喜欢 #13', '13', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('266', '2018-01-26 11:12:07', '13', '1', '1', '106', '群组帖子收到喜欢 #13', '13', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('267', '2018-01-26 11:12:08', '13', '2', '-1', '105', '撤销积分奖励 #266', '13', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('268', '2018-01-26 11:12:10', '13', '1', '1', '106', '群组帖子收到喜欢 #13', '13', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('269', '2018-01-26 11:13:41', '18', '2', '-1', '105', '撤销积分奖励 #265', '13', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('270', '2018-01-26 11:13:43', '18', '1', '1', '106', '群组帖子收到喜欢 #13', '13', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('271', '2018-01-26 11:18:07', '12', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('272', '2018-01-26 11:19:15', '1', '1', '1', '100040', '群组帖子收到喜欢 #10', '10', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('273', '2018-01-26 11:20:21', '1', '2', '-1', '100039', '撤销积分奖励 #272', '10', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('274', '2018-01-26 11:20:22', '1', '1', '1', '100040', '群组帖子收到喜欢 #10', '10', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('275', '2018-01-26 11:21:23', '21', '1', '1', '93', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('276', '2018-01-26 11:28:04', '15', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('277', '2018-01-26 11:43:18', '8', '1', '1', '106', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('278', '2018-01-26 14:22:51', '19', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('279', '2018-01-27 11:06:30', '8', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('280', '2018-01-28 00:02:28', '8', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('281', '2018-01-29 11:24:26', '15', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('282', '2018-01-30 11:24:48', '7', '1', '1', '114', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('283', '2018-01-30 14:36:44', '1', '1', '1', '100041', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('284', '2018-01-31 09:41:23', '14', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('285', '2018-01-31 17:20:29', '22', '1', '1', '99', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('286', '2018-01-31 17:20:39', '1', '1', '1', '100042', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('287', '2018-02-02 09:44:20', '15', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('288', '2018-02-02 11:37:01', '14', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('289', '2018-02-02 15:06:33', '1', '1', '1', '100043', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('290', '2018-02-02 16:33:07', '25', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('291', '2018-02-03 10:17:35', '22', '1', '1', '100', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('292', '2018-02-03 10:20:52', '25', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('293', '2018-02-03 10:25:48', '19', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('294', '2018-02-03 16:54:27', '1', '1', '1', '100044', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('295', '2018-02-03 21:04:48', '8', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('296', '2018-02-03 21:05:19', '8', '1', '1', '110', '群组帖子评论 #3', '3', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('297', '2018-02-04 19:47:38', '1', '1', '1', '100045', '群组帖子评论 #4', '4', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('298', '2018-02-04 23:30:40', '1', '1', '1', '100046', '群组帖子评论 #5', '5', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('299', '2018-02-05 16:05:06', '1', '1', '1', '100047', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('300', '2018-02-05 16:40:28', '22', '1', '1', '101', '群组帖子收到喜欢 #17', '17', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('301', '2018-02-05 16:58:20', '25', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('302', '2018-02-06 11:37:14', '1', '1', '1', '100048', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('303', '2018-02-08 08:46:53', '25', '1', '1', '106', '群组帖子收到喜欢 #17', '17', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('304', '2018-02-08 08:59:13', '25', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('305', '2018-02-09 11:36:01', '1', '1', '1', '100049', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('306', '2018-02-09 15:21:43', '25', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('307', '2018-02-09 19:14:31', '8', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('308', '2018-02-09 19:42:37', '8', '1', '1', '112', '群组帖子收到喜欢 #19', '19', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('309', '2018-02-14 18:22:47', '8', '1', '1', '113', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('310', '2018-02-22 12:45:01', '8', '1', '1', '114', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('311', '2018-02-24 13:16:14', '8', '1', '1', '115', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('312', '2018-02-25 13:09:26', '8', '1', '1', '116', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('313', '2018-02-25 13:19:44', '25', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('314', '2018-02-25 14:20:28', '11', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('315', '2018-02-25 14:31:43', '15', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('316', '2018-02-25 14:49:11', '1', '1', '1', '100050', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('317', '2018-02-26 08:32:00', '15', '1', '1', '112', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('318', '2018-02-26 08:55:19', '26', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('319', '2018-02-26 08:57:19', '26', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('320', '2018-02-26 09:44:07', '24', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('321', '2018-02-26 14:25:59', '15', '1', '1', '113', '群组帖子收到喜欢 #19', '19', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('322', '2018-02-26 14:26:02', '15', '2', '-1', '112', '撤销积分奖励 #321', '19', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('323', '2018-02-26 14:26:02', '15', '1', '1', '113', '群组帖子收到喜欢 #19', '19', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('324', '2018-02-26 14:26:20', '15', '1', '1', '114', '群组帖子收到喜欢 #17', '17', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('325', '2018-02-27 08:58:11', '15', '1', '1', '115', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('326', '2018-02-27 09:06:52', '26', '1', '1', '102', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('327', '2018-02-27 09:07:07', '22', '1', '1', '102', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('328', '2018-02-27 09:08:31', '16', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('331', '2018-02-27 09:21:46', '11', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('332', '2018-02-27 09:23:11', '1', '1', '1', '100051', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('333', '2018-02-27 09:58:00', '19', '1', '1', '106', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('334', '2018-02-27 10:46:50', '24', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('335', '2018-02-27 10:54:06', '18', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('336', '2018-02-27 11:27:17', '15', '1', '1', '116', '群组帖子收到喜欢 #20', '20', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('337', '2018-02-27 16:33:21', '10', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('338', '2018-02-28 08:57:24', '15', '1', '1', '117', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('339', '2018-02-28 11:18:29', '16', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('340', '2018-02-28 13:24:01', '9', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('341', '2018-02-28 15:25:35', '1', '1', '1', '100052', '群组帖子收到喜欢 #28', '28', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('342', '2018-02-28 15:25:41', '1', '1', '1', '100053', '群组帖子收到喜欢 #26', '26', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('343', '2018-02-28 15:30:50', '1', '1', '1', '100054', '群组帖子收到喜欢 #23', '23', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('344', '2018-02-28 15:30:57', '1', '1', '1', '100055', '群组帖子收到喜欢 #25', '25', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('345', '2018-02-28 15:30:59', '1', '2', '-1', '100054', '撤销积分奖励 #344', '25', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('346', '2018-02-28 15:31:00', '1', '1', '1', '100055', '群组帖子收到喜欢 #25', '25', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('347', '2018-02-28 15:31:30', '1', '1', '1', '100056', '群组帖子收到喜欢 #21', '21', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('348', '2018-02-28 16:49:14', '23', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('349', '2018-03-01 08:33:08', '15', '1', '1', '118', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('350', '2018-03-01 08:34:37', '1', '1', '1', '100057', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('351', '2018-03-01 14:25:20', '14', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('352', '2018-03-02 09:05:56', '15', '1', '1', '119', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('353', '2018-03-02 10:11:08', '22', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('354', '2018-03-02 14:25:27', '24', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('355', '2018-03-02 15:59:02', '19', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('356', '2018-03-02 16:12:10', '19', '1', '1', '108', '群组帖子收到喜欢 #23', '23', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('357', '2018-03-02 16:12:11', '19', '2', '-1', '107', '撤销积分奖励 #356', '23', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('358', '2018-03-02 16:12:12', '19', '1', '1', '108', '群组帖子收到喜欢 #23', '23', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('359', '2018-03-02 17:16:32', '1', '1', '1', '100058', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('360', '2018-03-04 05:29:02', '28', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('361', '2018-03-04 05:30:30', '28', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('362', '2018-03-04 05:30:55', '28', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('363', '2018-03-04 05:32:54', '28', '1', '1', '103', '群组帖子评论 #6', '6', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('364', '2018-03-05 10:38:59', '19', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('365', '2018-03-05 18:31:15', '1', '1', '1', '100059', '群组帖子收到喜欢 #32', '32', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('366', '2018-03-06 09:12:07', '15', '1', '1', '120', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('367', '2018-03-06 14:49:33', '29', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('368', '2018-03-06 14:49:45', '29', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('369', '2018-03-06 15:03:41', '29', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('370', '2018-03-07 09:28:50', '15', '1', '1', '121', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('371', '2018-03-07 11:47:15', '13', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('372', '2018-03-07 14:32:38', '23', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('373', '2018-03-07 15:45:48', '30', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('374', '2018-03-07 15:45:57', '30', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('375', '2018-03-07 15:46:32', '30', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('376', '2018-03-07 19:18:53', '1', '1', '1', '100060', '群组帖子评论 #7', '7', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('377', '2018-03-07 19:19:10', '8', '1', '1', '117', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('378', '2018-03-08 08:53:19', '15', '1', '1', '122', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('379', '2018-03-08 09:15:52', '14', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('380', '2018-03-08 16:33:47', '25', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('381', '2018-03-09 08:55:02', '15', '1', '1', '123', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('382', '2018-03-09 09:08:05', '25', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('383', '2018-03-09 14:31:16', '24', '1', '1', '106', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('384', '2018-03-09 18:04:23', '24', '1', '1', '107', '群组帖子收到喜欢 #29', '29', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('385', '2018-03-09 18:04:24', '24', '2', '-1', '106', '撤销积分奖励 #384', '29', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('386', '2018-03-09 18:04:25', '24', '1', '1', '107', '群组帖子收到喜欢 #29', '29', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('387', '2018-03-10 08:45:29', '15', '1', '1', '124', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('388', '2018-03-10 11:21:31', '25', '1', '1', '112', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('389', '2018-03-10 16:30:01', '1', '1', '1', '100061', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('390', '2018-03-10 18:41:38', '8', '1', '-10', '107', '申请群组 #6', '6', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('391', '2018-03-10 18:43:07', '8', '1', '-10', '97', '申请群组 #7', '7', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('392', '2018-03-10 18:43:56', '8', '1', '1', '98', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('393', '2018-03-10 18:45:50', '8', '1', '1', '99', '群组帖子评论 #8', '8', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('394', '2018-03-12 08:53:47', '11', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('395', '2018-03-12 09:03:52', '15', '1', '1', '125', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('396', '2018-03-12 09:31:08', '13', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('397', '2018-03-12 17:12:18', '8', '1', '1', '100', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('398', '2018-03-13 10:33:41', '15', '1', '1', '126', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('399', '2018-03-13 10:34:26', '24', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('400', '2018-03-13 10:49:25', '1', '1', '1', '100062', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('401', '2018-03-13 16:11:25', '11', '1', '1', '106', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('402', '2018-03-14 08:48:00', '15', '1', '1', '127', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('403', '2018-03-14 16:20:02', '31', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('404', '2018-03-14 16:20:10', '31', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('405', '2018-03-14 16:29:01', '31', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('406', '2018-03-14 19:55:02', '8', '1', '1', '101', '群组帖子评论 #9', '9', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('407', '2018-03-15 10:41:45', '15', '1', '1', '128', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('408', '2018-03-16 09:18:26', '15', '1', '1', '129', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('409', '2018-03-16 10:29:27', '24', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('410', '2018-03-16 13:50:00', '32', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('411', '2018-03-16 13:50:10', '32', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('412', '2018-03-19 08:50:04', '15', '1', '1', '130', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('413', '2018-03-20 11:34:09', '15', '1', '1', '131', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('414', '2018-03-20 18:52:28', '11', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('415', '2018-03-21 08:58:13', '15', '1', '1', '132', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('416', '2018-03-21 15:09:16', '18', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('417', '2018-03-21 18:53:55', '11', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('418', '2018-03-22 09:11:13', '15', '1', '1', '133', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('419', '2018-03-22 10:57:35', '25', '1', '1', '113', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('420', '2018-03-22 14:22:46', '11', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('421', '2018-03-23 08:36:13', '18', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('422', '2018-03-23 08:58:41', '15', '1', '1', '134', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('423', '2018-03-23 15:40:47', '11', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('424', '2018-03-23 17:01:07', '25', '1', '1', '114', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('425', '2018-03-23 17:01:16', '25', '2', '-1', '113', '撤销积分奖励 #303', '17', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('426', '2018-03-23 17:01:18', '25', '1', '1', '114', '群组帖子收到喜欢 #17', '17', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('427', '2018-03-25 17:47:44', '11', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('428', '2018-03-26 08:56:49', '26', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('429', '2018-03-26 08:56:58', '26', '1', '1', '104', '群组帖子收到喜欢 #39', '39', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('430', '2018-03-26 09:02:55', '15', '1', '1', '135', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('431', '2018-03-26 18:41:04', '11', '1', '1', '112', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('432', '2018-03-27 09:52:28', '15', '1', '1', '136', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('433', '2018-03-27 10:01:41', '19', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('434', '2018-03-28 09:02:43', '15', '1', '1', '137', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('435', '2018-03-28 09:40:04', '19', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('436', '2018-03-29 09:26:09', '15', '1', '1', '138', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('437', '2018-03-29 09:51:31', '26', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('438', '2018-03-29 11:30:32', '24', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('439', '2018-03-29 13:58:04', '1', '1', '1', '100063', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('440', '2018-03-29 14:06:34', '22', '1', '1', '104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('441', '2018-03-29 14:33:06', '8', '1', '1', '102', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('442', '2018-03-30 08:47:48', '15', '1', '1', '139', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('443', '2018-03-30 15:56:02', '16', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('444', '2018-03-30 16:06:36', '1', '1', '1', '100064', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('445', '2018-03-30 17:09:16', '8', '1', '1', '103', '群组帖子评论 #10', '10', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('446', '2018-03-30 17:09:32', '25', '1', '1', '115', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('447', '2018-04-03 09:30:48', '16', '1', '1', '106', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('448', '2018-04-03 09:54:24', '15', '1', '1', '140', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('449', '2018-04-04 09:09:18', '15', '1', '1', '141', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('450', '2018-04-04 14:48:17', '1', '1', '1', '100065', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('451', '2018-04-04 16:25:15', '22', '1', '1', '105', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('452', '2018-04-04 16:32:54', '25', '1', '1', '116', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('453', '2018-04-06 14:08:20', '8', '1', '-10', '93', '申请群组 #8', '8', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('454', '2018-04-06 14:08:49', '1', '1', '1', '100066', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('455', '2018-04-08 09:19:32', '22', '1', '1', '106', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('456', '2018-04-08 10:38:22', '19', '1', '1', '112', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('457', '2018-04-08 10:56:24', '25', '1', '1', '117', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('458', '2018-04-08 15:17:00', '16', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('459', '2018-04-09 08:34:56', '22', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('460', '2018-04-09 11:07:49', '25', '1', '1', '118', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('461', '2018-04-09 11:38:48', '22', '2', '-1', '106', '撤销积分奖励 #300', '17', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('462', '2018-04-09 11:38:49', '22', '1', '1', '107', '群组帖子收到喜欢 #17', '17', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('463', '2018-04-11 09:17:42', '25', '1', '1', '119', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('464', '2018-04-11 09:19:15', '22', '1', '1', '108', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('465', '2018-04-11 11:37:10', '1', '1', '1', '100067', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('466', '2018-04-11 12:32:24', '8', '1', '1', '94', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('467', '2018-04-12 08:57:21', '25', '1', '1', '120', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('468', '2018-04-12 10:23:21', '1', '1', '1', '100068', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('469', '2018-04-12 10:23:48', '1', '1', '1', '100069', '文章投稿 #1', '1', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('470', '2018-04-12 11:40:45', '8', '1', '1', '95', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('471', '2018-04-13 09:25:50', '1', '1', '1', '100070', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('472', '2018-04-13 11:17:42', '25', '1', '1', '121', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('473', '2018-04-13 21:04:26', '1', '1', '1', '100071', '文章投稿 #2', '2', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('474', '2018-04-15 12:19:28', '1', '1', '1', '100072', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('475', '2018-04-16 08:24:55', '22', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('476', '2018-04-16 11:44:50', '1', '1', '1', '100073', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('477', '2018-04-16 13:02:03', '25', '1', '1', '122', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('478', '2018-04-16 14:45:24', '25', '1', '1', '123', '群组发帖 #48', '48', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('479', '2018-04-18 14:54:59', '1', '1', '1', '100074', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('480', '2018-04-19 11:17:33', '1', '1', '1', '100075', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('481', '2018-04-20 17:03:08', '1', '1', '1', '100076', '文章投稿 #3', '3', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('482', '2018-04-20 17:09:48', '1', '1', '1', '100077', '文章投稿 #4', '4', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('483', '2018-04-20 17:13:42', '22', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('484', '2018-04-20 17:16:02', '1', '1', '1', '100078', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('485', '2018-04-20 19:05:56', '8', '1', '1', '96', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('486', '2018-04-23 09:12:41', '25', '1', '1', '124', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('487', '2018-04-24 11:31:52', '25', '1', '1', '125', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('488', '2018-04-24 11:33:46', '25', '1', '1', '126', '群组发帖 #49', '49', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('489', '2018-04-24 13:15:28', '13', '1', '1', '109', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('490', '2018-04-24 13:16:00', '13', '1', '1', '110', '群组发帖 #50', '50', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('491', '2018-04-25 08:49:01', '1', '1', '1', '100079', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('492', '2018-04-25 08:50:57', '7', '1', '1', '115', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('493', '2018-04-25 13:44:30', '25', '1', '1', '127', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('494', '2018-04-25 13:56:03', '25', '1', '1', '128', '群组发帖 #51', '51', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('495', '2018-04-27 11:21:27', '8', '1', '1', '97', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('496', '2018-04-27 11:30:09', '25', '1', '1', '129', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('497', '2018-04-27 14:16:45', '1', '1', '1', '100080', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('498', '2018-04-27 15:50:29', '25', '1', '1', '130', '文章投稿 #3', '3', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('499', '2018-04-28 09:26:11', '25', '1', '1', '131', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('500', '2018-04-28 14:51:14', '1', '1', '1', '100081', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('501', '2018-04-28 15:34:03', '25', '1', '1', '132', '群组发帖 #52', '52', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('502', '2018-04-28 16:15:35', '8', '1', '1', '98', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('503', '2018-04-28 16:19:42', '14', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('504', '2018-04-28 16:24:11', '14', '1', '1', '112', '文章投稿 #4', '4', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('505', '2018-04-28 17:14:42', '13', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('506', '2018-04-28 17:15:41', '13', '1', '1', '112', '文章投稿 #5', '5', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('507', '2018-04-29 22:14:23', '8', '1', '1', '99', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('508', '2018-04-29 22:14:57', '1', '1', '1', '100082', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('509', '2018-04-29 22:15:16', '1', '1', '1', '100083', '群组帖子评论 #11', '11', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('510', '2018-04-30 10:40:50', '8', '1', '1', '100', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('511', '2018-05-02 08:59:53', '1', '1', '1', '100084', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('512', '2018-05-02 11:09:30', '8', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('513', '2018-05-03 08:49:42', '25', '1', '1', '133', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('514', '2018-05-08 10:08:04', '13', '1', '1', '113', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('515', '2018-05-09 14:15:56', '13', '1', '1', '114', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('516', '2018-05-09 14:18:49', '13', '1', '1', '115', '群组发帖 #53', '53', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('517', '2018-05-17 16:19:20', '1', '1', '1', '100085', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('518', '2018-05-21 11:19:56', '8', '1', '1', '102', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('519', '2018-05-21 15:33:12', '25', '1', '1', '134', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('520', '2018-05-28 10:34:50', '1', '1', '1', '100086', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('521', '2018-05-31 11:30:37', '1', '1', '1', '100087', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('522', '2018-06-01 09:37:25', '1', '1', '1', '100088', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('523', '2018-06-05 14:41:39', '24', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('524', '2018-06-05 15:09:55', '24', '1', '1', '112', '群组发帖 #54', '54', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('525', '2018-06-08 13:54:20', '25', '1', '1', '135', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('526', '2018-06-09 18:22:47', '8', '1', '1', '103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('527', '2018-06-09 18:23:50', '8', '1', '1', '104', '群组发帖 #55', '55', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('528', '2018-06-10 16:24:42', '8', '1', '1', '105', '群组发帖 #56', '56', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('529', '2018-06-10 22:17:59', '8', '1', '1', '106', '群组帖子收到喜欢 #56', '56', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('530', '2018-06-12 09:11:48', '8', '1', '1', '107', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('531', '2018-06-12 10:43:44', '24', '1', '1', '113', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('532', '2018-06-13 18:06:31', '8', '1', '1', '108', '群组发帖 #57', '57', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('533', '2018-06-13 22:46:30', '8', '1', '1', '109', '群组帖子评论 #12', '12', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('534', '2018-06-22 10:17:33', '25', '1', '1', '136', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('535', '2018-06-25 10:12:45', '1', '1', '1', '100089', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('536', '2018-07-04 14:12:00', '19', '1', '1', '113', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('537', '2018-07-11 15:45:07', '18', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('538', '2018-07-18 16:58:29', '1', '1', '1', '100090', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('539', '2018-07-19 18:49:37', '8', '1', '1', '110', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('540', '2018-07-24 15:54:35', '1', '1', '1', '100091', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('541', '2018-07-26 14:41:02', '1', '1', '1', '100092', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('542', '2018-08-22 17:23:22', '1', '1', '1', '100093', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('543', '2018-09-04 10:23:49', '1', '1', '1', '100094', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('544', '2018-09-04 10:24:59', '22', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('545', '2018-09-13 19:25:02', '8', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('546', '2018-09-13 19:36:07', '8', '1', '1', '112', '群组发帖 #58', '58', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('547', '2018-09-20 13:47:29', '8', '1', '1', '113', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('548', '2018-09-20 13:49:16', '8', '1', '1', '114', '群组发帖 #59', '59', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('549', '2018-09-26 15:19:35', '8', '1', '1', '115', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('550', '2018-09-26 18:31:23', '33', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('551', '2018-09-26 18:31:29', '33', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('552', '2018-09-26 18:31:52', '33', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('553', '2018-09-28 10:04:33', '25', '1', '1', '137', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('554', '2018-09-28 10:30:05', '25', '1', '1', '138', '群组发帖 #60', '60', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('555', '2018-10-11 14:42:58', '8', '1', '1', '116', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('556', '2018-10-17 11:49:50', '18', '1', '1', '111', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('557', '2018-10-23 10:06:37', '1', '1', '1', '100095', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('558', '2018-10-26 12:57:07', '25', '1', '1', '139', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('559', '2018-11-02 11:11:09', '34', '1', '100', '100', '注册奖励', '0', '1', '1');
INSERT INTO `tbl_score_detail` VALUES ('560', '2018-11-02 11:11:19', '34', '1', '1', '101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('561', '2018-11-02 11:12:00', '34', '1', '1', '102', '邮箱认证', '0', '2', '1');
INSERT INTO `tbl_score_detail` VALUES ('562', '2018-11-30 18:40:33', '8', '1', '1', '117', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('563', '2018-11-30 18:41:16', '8', '1', '1', '118', '群组发帖 #61', '61', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('564', '2018-12-05 11:06:44', '1', '1', '1', '100096', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('565', '2018-12-05 11:07:37', '1', '1', '1', '100097', '文章投稿 #6', '6', '4', '1');
INSERT INTO `tbl_score_detail` VALUES ('566', '2018-12-11 18:22:56', '1', '1', '1', '100098', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('567', '2019-01-03 13:37:49', '25', '1', '1', '140', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('568', '2019-01-03 13:58:34', '25', '1', '1', '141', '群组发帖 #62', '62', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('569', '2019-01-05 19:32:26', '8', '1', '1', '119', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('570', '2019-01-05 19:34:25', '8', '1', '1', '120', '群组发帖 #63', '63', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('571', '2019-01-05 21:18:16', '8', '1', '1', '121', '群组发帖 #64', '64', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('572', '2019-01-06 20:05:47', '8', '1', '1', '122', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('573', '2019-01-09 15:06:34', '8', '1', '1', '123', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('574', '2019-01-09 15:10:45', '8', '1', '1', '124', '群组帖子收到喜欢 #18', '18', '13', '0');
INSERT INTO `tbl_score_detail` VALUES ('575', '2019-01-09 15:10:49', '8', '2', '-1', '123', '撤销积分奖励 #574', '18', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('576', '2019-01-09 15:10:50', '8', '1', '1', '124', '群组帖子收到喜欢 #18', '18', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('577', '2019-01-09 15:12:03', '22', '1', '1', '112', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('578', '2019-01-09 15:18:09', '22', '1', '1', '113', '群组发帖 #65', '65', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('579', '2019-01-09 22:20:33', '8', '1', '1', '125', '群组发帖 #66', '66', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('580', '2019-01-09 22:53:26', '8', '1', '1', '126', '群组发帖 #67', '67', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('581', '2019-01-10 04:30:51', '8', '1', '1', '127', '群组发帖 #68', '68', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('582', '2019-01-10 12:09:00', '1', '1', '1', '100099', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('583', '2019-01-14 17:01:47', '1', '1', '1', '100100', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('584', '2019-01-15 11:03:12', '1', '1', '1', '100101', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('585', '2019-01-15 17:14:43', '22', '1', '1', '114', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('586', '2019-01-16 00:30:12', '8', '1', '1', '128', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('587', '2019-01-16 15:17:07', '1', '1', '1', '100102', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('588', '2019-01-19 15:44:01', '8', '1', '1', '129', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('589', '2019-01-19 15:51:30', '8', '1', '1', '130', '群组发帖 #69', '69', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('590', '2019-01-24 13:54:58', '8', '1', '1', '131', '群组发帖 #70', '70', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('591', '2019-01-24 16:54:57', '8', '1', '1', '132', '群组发帖 #71', '71', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('592', '2019-01-24 17:43:46', '8', '1', '1', '133', '群组发帖 #72', '72', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('593', '2019-01-24 17:53:40', '8', '1', '1', '134', '群组发帖 #73', '73', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('594', '2019-01-24 18:08:57', '8', '1', '1', '135', '群组帖子收到喜欢 #73', '73', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('595', '2019-01-24 18:09:37', '8', '1', '1', '136', '群组帖子收到喜欢 #72', '72', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('596', '2019-01-24 18:09:43', '8', '1', '1', '137', '群组帖子收到喜欢 #70', '70', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('597', '2019-01-24 18:09:48', '8', '1', '1', '138', '群组帖子收到喜欢 #67', '67', '13', '1');
INSERT INTO `tbl_score_detail` VALUES ('598', '2019-01-24 22:35:58', '8', '1', '1', '139', '群组发帖 #74', '74', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('599', '2019-01-24 23:10:41', '8', '1', '1', '140', '群组发帖 #75', '75', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('600', '2019-01-27 13:26:00', '8', '1', '1', '141', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('601', '2019-02-11 19:36:57', '8', '1', '1', '142', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('602', '2019-02-11 19:38:05', '8', '1', '1', '143', '群组发帖 #76', '76', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('603', '2019-02-12 18:42:38', '8', '1', '1', '144', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('604', '2019-02-12 18:44:21', '8', '1', '-10', '134', '申请群组 #9', '9', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('605', '2019-02-12 18:46:25', '8', '1', '-10', '124', '申请群组 #10', '10', '10', '1');
INSERT INTO `tbl_score_detail` VALUES ('606', '2019-02-12 18:47:23', '8', '1', '1', '125', '群组发帖 #77', '77', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('607', '2019-02-18 13:20:38', '1', '1', '1', '100103', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('608', '2019-02-19 14:03:38', '25', '1', '1', '142', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('609', '2019-02-19 14:04:06', '25', '1', '1', '143', '群组帖子评论 #13', '13', '12', '1');
INSERT INTO `tbl_score_detail` VALUES ('610', '2019-02-19 16:18:02', '8', '1', '1', '126', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('611', '2019-02-19 18:04:17', '8', '1', '1', '127', '群组发帖 #78', '78', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('612', '2019-02-20 01:01:46', '8', '1', '1', '128', '群组发帖 #79', '79', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('613', '2019-02-20 10:59:22', '8', '1', '1', '129', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('614', '2019-02-21 23:45:53', '8', '1', '1', '130', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('615', '2019-02-22 00:01:56', '8', '1', '1', '131', '群组发帖 #80', '80', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('616', '2019-02-22 00:29:35', '8', '1', '1', '132', '群组发帖 #81', '81', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('617', '2019-02-22 00:33:37', '8', '1', '1', '133', '群组发帖 #82', '82', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('618', '2019-02-22 00:35:42', '8', '1', '1', '134', '群组发帖 #83', '83', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('619', '2019-02-22 00:41:35', '8', '1', '1', '135', '群组发帖 #84', '84', '11', '1');
INSERT INTO `tbl_score_detail` VALUES ('620', '2019-02-26 16:14:47', '22', '1', '1', '115', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('621', '2019-02-26 16:16:30', '1', '1', '1', '100104', '每天登陆奖励', '0', '3', '1');
INSERT INTO `tbl_score_detail` VALUES ('622', '2019-02-28 09:22:06', '22', '1', '1', '116', '每天登陆奖励', '0', '3', '1');

-- ----------------------------
-- Table structure for tbl_score_rule
-- ----------------------------
DROP TABLE IF EXISTS `tbl_score_rule`;
CREATE TABLE `tbl_score_rule` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `name` varchar(30) DEFAULT '0' COMMENT '规则名称',
  `score` int(11) DEFAULT '0' COMMENT '变化积分',
  `remark` varchar(255) DEFAULT NULL COMMENT '说明',
  `type` varchar(10) DEFAULT 'unlimite' COMMENT '奖励次数类型，day每天一次，week每周一次，month每月一次，year每年一次，one只有一次，unlimite不限次数',
  `status` int(11) DEFAULT '1' COMMENT '状态，0禁用，1启用',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_score_rule
-- ----------------------------
INSERT INTO `tbl_score_rule` VALUES ('1', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '注册奖励', '100', '注册奖励', 'one', '0');
INSERT INTO `tbl_score_rule` VALUES ('2', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '邮箱认证', '1', '邮箱认证奖励积分，只有一次', 'one', '1');
INSERT INTO `tbl_score_rule` VALUES ('3', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '每天登陆奖励', '1', '每天登陆奖励积分，一天仅限一次', 'day', '0');
INSERT INTO `tbl_score_rule` VALUES ('4', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '文章投稿', '1', '文章投稿奖励积分，如需审核，审核之后奖励', 'unlimite', '0');
INSERT INTO `tbl_score_rule` VALUES ('5', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '文章评论', '1', '评论文章奖励积分', 'unlimite', '0');
INSERT INTO `tbl_score_rule` VALUES ('6', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '文章收到喜欢', '1', '文章收到喜欢，作者奖励积分', 'unlimite', '0');
INSERT INTO `tbl_score_rule` VALUES ('7', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '发布微博', '1', '发布微博奖励积分', 'unlimite', '1');
INSERT INTO `tbl_score_rule` VALUES ('8', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '评论微博', '1', '评论微博奖励积分', 'unlimite', '1');
INSERT INTO `tbl_score_rule` VALUES ('9', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '微博收到点赞', '1', '微博收到点赞，作者奖励积分', 'unlimite', '1');
INSERT INTO `tbl_score_rule` VALUES ('10', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '申请群组', '-10', '申请群组扣除/奖励积分，如需要扣除积分，请填写负数', 'unlimite', '1');
INSERT INTO `tbl_score_rule` VALUES ('11', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '群组发帖', '1', '群组发帖奖励积分，如需审核，审核之后奖励', 'unlimite', '0');
INSERT INTO `tbl_score_rule` VALUES ('12', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '群组帖子评论', '1', '群组帖子评论奖励积分', 'unlimite', '0');
INSERT INTO `tbl_score_rule` VALUES ('13', '2017-11-27 17:24:32', '2017-11-27 17:24:32', '群组帖子收到喜欢', '1', '群组帖子收到喜欢奖励积分', 'unlimite', '0');

-- ----------------------------
-- Table structure for tbl_validate_code
-- ----------------------------
DROP TABLE IF EXISTS `tbl_validate_code`;
CREATE TABLE `tbl_validate_code` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime NOT NULL,
  `email` varchar(32) NOT NULL DEFAULT '',
  `code` varchar(50) NOT NULL DEFAULT '',
  `status` int(1) NOT NULL DEFAULT '0',
  `type` int(1) DEFAULT '0' COMMENT '1是重置密码，2会员激活',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=60 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_validate_code
-- ----------------------------
INSERT INTO `tbl_validate_code` VALUES ('1', '2017-12-08 15:24:51', '787501374@qq.com', '140006', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('2', '2017-12-08 15:25:13', 'haowenju@redoop.com', '221916', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('3', '2017-12-08 15:46:25', '787501374@qq.com', '274433', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('4', '2017-12-25 22:59:42', 'tongxiaojun@redoop.com', '114737', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('5', '2018-01-05 15:47:49', 'pangxinyou@redoop.com', '385369', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('6', '2018-01-05 16:50:20', 'niuhaisheng@redoop.com', '348850', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('7', '2018-01-05 17:00:24', 'zhangxing@redoop.com', '580595', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('8', '2018-01-08 10:12:20', 'sundafei@redoop.com', '807650', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('9', '2018-01-08 10:15:48', 'xingweidong@redoop.com', '152288', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('10', '2018-01-08 10:17:03', 'niuxin@redoop.com', '359770', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('11', '2018-01-08 11:00:01', 'wangchunli@redoop.com', '512312', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('12', '2018-01-08 11:21:57', 'sunweijian@redoop.com', '554548', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('13', '2018-01-08 16:21:03', 'zhaoshuai@redoop.com', '897090', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('14', '2018-01-09 16:13:27', 'sulongfei@redoop.com', '248278', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('15', '2018-01-10 08:40:16', 'liuxin@redoop.com', '790339', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('16', '2018-01-10 09:28:40', 'panbo@redoop.com', '485145', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('17', '2018-01-11 11:29:13', 'HTH_SWP@163.com', '763927', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('18', '2018-01-25 10:19:03', 'houjinxia@redoop.com', '261086', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('19', '2018-01-25 10:23:42', 'songxiaolei@redoop.com', '680210', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('20', '2018-01-26 10:16:37', 'mazeteng@redoop.com', '920727', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('21', '2018-01-26 11:27:03', 'wangchunli@redoop.com', 'e71b6e1bf0364a26b3cb4dc90990c8fa', '1', '1');
INSERT INTO `tbl_validate_code` VALUES ('22', '2018-02-05 16:57:07', 'mazeteng@redoop.com', '0e38a33b8cdf4096b79499f34f97dcc8', '0', '1');
INSERT INTO `tbl_validate_code` VALUES ('23', '2018-02-05 16:57:13', 'mazeteng@redoop.com', '572b6af138e94588b82c05eb30febb56', '1', '1');
INSERT INTO `tbl_validate_code` VALUES ('24', '2018-02-25 17:05:59', 'songxiaolei@redoop.com', '9617bb82f0044c578e490642755540cc', '0', '1');
INSERT INTO `tbl_validate_code` VALUES ('25', '2018-02-25 17:06:22', 'songxiaolei@redoop.com', 'b534ad544e1d4b63866e8d20a66a74de', '0', '1');
INSERT INTO `tbl_validate_code` VALUES ('26', '2018-02-25 17:30:59', 'songxiaolei@redoop.com', '2ac5de969cee46d9b0fe60284d904492', '0', '1');
INSERT INTO `tbl_validate_code` VALUES ('27', '2018-02-26 09:01:19', 'wangyabin@redoop.com', '543321', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('28', '2018-02-26 09:05:08', 'wangyabin@redoop.com', '130275', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('29', '2018-02-26 09:05:37', 'wangyabin@redoop.com', '993394', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('30', '2018-02-26 09:08:09', 'wangyabin@redoop.com', '357929', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('31', '2018-02-26 09:09:12', 'wangyabin@redoop.com', '352806', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('32', '2018-02-26 09:11:27', 'wangyabin@redoop.com', '280426', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('33', '2018-02-26 09:17:51', 'songxiaolei@redoop.com', 'e15b98792b8b4b14b080eb8487c0ecaf', '0', '1');
INSERT INTO `tbl_validate_code` VALUES ('34', '2018-02-26 09:23:02', 'songxiaolei@redoop.com', 'a430764a2e804cafa5a5cf8926b6108c', '0', '1');
INSERT INTO `tbl_validate_code` VALUES ('35', '2018-02-26 13:54:59', 'wangyabin@redoop.com', '225127', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('36', '2018-02-27 09:06:54', 'wangyabin@redoop.com', '606847', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('37', '2018-02-27 09:09:09', 'wangyabin@redoop.com', '651252', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('38', '2018-02-27 09:12:19', 'wangyabin@redoop.com', '966533', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('39', '2018-02-27 09:20:45', '787501374@qq.com', '981808', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('40', '2018-02-27 09:44:26', '787501374@qq.com', '914466', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('41', '2018-02-27 09:45:07', '787501374@qq.com', '910904', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('42', '2018-02-27 09:45:45', '787501374@qq.com', '329832', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('43', '2018-02-27 09:46:06', 'wangyabin@redoop.com', '317956', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('44', '2018-02-27 09:49:47', 'wangyabin@redoop.com', '172151', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('45', '2018-02-27 09:50:14', 'wangyabin@redoop.com', '230571', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('46', '2018-02-27 10:25:46', 'wangyabin@redoop.com', '790156', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('47', '2018-02-27 10:37:24', 'wangyabin@redoop.com', '784061', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('48', '2018-02-27 10:44:00', 'wangyabin@redoop.com', '443214', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('49', '2018-02-27 15:39:28', '787501374@qq.com', '977a937c47244ed791365b9c78c58bc8', '0', '1');
INSERT INTO `tbl_validate_code` VALUES ('50', '2018-03-02 10:10:15', 'hth_swp@163.com', '4cfa34189b7a4011b97a610c853f3817', '1', '1');
INSERT INTO `tbl_validate_code` VALUES ('51', '2018-03-04 05:30:35', '747146282@qq.com', '918990', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('52', '2018-03-06 15:03:10', 'leixianp@163.com', '227232', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('53', '2018-03-07 15:46:07', '2993001710@qq.com', '752548', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('54', '2018-03-14 16:28:11', 'guoxiaopei@redoop.com', '140409', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('55', '2018-03-16 13:50:15', 'silver@163.com', '538448', '0', '2');
INSERT INTO `tbl_validate_code` VALUES ('56', '2018-04-25 08:50:26', 'haowenju@redoop.com', '786d09bf90bb42fc8681bfb28c336b67', '1', '1');
INSERT INTO `tbl_validate_code` VALUES ('57', '2018-09-26 18:31:32', '303064157@qq.com', '480399', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('58', '2018-11-02 11:11:24', '526107212@qq.com', '335619', '1', '2');
INSERT INTO `tbl_validate_code` VALUES ('59', '2019-02-26 16:15:29', 'huangtianhao@redoop.com', '4d9bbbfa465c4fc38e518cd8f5166908', '1', '1');

-- ----------------------------
-- Table structure for tbl_weibo
-- ----------------------------
DROP TABLE IF EXISTS `tbl_weibo`;
CREATE TABLE `tbl_weibo` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime NOT NULL,
  `member_id` int(11) NOT NULL,
  `type` int(11) DEFAULT '0' COMMENT '0为普通文本,1为图片',
  `content` varchar(1000) DEFAULT NULL,
  `favor` int(11) DEFAULT '0' COMMENT '赞',
  `status` tinyint(11) DEFAULT '0' COMMENT '0未审核，1已审核，-1审核不通过',
  PRIMARY KEY (`id`),
  KEY `fk_weibo_member` (`member_id`) USING BTREE,
  CONSTRAINT `tbl_weibo_ibfk_1` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_weibo
-- ----------------------------

-- ----------------------------
-- Table structure for tbl_weibo_comment
-- ----------------------------
DROP TABLE IF EXISTS `tbl_weibo_comment`;
CREATE TABLE `tbl_weibo_comment` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime NOT NULL,
  `member_id` int(11) NOT NULL DEFAULT '0',
  `weibo_id` int(11) NOT NULL DEFAULT '0',
  `comment_id` int(11) DEFAULT NULL COMMENT '评论的id',
  `content` varchar(1000) DEFAULT NULL,
  `status` int(11) DEFAULT '0' COMMENT '0正常，1禁用',
  PRIMARY KEY (`id`),
  KEY `fk_weibo_comment_member` (`member_id`) USING BTREE,
  KEY `fk_weibo_comment_weibo` (`weibo_id`) USING BTREE,
  CONSTRAINT `tbl_weibo_comment_ibfk_1` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_weibo_comment_ibfk_2` FOREIGN KEY (`weibo_id`) REFERENCES `tbl_weibo` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_weibo_comment
-- ----------------------------

-- ----------------------------
-- Table structure for tbl_weibo_favor
-- ----------------------------
DROP TABLE IF EXISTS `tbl_weibo_favor`;
CREATE TABLE `tbl_weibo_favor` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `weibo_id` int(11) DEFAULT '0',
  `member_id` int(11) DEFAULT '0',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_weibo_id_member_id` (`weibo_id`,`member_id`) USING BTREE,
  KEY `fk_weibo_favor_member` (`member_id`) USING BTREE,
  CONSTRAINT `tbl_weibo_favor_ibfk_1` FOREIGN KEY (`member_id`) REFERENCES `tbl_member` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `tbl_weibo_favor_ibfk_2` FOREIGN KEY (`weibo_id`) REFERENCES `tbl_weibo` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tbl_weibo_favor
-- ----------------------------
